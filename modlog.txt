MODAL LOGICCambridge Tracts in Theoretical Computer Science
Editorial Board
S. Abramsky, Computer Laboratory, Oxford University
P. H. Aczel, Department of Computer Science, University of Manchester
J. W. de Bakker, Centrum voor Wiskunde en Informatica, Amsterdam
Y. Gurevich, Microsoft Research
J. V. Tucker, Department of Mathematics and Computer Science, University College of Swansea
Titles in the series
1.
2.
3.
5.
6.
7.
8.
9.
10.
11.
12.
14.
15.
17.
18.
19.
21.
22.
23.
26.
27.
28.
29.
30.
31.
32.
33.
34.
35.
36.
37.
38.
39.
40.
41.
42.
43.
44.
45.
46.
47.
48.
49.
51.
52.
53.
G. Chaitin Algorithmic Information Theory
L. C. Paulson Logic and Computation
M. Spivey Understanding Z
A. Ramsey Formal Methods in Artiﬁcial Intelligence
S. Vickers Topology via Logic
J.-Y. Girard, Y. Lafont & P. Taylor Proofs and Types
J. Cliﬀord Formal Semantics & Progmatics for Natural Language Processing
M. Winslett Updating Logical Databases
K. McEvoy & J. V. Tucker (eds) Theoretical Foundations of VLSI Design
T. H. Tse A Unifying Framework for Structured Analysis and Design Models
G. Brewka Nonmonotonic Reasoning
S. G. Hoggar Mathematics for Computer Graphics
S. Dasgupta Design Theory and Computer Science
J. C. M. Baeten (ed) Applications of Process Algebra
J. C. M. Baeten & W. P. Weijland Process Algebra
M. Manzano Extensions of First Order Logic
D. A. Wolfram The Clausal Theory of Types
V. Stoltenberg-Hansen, I. Lindström & E. Griﬀor Mathematical Theory of Domains
E.-R. Olderog Nets, Terms and Formulas
P. D. Mosses Action Semantics
W. H. Hesselink Programs, Recursion and Unbounded Choice
P. Padawitz Deductive and Declarative Programming
P. Gärdenfors (ed) Belief Revision
M. Anthony & N. Biggs Computational Learning Theory
T. F. Melham Higher Order Logic and Hardware Veriﬁcation
R. L. Carpenter The Logic of Typed Feature Structures
E. G. Manes Predicate Transformer Semantics
F. Nielson & H. R. Nielson Two Level Functional Languages
L. Feijs & H. Jonkers Formal Speciﬁcation and Design
S. Mauw & G. J. Veltink (eds) Algebraic Speciﬁcation of Communication Protocols
V. Stavridou Formal Methods in Circuit Design
N. Shankar Metamathematics, Machines and Gödel’s Proof
J. B. Paris The Uncertain Reasoner’s Companion
J. Dessel & J. Esparza Free Choice Petri Nets
J.-J. Ch. Meyer & W. van der Hoek Epistemic Logic for AI and Computer Science
J. R. Hindley Basic Simple Type Theory
A. Troelstra & H. Schwichtenberg Basic Proof Theory
J. Barwise & J. Seligman Information Flow
A. Asperti & S. Guerrini The Optimal Implementation of Functional Programming Languages
R. M. Amadio & P.-L. Curien Domains and Lambda-Calculi
W.-P. de Roever & K. Engelhardt Data Reﬁnement
H. Kleine Büning & T. Lettman Propositional Logic
L. Novak & A. Gibbons Hybrid Graph Theory and Network Analysis
H. Simmons Derivation and Computation
A. S. Troelstra & H. Schwictenberg Basic Proof Theory (Second Edition)
P. Blackburn, M. de Rijke & Y. Venema Modal LogicModal Logic
Patrick Blackburn
LORIA, Nancy
Maarten de Rijke
University of Amsterdam
Yde Venema
University of Amsterdamcambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town,
Singapore, São Paulo, Delhi, Tokyo, Mexico City
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by
Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9780521527149
© Cambridge University Press 2001
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2001
First paperback edition 2002
Fourth printing with corrections 2010
A catalogue record for this publication is available from the British Library
Library of Congress Cataloguing in Publication data
Blackburn, Patrick, 1959-
Modal logic / Patrick Blackburn, Maarten de Rijke, Yde Venema.
p. cm.
Includes bibliographical references and index.
ISBN 0 521 80200 8
1. Modality (Logic). I. Rijke, Maarten de. II. Venema, Yde, 1963- III. Title.
QA9.46.B58 2001
511.3 21-dc21 00-054667
isbn 978-0-521-80200-0 Hardback
isbn 978-0-521-52714-9 Paperback
Cambridge University Press has no responsibility for the persistence or
accuracy of URLs for external or third-party internet websites referred to in
this publication, and does not guarantee that any content on such websites is,
or will remain, accurate or appropriate. Information regarding prices, travel
timetables, and other factual information given in this work is correct at
the time of first printing but Cambridge University Press does not guarantee
the accuracy of such information thereafter.For JohanContents
Preface
1
1.1
1.2
1.3
1.4
1.5
1.6
1.7
1.8
page xi
1
2
9
16
28
31
33
37
48
Basic Concepts
Relational Structures
Modal Languages
Models and Frames
General Frames
Modal Consequence Relations
Normal Modal Logics
Historical Overview
Summary of Chapter 1
2
Models
2.1 Invariance Results
2.2 Bisimulations
2.3 Finite Models
2.4 The Standard Translation
2.5 Modal Saturation via Ultraﬁlter Extensions
2.6 Characterization and Deﬁnability
2.7 Simulation and Safety
2.8 Summary of Chapter 2
Notes50
51
64
73
83
91
100
110
117
118
3
3.1
3.2
3.3
3.4
3.5
3.6
3.7123
124
130
138
143
148
156
167
Frames
Frame Deﬁnability
Frame Deﬁnability and Second-Order Logic
Deﬁnable and Undeﬁnable Properties
Finite Frames
Automatic First-Order Correspondence
Sahlqvist Formulas
More about Sahlqvist Formulas
viiContents
viii
3.8 Advanced Frame Theory
3.9 Summary of Chapter 3
Notes178
183
185
4
Completeness
4.1 Preliminaries
4.2 Canonical Models
4.3 Applications
4.4 Limitative Results
4.5 Transforming the Canonical Model
4.6 Step by Step
4.7 Rules for the Undeﬁnable
4.8 Finitary Methods I
4.9 Finitary Methods II
4.10 Summary of Chapter 4
Notes188
189
196
201
211
217
223
229
239
247
256
258
5
Algebras and General Frames
5.1 Logic as Algebra
5.2 Algebraizing Modal Logic
5.3 The Jónsson-Tarski Theorem
5.4 Duality Theory
5.5 General Frames
5.6 Persistence
5.7 Summary of Chapter 5
Notes261
262
275
283
294
303
318
326
327
6
Computability and Complexity
6.1 Computing Satisﬁability
6.2 Decidability via Finite Models
6.3 Decidability via Interpretations
6.4 Decidability via Quasi-models and Mosaics
6.5 Undecidability via Tiling
6.6 NP
6.7 PSPACE
6.8 EXPTIME
6.9 Summary of Chapter 6
Notes332
333
338
347
356
364
373
381
393
406
407
7
7.1
7.2
7.3
7.4413
414
426
434
446
Extended Modal Logic
Logical Modalities
Since and Until
Hybrid Logic
The Guarded FragmentContentsix
7.5 Multi-Dimensional Modal Logic
7.6 A Lindström Theorem for Modal Logic
7.7 Summary of Chapter 7
Notes458
470
476
477
Appendix AA Logical Toolkit485
Appendix BAn Algebraic Toolkit497
Appendix CA Computational Toolkit504
Appendix DA Guide to the Literature516
Bibliography
List of Notation524
544
Index547Preface
Ask three modal logicians what modal logic is, and you are likely to get at least
three different answers. The authors of this book are no exception, so we will not
try to start off with a neat deﬁnition. Nonetheless, a number of general ideas guide
our thinking about the subject, and we will present the most important right away
as a series of three slogans. These are meant to be read now, and, perhaps more
importantly, referred back to occasionally; doing so will help you obtain a ﬁrm
grasp of the ideas and intuitions that have shaped this book. Following the slogans
we will discuss the aims and content of the book in more detail.
Our ﬁrst slogan is the simplest and most fundamental. It sets the basic theme on
which the others elaborate:
Slogan 1: Modal languages are simple yet expressive languages for talk-
ing about relational structures.
In this book we will be examining various propositional modal languages: that is,
the familiar language of propositional logic augmented by a collection of modal
operators. Like the familiar boolean connectives (¬, ∧, ∨, →, ⊥, and ), modal
operators do not bind variables. Thus, as far as syntax is concerned, we will be
working with the simplest non-trivial languages imaginable.
But in spite of their simplicity, propositional modal languages turn out to be an
excellent way of talking about relational structures, and this book is essentially an
attempt to map out some of the ramiﬁcations of this. For a start, it goes a long
way towards explaining the recent popularity of modal languages in applied logic.
Moreover, it introduces one of the fundamental themes in the mathematical study
of modal logic: the use of relational structures (that is, relational semantics, or
Kripke semantics) to explicate the logical structure of modal systems.
A relational structure is simply a set together with a collection of relations on
that set. Given the broad nature of this deﬁnition, it is unsurprising that relational
structures are to be found just about everywhere. Virtually all familiar mathe-
xixii
Preface
matical structures can be thought of as relational structures. Moreover, the enti-
ties commonly used to model the phenomena of interest in various applications
often turn out to be relational structures. For example, theoretical computer sci-
entists use labeled transition systems to model program execution, but a labeled
transition system is just a set (the states) together with a collection of binary re-
lations (the transition relations) that model the behavior of programs. Moreover,
relational structures play a fundamental modeling role in many other disciplines,
including knowledge representation, computational linguistics, formal semantics,
economics, and philosophy. As modal languages are the simplest languages in
which relational structures can be described, constrained, and reasoned about, it is
hardly surprising that applied modal logic has blossomed in recent years.
But relational structures have also played a fundamental role in the development
of the mathematics of modal logic: their use turned modal logic from a rather
esoteric branch of syntax manipulation into a concrete and intuitively compelling
ﬁeld. In fact, it is difﬁcult to overstate the importance of relational models to modal
logic: their discovery in the 1950s and early 1960s was the biggest single impetus
to the development of the ﬁeld. An early application was completeness theory, the
classiﬁcation of modal logics in relational terms. More recently, relational seman-
tics has played an important role in mapping out the computational complexity of
modal systems.
Modal languages may be simple – but what makes them special? Our next slogan
tries to pin this down:
Slogan 2: Modal languages provide an internal, local perspective on rela-
tional structures.
That is, modal languages talk about relational structures in a special way: ‘from
the inside’ and ‘locally.’ Rather than standing outside a relational structure and
scanning the information it contains from some celestial vantage point, modal for-
mulas are evaluated inside structures, at a particular state. The function of the
modal operators is to permit the information stored at other states to be scanned
– but, crucially, only the states accessible from the current point via an appropri-
ate transition may be accessed in this way. This idea will be made precise in the
following chapter when we deﬁne the satisfaction deﬁnition. In the meantime, the
reader who pictures a modal formula as a little automaton standing at some state in
a relational structure, and only permitted to explore the structure by making jour-
neys to neighboring states, will have grasped one of the key intuitions of modal
model theory.
The internal perspective modal languages offer makes them natural for many
applications. For a start, the decidability of many important modal systems stems
from the step-by-step way that modal formulas are evaluated. Moreover, in a num-Preface
xiii
ber of disciplines, simple languages offering an internal perspective on relational
structures have been devised; sometimes these (independently invented) systems
turn out to be variants of well-known modal systems, and can be analyzed using
modal techniques. For example, Kasper-Rounds logic (used in computational lin-
guistics) is essentially a natural notation for a certain fragment of propositional
dynamic logic with intersection, and many of the description logics used in knowl-
edge representation can be usefully viewed as (fragments of) modal languages.
Finally, it is also the stepwise way in which modal formulas are evaluated which
explains why the notion of bisimulation, a crucial tool in the process theoretic study
of labeled transition systems, unlocks the door to important characterizations of
modal expressivity.
So far there have been only two characters in this discussion: modal languages and
the structures which interpret them. Now it is certainly true that for much of its
history modal logic was studied in isolation, but the true richness of the subject
only becomes apparent when one adopts a broader perspective. Accordingly, the
reader should bear in mind that:
Slogan 3: Modal languages are not isolated formal systems.
One of the key lessons to have emerged since about 1970 is that it is fruitful to
systematically explore the way modal logic is related to other branches of math-
ematical logic. In the pair MODAL LANGUAGES, RELATIONAL STRUCTURES,
there are two obvious variations that should be considered: the relationships with
other languages for describing relational structures, and the use of other kinds of
structures for interpreting modal languages.
As regards the ﬁrst option, there are many well-known alternative languages
for talking about relational structure: most obviously, ﬁrst- or second-order clas-
sical languages. And indeed, every modal language has corresponding classical
languages that describe the same class of structures. But although both modal
and classical languages talk about relational structures, they do so very differently.
Whereas modal languages take an internal perspective, classical languages, with
their quantiﬁers and variable binding, are the prime example of how to take an
external perspective on relational structures. In spite of this, there is a standard
translation of any modal language into its corresponding classical language. This
translation provides a bridge between the worlds of modal and classical logic, en-
abling techniques and results to be imported and exported. The resultant study is
called correspondence theory, and it is a cornerstone of modern modal logic.
In the most important example of the second variation, modal logic is linked
up with universal algebra via the apparatus of duality theory. In this framework,
modal formulas are viewed as algebraic terms which have a natural algebraic se-
mantics in terms of boolean algebras with operators, and, from this perspective,xiv
Preface
modal logic is essentially the study of certain varieties of equational logic. Now,
even in isolation, this algebraic perspective is of interest – but what makes it a
truly formidable tool is the way it interacts with the perspective provided by re-
lational structures. Roughly speaking, relational structures can be constructed out
of algebras, and algebras can be constructed out of relational structures, and both
constructions preserve essential logical properties. The key technical result that
underlies this duality is the Jónsson-Tarski Theorem, a Stone-like representation
theorem for boolean algebras with operators. This opens the door to the world of
universal algebra and, as we will see, the powerful techniques to be found there
lend themselves readily to the analysis of modal logic.
Slogan 3 is fundamental to the way the material in this book is developed: modal
logic will be systematically linked to the wider logical world by both correspon-
dence and duality theory. We do not view modal logic as a ‘non-classical logic’
that studies ‘intensional phenomena’ via ‘possible world semantics.’ This is one
interpretation of the machinery we will discuss – but the real beauty of the subject
lies deeper.
Let us try and summarize our discussion. Modal languages are syntactically sim-
ple languages that provide an internal perspective on relational structures. Because
of their simplicity, they are becoming increasingly popular in a number of appli-
cations. Moreover, modal logic is surprisingly mathematically rich. This richness
is due to the intricate interplay between modal languages and the relational struc-
tures that interpret them. At its most straightforward, the relational interpretation
gives us a natural semantic perspective from which to attack problems directly.
But the interplay runs deeper. By adopting the perspective of correspondence the-
ory, modal logic can be regarded as a fragment of ﬁrst- or second-order classical
logic. Moreover, by adopting an algebraic perspective, we obtain a different (and
no less classical) perspective: modal logic as equational logic. The fascination of
modal logic ultimately stems from the (still not fully understood) links between
these perspectives.
What this book is about
This book is a course in modal logic, intended for both novices and more experi-
enced readers, that presents modal logic as a powerful and ﬂexible tool for working
with relational structures. It provides a thorough grounding in the basic relational
perspective on modal logic, and applies this perspective to issues in completeness,
computability, and complexity. In addition, it introduces and develops in some
detail the perspectives provided by correspondence theory and algebra.
This much is predictable from our earlier discussion. However, three additional
desiderata have helped shape the book. First, we have attempted to emphasize thePreface
xv
ﬂexibility of modal logic as a tool for working with relational structures. One still
encounters with annoying frequency the view that modal logic amounts to rather
simple-minded uses of two operators 3 and . This view has been out of date at
least since the late 1960s (say, since Hans Kamp’s expressive completeness result
for since/until logic, to give a signiﬁcant, if arbitrary, example), and in view of such
developments as propositional dynamic logic and arrow logic it is now hopelessly
anachronistic and unhelpful. We strongly advocate a liberal attitude in this book:
we switch freely between various modal languages and in the ﬁnal chapter we
introduce a variety of further ‘upgrades.’ And as far as we are concerned, it is all
just modal logic.
Second, two pedagogic goals have shaped the writing and selection of material:
we want to explicate a range of proof techniques which we feel are signiﬁcant and
worth mastering, and, where appropriate, we want to draw attention to some impor-
tant general results. These goals are pursued fairly single mindedly: on occasion,
a single result may be proved by a variety of methods, and every chapter (except
the following one) proves at least one very general and (we hope) very interesting
result. The reader looking for a catalogue of facts about his or her favorite modal
system probably will not ﬁnd it here. But such a reader may well ﬁnd the technique
needed to algebraize it, to analyze its expressive power, to prove a completeness
result, or to establish its decidability or undecidability – and may even discover
that the relevant results are a special case of something known.
Finally, contemporary modal logic is profoundly inﬂuenced by its applications,
particularly in theoretical computer science. Indeed, some of the most interesting
advances in the subject (for example, the development of propositional dynamic
logic, and the investigation of modal logic from a complexity-theoretic standpoint)
were largely due to computer scientists, not modal logicians. Such inﬂuences must
be acknowledged and incorporated, and we attempt to do so.
What this book is not about
Modal logic is a broad ﬁeld, and inevitably we have had to leave out a lot of in-
teresting material, indeed whole areas of active research. There are two principle
omissions: there is no discussion of ﬁrst-order modal systems or of non-Hilbert-
style proof theory and automated reasoning techniques.
The ﬁrst omission is relatively easy to justify. First-order modal logic is an en-
terprise quite distinct from the study of propositional systems: its principle concern
is how best to graft together classical logic and propositional modal logic. It is an
interesting ﬁeld, and one in which there is much current activity, but its concerns
lie outside the scope of this book.
The omission of proof theory and automated reasoning techniques calls for a
little more explanation. A considerable proportion of this book is devoted to com-xvi
Preface
pleteness theory and its algebraic ramiﬁcations; however, as is often the case in
modal logic, the proof systems discussed are basically Hilbert-style axiomatic sys-
tems. There is no discussion of natural deduction, sequent calculi, labeled deduc-
tive systems, resolution, or display calculi. A (rather abstract) tableaux system is
used once, but only as a tool to prove a complexity result. In short, there is little
in this book that a proof theorist would regard as real proof theory, and nothing
on implementation. Why is this? Essentially because modal proof theory and au-
tomated reasoning are still relatively youthful enterprises; they are exciting and
active ﬁelds, but as yet there is little consensus about methods and few general re-
sults. Moreover, these ﬁelds are moving fast; much that is currently regarded as
state of the art is likely to go rapidly out of date. For these reasons we have decided
– rather reluctantly – not to discuss these topics.
In addition to these major areas, there are a host of more local omissions. One
is provability and interpretability logic. While these are fascinating examples of
how modal logical ideas can be applied in mathematics, the principle interest of
these ﬁelds is not modal logic itself (which is simply used as a tool) but the formal
study of arithmetic: a typical introduction to these topics (and several excellent
ones exist, for example Boolos [68, 69], and Smoryński [416]) is typically about
ten percent modal and ninety percent arithmetical. A second omission is a topic
that is a traditional favorite of modal logicians: the ﬁne structure of the lattice of
normal modal logics in the basic 3 and 2 language; we conﬁne ourselves in this
book to the relatively easy case of logics extending S4.3. The reader interested in
learning more about this type of work should consult Bull and Segerberg [75] or
Chagrov and Zakharyaschev [88]. Other omissions we regret include: a discussion
of meta-logical properties such as interpolation, a detailed examination of local
versus global consequence, and an introduction to the modal μ-calculus and model
checking. Restrictions of space and time made their inclusion impossible.
Audience and prerequisites
The book is aimed at people who use or study modal logic, and more generally,
at people working with relational structures. We hope that the book will be of use
to two distinct audiences: a less experienced audience, consisting of students of
logic, computer science, artiﬁcial intelligence, philosophy, linguistics, and other
ﬁelds where modal logic and relational structures are of importance, and a more
experienced audience consisting of colleagues working in one or more of the above
research areas who would like to learn and apply modal logic in their own area.
To this end, there are two distinct tracks through this book: the basic track (this
consists of selected sections from each chapter, and will be described shortly) and
an advanced track (that is, the entire book).
The book starts at the beginning, and does not presuppose prior acquaintancePreface
xvii
with modal logic; but, even on the basic track, prior acquaintance with ﬁrst-order
logic and its semantics is essential. Furthermore, the development is essentially
mathematical and assumes that the reader is comfortable with such things as sets,
functions, relations and so on, and can follow mathematical argumentation, such
as proofs by induction. In addition, although we have tried to make the basic track
material as self-contained as possible, two of the later chapters probably require a
little more background knowledge than this. In particular, a reader who has never
encountered boolean (or some other) algebras before is likely to ﬁnd Chapter 5
hard going, and the reader who has never encountered the concept of computable
and uncomputable problems will ﬁnd Chapter 6 demanding. That said, only a
relatively modest background knowledge in these areas is required to follow the
basic track material; certainly the main thrust of the development should be clear.
The requisite background material in logic, algebra and computability can be found
in Appendices A, B, and C.
Needless to say, we have also tried to make the advanced track material as read-
able and understandable as possible. However, largely because of the different
kinds of background knowledge required in different places, advanced track read-
ers may sometimes need to supplement this book with a background reading in
model theory, universal algebra or computational complexity. Again, the required
material is sketched in the appendices.
Contents
The chapter-by-chapter breakdown of the material is as follows.
Chapter 1. Basic Concepts. This chapter introduces a number of key modal lan-
guages (namely the basic modal language, modal languages of arbitrary similarity
type, the basic temporal language, the language of propositional dynamic logic,
and arrow languages), and shows how they are interpreted on various kinds of re-
lational structures (namely models, frames and general frames). It also establishes
notation, discusses some basic concepts such as satisfaction, validity, logical con-
sequence and normal modal logics, and places them in historical perspective. The
entire chapter is essentially introductory; all sections lie on the basic track.
Chapter 2. Models. This chapter examines modal languages as tools for talking
about models. In the ﬁrst ﬁve sections we prove some basic invariance results,
introduce bisimulations, discuss the use of ﬁnite models, and, by describing the
standard translation, initiate the study of correspondence theory. All ﬁve sections
are fundamental to later developments – indeed the sections on bisimulations and
the standard translation are among the most important in the entire book – and to-
gether they constitute the basic track selection. The remaining two sections are on
the advanced track. They probe the expressive power of modal languages usingxviii
Preface
ultraﬁlter extensions, ultraproducts, and saturated models; establish the fundamen-
tal role of bisimulations in correspondence theory; and introduce the concepts of
simulation and safety.
Chapter 3. Frames. This chapter examines modal languages as tools for talk-
ing about frames; all sections, save the very last, lie on the basic track. The ﬁrst
three sections develop the basic theory of frame correspondence: we give exam-
ples of frame deﬁnability, show that relatively simple modal formulas can deﬁne
frame conditions beyond the reach of any ﬁrst-order formula (and explain why
this happens), and introduce the concepts needed to state the celebrated Goldblatt-
Thomason Theorem. After a short fourth section which discusses ﬁnite frames, we
embark on the study of the Sahlqvist fragment. This is a large class of formulas,
each of which corresponds to a ﬁrst-order frame condition, and we devote three
sections to it. In the ﬁnal (advanced) section we introduce some further frame
constructions and prove the Goldblatt-Thomason Theorem model theoretically.
Chapter 4. Completeness. This chapter has two parts; all sections, save the very
last, lie on the basic track. The ﬁrst part, consisting of the ﬁrst four sections, is an
introduction to basic completeness theory (including canonical models, complete-
ness-via-canonicity proofs, canonicity failure, and incompleteness). The second
part is a survey of methods that can be used to show completeness when canonic-
ity fails. We discuss transformation methods, the step-by-step technique, the use
of rules for the undeﬁnable, and devote the ﬁnal two sections to a discussion of
ﬁnitary methods. The ﬁrst of these sections proves the completeness of Proposi-
tional Dynamic Logic (PDL). The second (the only section on the advanced track)
examines extensions of S4.3, proving (among other things) Bull’s Theorem.
Chapter 5. Algebras and General Frames. The ﬁrst three sections lie on the basic
track: we discuss the role of algebra in logic, show how algebraic ideas can be
applied to modal logic via boolean algebras with operators, and then prove the
fundamental Jónsson-Tarski Theorem. With the basics thus laid we turn to duality
theory, which soon leads us to an algebraic proof of the Goldblatt-Thomason The-
orem (which was proved model theoretically in Chapter 3). In the two remaining
sections (which lie on the advanced track) we discuss general frames from an al-
gebraic perspective, introduce the concept of persistence (a generalization of the
idea of canonicity) and use it to prove the Sahlqvist Completeness Theorem, the
completeness-theoretic twin of the correspondence result proved in Chapter 3.
Chapter 6. Computability and Complexity. This chapter has two main parts. The
ﬁrst, comprising the ﬁrst ﬁve sections, is an introduction to decidability and un-
decidability in modal logic. We introduce the basic ideas involved in computing
modal satisﬁability and validity problems, and then discuss three ways of proving
decidability results: the use of ﬁnite models, the method of interpretations, andPreface
xix
the use of quasi-models and mosaics. The ﬁfth section gives two simple exam-
ples which illustrate how easily undecidable – and indeed, highly undecidable –
modal logics can arise. All of the ﬁrst part lies on the basic track. The remaining
three sections examine modal logic from the perspective of computational com-
plexity. In particular, the modal relevance of three central complexity classes (NP,
PSPACE, and EXPTIME) is discussed in some detail. We pay particular attention
to PSPACE, proving Ladner’s general PSPACE-hardness result in detail. These
sections lie on the advanced track, but this is partly because computational com-
plexity is likely to be a new subject for some readers. The material is elegant and
interesting, and we have tried to make these sections as self-contained and acces-
sible as possible.
Chapter 7. Extended Modal Logic. This chapter has a quite different ﬂavor from
the others: it is essentially the party at the end of the book in which we talk about
some of our favorite examples of extended modal systems. We will not offer any
advice about what to read here – simply pick and choose and enjoy. The topics
covered are: boosting the expressive power of modal languages with the aid of log-
ical modalities, completeness-via-completeness proofs in since/until logic, naming
states with the help of hybrid logics, and performing evaluation at sequences of
states in multi-dimensional modal logic. We also show how to export modal ideas
back to ﬁrst-order logic by deﬁning the guarded fragment, and conclude by proving
a Lindström Theorem for modal logic.
Nearly all sections end with exercises. Each chapter starts with a chapter guide out-
lining the main themes of the sections that follow. Moreover, each chapter ﬁnishes
with a summary, and – except the ﬁrst – with a section entitled Notes. These give
references for results discussed in the text. (In general we do not attribute results
in the text, though where a name has become ﬁrmly attached – for example, Bull’s
Theorem or Lindenbaum’s Lemma – we use it.) The Notes also give pointers to
relevant work not covered in the text. The ﬁnal section of Chapter 1 sketches the
history of modal logic, and Appendix D gives a brief guide to textbooks, survey
articles, and other material on modal logic.
Teaching the book
The book can be used as the basis for a number of different courses. Here are some
suggestions.
Modal Logic and Relational Structures. (1 Semester, 2 hours a week)
All of Chapter 1, all the basic track sections in Chapter 2, and all the basic track
sections in Chapter 3. This course introduces modal logic from a semantically ori-
ented perspective. It is not particularly technical (in fact, only Section 2.5 is likely
to cause any difﬁculties), and the student will come away with an appreciation ofxx
Preface
what modal languages are and the kind of expressivity they offer. It is deliberately
one-sided – it is intended as an antidote to traditional introductions.
An Introduction to Modal Logic. (1 Semester, 4 hours a week)
All of Chapter 1, all the basic track material in Chapter 2, the ﬁrst six or seven
sections of Chapter 3, the ﬁrst six or seven sections of Chapter 4, and the ﬁrst four
sections of Chapter 6. In essence, this course adds to the previous one the contents
of a traditional introduction to modal logic (namely completeness-via-canonical
models, and decidability-via-ﬁltrations) and includes extra material on decidability
which we believe should become traditional. This course gives a useful and fairly
balanced picture of many aspects of modern modal logic.
Modal Logic for Computer Scientists. (1 Semester, 4 hours a week)
All of Chapter 1, the ﬁrst four sections of Chapter 2, the ﬁrst four sections of
Chapter 3, the ﬁrst four sections of Chapter 4 plus Section 4.8 (completeness of
PDL), all of Chapter 6, and a selection of topics from Chapter 7. In our opinion,
this course is more valuable than the previous one, and in spite of its title it is not
just for computer science students. This course teaches basic notions of modal
expressivity (bisimulation, the standard translation, and frame deﬁnability), key
ideas on completeness (including incompleteness), covers both computability and
complexity, and will give the student an impression of the wide variety of options
available in modern modal logic. It comes close to our ideal of what a modern,
well-rounded introduction to modal logic should look like.
Mathematical Aspects of Modal Logic. (1 Semester, 4 hours a week)
Chapters 1, 2, and 3, the ﬁrst four sections of Chapter 4, and all of Chapter 5. If
you are teaching logicians, this is probably the course to offer. It is a demanding
course, and requires background knowledge in both model theory and algebra, but
we think that students with this background will like the way the story unfolds.
Modal Logic. (2 Semesters, 4 hours a week)
But of course, there is another option: teach the whole book. Given enough back-
ground knowledge and commitment, this is do-able in 2 semesters. Though we
should confess right away that the course’s title is highly misleading: once you
get to the end of the book, you will discover that far from having learned every-
thing about modal logic, you have merely arrived at the beginning of an unending
journey.
Hopefully these suggestions will spark further ideas. There is a lot of material
here, and by mixing and matching, perhaps combined with judicious use of other
sources (see Appendix D, the Guide to the Literature, for some suggestions), the
instructor should be able to tailor courses for most needs. The dependency diagram
(see Figure 1) will help your planning.Preface
xxi
1
2.1–2.5
3.7
2.6
2.7
3.1–3.6
3.8
4.1–4.8
5.6
5.5
5.1–5.4
4.9
6.1–6.5
6.6
6.7
6.8
7.1–7.6
Fig. 1. Dependency Diagram
Electronic support
We have set up a home page for this book, where we welcome feedback, and where
we will make selected solutions to the exercises and teaching materials available,
as well as any corrections that may need to be made. The URL is
http://www.mlbook.org
Acknowledgments
We want to thank the following colleagues for their helpful comments and useful
suggestions: Carlos Areces, Johan van Benthem, Giacomo Bonanno, Henry Chi-
naski, Jan van Eijck, Joeri Engelfriet, Paul Gochet, Rob Goldblatt, Val Goranko,
Ramon Jansana, Theo Janssen, Tim Klinger, Johan W. Klüwer, Alexander Kurz,
Holger Schlingloff, Moshe Vardi, and Rineke Verbrugge. Special thanks are due to
Maarten Marx who worked through earlier incarnations of Chapter 6 in great detail;
his comments transformed the chapter. We are grateful for the detailed comments
Ian Hodkinson made on a later version of this chapter. We are extremely grateful
to Costas Koutras for his extensive comments based on his experience of teaching
the book.
We had the good fortune of being able to try out (parts of) the material on stu-
dents in Amsterdam, Barcelona, Braga, Budapest, Cape Town, Chiba, Chia-Yi,
Johannesburg, Lisbon, Saarbrücken, Utrecht and Warwick. We want to thank all
our students, and in particular Maarten Stol, and the students of the University of
Amsterdam classes on modal logic of the years 1999–2001.xxii
Preface
We would like to thank our editor, David Tranah, for his support and advice, and
the anonymous referees for their valuable feedback. We are also extremely grateful
to our copy editor, who displayed amazing attention to detail in what (as we have
discovered) is a very difﬁcult task indeed.
We began the book when we were employed by the Netherlands Organization
for Scientiﬁc Research (NWO), project 102/62-356 ‘Structural and Semantic Par-
allels in Natural Languages and Programming Languages.’ We are grateful for
the ﬁnancial support by NWO. During the later stages of the writing we received
support from a variety of sources, for which we are extremely grateful. Patrick
Blackburn was based at the Department of Computational Linguistics at the Uni-
versity of Saarland. Maarten de Rijke was supported by the Spinoza project ‘Logic
in Action’ at ILLC, the University of Amsterdam, and by NWO under project
numbers 612-13-001, 365-20-005, 612.069.006, 612.000.106, 612.000.207, and
612.066.302. And Yde Venema was supported by a fellowship of the Royal Nether-
lands Academy of Arts and Sciences, and later, also by the Spinoza project ‘Logic
in Action.’ We also want to thank the Department of Mathematics and Computer
Science of the Free University in Amsterdam for the facilities they provided.
Concerning the second paperback printing
We made small corrections throughout the book, and more extensive changes to
Example 3.57 and Section 6.4, but the page numbering is essentially unaltered.
We are grateful to everyone who pointed out typos and errors in the ﬁrst print-
ing: Loredana Afanasiev, Fokko van de Bult, Seth Cable, Henry Chinaski, Rajeev
Goré, Helle Hansen, Philip Hölzenspies, Tanja Hötte, Dick de Jongh, Suvi Kar-
vonen, Clemens Kupke, Thomas Müller, Joshua Sacks, Thomas Schneider, Jerry
Seligman, Dmitry Shkatov, and Zhou Chunlai. Special thanks are due to Bernhard
Heinemann who went through the book very carefully and sent us long lists of ty-
pos.
Patrick Blackburn
Maarten de Rijke
Yde Venema1
Basic Concepts
Languages of propositional modal logic are propositional languages to which sen-
tential operators (usually called modalities or modal operators) have been added.
In spite of their syntactic simplicity, such languages turn out to be useful tools for
describing and reasoning about relational structures. A relational structure is a
non-empty set on which a number of relations have been deﬁned; they are wide-
spread in mathematics, computer science, artiﬁcial intelligence and linguistics, and
are also used to interpret ﬁrst-order languages.
Now, when working with relational structures we are often interested in struc-
tures possessing certain properties. Perhaps a certain transitive binary relation is
particularly important. Or perhaps we are interested in applications where ‘dead
ends,’ ‘loops,’ and ‘forkings’ are crucial, or where each relation is a partial func-
tion. Wherever our interests lie, modal languages can be useful, for modal oper-
ators are essentially a simple way of accessing the information contained in rela-
tional structures. As we will see, the local and internal access method that modali-
ties offer is strong enough to describe, constrain, and reason about many interesting
and important aspects of relational structures.
Much of this book is essentially an exploration and elaboration of these remarks.
The present chapter introduces the concepts and terminology we will need, and the
concluding section places them in historical context.
Chapter guide
Section 1.1: Relational Structures. Relational structures are deﬁned, and a num-
ber of examples are given.
Section 1.2: Modal Languages. We deﬁne the basic modal language and some of
its extensions.
Section 1.3: Models and Frames. Here we link modal languages and relational
structures. In fact, we introduce two levels at which modal languages can
be used to talk about structures: the level of models (which we explore
12
1 Basic Concepts
in Chapter 2) and the level of frames (which is examined in Chapter 3).
This section contains the fundamental satisfaction deﬁnition, and deﬁnes
the key logical notion of validity.
Section 1.4: General Frames. In this section we link modal languages and rela-
tional structures in yet another way: via general frames. Roughly speak-
ing, general frames provide a third level at which modal languages can be
used to talk about relational structures, a level intermediate between those
provided by models and frames. We will make heavy use of general frames
in Chapter 5.
Section 1.5: Modal Consequence Relations. Which conclusions do we wish to
draw from a given set of modal premises? That is, which consequence
relations are appropriate for modal languages? We opt for a local conse-
quence relation, though we note that there is a global alternative.
Section 1.6: Normal Modal Logics. Both validity and local consequence are de-
ﬁned semantically (that is, in terms of relational structures). However, we
want to be able to generate validities and draw conclusions syntactically.
We take our ﬁrst steps in modal proof theory and introduce Hilbert-style
axiom systems for modal reasoning. This motivates a concept of central
importance in Chapters 4 and 5: normal modal logics.
Section 1.7: Historical Overview. The ideas introduced in this chapter have a long
and interesting history. Some knowledge of this will make it easier to
understand developments in subsequent chapters, so we conclude with a
historical overview that highlights a number of key themes.
1.1 Relational Structures
Deﬁnition 1.1 A relational structure is a tuple F whose ﬁrst component is a non-
empty set W called the universe (or domain) of F, and whose remaining compo-
nents are relations on W . We assume that every relational structure contains at
least one relation. The elements of W have a variety of names in this book, includ-
ing: points, states, nodes, worlds, times, instants and situations.
An attractive feature of relational structures is that we can often display them as
simple pictures, as the following examples show.
Example 1.2 Strict partial orders (SPOs) are an important type of relational struc-
ture. A strict partial order is a pair (W, R) such that R is irreﬂexive (∀x ¬Rxx) and
transitive (∀xyz (Rxy∧Ryz → Rxz)). A strict partial order R is a linear order (or
a total order) if it also satisﬁes the trichotomy condition: ∀xy (Rxy∨x = y∨Ryx).
An example of an SPO is given in Figure 1.1, where W = {1, 2, 3, 4, 6, 8, 12, 24}
and Rxy means ‘x and y are different, and y can be divided by x.’ Obviously this is1.1 Relational Structures
3
24
@
@ 12
8
@
@
@ 6
4@
@
@
@3
2@
@
@
1
Fig. 1.1. A strict partial order
not a linear order. On the other hand, if we deﬁne Rxy by ‘x is numerically smaller
than y,’ we obtain a linear order over the same universe W . Important examples of
linear orders are (N, <), (Z, <), (Q, <) and (R, <), the natural numbers, integers,
rationals and reals in their usual order. We sometimes use the notation (ω, <) for
(N, <).
In many applications we want to work not with strict partial orders, but with
plain old partial orders (POs). We can think of a partial order as the reﬂexive
closure of a strict partial order; that is, if R is a strict partial order on W , then
R ∪ {(u, u) | u ∈ W } is a partial order (for more on reﬂexive closures, see Exer-
cise 1.1.3). Thus partial orders are transitive, reﬂexive (∀x Rxx) and antisymmetric
(∀xy (Rxy ∧ Ryx → x = y)). If a partial order is connected (∀xy (Rxy ∨ Ryx))
it is called a reﬂexive linear order (or a reﬂexive total order).
If we interpret the relation in Figure 1.1 reﬂexively (that is, if we take Rxy to
mean ‘x and y are equal, or y can be divided by x’) we have a simple example of
a partial order. Obviously, it is not a reﬂexive linear order. Important examples of
reﬂexive linear orders include (N, ≤) (or (ω, ≤)), (Z, ≤), (Q, ≤) and (R, ≤), the
natural numbers, integers, rationals and reals under their respective ‘less-than-or-
equal-to’ orderings.
Example 1.3 Labeled Transition Systems (LTSs), or more simply, transition sys-
tems, are a simple kind of relational structure widely used in computer science. An
LTS is a pair (W, {Ra | a ∈ A}) where W is a non-empty set of states, A is a non-
empty set (of labels), and for each a ∈ A, Ra ⊆ W × W . Transition systems can
be viewed as an abstract model of computation: the states are the possible states
of a computer, the labels stand for programs, and (u, v) ∈ Ra means that there is
an execution of the program a that starts in state u and terminates in state v. It is
natural to depict states as nodes and transitions Ra as directed arrows.
In Figure 1.2 a transition system with states w1 , w2 , w3 , w4 and labels a, b, c is
shown. Formally, Ra = {(w1 , w2 ), (w4 , w4 )}, while Rb = {(w2 , w3 )} and Rc =
{(w4 , w3 )}. This transition system is actually rather special, for it is deterministic:
if we are in a state where it is possible to make one of the three possible kinds of1 Basic Concepts
4
s
w1
a
w3
s
I
@
6
b @ c
@
4
@ws
-s
a
w2

Fig. 1.2. A deterministic transition system
transition (for example, an a transition) then it is ﬁxed which state that transition
will take us to. In short, the relations Ra , Rb and Rc are all partial functions.
Deterministic transition systems are important, but in theoretical computer sci-
ence it is more usual to take non-deterministic transition systems as the basic model
of computation. A non-deterministic transition system is one in which the state we
reach by making a particular kind of transition from a given state need not be ﬁxed.
That is, the transition relations do not have to be partial functions, but can be arbi-
trary relations.
s
w1
a
w3
s
I
@
6
b @ c
@
w4
- s a @ s
a
w2

Fig. 1.3. A non-deterministic transition system
In Figure 1.3 a non-deterministic transition system is shown: a is now a non-
deterministic program, for if we execute it in state w4 there are two possibilities:
either we loop back into w4 , or we move to w2 .
Transition systems play an important role in this book. This is not so much be-
cause of their computational interpretation (though that is interesting) but because
of their sheer ubiquity. Sets equipped with collections of binary relations are one
of the simplest types of mathematical structures imaginable, and they crop up just
about everywhere.
Example 1.4 For our next example we turn to the branch of artiﬁcial intelligence
called knowledge representation. A central concern of knowledge representation
is objects, their properties, their relations to other objects, and the conclusions one
can draw about them. For example, Figure 1.4 represents some of the ways Mike
relates to his surroundings.
One conclusion that can be drawn from this representation is that Sue has chil-
dren. Others are not so clear. For example, does Mike love Sue, and does he1.1 Relational Structures

Sue

son-of 6

BMW

owns


Mike

5

loves
-
Diana


Fig. 1.4. Mike and others
love his BMW? Assuming that absence of a not loves arc (like that connecting
the Mike and the Diana nodes) means that the loves relation holds, this is a safe
conclusion to draw. There are often such ‘gaps’ between pictures and relational
structures, and to ﬁll them correctly (that is, to know which relational structure
the picture corresponds to) we have to know which diagrammatic conventions are
being assumed.
Let us take the picture at face value. It gives us a set {BMW, Sue, Mike, Diana}
together with binary relations son-of, owns, and not loves. So we have here
another labeled transition system.
Example 1.5 Finite trees are ubiquitous in linguistics. For example, the tree de-
picted in Figure 1.5 represents some simple facts about phrase-structure, namely
that a sentence (S) can consist of a noun phrase (NP) and a verb phrase (VP); an NP
can consist of a proper noun (PN); and VPs can consist of a transitive verb (TV)
and an NP.
S
NP s
s
PN
s
@
@s VP
@
@s
s
TV
NP
s PN
Fig. 1.5. A ﬁnite decorated tree
Trees play an important role in this book, so we will take this opportunity to deﬁne
them. We ﬁrst introduce the following important concepts.
Deﬁnition 1.6 Let W be a non-empty set and R a binary relation on W . Then R+ ,
the transitive closure of R, is the smallest transitive relation on W that contains R.
That is,

R+ = {R | R is a transitive binary relation on W & R ⊆ R }.
Furthermore, R∗ , the reﬂexive transitive closure of R, is the smallest reﬂexive and
transitive relation on W containing R. That is,1 Basic Concepts
6
R∗ =

{R | R is a reﬂexive transitive binary relation on W & R ⊆ R }.
Note that R+ uv holds if and only if there is a sequence of elements u = w0 , w1 ,
. . . , wn = v (n > 0) from W such that for each i < n we have Rwi wi+1 . That
is, R+ uv means that v is reachable from u in a ﬁnite number of R-steps. Thus
transitive closure is a natural and useful notion; see Exercise 1.1.3.
With these concepts at our disposal, it is easy to say what a tree is.
Deﬁnition 1.7 A tree T is a relational structure (T, S) where:
(i) T , the set of nodes, contains a unique r ∈ T (called the root) such that
∀t ∈ T S ∗ rt.
(ii) Every element of T distinct from r has a unique S-predecessor; that is, for
every t = r there is a unique t ∈ T such that St t.
(iii) S is acyclic; that is, ∀t¬S+ tt. (It follows that S is irreﬂexive.)
Clearly, Figure 1.5 contains enough information to give us a tree (T, S) in the sense
just deﬁned: the nodes in T are the displayed points, and the relation S is indicated
by means of a straight line segment drawn from a node to a node immediately
below (that is, S is the obvious successor or daughter-of relation). The root of the
tree is the topmost node (the one labeled S).
But the diagram also illustrates something else: often we need to work with
structures consisting of not only a tree (T, S), but a whole lot else besides. For
example, linguists would not be particularly interested in the bare tree (T, S) just
deﬁned, rather they would be interested in (at least) the structure
(T, S, LEFT- OF , S, NP, VP, PN, TV).
Here S, NP, VP, PN, and TV are unary relations on T (note that S and S are distinct
symbols). These relations record the information attached to each node, namely the
fact that some nodes are noun phrase nodes, while others are proper name nodes,
sentential nodes, and so on. LEFT- OF is a binary relation which captures the left-
to-right aspect of the above picture; the fact that the NP node is to the left of the
VP node might be linguistically crucial.
Similar things happen in mathematical contexts. Sometimes we will need to
work with relational structures which are much richer than the simple trees (T, S)
just deﬁned, but which, perhaps in an implicit form, contain a relation with all the
properties required of S. It is useful to have a general term for such structures; we
will call them tree-like. A formal deﬁnition here would do more harm than good,
but in the text we will indicate, whenever we call a structure tree-like, where this
implicit tree (T, S) can be found. That is, unless it is obvious, we will say which
deﬁnable relation in the structure satisﬁes the conditions of Deﬁnition 1.7. One of1.1 Relational Structures
7
the most important examples of tree-like structures is the Rabin structure, which
we will meet in Section 6.3.
One often encounters the notion of a tree deﬁned in terms of the (reﬂexive) tran-
sitive closure of the successor relation. Such trees we call (reﬂexive and) transitive
trees, and they are dealt with in Exercises 1.1.4 and 1.1.5
Example 1.8 We have already seen that labeled transition systems can be regarded
as a simple model of computation. Indeed, they can be thought of as models for
practically any dynamic notion: each transition takes us from an input state to an
output state. But this treatment of states and transitions is rather unbalanced: it
is clear that transitions are second-class citizens. For example, if we talked about
LTSs using a ﬁrst-order language, we could not name transitions using constants
(they would be talked about using relation symbols) but we could have constants
for states. But there is a way to treat transitions as ﬁrst-class citizens: we can work
with arrow structures.
The objects of an arrow structure are things that can be pictured as arrows. As
concrete examples, the mathematically inclined reader might think of vectors, or
functions or morphisms in some category; the computer scientist of programs; the
linguist of the context changing potential of a grammatically well-formed piece of
text or discourse; the philosopher of some agent’s cognitive actions; and so on. But
note well: although arrows are the prime citizens of arrow structures, this does not
mean that they should always be thought of as primitive entities. For example, in
a two-dimensional arrow structure, an arrow a is thought of as a pair (a0 , a1 ) of
which a0 represents the starting point of a, and a1 its endpoint.
Having ‘deﬁned’ the elements of arrow structures to be objects graphically rep-
resentable as arrows, we should now ask: what are the basic relations which hold
between arrows? The most obvious candidate is composition: vector spaces have
an additive structure, functions can be composed, language fragments can be con-
catenated, and so on. So the central relation on arrows will be a ternary composi-
tion relation C, where Cabc says that arrow a is the outcome of composing arrow
b with arrow c (or conversely, that a can be decomposed into b and c). Note that
in many concrete examples, C is actually a (partial) function; for example, in the
two-dimensional framework we have
Cabc iff a0 = b0 , a1 = c1 and b1 = c0 .
(1.1)
What next? Well, in all the examples listed, the composition function has a neutral
element; think of the identity function or the SKIP-program. So, arrow structures
will contain degenerate arrows, transitions that do not lead to a different state.
Formally, this means that arrow structures will contain a designated subset I of
identity arrows; in the pair-representation, I will be (a subset of) the diagonal:
Ia iff a0 = a1 .
(1.2)1 Basic Concepts
8
Another natural relation is converse. In linguistics and cognitive science we might
view this as an ‘undo’ action (perhaps we have made a mistake and need to recover)
and in many ﬁelds of mathematics arrow-like objects have converses (vectors) or
inverses (bijective functions). So we will also give arrow structures a binary re-
verse relation R. Again, in many cases this relation will be a partial function. For
example, in the two-dimensional picture, R is given by
Rab iff a0 = b1 and a1 = b0 .
(1.3)
Although there are further natural candidates for arrow relations (notably some
notion of iteration) we will leave it at this. And now for the formal deﬁnition: an
arrow frame is a quadruple F = (W, C, R, I) such that C, R and I are a ternary,
a binary and a unary relation on W , respectively. Pictorially, we can think of them
as follows:
#
*

 @


b

a
@c
@
R
@
-
a
i
"
b
Cabc
q
Rab
a
?
Ia
The two-dimensional arrow structure, in which the universe consists of all pairs
over the set U (and the relations C, R and I are given by (1.1), (1.3) and (1.2),
respectively) is called the square over U , notation: SU . The square arrow frame
over U can be pictorially represented as a full graph over U : each arrow object
(a0 , a1 ) in SU can be represented as a ‘real’ arrow from a0 to a1 ; the relations
are as pictured above. Alternatively, square arrow frames can be represented two-
dimensionally; see the pictures in Example 1.27.
Exercises for Section 1.1
1.1.1 Let (W, R) be a quasi-order; that is, assume that R is transitive and reﬂexive. Deﬁne
the binary relation ∼ on W by putting s ∼ t iff Rst and Rts.
(a) Show that ∼ is an equivalence relation.
Let [s] denote the equivalence class of s under this relation, and deﬁne the following rela-
tion on the collection of equivalence classes: [s] ≤ [t] iff Rst.
(b) Show that this is well deﬁned.
(c) Show that ≤ is a partial order.
1.1.2 Let R be a transitive relation on a ﬁnite set W . Prove that R is well-founded iff R is
irreﬂexive. (R is called well-founded if there are no inﬁnite paths . . . Rs 2 Rs1 Rs0 .)
1.1.3 Let R be a binary relation on W . In Example 1.2 we deﬁned the reﬂexive closure
of R to be R ∪ {(u, u) | u ∈ W }. But we can also give a deﬁnition analogous to those1.2 Modal Languages
9
of R+ and R∗ in Deﬁnition 1.6, namely that it is the smallest reﬂexive relation on W that
contains R:

Rr = {R | R is a reﬂexive binary relation on W & R ⊆ R  }.
Explain why this new deﬁnition (and the deﬁnitions of R + and R∗ ) are well deﬁned. Show
the equivalence of the two deﬁnitions of reﬂexive closure. Finally, show that R + uv if and
only if there is a sequence of elements u = w 0 , w1 , . . . , wn = v from W such that for each
i < n we have Rwi wi+1 , and give an analogous sequence-based deﬁnition of reﬂexive
transitive closure.
1.1.4 A transitive tree is an SPO (T, <) such that (i) there is a root r ∈ T satisfying r < t
for all t ∈ T such that r = t, and (ii) for each t ∈ T , the set {s ∈ T | s < t} of
predecessors of t is ﬁnite and linearly ordered by <.
(a) Prove that if (T, S) is a tree then (T, S + ) is a transitive tree.
(b) Prove that (T, <) is a transitive tree iff (T, S < ) is a tree, where S< is the immediate
successor relation given by sS < t iff s < t and s < v < t for no v ∈ T .
(c) Under which conditions does the converse of (a) hold?
1.1.5 Deﬁne the notion of a reﬂexive and transitive tree, such that if (T, S) is a tree then
(T, S ∗ ) is a reﬂexive and transitive tree.
1.1.6 Show that the following formulas hold on square arrow frames:
(a) ∀xy (Rxy → Ryx),
(b) ∀xyz ((Cxyz ∧ Iz) ↔ x = y),
(c) ∀xx1 x2 x3 (∃y (Cxx1 y ∧ Cyx2 x3 ) ↔ ∃z (Cxzx3 ∧ Czx1 x2 )).
1.2 Modal Languages
It is now time to meet the modal languages we will be working with. First, we
introduce the basic modal language. We then deﬁne modal languages of arbitrary
similarity type. Finally we examine the following extensions of the basic modal
language in more detail: the basic temporal language, the language of proposi-
tional dynamic logic, and a language of arrow logic.
Deﬁnition 1.9 The basic modal language is deﬁned using a set of proposition let-
ters (or proposition symbols or propositional variables) Φ whose elements are usu-
ally denoted p, q, r, and so on, and a unary modal operator 3 (‘diamond’). The
well-formed formulas φ of the basic modal language are given by the rule
φ ::= p | ⊥ | ¬φ | ψ ∨ φ | 3φ,
where p ranges over elements of Φ. This deﬁnition means that a formula is either a
proposition letter, the propositional constant falsum (‘bottom’), a negated formula,
a disjunction of formulas, or a formula preﬁxed by a diamond.
Just as the familiar ﬁrst-order existential and universal quantiﬁers are duals to
each other (in the sense that ∀x α ↔ ¬∃x ¬α), we have a dual operator 2 (‘box’)10
1 Basic Concepts
for our diamond which is deﬁned by φ := ¬3¬φ. We also make use of the classi-
cal abbreviations for conjunction, implication, bi-implication and the constant true
(‘top’): φ∧ψ := ¬(¬φ∨¬ψ), φ → ψ := ¬φ∨ψ, φ ↔ ψ := (φ → ψ)∧(ψ → φ)
and  := ¬ ⊥.
Although we generally assume that the set Φ of proposition letters is a countably
inﬁnite set {p0 , p1 , . . .}, occasionally we need to make other assumptions. For
instance, when we are after decidability results, it may be useful to stipulate that
Φ is ﬁnite, while doing model theory or frame theory we may need uncountably
inﬁnite languages. This is why we take Φ as an explicit parameter when deﬁning
the set of modal formulas.
Example 1.10 Three readings of diamond and box have been extremely inﬂuen-
tial. First, 3φ can be read as ‘it is possibly the case that φ.’ Under this reading,
φ means ‘it is not possible that not φ,’ that is, ‘necessarily φ,’ and examples
of formulas we would probably regard as correct principles include all instances
of 2φ → 3φ (‘whatever is necessary is possible’) and all instances of φ → 3φ
(‘whatever is, is possible’). The status of other formulas is harder to decide. Should
φ → 23φ (‘whatever is, is necessarily possible’) be regarded as a general truth
about necessity and possibility? Should 3φ → 23φ (‘whatever is possible, is
necessarily possible’)? Are any of these formulas linked by a modal notion of log-
ical consequence, or are they independent claims about necessity and possibility?
These are difﬁcult (and historically important) questions. The relational semantics
deﬁned in the following section offers a simple and intuitively compelling frame-
work in which to discuss them.
Second, in epistemic logic the basic modal language is used to reason about
knowledge, though instead of writing 2φ for ‘the agent knows that φ’ it is usual to
write Kφ. Given that we are talking about knowledge (as opposed to, say, belief
or rumor), it seems natural to view all instances of Kφ → φ as true: if the agent
really knows that φ, then φ must hold. On the other hand (assuming that the agent
is not omniscient) we would regard φ → Kφ as false. But the legitimacy of other
principles is harder to judge (if an agent knows that φ, does she know that she
knows it?). Again, a precise semantics brings clarity.
Third, in provability logic 2φ is read as ‘it is provable (in some arithmetical
theory) that φ.’ A central theme in provability logic is the search for a complete
axiomatization of the provability principles that are valid for various arithmetical
theories (such as Peano Arithmetic). The Löb formula 2(2p → p) → 2p plays a
key role here. The arithmetical ramiﬁcations of this formula lie outside the scope
of the book, but in Chapters 3 and 4 we will explore its modal content.
That is the basic modal language. Let us now generalize it. There are two obvious
ways to do so. First, there seems no good reason to restrict ourselves to languages1.2 Modal Languages
11
with only one diamond. Second, there seems no good reason to restrict ourselves
to modalities that take only a single formula as argument. Thus the general modal
languages we will now deﬁne may contain many modalities, of arbitrary arities.
Deﬁnition 1.11 A modal similarity type is a pair τ = (O, ρ) where O is a non-
empty set, and ρ is a function O → N. The elements of O are called modal oper-
ators; we use  (‘triangle’), 0 , 1 , . . . , to denote elements of O. The function ρ
assigns to each operator  ∈ O a ﬁnite arity, indicating the number of arguments
 can be applied to.
In line with Deﬁnition 1.9, we often refer to unary triangles as diamonds, and
denote them by 3a or a, where a is taken from some index set. We often assume
that the arity of operators is known, and do not distinguish between τ and O.
Deﬁnition 1.12 A modal language ML(τ, Φ) is built up using a modal similarity
type τ = (O, ρ) and a set of proposition letters Φ. The set Form(τ, Φ) of modal
formulas over τ and Φ is given by the rule
φ ::= p | ⊥ | ¬φ | φ1 ∨ φ2 | (φ1 , . . . , φρ() ),
where p ranges over elements of Φ.
The similarity type of the basic modal language is called τ0 . In the sequel we
sometimes state results for modal languages of arbitrary similarity types, give the
proof for similarity types with diamonds only, and leave the general case as an ex-
ercise. For binary modal operators, we often use inﬁx notation; that is, we usually
write φψ instead of (φ, ψ). One other thing: note that our deﬁnition permits
nullary modalities (or modal constants), triangles that take no arguments at all.
Such modalities can be useful – we will see a natural example when we discuss
arrow logic – but they play a relatively minor role in this book. Syntactically (and
indeed, semantically) they are rather like propositional variables; in fact, they are
best thought of as propositional constants.
Deﬁnition 1.13 We now deﬁne dual operators for non-nullary triangles. For each
 ∈ O the dual  of  is deﬁned as (φ1 , . . . , φn ) := ¬(¬φ1 , . . . , ¬φn ). The
dual of a triangle of arity at least 2 is called a nabla. As in the basic modal language,
the dual of a diamond is called a box, and is written 2a or [a].
Three extensions of the basic modal language deserve special attention. Two of
these, the basic temporal language and the language of propositional dynamic logic
will be frequently used in subsequent chapters. The third is a simple language of
arrow logic; it will provide us with a natural example of a binary modality.
Example 1.14 (The Basic Temporal Language) The basic temporal language is
built using a set of unary operators O = {F , P }. The intended interpretation12
1 Basic Concepts
of a formula F φ is ‘φ will be true at some Future time,’ and the intended inter-
pretation of P φ is ‘φ was true at some Past time.’ This language is called the
basic temporal language, and it is the core language underlying a branch of modal
logic called temporal logic. It is traditional to write F  as F and P  as P , and
their duals are written as G and H, respectively. (The mnemonics here are: ‘it is
always Going to be the case’ and ‘it always Has been the case.’)
We can express many interesting assertions about time with this language. For
example, P φ → GP φ, says ‘whatever has happened will always have happened,’
and this seems a plausible candidate for a general truth about time. On the other
hand, if we insist that F φ → F F φ must always be true, it shows that we are
thinking of time as dense: between any two instants there is always a third. And if
we insist that GF p → F Gp (the McKinsey formula) is true, for all propositional
symbols p, we are insisting that atomic information true somewhere in the future
eventually settles down to being always true. (We might think of this as reﬂecting
a ‘thermodynamic’ view of information distribution.)
One ﬁnal remark: computer scientists will have noticed that the binary until
modality is conspicuous by its absence. As we will see in the following chapter,
the basic temporal language is not strong enough to express until. We examine a
language containing the until operator in Section 7.2.
Example 1.15 (Propositional Dynamic Logic) Another important branch of mo-
dal logic, again involving only unary modalities, is propositional dynamic logic.
PDL, the language of propositional dynamic logic, has an inﬁnite collection of
diamonds. Each of these diamonds has the form π, where π denotes a (non-
deterministic) program. The intended interpretation of πφ is ‘some terminating
execution of π from the present state leads to a state bearing the information φ.’
The dual assertion [π]φ states that ‘every execution of π from the present state leads
to a state bearing the information φ.’
So far, there is nothing really new – but a simple idea is going to ensure that
PDL is highly expressive: we will make the inductive structure of the programs
explicit in PDL’s syntax. Complex programs are built out of basic programs using
some repertoire of program constructors. By using diamonds which reﬂect this
structure, we obtain a powerful and ﬂexible language.
Let us examine the core language of PDL. Suppose we have ﬁxed some set of
basic programs a, b, c, and so on (thus we have basic modalities a, b, c, . . .
at our disposal). Then we are allowed to deﬁne complex programs π (and hence,
modal operators π) over this base as follows:
(choice) if π1 and π2 are programs, then so is π1 ∪ π2 .
The program π1 ∪ π2 (non-deterministically) executes π1 or π2 .1.2 Modal Languages
13
(composition) if π1 and π2 are programs, then so is π1 ; π2 .
This program ﬁrst executes π1 and then π2 .
(iteration) if π is a program, then so is π∗ .
π ∗ is a program that executes π a ﬁnite (possibly zero) number of times.
For the collection of diamonds this means that if π1  and π2  are modal operators,
then so are π1 ∪ π2 , π1 ; π2  and π1∗ . This notation makes it straightforward to
describe properties of program execution. Here is a fairly straightforward example.
The formula π∗ φ ↔ φ ∨ π ; π ∗ φ says that a state bearing the information φ can
be reached by executing π a ﬁnite number of times if and only if either we already
have the information φ in the current state, or we can execute π once and then ﬁnd
a state bearing the information φ after ﬁnitely many more iterations of π. Here is a
far more demanding example:
[π ∗ ](φ → [π]φ) → (φ → [π ∗ ]φ).
This is Segerberg’s axiom (or the induction axiom) and the reader should try work-
ing out what exactly it is that this formula says. We discuss this formula further in
Chapter 3; see Example 3.10.
If we conﬁne ourselves to these three constructors (and in this book for the most
part we do) we are working with a version of PDL called regular PDL. (This is
because the three constructors are the ones used in Kleene’s well-known analysis of
regular programs.) However, a wide range of other constructors have been studied.
Here are two:
(intersection) if π1 and π2 are programs, then so is π1 ∩ π2 .
The intended meaning of π1 ∩ π2 is: execute both π1 and π2 , in parallel.
(test) if φ is a formula, then φ? is a program.
This program tests whether φ holds, and if so, continues; if not, it fails.
To ﬂesh this out a little, the intended reading of π1 ∩ π2 φ is that if we execute
both π1 and π2 in the present state, then there is at least one state reachable by both
programs which bears the information φ. This is a natural constructor for a variety
of purposes, and we will make use of it in Section 6.5.
The key point to note about the test constructor is its unusual syntax: it allows us
to make a modality out of a formula. Intuitively, this modality accesses the current
state if the current state satisﬁes φ. On its own such a constructor is uninteresting
(φ?ψ simply means φ ∧ ψ). However, when other constructors are present, it can
be used to build interesting programs. For example, (p? ; a) ∪ (¬p? ; b) is ‘if p
then a else b.’
Nothing prevents us from viewing the basic programs as deterministic, and we
will discuss a fragment of deterministic PDL (DPDL) in Section 6.5.14
1 Basic Concepts
Example 1.16 (An Arrow Language) The type τ→ of arrow logic is a similarity
type with modal operators other than diamonds. The language of arrow logic is
designed to talk about the objects in arrow structures (entities which can be pictured
as arrows). The well-formed formulas φ of the arrow language are given by the rule
φ ::= p | ⊥ | ¬φ | φ ∨ ψ | φ ◦ ψ | ⊗φ | 1’.
That is, 1’ (‘identity’) is a nullary modality (a modal constant), the ‘converse’ oper-
ator ⊗ is a diamond, and the ‘composition’ operator ◦ is a dyadic operator. Possible
readings of these operators are:
1’
identity
‘skip’,
⊗φ
converse
‘φ conversely’,
φ ◦ ψ composition ‘ﬁrst φ, then ψ’.
Example 1.17 (Feature Logic and Description Logic) As we mentioned in the
Preface, researchers developing formalisms for describing graphs have sometimes
(without intending to) come up with notational variants of modal logic. For ex-
ample, computational linguists use Attribute-Value Matrices (AVMs) for describ-
ing feature structures (directed acyclic graphs that encode linguistic information).
Here is a fairly typical AVM:

 ⎤
⎡
PERSON
1st
⎣ AGREEMENT
⎦
NUMBER plural
CASE
dative
.
But this is just a two dimensional notation for the following modal formula:
AGREEMENT (PERSON 1st ∧ NUMBER plural) ∧ CASE dative.
Similarly, researchers in artiﬁcial intelligence needing a notation for describing and
reasoning about ontologies developed description logic. For example, the concept
of ‘being a hired killer for the mob’ is true of any individual who is a killer and is
employed by a gangster. In description logic we can deﬁne this concept as follows:
killer  ∃employer.gangster.
But this is simply the following modal formula lightly disguised:
killer ∧ employergangster.
It turns out that the links between modal logic on the one hand, and feature and
description logic on the other, are far more interesting than these rather simple ex-
amples might suggest. A modal perspective on feature or description logic capable
of accounting for other important aspects of these systems (such as the ability to
talk about re-entrancy in feature structures, or to perform ABox reasoning in de-
scription logic) must make use of the kinds of extended modal logics discussed in1.2 Modal Languages
15
Chapter 7 (in particular, logics containing the global modality, and hybrid logics).
Furthermore, some versions of feature and description logic make use of ideas
from PDL, and description logic makes heavy use of counting modalities (which
say such things as ‘at most 3 transitions lead to a φ state’).
Substitution
Throughout this book we will be working with the syntactic notion of one formula
being a substitution instance of another. In order to deﬁne this notion we ﬁrst
introduce the concept of a substitution as a function mapping proposition letters to
formulas.
Deﬁnition 1.18 Suppose we are working a modal similarity type τ and a set Φ of
proposition letters. A substitution is a map σ : Φ → Form(τ, Φ).
Now such a substitution σ induces a map (·)σ : Form(τ, Φ) → Form(τ, Φ)
which we can recursively deﬁne as follows:
⊥σ = ⊥,
pσ = σ(p),
(¬ψ)σ = ¬ψ σ ,
(ψ ∨ θ)σ = ψ σ ∨ θ σ ,
((ψ1 , . . . , ψn ))σ = (ψ1σ , . . . , ψnσ ).
This deﬁnition spells out exactly what is meant by carrying out uniform substitu-
tion. Finally, we say that χ is a substitution instance of ψ if there is some substitu-
tion τ such that ψτ = χ.
To give an example, if σ is the substitution that maps p to p ∧ 2q, q to 33q ∨ r
and leaves all other proposition letters untouched, then we have
(p ∧ q ∧ r)σ = ((p ∧ 2q) ∧ (33q ∨ r) ∧ r).
Exercises for Section 1.2
1.2.1 Using Kφ to mean ‘the agent knows that φ’ and M φ to mean ‘it is consistent with
what the agent knows that φ,’ represent the following statements:
(a) If φ is true, then it is consistent with what the agent knows that she knows that φ.
(b) If it is consistent with what the agent knows that φ, and it is consistent with what
the agent knows that ψ, then it is consistent with what the agent knows that φ ∧ ψ.
(c) If the agent knows that φ, then it is consistent with what the agent knows that φ.
(d) If it is consistent with what the agent knows that it is consistent with what the agent
knows that φ, then it is consistent with what the agent knows that φ.
Which of these seem plausible principles concerning knowledge and consistency?1 Basic Concepts
16
1.2.2 Suppose 3φ is interpreted as ‘φ is permissible’; how should 2φ be understood?
List formulas which seem plausible under this interpretation. Should the Löb formula
2(2p → p) → 2p be on your list? Why?
1.2.3 Explain how the program constructs ‘while φ do π’ and ‘repeat π until φ’
can be expressed in PDL.
1.2.4 Consider the following arrow formulas. Do you think they should be always true?
1’ ◦ p ↔ p,
⊗(p ◦ q) ↔ ⊗q ◦ ⊗p,
p ◦ (q ◦ r) ↔ (p ◦ q) ◦ r.
1.2.5 Show that ‘being-a-substitution-instance-of’ is a transitive concept. That is, show
that if χ is a substitution instance of ψ, and ψ is a substitution instance of φ, then χ is a
substitution instance of φ.
1.3 Models and Frames
Although our discussion has contained many semantically suggestive phrases such
as ‘true’ and ‘intended interpretation,’ as yet we have given them no mathematical
content. The purpose of this (key) section is to put that right. We do so by in-
terpreting our modal languages in relational structures. In fact, by the end of the
section we will have done this in two distinct ways: at the level of models and at
the level of frames. Both levels are important, though in different ways. The level
of models is important because this is where the fundamental notion of satisfaction
(or truth) is deﬁned. The level of frames is important because it supports the key
logical notion of validity.
Models and satisfaction
We start by deﬁning frames, models, and the satisfaction relation for the basic
modal language.
Deﬁnition 1.19 A frame for the basic modal language is a pair F = (W, R) such
that
(i) W is a non-empty set.
(ii) R is a binary relation on W .
That is, a frame for the basic modal language is simply a relational structure bearing
a single binary relation. We remind the reader that we refer to the elements of W
by many different names (see Deﬁnition 1.1).
A model for the basic modal language is a pair M = (F, V ), where F is a frame
for the basic modal language, and V is a function assigning to each proposition1.3 Models and Frames
17
letter p in Φ a subset V (p) of W . Formally, V is a map: Φ → P(W ), where
P(W ) denotes the power set of W . Informally we think of V (p) as the set of
points in our model where p is true. The function V is called a valuation. Given a
model M = (F, V ), we say that M is based on the frame F, or that F is the frame
underlying M.
Note that models for the basic modal language can be viewed as relational struc-
tures in a natural way, namely as structures of the form:
(W, R, V (p), V (q), V (r), . . .).
That is, a model is a relational structure consisting of a domain, a single binary
relation R, and the unary relations given to us by V . Thus, viewed from a purely
structural perspective, a frame F and a model M based on F, are simply two re-
lational models based on the same universe; indeed, a model is simply a frame
enriched by a collection of unary relations.
But in spite of their mathematical kinship, frames and models are used very dif-
ferently. Frames are essentially mathematical pictures of ontologies that we ﬁnd
interesting. For example, we may view time as a collection of points ordered by
a strict partial order, or feel that a correct analysis of knowledge requires that we
postulate the existence of situations linked by a relation of ‘being an epistemic
alternative to.’ In short, we use the level of frames to make our fundamental as-
sumptions mathematically precise.
The unary relations provided by valuations, on the other hand, are there to dress
our frames with contingent information. Is it raining on Tuesday or not? Is the
system write-enabled at time t6 ? Is a situation where Janet does not love him an
epistemic alternative for John? Such information is important, and we certainly
need to be able to work with it – nonetheless, statements only deserve the de-
scription ‘logical’ if they are invariant under changes of contingent information.
Because we have drawn a distinction between the fundamental information given
by frames, and the additional descriptive content provided by models, it will be
straightforward to deﬁne a modally reasonable notion of validity.
But this is jumping ahead. First we must learn how to interpret the basic modal
language in models. This we do by means of the following satisfaction deﬁnition.
Deﬁnition 1.20 Suppose w is a state in a model M = (W, R, V ). Then we induc-
tively deﬁne the notion of a formula φ being satisﬁed (or true) in M at state w as
follows:
M, w  p iff w ∈ V (p), where p ∈ Φ,
M, w ⊥
never,
M, w  ¬φ iff not M, w  φ,1 Basic Concepts
18
M, w  φ ∨ ψ iff M, w  φ or M, w  ψ,
M, w  3φ iff for some v ∈ W with Rwv we have M, v  φ. (1.4)
It follows from this deﬁnition that M, w  2φ if and only if for all v ∈ W such
that Rwv, we have M, v  φ. Finally, we say that a set Σ of formulas is true at a
state w of a model M, notation: M, w  Σ, if all members of Σ are true at w.
Note that this notion of satisfaction is intrinsically internal and local. We evaluate
formulas inside models, at some particular state w (the current state). Moreover,
3 works locally: the ﬁnal clause (1.4) treats 3φ as an instruction to scan states
in search of one where φ is satisﬁed. Crucially, only successors of the current
state (that is, states that are accessible from the current one by making one R-step)
can be scanned by our operators. Much of the characteristic ﬂavor of modal logic
springs from the perspective on relational structures embodied in the satisfaction
deﬁnition.
If M does not satisfy φ at w we often write M, w  φ, and say that φ is false or
refuted at w. When M is clear from the context, we write w  φ for M, w  φ and
w  φ for M, w  φ. It is convenient to extend the valuation V from proposition
letters to arbitrary formulas so that V (φ) always denotes the set of states at which
φ is true:
V (φ) := {w | M, w  φ}.
Deﬁnition 1.21 A formula φ is globally or universally true in a model M (nota-
tion: M  φ) if it is satisﬁed at all points in M (that is, if M, w  φ, for all
w ∈ W ). A formula φ is satisﬁable in a model M if there is some state in M at
which φ is true; a formula is falsiﬁable or refutable in a model if its negation is
satisﬁable.
A set Σ of formulas is globally true (satisﬁable, respectively) in a model M if
M, w  Σ for all states w in M (some state w in M, respectively).
Example 1.22 (i) Consider the frame F = ({w1 , w2 , w3 , w4 , w5 }, R), where
Rwi wj iff j = i + 1:
s
w1
-s
w2
-s
w3
-s
w4
-s
w5
If we choose a valuation V on F such that V (p) = {w2 , w3 }, V (q) = {w1 , w2 ,
w3 , w4 , w5 }, and V (r) = ∅, then in the model M = (F, V ) we have that
• M, w1  3p,
• M, w1  3p → p,
• M, w2  3(p ∧ ¬r), and
• M, w1  q ∧ 3(q ∧ 3(q ∧ 3(q ∧ 3q))).1.3 Models and Frames
19
Furthermore, M  2q. Now, it is clear that 2q is true at w1 , w2 , w3 and w4 , but
why is it true at w5 ? Well, as w5 has no successors at all (we often call such points
‘dead ends’ or ‘blind states’) it is vacuously true that q is true at all R-successors
of w5 . Indeed, any ‘boxed’ formula 2φ is true at any dead end in any model.
(ii) As a second example, let F be the SPO given in Figure 1.1, where W = {1,
2, 3, 4, 6, 8, 12, 24} and Rxy means ‘x and y are different, and y can be divided
by x.’ Choose a valuation V on this frame such that V (p) = {4, 8, 12, 24}, and
V (q) = {6}, and let M = (F, V ). Then we have that
• M, 4  2p,
• M, 6  2p,
• M, 2  2p, and
• M, 2  3(q ∧ 2p) ∧ 3(¬q ∧ 2p).
(iii) Whereas a diamond 3 corresponds to making a single R-step in a model,
stacking diamonds one in front of the other corresponds to making a sequence
of R-steps through the model. The following deﬁned operators will sometimes
be useful: we write 3n φ for φ preceded by n occurrences of 3, and 2n φ for φ
preceded by n occurrences of 2. If we like, we can associate each of these deﬁned
operators with its own accessibility relation. We do so inductively: R0 xy is deﬁned
to hold if x = y, and Rn+1 xy is deﬁned to hold if ∃z (Rxz ∧ Rn zy). Under this
deﬁnition, for any model M and state w in M we have M, w  3n φ iff there exists
a v such that Rn wv and M, v  φ.
(iv) The use of the word ‘world’ (or ‘possible world’) for the entities in W
derives from the reading of the basic modal language in which 3φ is taken to mean
‘possibly φ,’ and 2φ to mean ‘necessarily φ.’ Given this reading, the machinery of
frames, models, and satisfaction which we have deﬁned is essentially an attempt to
capture mathematically the view (often attributed to Leibniz) that necessity means
truth in all possible worlds, and that possibility means truth in some possible world.
The satisfaction deﬁnition stipulates that 3 and 2 check for truth not at all possi-
ble worlds (that is, at all elements of W ) but only at R-accessible possible worlds.
At ﬁrst sight this may seem a weakness of the satisfaction deﬁnition – but in fact, it
is its greatest source of strength. The point is this: varying R is a mechanism which
gives us a ﬁrm mathematical grip on the pre-theoretical notion of access between
possible worlds. For example, by stipulating that R = W × W we can allow all
worlds access to each other; this corresponds to the Leibnizian idea in its purest
form. Going to the other extreme, we might stipulate that no world has access to
any other. Between these extremes there is a wide range of options to explore.
Should interworld access be reﬂexive? Should it be transitive? What impact do
these choices have on the notions of necessity and possibility? For example, if we
demand symmetry, does this justify certain principles, or rule others out?
(v) Recall from Example 1.10 that in epistemic logic 2 is written as K and Kφ20
1 Basic Concepts
is interpreted as ‘the agent knows that φ.’ Under this interpretation, the intuitive
reading for the semantic clause governing K is: the agent knows φ in a situation
w (that is, w  Kφ) iff φ is true in all situations v that are compatible with her
knowledge (that is, if v  φ for all v such that Rwv). Thus, under this interpre-
tation, W is to be thought of as a collection of situations, R is a relation which
models the idea of one situation being epistemically accessible from another, and
V governs the distribution of primitive information across situations.
We now deﬁne frames, models and satisfaction for modal languages of arbitrary
similarity type.
Deﬁnition 1.23 Let τ be a modal similarity type. A τ -frame is a tuple F consisting
of the following ingredients:
(i) a non-empty set W ,
(ii) for each n ≥ 0, and each n-ary modal operator  in the similarity type τ ,
an (n + 1)-ary relation R.
So, again, frames are simply relational structures. If τ contains just a ﬁnite number
of modal operators 1 , . . . , n , we write F = (W, R1 , . . . , Rn ); otherwise we
write F = (W, R)∈τ or F = (W, {R |  ∈ τ }). We turn such a frame into a
model in exactly the same way that we did for the basic modal language: by adding
a valuation. That is, a τ -model is a pair M = (F, V ) where F is a τ -frame, and V
is a valuation with domain Φ and range P(W ), where W is the universe of F.
The notion of a formula φ being satisﬁed (or true) at a state w in a model M =
(W, {R |  ∈ τ }, V ) (notation: M, w  φ) is deﬁned inductively. The clauses
for the atomic and boolean cases are the same as for the basic modal language (see
Deﬁnition 1.20). As for the modal case, when ρ() > 0 we deﬁne
M, w  (φ1 , . . . , φn ) iff for some v1 , . . . , vn ∈ W with Rwv1 . . . vn
we have, for each i, M, vi  φi .
This is an obvious generalization of the way 3 is handled in the basic modal lan-
guage. Before going any further, the reader should formulate the satisfaction clause
for (φ1 , . . . , φn ).
On the other hand, when ρ() = 0 (that is, when  is a nullary modality) then
R is a unary relation and we deﬁne
M, w   iff w ∈ R.
That is, unlike other modalities, nullary modalities do not access other states. In
fact, their semantics is identical to that of the propositional variables, save that the
unary relations used to interpret them are not given by the valuation – rather, they
are part of the underlying frame.1.3 Models and Frames
21
As before, we often write w  φ for M, w  φ where M is clear from the
context. The concept of global truth (or universal truth) in a model is deﬁned
as for the basic modal language: it simply means truth at all states in the model.
And, as before, we sometimes extend the valuation V supplied by M to arbitrary
formulas.
Example 1.24 (i) Let τ be a similarity type with three unary operators a, b,
and c. Then a τ -frame has three binary relations Ra , Rb , and Rc (that is, it is a
labeled transition system with three labels). To give an example, let W , Ra , Rb
and Rc be as in Figure 1.2, and consider the formula ap → bp. Informally,
this formula is true at a state, if it has an Ra -successor satisfying p only if it has
an Rb -successor satisfying p. Let V be a valuation with V (p) = {w2 }. Then the
model M = (W, Ra , Rb , Rc , V ) has M, w1  ap → bp.
(ii) Let τ be a similarity type with a binary modal operator  and a ternary
operator . Frames for this τ contain a ternary relation R and a 4-ary rela-
tion S . As an example, let W = {u, v, w, s}, R = {(u, v, w)}, and S =
{(u, v, w, s)} as in Figure 1.6, and consider a valuation V on this frame with
V (p0 ) = {v}, V (p1 ) = {w} and V (p2 ) = {s}. Now, let φ be the formula
v
p0
w
p1
: R uvw
: S uvws
u
s
p2
Fig. 1.6. A simple frame
(p0 , p1 ) → (p0 , p1 , p2 ). An informal reading of φ is ‘any triangle of which the
evaluation point is a vertex, and which has p0 and p1 true at the other two vertices,
can be expanded to a rectangle with a fourth point at which p2 is true.’ The reader
should be able to verify that φ is true at u, and indeed at all other points, and hence
that it is globally true in the model.
Example 1.25 (Bidirectional Frames and Models) Recall from Example 1.14
that the basic temporal language has two unary operators F and P . Thus, according
to Deﬁnition 1.23, models for this language consist of a set bearing two binary re-
lations, RF (the into-the-future relation) and RP (the into-the-past relation), which
are used to interpret F and P respectively. However, given the intended reading
of the operators, most such models are inappropriate: clearly we ought to insist on1 Basic Concepts
22
working with models based on frames in which RP is the converse of RF (that is,
frames in which ∀xy (RF xy ↔ RP yx)).
Let us denote the converse of a relation R by Rˇ. We will call a frame of the
form (T, R, Rˇ) a bidirectional frame, and a model built over such a frame a bidi-
rectional model. From now on, we will only interpret the basic temporal language
in bidirectional models. That is, if M = (T, R, Rˇ, V ) is a bidirectional model
then:
M, t  F φ
M, t  P φ
iff
iff
∃s (Rts ∧ M, s  φ),
∃s (Rˇts ∧ M, s  φ).
But of course, once we have made this restriction, we do not need to mention Rˇ
explicitly any more: once R has been ﬁxed, its converse is ﬁxed too. That is, we
are free to interpret the basic temporal languages on frames (T, R) for the basic
modal language using the clauses
M, t  F φ
M, t  P φ
iff
iff
∃s (Rts ∧ M, s  φ),
∃s (Rst ∧ M, s  φ).
These clauses clearly capture a crucial part of the intended semantics: F looks
forwards along R, and P looks backwards along R. Of course, our models will
only start looking genuinely temporal when we insist that R has further properties
(notably transitivity, to capture the ﬂow of time), but at least we have pinned down
the fundamental interaction between the two modalities.
Example 1.26 (Regular Frames and Models) As explained in Example 1.15, the
language of PDL has an inﬁnite collection of diamonds, each indexed by a program
π built from basic programs using the constructors ∪, ; and ∗ . Now, according to
Deﬁnition 1.23, a model for this language has the form
(W, {Rπ | π is a program }, V ).
That is, a model is a labeled transition system together with a valuation. However,
given our reading of the PDL operators, most of these models are uninteresting. As
with the basic temporal language, we must insist on working with a class of models
that does justice to our intentions.
Now, there is no problem with the interpretation of the basic programs: any
binary relation can be regarded as a transition relation for a non-deterministic pro-
gram. Of course, if we were particularly interested in deterministic programs we
would insist that each basic program be interpreted by a partial function, but let us
ignore this possibility and turn to the key question: which relations should interpret
the structured modalities? Given our readings of ∪, ; and ∗ , as choice, composition,
and iteration, it is clear that we are only interested in relations constructed using1.3 Models and Frames
23
the following inductive clauses:
Rπ1 ∪π2= R π 1 ∪ Rπ 2 ,
Rπ1 ;π2= Rπ1 ◦ Rπ2 (= {(x, y) | ∃z (Rπ1 xz ∧ Rπ2 zy)}),
Rπ1∗= (Rπ1 )∗ , the reﬂexive transitive closure of Rπ1 .
These inductive clauses completely determine how each modality should be inter-
preted. Once the interpretation of the basic programs has been ﬁxed, the relation
corresponding to each complex program is ﬁxed too. This leads to the following
deﬁnition.
Suppose we have ﬁxed a set of basic programs. Let Π be the smallest set of pro-
grams containing the basic programs and all the programs constructed over them
using the regular constructors ∪, ; and ∗ . Then a regular frame for Π is a labeled
transition system (W, {Rπ | π ∈ Π}) such that Ra is an arbitrary binary relation
for each basic program a, and for all complex programs π, Rπ is the binary relation
inductively constructed in accordance with the previous clauses. A regular model
for Π is a model built over a regular frame; that is, a regular model is a regular
frame together with a valuation. When working with the language of PDL over the
programs in Π, we will only be interested in regular models for Π, for these are
the models that capture the intended interpretation.
What about the ∩ and ? constructors? Clearly the intended reading of ∩ demands
that Rπ1 ∩π2 = Rπ1 ∩Rπ2 . As for ?, it is clear that we want the following deﬁnition:
Rφ? = {(x, y) | x = y and y  φ}.
This is indeed the clause we want, but note that it is rather different from the others:
it is not a frame condition. Rather, in order to determine the relation Rφ? , we need
information about the truth of the formula φ, and this can only be provided at the
level of models.
Example 1.27 (Arrow Models) Arrow frames were deﬁned in Example 1.8 and
the arrow language in Example 1.16. Given these deﬁnitions, it is clear how the
language of arrow logic should be interpreted. First, an arrow model is a structure
M = (F, V ) such that F = (W, C, R, I) is an arrow frame and V is a valuation.
Then:
M, a  1’ iff Ia,
M, a  ⊗φ iff M, b  φ for some b with Rab,
M, a  φ ◦ ψ iff M, b  φ and M, c  ψ for some b and c with Cabc.
When F is a square frame SU (as deﬁned in Example 1.8), this works out as
follows. V now maps propositional variables to sets of pairs over U ; that is, to1 Basic Concepts
24
binary relations. The truth deﬁnition can be rephrased as follows:
M, (a0 , a1 )  1’ iff a0 = a1 ,
M, (a0 , a1 )  ⊗φ iff M, (a1 , a0 )  φ,
M, (a0 , a1 )  φ ◦ ψ iff M, (a0 , u)  φ and M, (u, a1 )  ψ for some u ∈ U .
Such situations can be represented pictorially in two ways. First, one could draw
the graph-like structures as given in Example 1.8. Alternatively, one could draw
a square model two-dimensionally, as in the picture below. It will be obvious that
the modal constant 1’ holds precisely at the diagonal points and that ⊗φ is true at a
point iff φ holds at its mirror image with respect to the diagonal. The formula φ ◦ ψ
holds at a point a iff we can draw a rectangle abcd such that: b lies on the vertical
line through a, d lies on the horizontal line through a; and c lies on the diagonal.
q
q
dψ
q
aφ◦ψ
φ
1’
q
⊗φ
q
c
q
bφ
Frames and validity
It is time to deﬁne one of the key concepts in modal logic. So far we have been
viewing modal languages as tools for talking about models. But models are com-
posite entities consisting of a frame (our underlying ontology) and contingent in-
formation (the valuation). We often want to ignore the effects of the valuation and
get a grip on the more fundamental level of frames. The concept of validity lets
us do this. A formula is valid on a frame if it is true at every state in every model
that can be built over the frame. In effect, this concept interprets modal formulas
on frames by abstracting away from the effects of particular valuations.
Deﬁnition 1.28 A formula φ is valid at a state w in a frame F (notation: F, w  φ)
if φ is true at w in every model (F, V ) based on F; φ is valid in a frame F (notation:
F  φ) if it is valid at every state in F. A formula φ is valid on a class of frames
F (notation: F  φ) if it is valid on every frame F in F; and it is valid (notation:
 φ) if it is valid on the class of all frames. The set of all formulas that are valid in
a class of frames F is called the logic of F (notation: ΛF ).1.3 Models and Frames
25
Our deﬁnition of the logic of a frame class F (as the set of ‘all’ formulas that
are valid on F) is underspeciﬁed: we did not say which collection of proposition
letters Φ should be used to build formulas. But usually the precise form of this
collection is irrelevant for our purposes. On the few occasions in this book where
more precision is required, we will explicitly deal with the issue. (If the reader is
worried about this, he or she may just ﬁx a countable set Φ of proposition letters
and deﬁne ΛF to be {φ ∈ Form(τ, Φ) | F  φ}.)
As will become abundantly clear in the course of the book, validity differs from
truth in many ways. Here is a simple example. When a formula φ ∨ ψ is true at a
point w, this means that either φ or ψ is true at w (the satisfaction deﬁnition tells
us so). On the other hand, if φ ∨ ψ is valid on a frame F, this does not mean that
either φ or ψ is valid on F (p ∨ ¬p is a simple counterexample).
Example 1.29 (i) The formula 3(p ∨ q) → (3p ∨ 3q) is valid on all frames. To
see this, take any frame F and state w in F, and let V be a valuation on F. We have
to show that if (F, V ), w  3(p ∨ q), then (F, V ), w  3p ∨ 3q. So assume that
(F, V ), w  3(p ∨ q). Then, by deﬁnition there is a state v such that Rwv and
(F, V ), v  p ∨ q. But, if v  p ∨ q then either v  p or v  q. Hence either
w  3p or w  3q. Either way, w  3p ∨ 3q.
(ii) The formula 33p → 3p is not valid on all frames. To see this we need to
ﬁnd a frame F, a state w in F, and a valuation on F that falsiﬁes the formula at w.
So let F be a three-point frame with universe {0, 1, 2} and relation {(0, 1), (1, 2)}.
Let V be any valuation on F such that V (p) = {2}. Then (F, V ), 0  33p, but
(F, V ), 0  3p since 0 is not related to 2.
(iii) But there is a class of frames on which 33p → 3p is valid: the class
of transitive frames. To see this, take any transitive frame F and state w in F,
and let V be a valuation on F. We have to show that if (F, V ), w  33p, then
(F, V ), w  3p. So assume that (F, V ), w  33p. Then by deﬁnition there are
states u and v such that Rwu and Ruv and (F, V ), v  p. But as R is transitive, it
follows that Rwv, hence (F, V ), w  3p.
(iv) As the previous example suggests, when additional constraints are imposed
on frames, more formulas may become valid. For example, consider the frame
depicted in Figure 1.2. On this frame the formula ap → bp is not valid; a coun-
termodel is obtained by putting V (p) = {w2 }. Now, consider a frame satisfying
the condition Ra ⊆ Rb ; an example is depicted in Figure 1.7.
w
s
a -
s
-
b
b

Fig. 1.7. A frame satisfying R a ⊆ Rb26
1 Basic Concepts
On this frame it is impossible to refute the formula ap → bp at w, because a
refutation would require the existence of a point u with Ra wu and p true at u, but
not Rb wu; but such points are forbidden when we insist that Ra ⊆ Rb .
This is a completely general point: in every frame F of the appropriate similarity
type, if F satisﬁes the condition Ra ⊆ Rb , then ap → bp is valid in F. More-
over, the converse to this statement also holds: whenever ap → bp is valid on
a given frame F, then the frame must satisfy the condition Ra ⊆ Rb . To use the
terminology we will introduce in Chapter 3, the formula ap → bp deﬁnes the
property that Ra ⊆ Rb .
(v) When interpreting the basic temporal language (see Example 1.25) we ob-
served that arbitrary frames of the form (W, RP , RF ) were uninteresting given the
intended interpretation of F and P , and we insisted on interpreting them using a
relation R and its converse. Interestingly, there is a sense in which the basic tempo-
ral language itself is strong enough to enforce the condition that the relation RP is
the converse of the relation RF : such frames are precisely the ones which validate
both the formulas p → GP p and p → HF p; see Exercise 3.1.1.
(vi) The formula F q → F F q is not valid on all frames. To see this we need
to ﬁnd a frame T = (T, R), a state t in T, and a valuation on T that falsiﬁes
this formula at t. So let T = {0, 1}, and let R be the relation {(0, 1)}. Let
V be a valuation such that V (p) = {1}. Then (T, V ), 0  F p, but obviously
(T, V ), 0  F F p.
(vii) But there is a frame on which F p → F F p is valid. As the universe of the
frame take the set of all rational numbers Q, and let the frame relation be the usual
<-ordering on Q. To show that F p → F F p is valid on this frame, take any point
t in it, and any valuation V such that (Q, <, V ), t  F p; we have to show that
t  F F p. But this is easy: as t  F p, there exists a t such that t < t and t  p.
Because we are working on the rationals, there must be an s with t < s and s < t
(for example, (t + t )/2). As s  F p, it follows that t  F F p.
(viii) The special conditions demanded of PDL models also give rise to validities.
For example,
π1 ; π2 p ↔ π1 π2 p
is valid on any frame such that Rπ1 ;π2 = Rπ1 ◦ Rπ2 , and in fact the converse is also
true. The reader is asked to prove this in Exercise 3.1.2.
(ix) In our last example we consider arrow logic. We claim that in any square
arrow frame SU , the formula ⊗(p ◦ q) → ⊗q ◦ ⊗p is valid. For, let V be a
valuation on SU , and suppose that for some pair of points u, v in U , we have
(SU , V ), (u, v)  ⊗(p ◦ q). It follows that (SU , V ), (v, u)  p ◦ q, and hence,
there must be a w ∈ U for which (SU , V ), (v, w)  p and (SU , V ), (w, u)  q.
But then we have (SU , V ), (w, v)  ⊗p and (SU , V ), (u, w)  ⊗q. This in turn
implies that (SU , V ), (u, v)  ⊗q ◦ ⊗p.1.3 Models and Frames
27
Exercises for Section 1.3
1.3.1 Show that when evaluating a formula φ in a model, the only relevant information in
the valuation is the assignments it makes to the propositional letters actually occurring in
φ. More precisely, let F be a frame, and V and V  be two valuations on F such that V (p) =
V  (p) for all proposition letters p in φ. Show that (F, V )  φ iff (F, V  )  φ. Work in the
basic modal language. Do this exercise by induction on the number of connectives in φ (or
as we usually put it, by induction on φ). (If you are unsure how to do this, glance ahead to
Proposition 2.3 where such a proof is given in detail.)
1.3.2 Let N = (N, S1 , S2 ) and B = (B, R1 , R2 ) be the following frames for a modal
similarity type with two diamonds 3 1 and 32 . Here N is the set of natural numbers, B is
the set of strings of 0s and 1s, and the relations are deﬁned by
mS1 n
mS2 n
sR1 t
sR2 t
iff
iff
iff
iff
n = m + 1,
m > n,
t = s0 or t = s1,
t is a proper initial segment of s.
Which of the following formulas are valid on N and B, respectively?
(a) (31 p ∧ 31 q) → 31 (p ∧ q),
(b) (32 p ∧ 32 q) → 32 (p ∧ q),
(c) (31 p ∧ 31 q ∧ 31 r) → (31 (p ∧ q) ∨ 31 (p ∧ r) ∨ 31 (q ∧ r)),
(d) p → 31 22 p,
(e) p → 32 21 p,
(f) p → 21 32 p,
(g) p → 22 31 p.
1.3.3 Consider the basic temporal language and the frames (Z, <), (Q, <) and (R, <)
(the integer, rational, and real numbers, respectively, all ordered by the usual less-than
relation <). In this exercise we use Eφ to abbreviate P φ ∨ φ ∨ F φ, and Aφ to abbreviate
Hφ ∧ φ ∧ Gφ. Which of the following formulas are valid on these frames?
(a) GGp → p,
(b) (p ∧ Hp) → F Hp,
(c) (Ep ∧ E¬p ∧ A(p → Hp) ∧ A(¬p → G¬p)) → E(Hp ∧ G¬p).
1.3.4 Show that every formula that has the form of a propositional tautology is valid.
Further, show that 2(p → q) → (2p → 2q) is valid.
1.3.5 Show that each of the following formulas is not valid by constructing a frame F =
(W, R) that refutes it.
(a) ⊥,
(b) 3p → 2p,
(c) p → 23p,
(d) 32p → 23p.
Find, for each of these formulas, a non-empty class of frames on which it is valid.
1.3.6 Show that the arrow formulas φ ◦ (ψ ◦ χ) ↔ (φ ◦ ψ) ◦ χ and 1’ ◦ φ ↔ φ are valid in
any square.1 Basic Concepts
28
1.4 General Frames
At the level of models the fundamental concept is satisfaction. This is a relatively
simple concept involving only a frame and a single valuation. By ascending to the
level of frames we get a deeper grip on relational structures – but there is a price to
pay. Validity lacks the concrete character of satisfaction, for it is deﬁned in terms of
all valuations on a frame. However, there is an intermediate level: a general frame
(F, A) is a frame F together with a restricted, but suitably well-behaved collection
A of admissible valuations.
General frames are useful for at least two reasons. First, there may be appli-
cation driven motivations to exclude certain valuations. For instance, if we were
using (N, <) to model the temporal distribution of outputs from a computational
device, it would be unreasonable to let valuations assign non-recursively enumer-
able sets to propositional variables. But perhaps the most important reason to work
with general frames is that they support a notion of validity that is mathematically
simpler than the frame-based one, without losing too many of the concrete prop-
erties that make models so easy to work with. This ‘simpler behavior’ will only
really become apparent when we discuss the algebraic perspective on complete-
ness theory in Chapter 5. It will turn out that there is a fundamental and universal
completeness result for general frame validity, something that the frame semantics
lacks. Moreover, we will discover that general frames are essentially a set-theoretic
representation of boolean algebras with operators. Thus, the A in (W, R, A) stands
not only for Admissible, but also for Algebra.
So what is a ‘suitably well-behaved collection of valuations’? It simply means a
collection of valuations closed under the set-theoretic operations corresponding to
our connectives and modal operators. Now, fairly obviously, the boolean connec-
tives correspond to the boolean operations of union, relative complement, and so
on – but what operations on sets do modalities correspond to? Here is the answer.
Let us ﬁrst consider the basic modal similarity type with one diamond. Given a
frame F = (W, R), let mR be the following operation on the power set of W :
mR (X) = {w ∈ W | Rwx for some x ∈ X }.
Think of mR (X) as the set of states that ‘see’ a state in X. This operation corre-
sponds to the diamond in the sense that for any valuation V and any formula φ we
have V (3φ) = mR (V (φ)).
Moving to the general case, we obtain the following deﬁnition.
Deﬁnition 1.30 Given an (n + 1)-ary relation R on a set W , we deﬁne the follow-
ing n-ary operation mR on the power set P(W ) of W :
mR (X1 , . . . , Xn ) =
{w ∈ W | Rww1 . . . wn for some w1 ∈ X1 , . . . , wn ∈ Xn }.1.4 General Frames
29
Example 1.31 Let ⊗ be the converse operator of arrow logic, and recall that we
use the letter R to denote the accessibility relation for ⊗. Thus on a square frame
SU , by the rather special nature of R, we have that, for any subset X of U2 :
mR (X) = {(a0 , a1 ) ∈ U 2 | a0 = x1 and a1 = x0 for some (x0 , x1 ) ∈ X }
= {(x1 , x0 ) ∈ U 2 | (x0 , x1 ) ∈ X}.
In other words, mR (X) is nothing but the converse of the binary relation X.
Deﬁnition 1.32 (General Frames) Let τ be a modal similarity type. A general τ -
frame is a pair (F, A) where F = (W, R)∈τ is a τ -frame, and A is a non-empty
collection of admissible subsets of W closed under the following operations:
(i) union: if X, Y ∈ A, then X ∪ Y ∈ A.
(ii) relative complement: if X ∈ A, then W \ X ∈ A.
(iii) modal operations: if X1 , . . . , Xn ∈ A, then mR (X1 , . . . , Xn ) ∈ A for all
 ∈ τ.
A model based on a general frame is a triple (F, A, V ) where (F, A) is a general
frame and V is a valuation satisfying the constraint that for each proposition letter
p, V (p) is an element of A. Valuations satisfying this constraint are called admis-
sible for (F, A).
It follows immediately from the ﬁrst two clauses of the deﬁnition that both the
empty set and the universe of a general frame are always admissible. Note that
an ordinary frame F = (W, R)∈τ can be regarded as a general frame where
A = P(W ) (that is, a general frame in which all valuations are admissible). Also,
note that if a valuation V is admissible for a general frame (F, A), then the closure
conditions listed in Deﬁnition 1.32 guarantee that V (φ) ∈ A, for all formulas
φ. In short, a set of admissible valuations A is a ‘logically closed’ collection of
information assignments.
Deﬁnition 1.33 A formula φ is valid at a state w in a general frame (F, A) (no-
tation: (F, A), w  φ) if φ is true at w in every admissible model (F, A, V ) on
(F, A); and φ is valid in a general frame (F, A) (notation: (F, A)  φ) if φ is true
at every state in every admissible model (F, A, V ) on (F, A).
A formula φ is valid on a class of general frames G (notation: G  φ) if it is
valid on every general frame (F, A) in G. Finally, if φ is valid on the class of all
general frames we say that it is g-valid and write g φ. We will learn in Chapter 4
(see Exercise 4.1.1) that a formula φ is valid if and only if it is g-valid.
Clearly, for any frame F, if F  φ then for any collection of admissible assign-
ments A on F, we have (F, A)  φ too. The converse does not hold. Here is a
counterexample that will be useful in Chapter 4.1 Basic Concepts
30
Example 1.34 Consider the McKinsey formula, 23p → 32p. It is easy to see
that the McKinsey formula is not valid on the frame (N, <), for we obtain a coun-
termodel by choosing a valuation for p that lets the truth value of p alternate in-
ﬁnitely often (for instance, by letting V (p) be the collection of even numbers).
However, there is a general frame based on (N, <) in which the McKinsey for-
mula is valid. First some terminology: a set is co-ﬁnite if its complement is ﬁnite.
Now consider the general frame f = (N, <, A), where A is the collection of all
ﬁnite and co-ﬁnite sets. We leave it as an exercise to show that f satisﬁes all the
constraints of Deﬁnition 1.32; see Exercise 1.4.5.
To see that the McKinsey formula is indeed valid on f, let V be an admissible
valuation, and let n ∈ N. If (f, V ), n  23p, then V (p) must be co-ﬁnite (why?),
hence for some k every state l ≥ k is in V (p). But this means that (f, V ), n  32p,
as required.
Although we will make an important comment about general frames in Section 3.2,
and use them to help prove an incompleteness result in Section 4.4, we will not re-
ally be in a position to grasp their signiﬁcance until Chapter 5, when we introduce
boolean algebras with operators. Until then, we will concentrate on modal lan-
guages as tools for talking about models and frames.
Exercises for Section 1.4
1.4.1 Deﬁne, analogous to m R , an operation l R on the power set of a frame such that for an
arbitrary modal formula φ and an arbitrary valuation V we have that l R (V (φ)) = V (2φ).
Extend this deﬁnition to the dual of a polyadic modal operator.
1.4.2 Consider the basic modal formula 3p → p.
(a) Construct a frame F = (W, R) and a general frame f = (F, A) such that F  3p →
p, but f  3p → p.
(b) Construct a general frame (F, A) and a valuation V on F such that (F, A)  3p →
p, but (F, V )  3p → p.
1.4.3 Show that if B is any collection of valuations over some frame F, then there is a
smallest general frame (F, A) such that B ⊆ A. (‘Smallest’ means that for any general
frame (F, A ) such that B ⊆ A , A ⊆ A .)
1.4.4 Recall that in any arrow frame, we use C and I to denote the relations associated
with the modalities ◦ and 1’, respectively. Show that for square arrow frames, the operation
mC is nothing but composition of two binary relations. What is m I ?
1.4.5 Consider the basic modal language, and the general frame f = (N, <, A), where A
is the collection of all ﬁnite and co-ﬁnite sets. Show that f is a general frame.
1.4.6 Consider the structure g = (N, C, A) where A is the collection of ﬁnite and co-ﬁnite
subsets of N, and C is deﬁned by
Cn1 n2 n3 iff n1 ≤ n2 + n3 and n2 ≤ n3 + n1 and n3 ≤ n1 + n2 .1.5 Modal Consequence Relations
31
If C is the accessibility relation of a dyadic modal operator, show that g is a general frame.
1.4.7 Let M = (F, V ) be some modal model. Prove that the structure
(F, {V (φ) | φ is a formula })
is a general frame.
1.5 Modal Consequence Relations
While the idea of validity in frames (and indeed, validity in general frames) gives
rise to logically interesting formulas, so far we have said nothing about what logical
consequence might mean for modal languages. That is, we have not explained what
it means for a set of modal formulas Σ to logically entail a modal formula φ.
This we will now do. In fact, we will introduce two families of consequence
relations: a local one and a global one. Both families will be deﬁned semantically;
that is, in terms of classes of structures. We will deﬁne these relations for all three
kinds of structures we have introduced, though in practice we will be primarily
interested in semantic consequence over frames. Before going further, a piece of
terminology. If S is a class of models, then a model from S is simply a model M in
S. On the other hand, if S is a class of frames (or a class of general frames) then a
model from S is a model based on a frame (general frame) in S.
What is a modally reasonable notion of logical consequence? Two things are
fairly clear. First, it seems sensible to hold on to the familiar idea that a relation
of semantic consequence holds when the truth of the premises guarantees the truth
of the conclusion. Second, it should be clear that the inferences we are entitled to
draw will depend on the class of structures we are working with. (For example,
different inferences will be legitimate on transitive and intransitive frames.) Thus
our deﬁnition of consequence will have to be parametric: it must make reference
to a class of structures S.
Here is the standard way of meeting these requirements. Suppose we are work-
ing with a class of structures S. Then, for a formula φ (the conclusion) to be a
logical consequence of Σ (the premises) we should insist that whenever Σ is true
at some point in some model from S, then φ should also be true in that same model
at the same point. In short, this deﬁnition demands that the maintenance of truth
should be guaranteed point to point or locally.
Deﬁnition 1.35 (Local Semantic Consequence) Let τ be a similarity type, and
let S be a class of structures of type τ (that is a class of models, a class of frames,
or a class of general frames of this type). Let Σ and φ be a set of formulas and
a single formula from a language of type τ . We say that φ is a local semantic
consequence of Σ over S (notation: Σ S φ) if for all models M from S, and all
points w in M, if M, w  Σ then M, w  φ.32
1 Basic Concepts
Example 1.36 Suppose that we are working with Tran, the class of transitive
frames. Then:
{33p} Tran 3p.
On the other hand, 3p is not a local semantic consequence of {33p} over the
class of all frames.
Local consequence is the notion of logical entailment explored in this book, but it
is by no means the only possibility. Here is an obvious variant.
Deﬁnition 1.37 (Global Semantic Consequence) Let τ , S, Σ and φ be as in Deﬁ-
nition 1.35. We say that φ is a global semantic consequence of Σ over S (notation:
Σ gS φ) if and only if for all structures S in S, if S  Σ then S  φ. (Here,
depending on the kind of structures S contains,  denotes either validity in a frame,
validity in a general frame, or global truth in a model.)
Again, this deﬁnition hinges on the idea that premises guarantee conclusions, but
here the guarantee covers global notions of correctness.
Example 1.38 The local and global consequence relations are different. Consider
the formulas p and 2p. It is easy to see that p does not locally imply 2p – indeed,
that this entailment should not hold is pretty much the essence of locality. On the
other hand, suppose that we consider a model M where p is globally true. Then p
certainly holds at all successors of all states, so M  2p, and so p g 2p.
Nonetheless, there is a systematic connection between the two consequence rela-
tions, as the reader is asked to show in Exercise 1.5.3.
Exercises for Section 1.5
1.5.1 Let K be a class of frames for the basic modal similarity type, and let M(K) denote
the class of models based on a frame in K. Prove that 2p  gM(K) p iff K |= ∀x∃y Ryx
(every point has a predecessor).
Does this equivalence hold as well if we work with  gK instead?
1.5.2 Let M denote the class of all models, and F the class of all frames. Show that if
Σ gM φ then Σ gF φ, but that the converse is false.
1.5.3 Let Σ be a set of formulas in the basic modal language, and let M denote the class
of all models. Show that Σ  gM φ iff {2n σ | σ ∈ Σ, n ∈ ω} M φ.
1.5.4 Again, let M denote the class of all models. Show that the local consequence relation
does have the deduction theorem: φ  M ψ iff  φ → ψ, but the global one does not.
However, show that on the class Tran of transitive models we have that φ  gTran ψ iff
gTran 2φ → ψ.1.6 Normal Modal Logics
33
1.6 Normal Modal Logics
Till now our discussion has been largely semantic; but logic has an important syn-
tactic dimension, and our discussion raises some obvious questions. Suppose we
are interested in a certain class of frames F: are there syntactic mechanisms capable
of generating ΛF , the formulas valid on F? And are such mechanisms capable of
coping with the associated semantic consequence relation? The modal logician’s
response to such questions is embodied in the concept of a normal modal logic.
A normal modal logic is simply a set of formulas satisfying certain syntactic clo-
sure conditions. Which conditions? We will work towards the answer by deﬁning a
Hilbert-style axiom system called K. K is the ‘minimal’ (or ‘weakest’) system for
reasoning about frames; stronger systems are obtained by adding extra axioms. We
discuss K in some detail, and then, at the end of the section, deﬁne normal modal
logics. By then, the reader will be in a position to see that the deﬁnition is a more-
or-less immediate abstraction from what is involved in Hilbert-style approaches to
modal proof theory. We will work in the basic modal language.
Deﬁnition 1.39 A K-proof is a ﬁnite sequence of formulas, each of which is an
axiom, or follows from one or more earlier items in the sequence by applying a
rule of proof . The axioms of K are all instances of propositional tautologies plus:
(K)
(Dual)
2(p → q) → (2p → 2q)
3p ↔ ¬2¬p.
The rules of proof of K are:
• Modus ponens: given φ and φ → ψ, prove ψ.
• Uniform substitution: given φ, prove θ, where θ is obtained from φ by uniformly
replacing proposition letters in φ by arbitrary formulas.
• Generalization: given φ, prove 2φ.
A formula φ is K-provable if it occurs as the last item of some K-proof, and if this
is the case we write K φ.
Some comments. Tautologies may contain modalities (for example, 3q ∨ ¬3q is a
tautology, as it has the same form as p ∨ ¬p). As tautologies are valid on all frames
(Exercise 1.3.4), they are a safe starting point for modal reasoning. Our decision
to add all propositional tautologies as axioms is an example of axiomatic overkill;
we could have chosen a small set of tautologies capable of generating the rest via
the rules of proof, but this reﬁnement is of little interest for our purposes.
Modus ponens is probably familiar to all our readers, but there are two important
points we should make. First, modus ponens preserves validity. That is, if  φ and
 φ → ψ then  ψ. Given that we want to reason about frames, this property is
crucial. Note, however, that modus ponens also preserves two further properties,34
1 Basic Concepts
namely global truth (if M  φ and M  φ → ψ then M  ψ) and satisﬁability
(if M, w  φ and M, w  φ → ψ then M, w  ψ). That is, modus ponens is not
only a correct rule for reasoning about frames, it is also a correct rule for reasoning
about models, both globally and locally.
Uniform substitution should also be familiar. It mirrors the fact that validity ab-
stracts away from the effects of particular assignments: if a formula is valid, this
cannot be because of the particular value its propositional symbols have, thus we
should be free to uniformly replace these symbols with any other formula what-
soever. And indeed, as the reader should check, uniform substitution preserves
validity. Note, however, that it does not preserve either global truth or satisﬁabil-
ity. (For example, q is obtainable from p by uniform substitution, but just because
p is globally true in some model, it does not follow that q is too!) In short, uniform
substitution is strictly a tool for generating new validities from old.
That is the classical core of our Hilbert system, so let us turn to the the genuinely
modal axioms and rules of proof. First the axioms. The K axiom is the fundamental
one. It is clearly valid (as the reader who has not done Exercise 1.3.4 should now
check) but why is it a useful addition to our Hilbert system?
K is sometimes called the distribution axiom, and is important because it lets us
transform 2(φ → ψ) (a boxed formula) into 2φ → 2ψ (an implication). This
box-over-arrow distribution enables further purely propositional reasoning to take
place. For example, suppose we are trying to prove 2ψ, and have constructed a
proof sequence containing both 2(φ → ψ) and 2φ. If we could apply modus
ponens under the scope of the box, we would have proved 2ψ. This is what distri-
bution lets us do: as K contains the axiom 2(p → q) → (2p → 2q), by uniform
substitution we can prove 2(φ → ψ) → (2φ → 2ψ). But then a ﬁrst application
of modus ponens proves 2φ → 2ψ, and a second proves 2ψ as desired.
The Dual axiom obviously reﬂects the duality of 3 and 2; nonetheless, readers
familiar with other discussions of K (many of which have K as the sole modal
axiom) may be surprised at its inclusion. Do we really need it? Yes, we do. In this
book, 3 is primitive and 2 is an abbreviation. Thus our K axiom is really shorthand
for ¬3¬(p → q) → (¬3¬p → ¬3¬q). We need a way to maneuver around
these negations, and this is the syntactic role that Dual plays. (Incidentally had we
chosen 2 as our primitive operator, Dual would not have been required.) We prefer
working with a primitive 3 (apart from anything else, it is more convenient for the
algebraic work of Chapter 5) and do not mind adding Dual as an extra axiom. Dual,
of course, is valid.
It only remains to discuss the modal rule of proof: generalization (another com-
mon name for it is necessitation). Generalization ‘modalizes’ provable formulas by
stacking boxes in front. Roughly speaking, while the K axiom lets us apply classi-
cal reasoning inside modal contexts, necessitation creates new modal contexts for
us to work with; modal proofs arise from the interplay of these two mechanisms.1.6 Normal Modal Logics
35
Note that generalization preserves validity: if it is impossible to falsify φ, then
obviously we will never be able to falsify φ at any accessible state! Similarly,
generalization preserves global truth. But it does not preserve satisfaction: just
because p is true in some state, we cannot conclude that p is true at all accessible
states.
K is the minimal modal Hilbert system in the following sense. As we have
seen, its axioms are all valid, and all three rules of inference preserve validity,
hence all K-provable formulas are valid. (To use the terminology introduced in
Deﬁnition 4.9, K is sound with respect to the class of all frames.) Moreover, as we
will prove in Theorem 4.23, the converse is also true: if a basic modal formula is
valid, then it is K-provable. (That is, K is complete with respect to the class of all
frames.) In short, K generates precisely the valid formulas.
Example 1.40 The formula (2p ∧ 2q) → 2(p ∧ q) is valid on any frame, so
it should be K-provable. And indeed, it is. To see this, consider the following
sequence of formulas:
1.
2.
3.
4.
5.
6.
7.
8.
 p → (q → (p ∧ q))
Tautology
 2(p → (q → (p ∧ q)))
Generalization: 1
 2(p → q) → (2p → 2q)
K axiom
 2(p → (q → (p ∧ q))) → (2p → 2(q → (p ∧ q)))
Uniform Substitution: 3
 2p → 2(q → (p ∧ q))
Modus Ponens: 2, 4
 2(q → (p ∧ q)) → (2q → 2(p ∧ q)) Uniform Substitution: 3
 2p → (2q → 2(p ∧ q))
Propositional Logic: 5, 6
 (2p ∧ 2q) → 2(p ∧ q)
Propositional Logic: 7
Strictly speaking, this sequence is not a K-proof – it is a subsequence of the proof
consisting of the most important items. The annotations in the right-hand column
should be self-explanatory; for example ‘Modus Ponens: 2, 4’ labels the formula
obtained from the second and fourth formulas in the sequence by applying modus
ponens. To obtain the full proof, ﬁll in the items that lead from line 6 to 8.
Remark 1.41 Warning: there is a pitfall that is very easy to fall into if you are used
to working with natural deduction systems: we cannot freely make and discharge
assumptions in the Hilbert system K. The following ‘proof’ shows what can go
wrong if we do:
1. p
Assumption
2. 2p
Generalization: 1
3. p → 2p Discharge assumption
So we have ‘proved’ p → 2p! This is obviously wrong: this formula is not valid,
hence it is not K-provable. And it should be clear where we have gone wrong:36
1 Basic Concepts
we cannot use assumptions as input to generalization, for, as we have already re-
marked, this rule does not preserve satisﬁability. Generalization is there to enable
us to generate new validities from old. It is not a local rule of inference.
For many purposes, K is too weak. If we are interested in transitive frames, we
would like a proof system which reﬂects this. For example, we know that 33p →
3p is valid on all transitive frames, so we would want a proof system that generates
this formula; K does not do this, for 33p → 3p is not valid on all frames.
But we can extend K to cope with many such restrictions by adding extra ax-
ioms. For example, if we enrich K by adding 33p → 3p as an axiom, we obtain
the Hilbert system called K4. As we will show in Theorem 4.27, K4 is sound and
complete with respect to the class of all transitive frames (that is, it generates pre-
cisely the formulas valid on transitive frames). More generally, given any set of
modal formulas Γ , we are free to add them as extra axioms to K, thus forming the
axiom system KΓ. As we will learn in Chapter 4, in many important cases it is
possible to characterize such extensions in terms of frame validity.
One ﬁnal issue remains to be discussed: do such axiomatic extensions of K give
us a grip on semantic consequence, and in particular, the local semantic conse-
quence relation over classes of frames (see Deﬁnition 1.35)?
In many important cases they do. Here is the basic idea. Suppose we are inter-
ested in transitive frames, and are working with K4. We capture the notion of local
consequence over transitive frames in K4 as follows. Let Σ be a set of formulas,
and φ a formula. Then we say that φ is a local syntactic consequence of Σ in K4
(notation: Σ K4 φ) if and only if there is some ﬁnite subset {σ1 , . . . , σn } of Σ
such that K4 σ1 ∧ · · · ∧ σn → φ. In Theorem 4.27 we will show that
Σ K4 φ iff Σ Tran φ,
where Tran denotes local semantic consequence over transitive frames. In short,
we have reduced the local semantic consequence relation over transitive frames to
provability in K4.
Deﬁnition 1.42 (Normal Modal Logics) A normal modal logic Λ is a set of for-
mulas that contains all tautologies, 2(p → q) → (2p → 2q), and 3p ↔ ¬2¬p,
and that is closed under modus ponens, uniform substitution and generalization.
We call the smallest normal modal logic K.
This deﬁnition is a direct abstraction from the ideas underlying modal Hilbert sys-
tems. It throws away all talk of proof sequences and concentrates on what is really
essential: the presence of axioms and closure under the rules of proof.
We will rarely mention Hilbert systems again: we prefer to work with the more
abstract notion of normal modal logics. For a start, although the two approaches
are equivalent (see Exercise 1.6.6), it is simpler to work with the set-theoretical1.7 Historical Overview
37
notion of membership than with proof sequences. More importantly, in Chapters 4
and 5 we will prove results that link the semantic and syntactic perspectives on
modal logic. These results will hold for any set of formulas fulﬁlling the normality
requirements. Such a set might be the formulas generated by a Hilbert-style proof
system – but it could just as well be the formulas provable in a natural-deduction
system, a sequent system, a tableaux system, or a display calculus. Finally, the
concept of a normal modal logic makes good semantic sense: for any class of
frames F, we have that ΛF , the set of formulas valid on F, is a normal modal logic;
see Exercise 1.6.7.
Exercises for Section 1.6
1.6.1 Give K-proofs of (2p ∧ 3q) → 3(p ∧ q) and 3(p ∨ q) ↔ (3p ∨ 3q).
1.6.2 Let φ− be the ‘demodalized’ version of a modal formula φ; that is, φ − is obtained
from φ by simply erasing all diamonds. Prove that φ − is a propositional tautology when-
ever φ is K-provable. Conclude that not every modal formula is K-provable.
1.6.3 The axiom system known as S4 is obtained by adding the axiom p → 3p to K4.
Show that S4 p → 23p; that is, show that S4 does not prove this formula. (Hint: ﬁnd an
appropriate class of frames for which S4 is sound.) If we add this formula as an axiom to
S4 we obtain the system called S5. Give an S5-proof of 32p → 2p.
1.6.4 Try adapting K to obtain a minimal Hilbert system for the basic temporal language.
Does your system cope with the fact that we only interpret this language on bidirectional
frames? Then try and deﬁne a minimal Hilbert system for the language of propositional
dynamic logic.
1.6.5 This exercise is only for readers who like syntactical manipulations and have a lot
of time to spare. KL is the axiomatization obtained by adding the Löb formula 2(2p →
p) → 2p as an extra axiom to K. Try and ﬁnd a KL proof of 2p → 22p. That is, show
that KL = KL4.
1.6.6 In Chapter 4 we will use KΓ to denote the smallest normal modal logic containing
Γ ; the point of the present exercise is to relate this notation to our discussion of Hilbert
systems. So (as discussed above) suppose we form the axiom system KΓ by adding as
axioms all the formulas in Γ to K. Show that the Hilbert system KΓ proves precisely the
formulas contained in the normal modal logic KΓ.
1.6.7 Let F be a class of frames. Show that Λ F is a normal modal logic.
1.7 Historical Overview
The ideas introduced in this chapter have a long history. They evolved as responses
to particular problems and challenges, and knowing something of the context in38
1 Basic Concepts
which they arose will make it easier to appreciate why they are considered im-
portant, and the way they will be developed in subsequent chapters. Some of the
discussion that follows may not be completely accessible at this stage. If so, do not
worry. Just note the main points, and try again once you have explored the chapters
that follow.
We ﬁnd it useful to distinguish three phases in the development of modal logic:
the syntactic era, the classical era, and the modern era. Roughly speaking, most of
the ideas introduced in this chapter stem from the classical era, and the remainder
of the book will explore them from the point of view of the modern era.
The syntactic era (1918–1959)
We have opted for 1918, the year that C.I. Lewis published his Survey of Symbolic
Logic [299], as the birth of modal logic as a mathematical discipline. Lewis was
certainly not the ﬁrst to consider modal reasoning, indeed he was not even the
ﬁrst to construct symbolic systems for this purpose: Hugh MacColl, who explored
the consequences of enriching propositional logic with operators  (‘it is certain
that’) and η (‘it is impossible that’) seems to have been the ﬁrst to do that (see
his book Symbolic Logic and its Applications [305], and for an overview of his
work, see [369]). But MacColl’s work is ﬁrmly rooted in the nineteenth century
algebraic tradition of logic (well-known names in this tradition include Boole, De
Morgan, Jevons, Peirce, Schröder, and Venn), and linking MacColl’s contributions
to contemporary concerns is a non-trivial scholarly task. The link between Lewis’s
work and contemporary modal logic is more straightforward.
In his 1918 book, Lewis extended propositional calculus with a unary modality
I (‘it is impossible that’) and deﬁned the binary modality φ ≺ ψ (φ strictly implies
ψ) to be I(φ ∧ ¬ψ). Strict implication was meant to capture the notion of logical
entailment, and Lewis presented a ≺-based axiom system. Lewis and Langford’s
joint book Symbolic Logic [300], published in 1932, contains a more detailed de-
velopment of Lewis’s ideas. Here 3 (‘it is possible that’) is primitive and φ ≺ ψ
is deﬁned to be ¬3(φ ∧ ¬ψ). Five axiom systems of ascending strength, S1–S5,
are discussed; S3 is equivalent to Lewis’s system of 1918, and only S4 and S5 are
normal modal logics. Lewis’s work sparked interest in the idea of ‘modalizing’
propositional logic, and there were many attempts to axiomatize such concepts as
obligation, belief and knowledge. Von Wright’s monograph An Essay in Modal
Logic [464] is an important example of this type of work.
But in important respects, Lewis’s work seems strange to modern eyes. For a
start, his axiomatic systems are not modular. Instead of extending a base system of
propositional logic with speciﬁcally modal axioms (as we did in this chapter when
we deﬁned K), Lewis deﬁnes his axioms directly in terms of ≺. The modular
approach to modal Hilbert systems is due to Kurt Gödel. Gödel [175] showed1.7 Historical Overview
39
that (propositional) intuitionistic logic could be translated into S4 in a theorem-
preserving way. However instead of using the Lewis and Langford axiomatization,
Gödel took 2 as primitive and formulated S4 in the way that has become standard:
he enriched a standard system for classical propositional logic with the rule of
generalization, the K axiom, and the additional axioms (2p → p and 2p → 22p).
But the fundamental difference between current modal logic and the work of
Lewis and his contemporaries is that the latter is essentially syntactic. Propositional
logic is enriched with some new modality. By considering various axioms, the
logician tries to pin down the logic of the intended interpretation. This simple view
of logical modeling has its attractions, but is open to serious objections. First, there
are technical difﬁculties. Suppose we have several rival axiomatizations of some
concept. Forget for now the problem of judging which is the best, for there is a
more basic difﬁculty: how can we tell if they are really different? If we only have
access to syntactic ideas, proving that two Hilbert systems generate different sets
of formulas can be extremely difﬁcult. Indeed, even showing syntactically that two
Hilbert systems generate the same set of formulas can be highly non-trivial (recall
Exercise 1.6.5).
Proving distinctness theorems was standard activity in the syntactic era; for in-
stance, Parry [355] showed that S2 and S3 are distinct, and papers addressing such
problems were common till the late 1950s. Algebraic methods were often used to
prove distinctness. The propositional symbols would be viewed as denoting the
elements of some algebra, and complex formulas would be interpreted using the
algebraic operations. Indeed, algebras were the key tool driving the technical de-
velopment of the period. For example, McKinsey [322] used them to analyze S2
and S4 and show their decidability; McKinsey and Tarski [324, 325] and McKin-
sey [323] extended this work in a variety of directions (giving, among other things,
a topological interpretation of S4); while Dummett and Lemmon [117] built on this
work to isolate and analyze S4.2 and S4.3, two important normal logics between
S4 and S5. But for all their technical utility, algebraic methods seemed of limited
help in providing reliable intuitions about modal languages and their associated
logics. Sometimes algebraic elements were viewed as multiple truth values. But
Dugundji [116] showed that no logic between S1 and S5 could be viewed as an
n-valued logic for ﬁnite n, so the multi-valued perspective on modal logic was not
suited as a reliable source of insight.
The lack of a natural semantics brings up a deeper problem facing the syntac-
tic approach: how do we know we have considered all the relevant possibilities?
Nowadays the normal logic T (that is, K enriched with the axiom p → 3p) would
be considered a fundamental logic of possibility; but Lewis overlooked T (it is
intermediate between S2 and S4 and neither contains nor is contained by S3).
Moreover, although Lewis did isolate two logics still considered important (namely
S4 and S5), how could he claim that either system was, in any interesting sense,40
1 Basic Concepts
complete? Perhaps there are important axioms missing from both systems? The
existence of so many competing logics should make us skeptical of claims that it
is easy to ﬁnd all the relevant axioms and rules; and without precise, intuitively
acceptable, criteria of what the reasonable logics are (in short, the type of crite-
ria a decent semantics provides us with) we have no reasonable basis for claiming
success.
For further discussion of the work of this period, the reader should consult the
historical section of Bull and Segerberg [75]). We close our discussion of the syn-
tactic era by noting three lines of work that anticipate later developments: Carnap’s
state-description semantics, Prior’s work on temporal logic, and the Jónsson and
Tarski Representation Theorem for boolean algebras with operators.
A state description is simply a collection of propositional letters. (Actually,
Carnap used state descriptions in his pioneering work on ﬁrst-order modal logic,
so a state for Carnap could be a set of ﬁrst-order formulas.) If S is a collection of
state descriptions, and s ∈ S, then a propositional symbol p is satisﬁed at s if and
only if p ∈ s. Boolean operators are interpreted in the obvious way. Finally, 3φ is
satisﬁed at s ∈ S if and only if there is some s ∈ S such that s satisﬁes φ. (See,
for example, Carnap [85, 86].)
Carnap’s interpretation of 3φ in state descriptions is strikingly close to the idea
of satisfaction in models. However one crucial idea is missing: the use of an
explicit relation R over state descriptions. In Carnap’s semantics, satisfaction for
3 is deﬁned in terms of membership in S (in effect, R is taken to be S × S). This
implicit ﬁxing of R reduces the utility of his semantics: it yields a semantics for
one ﬁxed interpretation of 3, but deprives us of the vital parameter needed to map
logical options.
Arthur Prior founded temporal logic (or as he called it, tense logic) in the early
1950s. He invented the basic temporal language and many other temporal lan-
guages, both modal and non-modal. Like most of his contemporaries, Prior viewed
the axiomatic exploration of concepts as one of the logician’s key tasks. But there
the similarity ends: his writings are packed with an extraordinary number of se-
mantic ideas and insights. By 1955 Prior had interpreted the basic modal lan-
guage in models based on (ω, <) (see Prior [364], and Chapter 2 of Prior [365]),
and used what would now be called soundness arguments to distinguish logics.
Moreover, the relative expressivity of modal and classical languages (such as the
Prior-Meredith U-calculus [327]) is a constant theme of his writings; indeed, much
of his work anticipates later work in correspondence theory and extended modal
logic. His work is hard to categorize, and impossible to summarize, but one thing
is clear: because of his inﬂuence temporal logic was an essentially semantically
driven enterprise. The best way into his work is via Prior [365].
With the work of Jónsson and Tarski [255, 256] we reach the most important
(and puzzling) might-have-beens in the history of modal logic. Brieﬂy, Jónsson1.7 Historical Overview
41
and Tarski investigated the representation theory of boolean algebras with operators
(that is, modal algebras). As we have remarked, while modal algebras were useful
tools, they seemed of little help in guiding logical intuitions. The representation
theory of Jónsson and Tarski should have swept this apparent shortcoming away for
good, for in essence they showed how to represent modal algebras as the structures
we now call models! In fact, they did a lot more than this. Their representation
technique is essentially a model building technique, hence their work gave the
technical tools needed to prove the completeness result that dominated the classical
era (indeed, their approach is an algebraic analog of the canonical model technique
that emerged 15 years later). Moreover, they provided all this for modal languages
of arbitrary similarity type, not simply the basic modal language.
Unfortunately, their work was overlooked for 20 years; not until the start of the
modern era was its signiﬁcance appreciated. It is unclear to us why this happened.
Certainly it did not help matters that Jónsson and Tarski do not mention modal
logic in their classic article; this is curious since Tarski had already published joint
papers with McKinsey on algebraic approaches to modal logic. Maybe Tarski did
not see the connection at all: Copeland [97, page 13] writes that Tarski heard
Kripke speak about relational semantics at a 1962 talk in Finland, a talk in which
Kripke stressed the importance of the work by Jónsson and Tarski. According to
Kripke, following the talk Tarski approached him and said he was unable to see
any connection between the two lines of work.
Even if we admit that a connection which now seems obvious may not have
been so at the time, a puzzle remains. Tarski was based in California, which in
the 1960s was the leading center of research in modal logic, yet in all those years,
the connection was never made. For example, in 1966 Lemmon (also based in
California) published a two part paper on algebraic approaches to modal logic [295]
which reinvented (some of) the ideas in Jónsson and Tarski (Lemmon attributes
these ideas to Dana Scott), but only cites the earlier Tarski and McKinsey papers.
We present the work by Jónsson and Tarski in Chapter 5; their Representation
Theorem underpins the work of the entire chapter.
The classical era (1959–1972)
‘Revolutionary’ is an overused word, but no other word adequately describes the
impact relational semantics (that is, the concepts of frames, models, satisfaction,
and validity presented in this chapter) had on the study of modal logic. Problems
which had previously been difﬁcult (for example, distinguishing Hilbert systems)
suddenly yielded to straightforward semantic arguments. Moreover, like all revolu-
tions worthy of the name, the new world view came bearing an ambitious research
program. Much of this program revolved around the concept of completeness: at
last is was possible to give a precise and natural meaning to claims that a logic gen-42
1 Basic Concepts
erated everything it ought to. (For example, K4 could now be claimed complete
in a genuinely interesting sense: it generated all the formulas valid on transitive
frames.) Such semantic characterizations are both simple and beautiful (especially
when viewed against the complexities of the preceding era) and the hunt for such
results was to dominate technical work for the next 15 years. The two outstanding
monographs of the classical era – the existing fragment of Lemmon and Scott’s An
Introduction to Modal Logic [296], and Segerberg’s An Essay in Classical Modal
Logic [404] – are largely devoted to completeness issues.
Some controversy attaches to the birth of the classical era. Brieﬂy, relational
semantics is often called Kripke semantics, and Kripke [283] (in which S5-based
modal predicate logic is proved complete with respect to models with an implicit
global relation), Kripke [284] (which introduces an explicit accessibility relation R
and gives semantic characterization of some propositional modal logics in terms of
this relation) and Kripke [285] (in which relational semantics for ﬁrst-order modal
languages is deﬁned) were crucial in establishing the relational approach: they are
clear, precise, and ever alert to the possibilities inherent in the new framework: for
example, Kripke [285] discusses provability interpretations of propositional modal
languages. Nonetheless, Hintikka had already made use of relational semantics to
analyze the concept of belief and distinguish logics, and Hintikka’s ideas played
an important role in establishing the new paradigm in philosophical circles; see,
for example, [224]. Furthermore, it has since emerged that Kanger, in a series of
papers and monographs published in 1957, had introduced the basic idea of rela-
tional semantics for propositional and ﬁrst-order modal logic; see, for example,
Kanger [261, 262]. And a number of other authors (such as Arthur Prior, and
Richard Montague [335]) had either published or spoken about similar ideas ear-
lier. Finally, the fact remains that Jónsson and Tarski had already presented and
generalized the mathematical ideas needed to analyze propositional modal logics.
But disputes over priority should not distract the reader from the essential point:
somewhere around 1960 modal logic was reborn as a new ﬁeld, acquiring new
questions, methods, and perspectives. The magnitude of the shift, not who did
what when, is what is important here. (The reader interested in more detail on who
did what when, should consult Goldblatt [182]. Incidentally, Goldblatt concludes
that Kripke’s contributions were the most signiﬁcant.)
So by the early 1960s it was clear that relational semantics was an important tool
for classifying modal logics. But how could its potential be unlocked? The key tool
required – the canonical models we discuss in Chapter 4 – emerged with surpris-
ing speed. They seem to have ﬁrst been used in Makinson [307] and in Cress-
well [99] (although Cresswell’s so-called subordination relation differs slightly
from the canonical relation), and in Lemmon and Scott [296] they appear full-
ﬂedged in the form that has become standard.
Lemmon and Scott [296] is a fragment of an ambitious monograph that was in-1.7 Historical Overview
43
tended to cover all then current branches of modal logic. At the time of Lemmon’s
death in 1966, however, only the historical introduction and the chapter on the ba-
sic modal languages had been completed. Nonetheless, it is a gem. Although for
the next decade it circulated only in manuscript form (it was not published until
1977) it was enormously inﬂuential, setting much of the agenda for subsequent
developments. It unequivocally established the power of the canonical model tech-
nique, using it to prove general results of a sort not hitherto seen. It also introduced
ﬁltrations, an important technique for building ﬁnite models we will discuss in
Chapter 2, and used them to prove a number of decidability results.
While Lemmon and Scott showed how to exploit canonical models directly,
many important normal logics (notably, KL and the modal and temporal logic of
structures such as (N, <), (Z, <), (Q, <), and (R, <), and their reﬂexive counter-
parts) cannot be analyzed in this way. However, as Segerberg [403, 404] showed,
it is possible to use canonical models indirectly: one can transform the canonical
model into the required form and prove these (and a great many other) complete-
ness results. Segerberg-style transformation proofs are discussed in Section 4.5.
But although completeness and canonical models were the dominant issues of
the classical era, there is a small body of work which anticipates more recent
themes. For example, Robert Bull, swimming against the tide of fashion, used
algebraic arguments to prove a striking result: all normal extensions of S4.3 are
characterized by classes of ﬁnite models (see Bull [74]). Although model-theoretic
proofs of Bull’s Theorem were sought (see, for example, Segerberg [404, page
170]), not until Fine [128] did these efforts succeed. Kit Fine was shortly to play a
key role in the birth of the modern era, and the technical sophistication which was
to characterize his later work is already evident in this paper; we discuss Fine’s
proof in Theorem 4.96. As a second example, in his 1968 PhD thesis [258], Hans
Kamp proved one of the few (and certainly the most interesting) expressivity results
of the era. He deﬁned two natural binary modalities, since and until (discussed in
Chapter 7), showed that the standard temporal language was not strong enough to
deﬁne them, and proved that over Dedekind continuous strict total orders (such as
(R, <)) his new modalities offered full ﬁrst-order expressive power.
Summing up, the classical era supplied many of the fundamental concepts and
methods used in contemporary modal logic. Nonetheless, viewed from a modern
perspective, it is striking how differently these ideas were put to work then. For
a start, the classical era took over many of the goals of the syntactic era. Modal
investigations still revolved round much the same group of concepts: necessity,
belief, obligation and time. Moreover, although modal research in the classical era
was certainly not syntactical, it was, by and large, syntactically driven. That is –
with the notable exception of the temporal tradition – relational semantics seems
to have been largely viewed as a tool for analyzing logics: soundness results could
distinguish logics, and completeness results could give them nice characterizations.44
1 Basic Concepts
Relational structures, in short, were not really there to be described – they were
there to fulﬁll an analytic role. (This goes a long way towards explaining the lack
of expressivity results for the basic modal language; Kamp’s result, signiﬁcantly,
was grounded in the Priorean tradition of temporal logic.) Moreover, it was a self-
contained world in a way that modern modal logic is not. Modal languages and
relational semantics: the connection between them seemed clear, adequate, and
well understood. Surely nothing essential was missing from this paradise?
The modern era (1972–present)
Two forces gave rise to the modern era: the discovery of frame incompleteness re-
sults, and the adoption of modal languages in theoretical computer science. These
unleashed a wealth of activity which profoundly changed the course of modal logic
and continues to inﬂuence it till this day. The incompleteness results forced a fun-
damental reappraisal of what modal languages actually are, while the inﬂuence of
theoretical computer science radically changed expectations of what they could be
used for, and how they were to be applied.
Frame-based analyses of modal logic were revealing and intoxicatingly success-
ful – but was every normal logic complete with respect to some class of frames?
Lemmon and Scott knew that this was a difﬁcult question; they had shown, for
example, that there were obstacles to adapting the canonical model method to ana-
lyze the logic yielded by the McKinsey axiom. Nonetheless, they conjectured that
the answer was yes:
However, it seems reasonable to conjecture that, if a consistent normal K-
system S is closed with respect to substitution instances . . . then S determines
a class ΓS of world systems such that S A iff |=ΓS A. We have no proof of
this conjecture. But to prove it would be to make a considerable difference to
our theoretical understanding of the general situation. [296, page 76]
Other optimistic sentiments can be found in the literature of the period. Segerberg’s
thesis is more cautious, simply identifying it as ‘probably the outstanding question
in this area of modal logic at the present time’ [404, page 29].
The question was soon resolved – negatively. In 1972, S.K. Thomason [433]
showed that there were incomplete normal logics in the basic temporal language,
and in 1974 Thomason [434] and Fine [129] both published examples of incom-
plete normal logics in the basic modal language. Moreover, in an important series
of papers Thomason showed that these results were ineradicable: as tools for talk-
ing about frames, modal languages were essentially monadic second-order logic in
disguise, and hence were intrinsically highly complex.
These results stimulated what remains some of the most interesting and innova-
tive work in the history of the subject. For a start, it was now clear that it no longer1.7 Historical Overview
45
sufﬁced to view modal logic as an isolated formal system; on the contrary, it was
evident that a full understanding of what modal languages were, required that their
position in the logical universe be located as accurately as possible. Over the next
few years, modal languages were to be extensively mapped from the perspective of
both universal algebra and classical model theory.
Thomason [433] had already adopted an algebraic perspective on the basic tem-
poral language. Moreover, this paper introduced general frames, showed that
they were equivalent to semantics based on boolean algebras with operators, and
showed that these semantics were complete in a way that the frame-based seman-
tics was not: every normal temporal logic was characterized by some algebra.
Goldblatt introduced the universal algebraic approach towards modal logic and
developed modal duality theory (the categorical study of the relation between rela-
tional structures endowed with topological structure on the one hand, and boolean
algebras with operators on the other). This led to a belated appreciation of the
fundamental contributions made in Jónsson and Tarski’s pioneering work. Gold-
blatt and Thomason showed that the concepts and results of universal algebra could
be applied to yield modally interesting results; the best known example of this is
the Goldblatt-Thomason Theorem, a model theoretic characterization of modally
deﬁnable frame classes obtained by applying the Birkhoff Variety Theorem to
boolean algebras with operators. We discuss such work in Chapter 5 (and in Chap-
ter 3 we discuss the Goldblatt-Thomason Theorem from the perspective of ﬁrst-
order model theory). Work by Blok made deeper use of algebras, and universal
algebra became a key tool in the exploration of completeness theory. The revival
of algebraic semantics – together with a genuine appreciation of why it was so
important – is one of the most enduring legacies of this period.
But the modern period also ﬁrmly linked modal languages with classical model
theory. One line of inquiry that led naturally in this direction was the following:
given that modal logic was essentially second-order in nature, why was it so often
ﬁrst-order, and very simple ﬁrst-order at that? That is, from the modern perspec-
tive, incomplete normal logics were to be expected – it was the elegant results of
the classical period that now seemed in need of explanation. One type of answer
was given in the work of Sahlqvist [396], who isolated a large set of axioms which
guaranteed completeness with respect to ﬁrst-order deﬁnable classes of frames.
(We deﬁne the Sahlqvist fragment in Section 3.6, where we discuss the Sahlqvist
Correspondence Theorem, an expressivity result. The twin Sahlqvist Complete-
ness Theorem is proved algebraically in Theorem 5.91.) Another type of answer
was developed in Fine [132] and van Benthem [40, 41]; we discuss this work (albeit
from an algebraic perspective) in Chapter 5.
A different line of work also linked modal and classical languages: an investiga-
tion of modal languages viewed purely as description languages. The classical era
largely ignored expressivity in favor of completeness, but the Sahlqvist Correspon-46
1 Basic Concepts
dence Theorem showed the narrowness of this perspective: a beautiful result about
the basic modal language that did not even mention normal modal logics! Ex-
pressivity issues were subsequently studied by van Benthem, who developed the
subject now known as correspondence theory, along two main lines; see [42, 43].
One views modal languages as tools for describing frames (that is, as second-order
description languages) and probes their expressive power. This line of investiga-
tion, together with Sahlqvist’s work, forms the basis of Chapter 3. The second line
explores modal languages as tools for talking about models, an intrinsically ﬁrst-
order perspective. This lead van Benthem to isolate the concept of a bisimulation,
and prove the fundamental Characterization Theorem: viewed as a tool for talk-
ing about models, modal languages are the bisimulation invariant fragment of the
corresponding ﬁrst-order language. Bisimulation driven investigations of modal
expressivity are now standard, and much of Chapter 2 is devoted to such issues.
The impact of theoretical computer science was less dramatic than the discov-
ery of the incompleteness results, but its inﬂuence has been equally profound.
Burstall [82] already suggests using modal logic to reason about programs, but the
birth of this line of work really dates from Pratt [362] (the paper which gave rise
to PDL) and Pnueli [359] (which suggested using temporal logic to reason about
execution-traces of programs). Computer scientists tended to develop powerful
modal languages; PDL in its many variants is an obvious example (see Harel [209]
for a detailed survey). And since the appearance of Gabbay et al. [160] the tempo-
ral languages used by computer scientists typically contain the until operator, and
often additional operators which are evaluated with respect to paths (see Clarke
and Emerson [94]). Gabbay also noted the signiﬁcance of Rabin’s Theorem [368]
for modal decidability (we discuss this in Chapter 6), and applied it to a wide range
of languages and logics; see Gabbay [145, 146, 147].
Computer scientists brought a new array of questions to the study of modal logic.
For a start, they initiated the study of the computational complexity of normal log-
ics. Already by 1977 Ladner [292] had showed that every normal logic between K
and S4 had a PSPACE-hard satisﬁability problem, while the results of Fischer and
Ladner [135] and Pratt [363] together show that PDL has an EXPTIME-complete
satisﬁability problem. (These results are proved in Chapter 6.) Moreover, the in-
terest of the modal expressivity studies emerging in correspondence theory was
reinforced by several lines of work in computer science. To give one particularly
nice example, computer scientists studying concurrent systems independently iso-
lated the notion of bisimulation (see Park [354]). This paved the way for the work
of Hennessy and Milner [219] who showed that weak modal languages could be
used to classify various notions of process invariance.
But one of the most signiﬁcant endowments from computer science has actu-
ally been something quite simple: it has helped remove a lingering tendency to see
modal languages as intrinsically ‘intensional’ formalisms, suitable only for ana-1.7 Historical Overview
47
lyzing such concepts as knowledge, obligation and belief. During the 1990s this
point was strongly emphasized when connections were discovered between modal
logic and knowledge representation formalisms. In particular, description logics
are a family of languages that come equipped with effective reasoning methods,
and a special focus on balancing expressive power and computational and algo-
rithmic complexity; see Donini et al. [115]. The discovery of this connection has
lead to a renewed focus on efﬁcient reasoning methods, dedicated languages that
are ﬁne-tuned for speciﬁc modeling tasks, and a variety of novel uses of modal
languages; see Schild [400] for the ﬁrst paper to make the connection between the
two ﬁelds, and De Giacomo [106], Areces [12], and Areces and de Rijke [15] for
work exploiting the connection.
And this is but one example. Links with computer science and other disciplines
have brought enormous richness and variety to modal logic. Computer science has
seen a shift of emphasis from isolated programs to complex entities collaborating
in heterogeneous environments; this gives rise to new challenges for the use of
modal logic in theoretical computer science. For instance, agent-based theories
require ﬂexible modeling facilities together with efﬁcient reasoning mechanisms;
see Wooldridge and Jennings [463] for a discussion of the agent paradigm, and
Bennet et al. [34] for the link with modal logic. More generally, complex com-
putational architectures call for a variety of combinations of modal languages; see
the proceedings of the Frontiers of Combining Systems workshop series for refer-
ences [16, 152, 268].
Similar developments took place in foundational research in economics. Game
theory (Osborne and Rubinstein [350]) also shows a nice interplay between the no-
tions of action and knowledge; recent years have witnessed an increasing tendency
to give a formal account of epistemic notions; see Battigalli and Bonanno [31] or
Kaneko and Nagashima [260]. For modal logics that combine dynamic and epis-
temic notions to model games we refer to Baltag [21] and van Ditmarsch [109].
Further examples abound. Database theory continues to be a fruitful source
of questions for logicians, modal or otherwise. For instance, developments in
temporal databases have given rise to new challenges for temporal logicians (see
Finger [134]), while description logicians have found new applications for their
modeling and reasoning methods in the area of semistructured data (see Calvanese
et al. [84]). In the related, but more philosophically oriented area of belief re-
vision, Fuhrmann [144] has given a modal formalization of one of the most in-
ﬂuential approaches in the area, the AGM approach [4]. Authors such as Fried-
man and Halpern [142], Gerbrandy and Groeneveld [170], de Rijke [384], and
Segerberg [410] have discussed various alternative modal formalizations.
Cognitive phenomena have long been of interest to modal logicians. This is clear
from examples such as belief revision, but perhaps even more so from language-
related work in modal logic. The feature logic mentioned in Example 1.17 is but48
1 Basic Concepts
one example; authors such as Blackburn, Gardent, Meyer-Viol, and Spaan [61, 58],
Kasper and Rounds [266, 394], Kracht [280], Kurtonina [287], and Reape [376]
have offered a variety of modal logical perspectives on grammar formalisms. Oth-
ers have analyzed the semantics of natural language by modal means; see Fer-
nando [126] for a sample of modern work along these lines.
During the 1980s and 1990s a number of new themes on the interface of modal
logic and mathematics received considerable attention. One of these themes con-
cerns links between modal logic and non-wellfounded set theory; work that we
should mention here includes Aczel [2], Barwise and Moss [27], and Baltag [20,
22]; see the Notes to Chapter 2 for further discussion. Non-well-founded sets and
many other notions, such as automata and labeled transition systems, have been
brought together under the umbrella of co-algebras (see Jacobs and Rutten [242]),
which form a natural and elegant way to model state-based dynamic systems. Since
it was discovered that modal logic is as closely related to co-algebras as equational
logic is to algebras, there has been a wealth of results reporting on this connection;
we only mention Jacobs [241], Kurz [290] and Rößiger [393] here.
Another 1990s theme on the interface of modal logic and mathematics concerns
an old one: geometry. Work by Balbiani et al. [19], Stebletsova [423] and Ven-
ema [448] indicates that modal logic may have interesting things to say about ge-
ometry, while Aiello and van Benthem [3] and Lemon and Pratt [297] investigate
the potential of modal logic as a tool for reasoning about space.
As should now be clear to all our readers, the simple question posed by the modal
satisfaction deﬁnition – what happens at accessible states? – gives us a natural
way of working with any relational structure. This has opened up a host of new
applications for modal logic. Moreover, once the relational perspective has been
fully assimilated, it opens up rich new approaches to traditional subjects: see van
Benthem [45] and Fagin, Halpern, Moses, and Vardi [125] for thoroughly modern
discussions of temporal logic and epistemic logic respectively.
1.8 Summary of Chapter 1
 Relational Structures: A relational structure is a set together with a collection
of relations. Relational structures can be used to model key ideas from a wide
range of disciplines.
 Description Languages: Modal languages are simple languages for describing
relational structures.
 Similarity Types: The basic modal language contains a single primitive unary
operator 3. Modal languages of arbitrary similarity type may contain many
modalities  of arbitrary arity.
 Basic Temporal Language: The basic temporal language has two operators F1.8 Summary of Chapter 1
49
and P whose intended interpretations are ‘at some time in the future’ and ‘at
some time in the past.’
 Propositional Dynamic Logic: The language of propositional dynamic logic
has an inﬁnite collection of modal operators indexed by programs π built up
from atomic programs using union ∪, composition ; and iteration ∗ ; additional
constructors such as intersection ∩ and test ? may also be used. The intended
interpretation of πφ is ‘some terminating execution of program π leads to a
state where φ holds.’
 Arrow Logic: The language of arrow logic is designed to talk about any object
that may be represented by arrows; it has a modal constant 1’ (‘skip’), a unary
operator ⊗ (‘converse’), and a dyadic operator ◦ (‘composition’).
 Satisfaction: The satisfaction deﬁnition is used to interpret formulas inside mod-
els. This satisfaction deﬁnition has an obvious local ﬂavor: modalities are inter-
preted as scanning the states accessible from the current state.
 Validity: A formula is valid on a frame when it is globally true, no matter what
valuation is used. This concept allows modal languages to be viewed as lan-
guages for describing frames.
 General Frames: Modal languages can also be viewed as talking about general
frames. A general frame is a frame together with a set of admissible valuations.
General frames offer some of the advantages of both models and frames and are
an important technical tool.
 Semantic Consequence: Semantic consequence relations for modal languages
need to be relativized to classes of structures. The classical idea that the truth
of the premises should guarantee the truth of the conclusion can be interpreted
either locally or globally. In this book we almost exclusively use the local inter-
pretation.
 Normal Modal Logics: Normal modal logics are the unifying concept in modal
proof theory. Normal modal logics contain all tautologies, the K axiom and the
Dual axiom; in addition they should be closed under modus ponens, uniform
substitution and generalization.2
Models
In Section 1.3 we deﬁned what it means for a formula to be satisﬁed at a state in
a model – but as yet we know virtually nothing about this fundamental semantic
notion. What exactly can we say about models when we use modal languages
to describe them? Which properties of models can modal languages express, and
which lie beyond their reach?
In this chapter we examine such questions in detail. We introduce disjoint
unions, generated submodels, bounded morphisms, and ultraﬁlter extensions, the
‘big four’ operations on models that leave modal satisfaction unaffected. We dis-
cuss two ways to obtain ﬁnite models and show that modal languages have the ﬁnite
model property. Moreover, we deﬁne the standard translation of modal logic into
ﬁrst-order logic, thus opening the door to correspondence theory, the systematic
study of the relationship between modal and classical logic. All this material plays
a fundamental role in later work; indeed, the basic track sections in this chapter are
among the most important in the book.
But the central concept of the chapter is that of a bisimulation between two
models. Bisimulations reﬂect, in a particularly simple and direct way, the locality
of the modal satisfaction deﬁnition. We introduce them early on, and they gradually
come to dominate our discussion. By the end of the chapter we will have a good
understanding of modal expressivity over models, and the most interesting results
all hinge on bisimulations.
Chapter guide
Section 2.1: Invariance Results (Basic track). We introduce three classic ways of
constructing new models from old ones that do not affect modal satisfac-
tion: disjoint unions, generated submodels, and bounded morphisms. We
also meet isomorphisms and embeddings.
Section 2.2: Bisimulations (Basic track). We introduce bisimulations and show
that modal satisfaction is invariant under bisimulation. We will see that
502.1 Invariance Results
51
the model constructions introduced in the ﬁrst section are all special cases
of bisimulation, learn that modal equivalence does not always imply bisim-
ilarity, and examine an important special case in which it does.
Section 2.3: Finite Models (Basic track). Here we show that modal languages en-
joy the ﬁnite model property. We do so in two distinct ways: by the se-
lection method (ﬁnitely approximating a bisimulation), and by ﬁltration
(collapsing a model into a ﬁnite number of equivalence classes).
Section 2.4: The Standard Translation (Basic track). We start our study of cor-
respondence theory. By deﬁning the standard translation, we link modal
languages to ﬁrst-order (and other classical) languages and raise the two
central questions that dominate later sections: What part of ﬁrst-order logic
does modal logic correspond to? And which properties of models are de-
ﬁnable by modal means?
Section 2.5: Modal Saturation via Ultraﬁlter Extensions (Basic track). The ﬁrst
step towards obtaining some answers is to introduce ultraﬁlter extensions,
the last of the big four modal model constructions. We then show that al-
though modal equivalence does not imply bisimilarity, it does imply bisim-
ilarity somewhere else, namely in the ultraﬁlter extensions of the models
concerned.
Section 2.6: Characterization and Deﬁnability (Advanced track). We prove the
two main results of this chapter. First, we prove van Benthem’s Theorem
stating that modal languages are the bisimulation invariant fragments of
ﬁrst-order languages. Second, we show that modally deﬁnable classes of
(pointed) models are those that are closed under bisimulations and ultra-
products and whose complements are closed under ultrapowers.
Section 2.7: Simulation and Safety (Advanced track). We prove two results that
give the reader a glimpse of recent work in modal model theory. The ﬁrst
describes the properties that are preserved under simulations (a one-way
version of bisimulation), the second characterizes the ﬁrst-order deﬁnable
operations on binary relations which respect bisimilarity.
2.1 Invariance Results
Mathematicians rarely study structures in isolation. They are usually interested in
the relations between different structures, and in operations that build new struc-
tures from old. Questions that naturally arise in such contexts concern the structural
properties that are invariant under, or are preserved by, such relations and opera-
tions. We will not give precise deﬁnitions of these notions, but roughly speaking, a
property is preserved by a certain relation or operation if, whenever two structures
are linked by the relation or operation, then the second structure has the property2 Models
52
if the ﬁrst one has it. We speak of invariance if the property is preserved in both
directions.
Logicians add a descriptive twist to this. For example, modal logicians want to
know when two structures, or perhaps two points in distinct structures, are indis-
tinguishable by modal languages. That is, when do they satisfy exactly the same
modal formulas?
Deﬁnition 2.1 Let M and M be models of the same modal similarity type τ , and
let w and w be states in M and M respectively. The τ -theory (or τ -type) of w is
the set of all τ -formulas satisﬁed at w: that is, {φ | M, w  φ}. We say that w and
w are (modally) equivalent (notation: w  w ) if they have the same τ -theories.
The τ -theory of the model M is the set of all τ -formulas satisﬁed by all states
in M: that is, {φ | M  φ}. Models M and M are called (modally) equivalent
(notation: M  M ) if their theories are identical.
We now introduce three important ways of constructing new models from old ones
which leave the theories associated with states unchanged: disjoint unions, gen-
erated submodels, and bounded morphisms. These constructions (together with
ultraﬁlter extensions, which we introduce in Section 2.5) play an important role
throughout the book. For example, in the following chapter we will see that they
lift to the level of frames (where they preserve validity), we will use them repeat-
edly in our work on completeness and complexity, and in Chapter 5 we will see
that they have important algebraic analogs.
Disjoint Unions
Suppose we have the following two models:
'
'
$
w 
vt0
t
M&
v
- t1
$
v
- t2
v
- t3
N
%
%
&
Do not worry that we have not speciﬁed the valuations – they are irrelevant here.
All that matters is that M and N have disjoint domains, for we are now going to
lump them together to form the model M  N:
$
'
w 
t
M  N&
vt0
v
- t1
v
- t2
v
- t3
%
The model M  N is called the disjoint union of M and N. It gathers together all
the information in the two smaller models unchanged: we have not altered the way
the points are related, nor the way atomic information is distributed. Suppose we2.1 Invariance Results
53
are working in the basic modal language, and suppose that a formula φ is true at
(say) v1 in N: is φ still true at v1 in M  N? More generally, is modal satisfaction
preserved from points in the original models to the points in the disjoint union?
And what about the reverse direction: if a modal formula is true at some state in
M  N, is it also true at that same state in the smaller model it came from?
The answer to these questions is clearly yes: modal satisfaction must be invariant
(that is, preserved in both directions) under the formation of disjoint unions. Modal
satisfaction is intrinsically local: only the points accessible from the current state
are relevant to truth or falsity. If we evaluate a formula φ at (say) w, it is completely
irrelevant whether we perform the evaluation in M or M  N; φ simply cannot
detect the presence or absence of states in other islands.
Deﬁnition 2.2 (Disjoint Unions) We ﬁrst deﬁne disjoint unions for the basic
modal language. We say that two models are disjoint if their domains contain
no common elements. For disjoint models Mi = (Wi , Ri , Vi ) (i ∈ I), their
disjoint union is the structure i Mi = (W, R, V ), where W is the union of
the sets Wi , R is the union of the relations Ri , and for each proposition letter
p, V (p) = i∈I Vi (p).
Now for the general case. For disjoint τ -structures Mi = (Wi , Ri , Vi )∈τ
(i ∈ I) of the same modal similarity type τ , their disjoint union is the structure
i Mi = (W, R , V )∈τ such that W is the union of the sets Wi ; for each  ∈ τ ,
R is the union i∈I Ri ; and V is deﬁned as in the basic modal case.
If we want to put together a collection of models that are not disjoint, we ﬁrst
have to make them disjoint (say by indexing the domains of these models). To use
the terminology introduced shortly, we simply take mutually disjoint isomorphic
copies of the models we wish to combine, and combine the copies instead.
Proposition 2.3 Let τ be a modal similarity type and, for all i ∈ I, let Mi be a
τ -model. Then, for each modal formula φ, for each i ∈ I, and each element w
of Mi , we have Mi , w  φ iff i∈I Mi , w  φ. In words: modal satisfaction is
invariant under disjoint unions.
Proof. We will prove the result for the basic similarity type. The proof is by in-
duction on φ. Let i be some index; we will prove, for each basic modal formula φ,
and each element w of Mi , that Mi , w  φ iff M, w  φ, where M is the disjoint
union i∈I Mi .
First suppose that φ contains no connectives. Now, if φ is a proposition letter
p, then we have Mi , w  φ iff w ∈ Vi (p) iff (by deﬁnition of V ) w ∈ V (p)
iff M, w  φ. On the other hand, φ could be ⊥ (for the purposes of inductive
proofs it is convenient to regard ⊥ as a propositional letter rather than as a logical
connective). But trivially ⊥ is false at w in both models, so we have the desired
equivalence here too.54
2 Models
Our inductive hypothesis is that the desired equivalence holds for all formulas
containing at most n connectives (where n ≥ 0). We must now show that the
equivalence holds for all formulas φ containing n + 1 connectives. Now, if φ is
of the form ¬ψ or ψ ∨ θ this is easily done – we will leave this to the reader – so
as we are working with the basic similarity type, it only remains to establish the
equivalence for formulas of the form 3ψ. So assume that Mi , w  3ψ. Then
there is a state v in Mi with Ri wv and Mi , v  ψ. By the inductive hypothesis,
M, v  ψ. But by deﬁnition of M, we have Rwv, so M, w  3ψ.
For the other direction, assume that M, w  3ψ holds for some w in Mi . Then
there is a v with Rwv and M, v  ψ. It follows by the deﬁnition of R that Rj wv for
some j, and by the disjointness of the universes we must have that j = i. But then
we ﬁnd that v belongs to Mi as well, so we may apply the inductive hypothesis;
this yields Mi , v  ψ, so we ﬁnd that Mi , w  3ψ.
We will use Proposition 2.3 all through the book – here is a simple application
which hints at the ideas we will explore in Chapter 7.
Example 2.4 Deﬁned modalities are a convenient shorthand for concepts we ﬁnd
useful. We have already seen some examples. In this book 2, the ‘true at all
accessible states modality,’ is shorthand for ¬3¬, and we have inductively deﬁned
a ‘true somewhere n-steps from here’ modality 3n for each natural number n (see
Example 1.22). But while it is usually easy to show that some modality is deﬁnable
(we need simply write down its deﬁnition), how do we show that some proposed
operator is not deﬁnable? Via invariance results! As an example, consider the
global modality. The global diamond E has as its (intended) accessibility relation
the relation W × W implicitly present in any model. That is:
M, w  Eφ iff M, v  φ for some state v in M.
Its dual, A, the global box, thus has the following interpretation:
M, w  Aφ iff M, v  φ for all states v in M.
Thus the global modality brings a genuinely global dimension to modal logic. But
is it deﬁnable in the basic modal language? Intuitively, no: as 3 and 2 work
locally, it seems unlikely that they can deﬁne a truly global modality over arbitrary
structures. Fine – but how do we prove this?
With the help of the previous proposition. Suppose we could deﬁne A. Then
we could write down an expression α(p) containing only symbols from the basic
modal language such that for every model M, M, w  α(p) iff M  p. We
now derive a contradiction from this supposition. Consider a model M1 where
p holds everywhere, and a model M2 where p holds nowhere. Let w be some
point in M1 . It follows that M1 , w  α(p), so as (by assumption) α(p) contains2.1 Invariance Results
55
only symbols from the basic modal language, by Proposition 2.3 we have that
M1  M2 , w  α(p). But this implies that M1  M2 , v  p for every v in M2 ,
which, again by Proposition 2.3, in turn implies that M2  p: contradiction. We
conclude that the global box (and hence the global diamond) is not deﬁnable in the
basic modal language.
So, if we want the global modality, then we either have to introduce it as a
primitive (we will do this in Section 7.1), or we have to work with restricted classes
of models on which it is deﬁnable (in Exercise 1.3.3 we worked with a class of
models in which we could deﬁne A in the basic temporal language).
Generated submodels
Disjoint unions are a useful way of making bigger models from smaller ones – but
we also want methods for doing the reverse. That is, we would like to know when it
is safe to throw points away from a model without affecting satisﬁability. Disjoint
unions tell us a little about this (if a model is a disjoint union of smaller models,
we are free to work with the component models), but in practice we usually need
something sharper: generated submodels.
Suppose we are using the basic modal language to talk about a model M based
on the frame (Z, <), the integers with their usual order. It does not matter what the
valuation is – all that is important is that M looks something like this:


...
- t−3 - −2
t
- −1
t
- 0
t
- 1
t
- 2t
- 3t
- ...


First suppose that we form a submodel M− of M by throwing away all the positive
numbers, and restricting the original valuation (whatever it was) to the remaining
numbers. So M− looks something like this:


...

- t−3 - −2
t
- −1
t
- 0
t

The basic modal language certainly can see that M and M− are different. For
example, it sees that 0 has successors in M (note that M, 0  3) but is a dead
end in M− (note that M− , 0  3). So there is no invariance result for arbitrary
submodels. But now consider the submodel M+ of M that is formed by omitting
the negative numbers, and restricting the original valuation to the numbers that
remain:

0
- 1
t
t


- 2t
- 3t
- ...
56
2 Models
Suppose a basic modal formula φ is satisﬁed at some point n in M. Is φ also
satisﬁed at the same point n in M+ ? The answer must be yes. The only points that
are relevant to φ’s satisﬁability are the points greater than n – and all such points
belong to M+ . Similarly, it is clear that if M+ satisﬁes a basic modal formula φ at
m, then M must too.
In short, it seems plausible that modal invariance holds for submodels which
are closed under the accessibility relation of the original model. Such models are
called generated submodels, and they do indeed give rise to the invariance result
we are looking for.
Deﬁnition 2.5 (Generated Submodels) We ﬁrst deﬁne generated submodels for
the basic modal language. Let M = (W, R, V ) and M = (W  , R , V  ) be two
models; we say that M is a submodel of M if W  ⊆ W , R is the restriction of R
to W  (that is: R = R ∩ (W  × W  )), and V  is the restriction of V to M (that is:
for each p, V  (p) = V (p) ∩ W  ). We say that M is a generated submodel of M
(notation: M  M) if M is a submodel of M and for all points w the following
closure condition holds:
if w is in M and Rwv, then v is in M .
 , V )
For the general case, we say that a model M = (W  , R
∈τ is a generated
submodel of the model M = (W, R, V )∈τ (notation: M  M) whenever M
is a submodel of M (with respect to R for all  ∈ τ ), and the following closure
condition is fulﬁlled for all  ∈ τ
if u ∈ W  and Ruu1 . . . un , then u1 , . . . , un ∈ W  .
Let M be a model, and X a subset of the domain of M; the submodel generated
by X is the smallest generated submodel of M whose domain contains X (such a
model always exists: why?). Finally, a rooted or point generated model is a model
that is generated by a singleton set, the element of which is called the root of the
frame.
Proposition 2.6 Let τ be a modal similarity type and let M and M be τ -models
such that M is a generated submodel of M. Then, for each modal formula φ and
each element w of M we have that M, w  φ iff M , w  φ. In words: modal
satisfaction is invariant under generated submodels.
Proof. By induction on φ. The reader unused to such proofs should write out the
proof in full. In Proposition 2.19 we provide an alternative proof based on the
observation that generated submodels induce a bisimulation.
Four remarks. First, note that the invariance result for disjoint unions (Proposi-
tion 2.3) is a special case of the result for generated submodels: any component of2.1 Invariance Results
57
a disjoint union is a generated submodel of the disjoint union. Second, using an
argument analogous to that used in Example 2.4 to show that the global box cannot
be deﬁned in the basic modal language, we can use Proposition 2.6 to show that we
cannot deﬁne a backward looking modality in terms of 3; see Exercise 2.1.2. Thus
if we want such a modality we have to add it as a primitive – which is exactly what
we did, of course, when deﬁning the basic temporal language. Third, although we
have not explicitly discussed generated submodels for the basic temporal language,
PDL, or arrow logic, the required concepts are all special cases of Deﬁnition 2.5,
and thus the respective invariance results are special cases of Proposition 2.6. But
it is worth making a brief comment about the basic temporal language. When we
think explicitly in terms of bidirectional frames (see Example 1.25) it is obvious
that we are interested in submodels closed under both RF and RP . But when work-
ing with the basic temporal language we usually leave RP implicit: we work with
ordinary models (W, R, V ), and use Rˇ, the converse of R, as RP . Thus a tem-
poral generated submodel of (W, R, V ) is a submodel (W , R , V  ) that is closed
under both R and Rˇ. Finally, generated submodels are heavily used throughout
the book: given a model M that satisﬁes a formula φ at a state w, very often the
ﬁrst thing we will do is form the submodel of M generated by w, thus trimming
what may be a very unwieldy satisfying model down to a more manageable one.
Morphisms for modalities
In mathematics the idea of morphisms or structure preserving maps is of funda-
mental importance. What notions of morphism are appropriate for modal logic?
That is, what kinds of morphism give rise to invariance results? We will approach
the answer bit by bit, introducing a number of important concepts on the way. We
will start by considering the general notion of homomorphism (this is too weak to
yield invariance, but it is the starting point for better attempts), then we will deﬁne
strong homomorphisms, embeddings, and isomorphisms (these do give us invari-
ance, but are not particularly modal), and ﬁnally we will zero in on the answer:
bounded morphisms.
Deﬁnition 2.7 (Homomorphisms) Let τ be a modal similarity type and let M and
M be τ -models. By a homomorphism f from M to M (notation: f : M → M )
we mean a function f from W to W  with the following properties:
(i) For each proposition letter p and each element w from M, if w ∈ V (p),
then f (w) ∈ V  (p).
(ii) For each n ≥ 0 and each n-ary  ∈ τ , and (n + 1)-tuple w from M, if
 (the homomorphic
(w0 , . . . , wn ) ∈ R then (f (w0 ), . . . , f (wn )) ∈ R
condition).2 Models
58
We call M the source and M the target of the homomorphism.
Note that for the basic modal language, item (ii) is just this:
if Rwu then R f (w)f (u).
Thus item (ii) simply says that homomorphisms preserve relational links.
Are modal formulas invariant under homomorphisms? No: although homomor-
phisms reﬂect the structure of the source in the structure of the target, they do
not reﬂect the structure of the target back in the source. It is easy to turn this
observation into a counterexample, and we will leave this task to the reader as
Exercise 2.1.3.
So let us try and strengthen the deﬁnition. There is an obvious way of doing
so: turn the conditionals into equivalences. This leads to a number of important
concepts.
Deﬁnition 2.8 (Strong Homomorphisms, Embeddings and Isomorphisms) Let
τ be a modal similarity type and let M and M be τ -models. By a strong homo-
morphism of M into M we mean a homomorphism f : M → M which satisﬁes
the following stronger version of the above items (i) and (ii):
(i) For each proposition letter p and element w from M, w ∈ V (p) iff f (w) ∈
V  (p).
(ii) For each n ≥ 0 and each n-ary  in τ and (n + 1)-tuple w from M, (w0 ,
 (the strong homomorphic
. . . , wn ) ∈ R iff (f (w0 ), . . . , f (wn )) ∈ R
condition).
An embedding of M into M is a strong homomorphism f : M → M which is
injective. An isomorphism is a bijective strong homomorphism. We say that M
is isomorphic to M , in symbols M ∼
= M , if there is an isomorphism from M to

M.
Note that for the basic modal language, item (ii) is just:
Rwu iff R f (w)f (u).
That is, item (ii) says that relational links are preserved from the source model to
the target and back again. So it is not particularly surprising that we have a number
of invariance results.
Proposition 2.9 Let τ be a modal similarity type and let M and M be τ -models.
Then the following holds:
(i) For all elements w and w of M and M , respectively, if there exists a
surjective strong homomorphism f : M → M with f (w) = w , then w
and w are modally equivalent.2.1 Invariance Results
59
(ii) If M ∼
= M , then M  M .
Proof. The ﬁrst item follows by induction on φ; the second one is an immediate
consequence.
None of the above results is particularly modal. For a start, as in all branches of
mathematics, ‘isomorphic’ basically means ‘mathematically identical.’ Thus, we
do not want to be able to distinguish isomorphic structures in modal (or indeed,
any other) logic. Quite the contrary: we want to be free to work with structures
‘up to isomorphism’ – as we did, for example, in our discussion of disjoint union,
when we talked of taking isomorphic copies. Item (ii) tells us that we can do this,
but it is not a surprising result.
But why is item (i), the invariance result for strong homomorphisms, not ‘gen-
uinely modal’? Quite simply, because there are many morphisms which do give
rise to invariance, but which fail to qualify as strong homomorphisms. To ensure
modal invariance we need to ensure that some target structure is reﬂected back in
the source, but strong morphisms do this in a much too heavy-handed way. The
crucial concept is more subtle.
Deﬁnition 2.10 (Bounded Morphisms – the Basic Case) We ﬁrst deﬁne bounded
morphisms for the basic modal language. Let M and M be models for the basic
modal language. A mapping f : M = (W, R, V ) → M = (W  , R , V  ) is a
bounded morphism if it satisﬁes the following conditions:
(i) w and f (w) satisfy the same proposition letters.
(ii) f is a homomorphism with respect to the relation R (that is, if Rwv then
R f (w)f (v)).
(iii) If R f (w)v  then there exists v such that Rwv and f (v) = v (the back
condition).
If there is a surjective bounded morphism from M to M , then we say that M is a
bounded morphic image of M, and write M
M .
The idea embodied in the back condition is utterly fundamental to modal logic –
in fact, it is the idea that underlies the notion of bisimulation – so we need to get a
good grasp of what it involves right away. Here is a useful example.
Example 2.11 Consider the models M = (W , R, V ) and M = (W  , R , V  ),
where
• W = N (the natural numbers), Rmn iff n = m + 1, and V (p) = {n ∈ N |
n is even},
• W  = {e, o}, R = {(e, o), (o, e)}, and V  (p) = {e}.2 Models
60

0
t
- 1
t

- 2
t
- 3
t
- 4
t
- 5t

-
...

?
e t

- t?
o
...



Fig. 2.1. A bounded morphism.
Now, let f : W → W  be the following map:
f (n) =
e if n is even
o if n is odd
Figure 2.1 sums this all up in a simple picture.
Now, f is not a strong homomorphism (why not?), but it is a (surjective) bounded
morphism from M to M . Let us see why. Trivially f satisﬁes item (i) of the
deﬁnition. As for the homomorphic condition consider an arbitrary pair (n, n + 1)
in R. There are two possibilities: n is either even or odd. Suppose n is even. Then
n + 1 is odd, so f (n) = e and f (n + 1) = o. But then we have R f (n)f (n + 1),
as required. The argument for n odd is analogous.
And now for the interesting part: the back condition. Take an arbitrary element
n of W and assume that R f (n)w . We have to ﬁnd an m ∈ W such that Rnm
and f (m) = w . Let us assume that n is odd (the case for even n is similar). As
n is odd, f (n) = o, so by deﬁnition of R , we must have that w = e. But then
f (n + 1) = w since n + 1 is even, and by the deﬁnition of R we have that n + 1
is a successor of n. Hence, n + 1 is the m that we were looking for.
Deﬁnition 2.12 (Bounded Morphisms – the General Case) The deﬁnition of
a bounded morphism for general modal languages is obtained from the above by
adapting the homomorphic and back conditions of Deﬁnition 2.10 as follows:
 f (w)f (v ) . . . f (v ).
(ii) For all  ∈ τ , Rwv1 . . . vn implies R
1
n




(iii) If Rf (w)v1 . . . vn then there exist v1 . . . vn such that Rwv1 . . . vn and
f (vi ) = vi (for 1 ≤ i ≤ n).
Example 2.13 Suppose we are working in the modal similarity type of arrow
logic; see Example 1.16 and 1.27. Recall that the language has a modal constant
1’, a unary operator ⊗ and a single dyadic operator ◦. Semantically, to these oper-
ators correspond a unary relation I, a binary R and a ternary C. We will deﬁne a2.1 Invariance Results
61
bounded morphism from a square model to a model based on the addition of the
integer numbers. We will use the following notation: if x is an element of Z × Z,
then x0 denotes its ﬁrst component, and x1 its second component.
Consider the two models M = (W, C, R, I, V ) and M = (W  , C  , R , I  , V  )
where
• W = Z × Z, Cxyz iff x0 = y0 , y1 = z0 and z1 = x1 , Rxy if x0 = y1
and x1 = y0 , Ix iff x0 = x1 , and ﬁnally, the valuation V is given by V (p) =
{(x0 , x1 ) | x1 − x0 is even },
• W  = Z, C  stu iff s = t + u, R st iff s = −t, I  s iff s = 0, and the valuation
V  is given by V  (p) = {s ∈ Z | s is even }.
This example is best understood by looking at Figure 2.2. The left picture shows a
fragment of the model M; the points of Z × Z are represented as disks or circles,
depending on whether p is true or not. The diagonal is indicated by the dashed
diagonal line.
..
aqaaqaqa
qaqaq
.
a
aqaqaq
qaqaqa
aqaqaaqa
..
2

1
 0
 -1
 -2

a
..
.
..
.
.
Fig. 2.2. Another bounded morphism.
The right-hand side of Figure 2.2 gives a pictorial representation of the function
f : Z × Z → Z given by
f (z) = z1 − z0 .
We claim that f is a bounded morphism for this similarity type. The clause for the
propositional variables is trivial. For the unary relation I we only have to check
that for any z in Z × Z, z0 = z1 iff z1 − z0 = 0. This is obviously true. We leave
the case of the binary relation R to the reader.
So let us turn to the clauses for the ternary relation C. To check item (ii) (the
homomorphic condition), assume that Cxyz holds for x, y and z in W . That is,
we have that x0 = y0 , y1 = z0 and z1 = x1 . But then we ﬁnd that
f (x) = x1 − x0 = z1 − y0 = z1 − z0 + y1 − y0 = f (z) + f (y),62
2 Models
so by deﬁnition of C we do indeed ﬁnd that C f (x)f (y)f (z).
For item (iii) (the back condition) assume that we have C f (x)tu for some
x ∈ Z × Z and t, u ∈ Z. In other words, we have that x1 − x0 = t + u. Consider
the pairs y := (x0 , x0 + t) and z := (x0 + t, x1 ). It is obvious that Cxyz; we also
ﬁnd that f (y) = t and f (z) = x1 − (x0 + t) = (x1 − x0 ) − t = u. Hence y and z
are the elements of W that we need to satisfy item (iii) .
Deﬁnition 2.12 covers the basic temporal language, PDL, and arrow logic, as spe-
cial cases – but once more it is worth issuing a warning concerning the basic tem-
poral language. Although RP is usually presented implicitly (as the converse of the
relation R in some model (W, R, V )) we certainly cannot ignore it. Thus a tempo-
ral bounded morphism from (W1 , R1 , V1 ) to (W2 , R2 , V2 ) is a bounded morphism
from (W1 , R1 , Rˇ1 , V1 ) to (W2 , R2 , Rˇ2 , V2 ).
Proposition 2.14 Let τ be a modal similarity type and let M and M be τ -models
such that f : M → M is a bounded morphism. Then, for each modal formula φ,
and each element w of M we have M, w  φ iff M , f (w)  φ. In words: modal
satisfaction is invariant under bounded morphisms.
Proof. Let M, M and f be as in the statement of the proposition. We will prove
that for each formula φ and state w, M, w  φ iff M , f (w)  φ. The proof is
by induction on φ. We will assume that τ is the basic similarity type, leaving the
general case to the reader.
The base step and the boolean cases are routine, so let us turn to the case where
φ is of the form 3ψ. Assume ﬁrst that M, w  3ψ. This means there is a state
v with Rwv and M, v  ψ. By the inductive hypothesis, M , f (v)  ψ. By the
homomorphic condition, R f (w)f (v), so M , f (w)  3ψ.
For the other direction, assume that M , f (w)  3ψ. Thus there is a successor
of f (w) in M , say v , such that M , v   ψ. Now we use the back condition
(of Deﬁnition 2.10). This yields a point v in M such that Rwv and f (v) = v .
Applying the inductive hypothesis, we obtain M, v  ψ, so M, w  3ψ.
Here is a simple application: we will now show that any satisﬁable formula can be
satisﬁed in a tree-like model. To put it another way: modal logic has the tree model
property.
Let τ be a modal similarity type containing only diamonds (thus if M is a
τ -model, it has the form (W, R1 , R2 , . . . , V ), where each Ri is a binary rela-
tion on W ). In this context we will call a τ -model M tree-like if the structure
(W, i Ri , V ) is a tree in the sense of Deﬁnition 1.7.
Proposition 2.15 Assume that τ is a modal similarity type containing only dia-
monds. Then, for any rooted τ -model M there exists a tree-like τ -model M such
that M
M. Hence any satisﬁable τ -formula is satisﬁable in a tree-like model.2.1 Invariance Results
63
Proof. Let w be the root of M. Deﬁne the model M as follows. Its domain W 
consists of all ﬁnite sequences (w, u1 , . . . , un ) such that n ≥ 0 and for some modal
operators a1 , . . . , an  ∈ τ there is a path wRa1 u1 · · · Ran un in M. Deﬁne
(w, u1 , . . . , un )Ra (w, v1 , . . . , vm ) to hold if m = n + 1, ui = vi for i = 1, . . . , n,
and Ra un vm holds in M. That is, Ra relates two sequences iff the second is an
extension of the ﬁrst with a state from M that is a successor of the last element
of the ﬁrst sequence. Finally, V  is deﬁned by putting (w, u1 , . . . , un ) ∈ V  (p)
iff un ∈ V (p). As the reader is asked to check in Exercise 2.1.4, the mapping
f : (w, u1 , . . . , un ) → un deﬁnes a surjective bounded morphism from M to M,
thus M and M are equivalent.
But then it follows that any satisﬁable τ -formula is satisﬁable in a tree-like
model. For suppose φ is satisﬁable in some τ -model at a point w. Let M be
the submodel generated by w. By Proposition 2.6, M, w  φ, and as M is rooted
we can form an equivalent tree-like model M as just described.
The method used to construct M from M is well known in both modal logic and
computer science: it is called unraveling (or unwinding, or unfolding). In essence,
we built M by treating the paths through M as ﬁrst class citizens: this untangles
the (possibly very complex) way information is stored in M, and makes it possible
to present it as a tree. We will make use of unraveling several times in later work; in
the meantime, Exercise 2.1.7 asks the reader to extend the notion of ‘tree-likeness’
to arbitrary modal similarity types, and generalize Proposition 2.15.
Exercises for Section 2.1
2.1.1 Suppose we wanted an operator D with the following satisfaction deﬁnition: for any
model M and any formula φ, M, w  Dφ iff there is a u = w such that M, u  φ. This
operator is called the difference operator and we will discuss it further in Section 7.1. Is
the difference operator deﬁnable in the basic modal language?
2.1.2 Use generated submodels to show that the backward looking modality (that is, the P
of the basic temporal language) cannot be deﬁned in terms of the forward looking operator
3.
2.1.3 Give the simplest possible example which shows that the truth of modal formulas is
not invariant under homomorphisms, even if condition (i) is strengthened to an equivalence.
Is modal truth preserved under homomorphisms?
2.1.4 Show that the mapping f deﬁned in the proof of Proposition 2.15 is indeed a surjec-
tive bounded morphism.
2.1.5 Let B = (B, R) be the transitive binary tree; that is, B is the set of ﬁnite strings
of 0s and 1s, and Rστ holds if σ is a proper initial segment of τ . Let N = (N, <) be the
frame of the natural numbers with the usual ordering.64
2 Models
(a) Let V0 be the valuation on N given by V 0 (p) = {2n | n ∈ N} for each proposition
letter p. Deﬁne a valuation U 0 on B and a bounded morphism from (B, U 0 ) to
(N, V0 ).
(b) Let U1 be the valuation on B given by U 1 (p) = {1σ | σ ∈ B} for each proposition
letter p. Give a valuation V 1 on N and a homomorphism from (B, U 1 ) to (N, V1 )
(c) Can you also ﬁnd bounded morphisms?
2.1.6 Show that every model is the bounded morphic image of the disjoint union of point-
generated (that is: rooted) models. This exercise may look rather technical, but in fact it is
very straightforward – think about it!
2.1.7 This exercise generalizes Proposition 2.15 to arbitrary modal similarity types.
(a) Deﬁne a suitable notion of tree-like model that works for arbitrary modal similarity
types. (Hint: in case of R  s0 s1 . . . sn , think of s0 as being the parent node and of
s1 , . . . , sn as the children.)
(b) Generalize Proposition 2.15 to arbitrary modal similarity types.
2.2 Bisimulations
What do the invariance results of the previous section have in common? They all
deal with special sorts of relations between two models, namely relations with the
following properties: related states carry identical atomic information, and when-
ever it is possible to make a transition in one model, it is possible to make a match-
ing transition in the other. For example, with generated submodels the inter-model
relation is identity, and every transition in one model is matched by an identical
transition in the other. With bounded morphisms, the inter-model relation is a func-
tion, and the notion of matching involves both the homomorphic link from source
to target, and the back condition which reﬂects target structure in the source.
This observation leads us to the central concept of the chapter: bisimulations.
Quite simply, a bisimulation is a relation between two models in which related
states have identical atomic information and matching transition possibilities. The
interesting part of the deﬁnition is the way it makes the notion of ‘matching transi-
tion possibilities’ precise.
Deﬁnition 2.16 (Bisimulations – the Basic Case) We ﬁrst give the deﬁnition for
the basic modal language. Let M = (W, R, V ) and M = (W  , R , V  ) be two
models.
A non-empty binary relation Z ⊆ W × W  is called a bisimulation between M
and M (notation: Z : M ↔ M ) if the following conditions are satisﬁed:
(i) If wZw then w and w satisfy the same proposition letters.
(ii) If wZw and Rwv, then there exists v (in M ) such that vZv and R w v 
(the forth condition).2.2 Bisimulations
65
(iii) The converse of (ii): if wZw and R w v  , then there exists v (in M) such
that vZv and Rwv (the back condition).
When Z is a bisimulation linking two states w in M and w in M we say that w
and w are bisimilar, and we write Z : M, w ↔ M , w . If there is a bisimulation
Z such that Z : M, w ↔ M , w , we sometimes write M, w ↔ M , w , or w ↔ w
if the models are clear from the context. Finally, if M and M are linked by some
bisimulation, we write M ↔ M .
Think of Deﬁnition 2.16 pictorially. Figure 2.3 shows the content of the forth
clause. Suppose we know that wZw and Rwv (the solid arrow in M and the Z-
link at the bottom of the diagram display this information). Then the forth condition
says that it is always possible to ﬁnd a v that ‘completes the square’ (this is shown
by the dashed arrow in M and the dotted Z-link at the top of the diagram). Note
the symmetry between the back and forth clauses: to visualize the back clause,
simply reﬂect the picture through its vertical axis.
vq
qv
6
Zq
6
w
q

Z
w
M
M
Fig. 2.3. The forth condition.
In effect, bisimulations are a relational generalization of bounded morphisms: we
drop the directionality from source to target (and with it the homomorphic con-
dition) and replace it with a back-and-forth system of matching moves between
models.
Example 2.17 The models M and M shown in Figure 2.4 are bisimilar. To see
this, deﬁne the following relation Z between their states: Z = {(1, a), (2, b),
(2, c), (3, d), (4, e), (5, e)}. Condition (i) of Deﬁnition 2.16 is obviously satisﬁed:
Z-related states make the same propositional letters true. Moreover, the back and
forth conditions are satisﬁed too: any move in M can be matched by a similar move
in M , and conversely, as the reader should check.
This example also shows that bisimulation is a genuine generalization of the
constructions discussed in the previous section. Although M and M are bisimilar,
neither is a generated submodel nor a bounded morphic image of the other.2 Models
$ '
66
'
4
M
b

s - 2s - 3s
p
q
p@
R sq
@
1
&
5
$
sq
a  @
R ds
@
s
p@
p
Rs
@
q
sq
%
&
c
- es
q
M
%
Fig. 2.4. Bisimilar models.
Deﬁnition 2.18 (Bisimulations – the General Case) Let τ be a modal similarity
 , V )
type, and let M = (W, R, V )∈τ and M = (W  , R
∈τ be τ -models. A

non-empty binary relation Z ⊆ W × W is called a bisimulation between M and
M (notation: Z : M ↔ M ) if the above condition (i) from Deﬁnition 2.16
is satisﬁed (that is, Z-related states satisfy the same proposition letters) and in
addition the following conditions (ii) and (iii) are satisﬁed:
(ii) If wZw and Rwv1 . . . vn then there are v1 , . . . , vn (in W  ) such that
 w v  . . . v  and for all i (1 ≤ i ≤ n) v Zv  (the forth condition).
R
i
n
1
i
 w v  . . . v  then there are v , . . . , v
(iii) The converse of (ii) : if wZw and R
1
n
n
1
(in W ) such that Rwv1 . . . vn and for all i (1 ≤ i ≤ n) vi Zvi (the back
condition).
Examples of bisimulations abound – indeed, as we have already mentioned, the
constructions of the previous section (disjoint unions, generated submodels, iso-
morphisms, and bounded morphisms), are all bisimulations:
Proposition 2.19 Let τ be a modal similarity type, and let M, M and Mi (i ∈ I)
be τ -models.
(i) If M ∼
= M , then M ↔ M .
(ii) For every i ∈ I and every w in Mi , Mi , w ↔ i Mi , w.
(iii) If M  M, then M , w ↔ M, w for all w in M .
(iv) If f : M
M , then M, w ↔ M , f (w) for all w in M.
Proof. We only prove the second item, leaving the others as Exercise 2.2.2. As-
sume we are working in the basic modal language. Deﬁne a relation Z between
Mi and i Mi by putting Z = {(w, w) | w ∈ Mi }. Then Z is a bisimulation.
To see this, observe that clause (i) of Deﬁnition 2.16 is trivially fulﬁlled, and as to
clauses (ii) and (iii), any R-step in Mi is reproduced in i Mi , and by the disjoint-
ness condition every R-step in i Mi that departs from a point that was originally
in Mi , stems from a corresponding R-step in Mi . The reader should extend this
argument to arbitrary similarity types.2.2 Bisimulations
67
We will now show that modal satisﬁability is invariant under bisimulations (and
hence, by Proposition 2.19, provide an alternative proof that modal satisﬁability is
invariant under disjoint unions, generated submodels, isomorphisms, and bounded
morphisms). The key thing to note about the following proof is how straightfor-
ward it is – the back and forth clauses in the deﬁnition of bisimulation are precisely
what is needed to push the induction through.
Theorem 2.20 Let τ be a modal similarity type, and let M, M be τ -models. Then,
for every w ∈ W and w ∈ W  , w ↔ w implies that w  w . In words, modal
formulas are invariant under bisimulation.
Proof. By induction on φ. The case where φ is a proposition letter follows from
clause (i) of Deﬁnition 2.16, and the case where φ is ⊥ is immediate. The boolean
cases are immediate from the induction hypothesis.
As for formulas of the form 3ψ, we have M, w  3ψ iff there exists a v in M
such that Rwv and M, v  ψ. As w ↔ w we ﬁnd by clause (ii) of Deﬁnition
2.16 that there exists a v in M such that R w v  and v ↔ v  . By the induction
hypothesis, M , v   ψ, hence M , w  3ψ. For the converse direction use
clause (iii) of Deﬁnition 2.16.
The argument for the general modal case, with triangles , is an easy extension
of that just given, as the reader should check.
This ﬁnishes our discussion of the basics of bisimulation – so let us now try and
understand the concept more deeply. Some of the remarks that follow are concep-
tual, and some are technical, but they all point to ideas that crop up throughout the
book.
Remark 2.21 (Bisimulation, Locality, and Computation) In the Preface we sug-
gested that the reader think of modal formulas as automata. Evaluating a modal
formula amounts to running an automaton: we place it at some state inside a struc-
ture and let it search for information. The automaton is only permitted to explore
by making transitions to neighboring states; that is, it works locally.
Suppose such an automaton is standing at a state w in a model M, and we pick it
up and place it at a state w in a different model M ; would it notice the switch? If
w and w are bisimilar, no. Our automaton cares only about the information at the
current state and the information accessible by making a transition – it is indifferent
to everything else. Thus the deﬁnition of bisimulation spells out exactly what we
have to do if we want to fool such an automaton as to where it is being evaluated.
Viewed this way, it is clear that the concept of bisimulation is a direct reﬂection of
the locality of the modal satisfaction deﬁnition.
But there is a deeper link between bisimulation and computation than our in-
formal talk of automata might suggest. As we discussed in Example 1.3, labeled2 Models
68


s
w


. . .
w
s
Z
~
Z
 Z
~
Z

Z
. . .
~
Z
Z
~.
Z


.

M
N
..
.
Fig. 2.5. Equivalent but not bisimilar.
transition systems (LTSs) are a standard way of thinking about computation: when
we traverse an LTS we build a sequence of state transitions – or to put it another
way, we compute. When are two LTSs computationally equivalent? More pre-
cisely, if we ignore practical issues (such as how long it takes to actually perform
a computation) when can two different LTSs be treated as freely exchangeable
(‘observationally equivalent’) black boxes? One natural answer is: when they are
bisimilar. Bisimulation turns out to be a very natural notion of equivalence for both
mathematical and computational investigations. For more on the history of bisim-
ulation and the connection with computer science, see the Notes.
Remark 2.22 (Bisimulation and First-Order Logic) According to Theorem 2.20
modal formulas cannot distinguish between bisimilar states or between bisimilar
models, even though these states or models may be quite different. It follows
that modal logic is very different from ﬁrst-order logic, for arbitrary ﬁrst-order
formulas are certainly not invariant under bisimulations. For example, the model
M of Example 2.17 satisﬁes the formula
∃y1 y2 y3 (y1 = y2 ∧ y1 = y3 ∧ y2 = y3 ∧ Rxy1 ∧ Rxy2 ∧ Ry1 y3 ∧ Ry2 y3 ),
if we assign the state a to the free variable x. This formula says that there is a
diamond-shaped conﬁguration of points, which is true of the point a in M , but
not of the state 1 in M. But as far as modal logic is concerned, M and M, being
bisimilar, are indistinguishable. In Section 2.4 we will start examining the links
between modal logic and ﬁrst-order logic more systematically.
Now for a fundamental question: is the converse of Theorem 2.20 true? That is, if
two models are modally equivalent, must they be bisimilar? The answer is no.
Example 2.23 Consider the basic modal language. We may just as well work with
an empty set of proposition letters here. Deﬁne models M and N as in Figure 2.5,
where arrows denote R-transitions. Each of M and N has, for each n > 0, a ﬁnite
branch of length n; the difference between the models is that, in addition, N has an
inﬁnite branch.2.2 Bisimulations
69
One can show that for all modal formulas φ, M, w  φ iff N, w  φ (this is
easy if one is allowed to use some results that we will prove further on, namely
Proposition 2.31 and Lemma 2.33, but it is not particularly hard to prove from ﬁrst
principles, and the reader may like to try this). But even though w and w are
modally equivalent, there is no bisimulation linking them. To see this, suppose
that there was such a bisimulation Z: we will derive a contradiction from this
supposition.
Since w and w are linked by Z, there has to be a successor of w, say v0 , which
is linked to the ﬁrst point v0 on the inﬁnite path from w . Suppose that n is the
length of the (maximal) path leading from w through v0 , and let w, v0 , . . . , vn−1
be the successive points on this path. Using the bisimulation conditions n − 1

times, we ﬁnd points v1 , . . . , vn−1
on the inﬁnite path emanating from w , such







that v0 R v1 . . . R vn−1 and vi Zvi for each i. Now vn−1
has a successor, but vn−1
does not; hence, there is no way that these two points can be bisimilar.
Nonetheless, it is possible to prove a restricted converse to Theorem 2.20, namely
the Hennessy-Milner Theorem. Let τ be a modal similarity type, and M a τ -
model. M is image-ﬁnite if for each state u in M and each relation R in M, the
set { (v1 , . . . , vn ) | Ruv1 . . . vn } is ﬁnite; observe that we are not putting any
restrictions on the total number of different relations R in the model M – just that
each of them is image-ﬁnite.
Theorem 2.24 (Hennessy-Milner Theorem) Let τ be a modal similarity type,
and let M and M be two image-ﬁnite τ -models. Then, for every w ∈ W and
w ∈ W  , w ↔ w iff w  w .
Proof. Assume that our similarity type τ only contains a single diamond (that is,
we will work in the basic modal language). The direction from left to right follows
from Theorem 2.20; for the other direction, we will prove that the relation 
of modal equivalence itself satisﬁes the conditions of Deﬁnition 2.16 – that is, we
show that the relation of modal equivalence on these models is itself a bisimulation.
(This is an important idea; we will return to it in Section 2.5.)
The ﬁrst condition is immediate. For the second one, assume that w  w
and Rwv. We will try to arrive at a contradiction by assuming that there is no v
in M with R w v  and v  v . Let S  = {u | R w u }. Note that S  must
be non-empty, for otherwise M , w  ⊥, which would contradict w  w
since M, w  3. Furthermore, as M is image-ﬁnite, S must be ﬁnite, say
S  = {w1 , . . . , wn }. By assumption, for every wi ∈ S  there exists a formula ψi
such that M, v  ψi but M , wi  ψi . It follows that
M, w  3(ψ1 ∧ · · · ∧ ψn ) and M , w  3(ψ1 ∧ · · · ∧ ψn ),
which contradicts our assumption that w  w . The third condition of Deﬁni-70
2 Models
tion 2.16 may be checked in a similar way. Extending the proof to other similarity
types is routine.
Theorem 2.20 (together with the Hennessy-Milner Theorem) on the one hand, and
Example 2.23 on the other, mark important boundaries. Clearly, bisimulations have
something important to say about modal expressivity over models, but they do not
tell us everything. Two pieces of the jigsaw puzzle are missing. For a start, we are
still considering modal languages in isolation: as yet, we have made no attempt to
systematically link them to ﬁrst-order logic. We will remedy this in Section 2.4 and
this will eventually lead us to a beautiful result, the van Benthem Characterization
Theorem (Theorem 2.68): modal logic is the bisimulation invariant fragment of
ﬁrst-order logic.
The second missing piece is the notion of an ultraﬁlter extension. We will intro-
duce this concept in Section 2.5, and this will eventually lead us to Theorem 2.62.
Informally, this theorem says: modal equivalence implies bisimilarity-somewhere-
else. Where is this mysterious ‘somewhere else’? In the ultraﬁlter extension. As
we will see, although modally equivalent models need not be bisimilar, they must
have bisimilar ultraﬁlter extensions.
Remark 2.25 (Bisimulations for the Basic Temporal Language, PDL, and Ar-
row Logic) Although we have already said the most fundamental things that need
to be said on this topic (Deﬁnition 2.18 and Theorem 2.20 covers these languages),
a closer look reveals some interesting results for PDL and arrow logic. But let us
ﬁrst discuss the basic temporal language.
First we issue our (by now customary) warning. When working with the basic
temporal language, we usually work with models (W, R, V ) and implicitly take RP
to be Rˇ. Thus we need a notion of bisimulation which takes Rˇ into account, and
so we deﬁne a temporal bisimulation between models (W, R, V ) and (W , R , V  )
to be a relation Z between the states of the two models that satisﬁes the clauses
of Deﬁnition 2.16, and in addition the following two clauses (iv) and (v) requiring
that backward steps in one model should be matched by similar steps in the other
model:
(iv) If wZw and Rvw, then there exists v (in M ) such that vZv and R v  w .
(v) The converse of (iv): if wZw and R v  w , then there exists v (in M) such
that vZv and Rvw.
If we do not do this, we are in trouble. For example, if M is a model whose
underlying frame is the integers, and M is the submodel of M generated by 0
(according to the deﬁnition for the basic modal language), then these two models
are bisimilar in the sense of Deﬁnition 2.16, and hence equivalent as far as the
basic modal language is concerned. But they are not equivalent as far as the basic
temporal language is concerned: M, 0  P , but M , 0  P .2.2 Bisimulations
71
Given our previous discussion, this is unsurprising. What is (pleasantly) sur-
prising is that things do not work this way in PDL. Suppose we are given two
regular models. Checking that these models are bisimilar for the language of PDL
means checking that bisimilarity holds for all the (inﬁnitely many) relations that
exist in regular models (see Example 1.26). But as it turns out, most of this work
is unnecessary. Once we have checked that bisimilarity holds for all the relations
which interpret the basic programs, we do not have to check anything else: the
relations corresponding to complex programs will automatically be bisimilar. In
Section 2.7 we will introduce some special terminology to describe this: the oper-
ations in regular PDL’s modality building repertoire (∪, ; and ∗ ) will be called safe
for bisimulation. Note that taking the converse of a relation is not an operation that
is safe for bisimulation (in effect, that is what we just noted when discussing the
basic temporal language).
What about arrow logic? The required notion of bisimulation is given by Def-
inition 2.18; note that the clause for 1’ reads that for bisimilar points a and a we
have Ia iff I  a.
Remark 2.26 (The Algebra of Bisimulations) Bisimulations give rise to alge-
braic structure quite naturally. For instance, if Z0 is a bisimulation between M0
and M1 , and Z1 a bisimulation between M1 and M2 , then the composition of Z0
and Z1 is a bisimulation linking M0 and M2 . It is also a rather easy observation
that the set of bisimulations between two models is closed under taking arbitrary
(ﬁnite or inﬁnite) unions. This shows that if two points are bisimilar, there is al-
ways a maximal bisimulation linking them; see Exercise 2.2.8. Further information
on closure properties of the set of bisimulations between two models can be found
in Section 2.7.
Exercises for Section 2.2
2.2.1 Consider a modal similarity type with two diamonds a and b, and with Φ = {p}.
Show that the following two models are bisimilar:
w s
p
b
a
v
-s p
w0
s
p
a - v0s
p
b - ws1
p
a - v1s . . .
p
2.2.2 This exercise asks the reader to complete in detail the proof of Proposition 2.19,
which links bisimulations and the model constructions discussed in the previous section.
You should prove these results for arbitrary similarity types.
(a) Show that if M ∼
= M , then M ↔ M .
(b) Show that if i Mi is the disjoint union of the models M i (i ∈ I), then, for each i,
Mi ↔ i Mi .
(c) Show that if M is a generated submodel of M, then M  ↔ M.
(d) Show that if M  is a bounded morphic image of M, then M  ↔ M.2 Models
72
2.2.3 This exercise is about temporal bisimulations.
(a) Show from ﬁrst principles that the truth of basic temporal formulas is invariant
under temporal bisimulations. (That is, do not appeal to any of the results proved
in this section.)
(b) Let M and M be ﬁnite rooted models for basic temporal logic with F and P . Let
w and w  be the roots of M and M  , respectively. Prove that if w and w  satisfy
the same basic temporal formulas with F and P , then there exists a basic temporal
bisimulation that relates w and w  .
2.2.4 Consider the binary until operator U . In a model M = (W, R, V ) its truth deﬁnition
reads:
M, t  U (φ, ψ)
iff there is a v such that Rtv and v  φ, and
for all u such that Rtu and Ruv: u  ψ.
Prove that U is not deﬁnable in the basic modal language. Hint: think about the following
two models, but with arrows added to make sure that the relations are transitive:
v1
v0
t
t
t0 *
q H
YH u 
*q H
YH t1
t
H t
H t
I
I

p
t s0
t s1
v
t
u
*

YH t
 q H
t
H t
I

p
t s
2.2.5 Consider the following two models, which we are going to use to interpret the basic
temporal language: M 0 = (R, <, V0 ) and M1 = (R, <, V1 ), where V0 makes q true at all
non-zero integers and V 1 in addition makes q true at all points of the form 1/z with z a
non-zero integer number.
(a) Prove that there is a temporal bisimulation between M 0 and M1 , linking 0 (in the
one model) to 0 (in the other model).
(b) Let Π be the progressive operator deﬁned by the following truth table:
M, s  Πφ
iff
there are t and u such that t < s < u and
M, x  φ for all x between t and u.
Prove that this operator is not deﬁnable in the basic temporal language.
2.2.6 Suppose we have two bisimilar LTSs. Show that bisimilar states in these LTSs satisfy
exactly the same formulas of PDL.
2.2.7 Prove that two square arrow models M = (S U , V ) and M = (SU  , V  ) are bisim-
ilar if and only if there is a relation Z between pairs over U and pairs over U  such that
(i) if (u, v)Z(u , v  ), then (u, v) ∈ V (p) iff (u , v  ) ∈ V  (p),
(ii) if (u, v)Z(u , v  ), then u = v iff u = v  ,
(iii) if (u, v)Z(u , v  ), then (v, u)Z(v  , u ),
(iv) if (u, v)Z(u , v  ), then for any w ∈ U there exists a w  ∈ U  such that both
(u, w)Z(u , w ) and (w, v)Z(w  , v  ),
(v) the converse of (iv): if (u, v)Z(u  , v  ), then for any w  ∈ U  there exists a w ∈ U
such that both (u, w)Z(u  , w ) and (w, v)Z(w  , v  ),2.3 Finite Models
73
Must any two bisimilar square arrow models be isomorphic? (Hint: think of V (p) and
V  (p) as the natural ordering relations of the rational and the real numbers, respectively.)
2.2.8 Suppose that {Z i | i ∈ I} is a non-empty collection of bisimulations between M and
M . Prove that the relation i∈I Zi is also a bisimulation between M and M  . Conclude
that if M and M are bisimilar, then there is a maximal bisimulation between M and M  ;
that is, a bisimulation Z m such that for any bisimulation Z : M ↔ M we have Z ⊆ Zm .
2.3 Finite Models
Preservation and invariance results can be viewed either positively or negatively.
Viewed negatively, they map the limits of modal expressivity: they tell us, for
example, that modal languages are incapable of distinguishing a model from its
generated submodels. Viewed positively, they are a toolkit for transforming mod-
els into more desirable forms without affecting satisﬁability. Proposition 2.15 has
already given us a taste of this perspective (we showed that modal languages have
the tree model property) and it will play an important role when we discuss com-
pleteness in Chapter 4.
The results of this section are similarly double-edged. We are going to investi-
gate modal expressivity over ﬁnite models, and the basic result we will prove is that
modal languages have the ﬁnite model property: if a modal formula is satisﬁable
on an arbitrary model, then it is satisﬁable on a ﬁnite model.
Deﬁnition 2.27 (Finite Model Property) Let τ be a modal similarity type, and
let M be a class of τ -models. We say that τ has the ﬁnite model property with
respect to M if the following holds: if φ is a formula of similarity type τ , and φ is
satisﬁable in some model in M, then φ is satisﬁable in a ﬁnite model in M.
In this section we will mostly be concerned with the special case in which M in
Deﬁnition 2.27 is the collection of all τ -models, so to simplify terminology here
we will use the term ‘ﬁnite model property’ for this special case. The fact that
modal languages have the ﬁnite model property (in this sense) can be viewed as a
limitative result: modal languages simply lack the expressive strength to force the
existence of inﬁnite models. (By way of contrast, it is easy to write down ﬁrst-
order formulas which can only be satisﬁed on inﬁnite models.) On the other hand,
the result is a source of strength: we do not need to bother about (arbitrary) inﬁnite
models, for we can always ﬁnd an equivalent ﬁnite one. This opens the door to the
decidability results of Chapter 6. (The satisﬁability problem for ﬁrst-order logic,
as the reader probably knows, is undecidable over arbitrary models.)
We will discuss two methods for building ﬁnite models for satisﬁable modal
formulas. The ﬁrst is to (carefully!) select a ﬁnite submodel of the satisfying model,
the second (called the ﬁltration method) is to deﬁne a suitable quotient structure.2 Models
74
Selecting a ﬁnite submodel
The selection method draws together four observations. Here is the ﬁrst. We know
that modal satisfaction is intrinsically local: modalities scan the states accessible
from the current state. How much of the model can a modal formula see from the
current state? That obviously depends on how deeply the modalities it contains are
nested.
Deﬁnition 2.28 (Degree) We deﬁne the degree of modal formulas as follows:
deg(p) = 0,
deg(⊥) = 0,
deg(¬φ) = deg(φ),
deg(φ ∨ ψ) = max{deg(φ), deg(ψ)},
deg((φ1 , . . . , φn )) = 1 + max{deg(φ1 ), . . . , deg(φn )}.
In particular, the degree of a basic modal formula 3φ is 1 + deg(φ).
Second, we observe the following:
Proposition 2.29 Let τ be a ﬁnite modal similarity type, and assume that our col-
lection of proposition letters is ﬁnite as well.
(i) For all n, up to logical equivalence there are only ﬁnitely many formulas of
degree at most n.
(ii) For all n, and every τ -model M and state w of M, the set of all τ -formulas
of degree at most n that are satisﬁed by w, is equivalent to a single formula.
Proof. We prove the ﬁrst item by induction on n. The case n = 0 is obvious. As
for the case n+1, observe that every formula of degree ≤ n+1 is a boolean combi-
nation of proposition letters and formulas of the form 3ψ, where deg(ψ) ≤ n. By
the induction hypothesis there can only be ﬁnitely many non-equivalent such for-
mulas ψ. Thus there are only ﬁnitely many non-equivalent boolean combinations
of proposition letters and formulas 3ψ, where ψ has degree at most n. Hence,
there are only ﬁnitely many non-equivalent formulas of degree at most n + 1.
Item (ii) is immediate from item (i).
Third, we observe that there is a natural way of ﬁnitely approximating a bisimula-
tion. These ﬁnite approximations will prove crucial in our search for ﬁnite models.
Deﬁnition 2.30 (n-Bisimulations) Here we deﬁne n-bisimulations for modal
similarity types containing only diamonds, leaving the deﬁnition of the general
case as part of Exercise 2.3.2. Let M and M be models, and let w and w be
states of M and M , respectively. We say that w and w are n-bisimilar (notation:2.3 Finite Models
75
w ↔n w ) if there exists a sequence of binary relations Zn ⊆ · · · ⊆ Z0 with the
following properties (for i + 1 ≤ n):
(i) wZn w .
(ii) If vZ0 v  then v and v agree on all proposition letters.
(iii) If vZi+1 v  and Rvu, then there exists u with R v  u and uZi u .
(iv) If vZi+1 v  and R v  u , then there exists u with Rvu and uZi u .
The intuition is that if w ↔n w , then w and w bisimulate up to depth n. Clearly,
if w ↔ w , then w ↔n w for all n – but the converse need not hold; see Exer-
cise 2.3.1.
Fourth, we observe that for languages containing only ﬁnitely many proposition
letters, there is an exact match between modal equivalence and n-bisimilarity for
all n. That is, for such languages not only does n-bisimilarity for all n imply modal
equivalence, but the converse holds as well.
Proposition 2.31 Let τ be a ﬁnite modal similarity type, Φ a ﬁnite set of proposi-
tion letters, and let M and M be models for this language. Then for every w in M
and w in M , the following are equivalent:
(i) w ↔n w .
(ii) w and w agree on all modal formulas of degree at most n.
It follows that ‘n-bisimilarity for all n’ and modal equivalence coincide as rela-
tions between states.
Proof. The implication (i) ⇒ (ii) may be proved by induction on n. For the con-
verse implication one can use an argument similar to the one used in the proof of
Theorem 2.24; we leave the proof as part of Exercise 2.3.2.
It is time to draw these observations together. The following deﬁnition and lemma,
which are about rooted models, give us half of what we need to build ﬁnite models.
Deﬁnition 2.32 Let τ be a modal similarity type containing only diamonds. Let
M = (W, R1 , . . . , Rn , . . . , V ) be a rooted τ -model with root w. The notion of
the height of states in M is deﬁned by induction. The only element of height 0 is
the root of the model; the states of height n + 1 are those immediate successors of
elements of height n that have not yet been assigned a height smaller than n + 1.
The height of a model M is the maximum n such that there is a state of height n in
M, if such a maximum exists; otherwise the height of M is inﬁnite.
For a natural number k, the restriction of M to k (notation: M k) is deﬁned
as the submodel containing only states whose height is at most k. More precisely,
(M k) = (Wk , R1k , . . . , Rnk , . . . , Vk ), where Wk = {v | height(v) ≤ k},
Rnk = Rn ∩ (Wk × Wk ), and for each p, Vk (p) = V (p) ∩ Wk .76
2 Models
In words: the restriction of M to k contains all states that can be reached from
the root in at most k steps along the accessibility relations. Typically, this will not
give a generated submodel, so why does it interest us? Because, as we can now
show, given a formula φ of degree k that is satisﬁable in some rooted model M, the
restriction of M to k contains all the states we need to satisfy φ. To put it another
way: we are free to simply delete all states that lie beyond the ‘k-horizon.’
Lemma 2.33 Let τ be a modal similarity type that contains only diamonds. Let
M be a rooted τ -model, and let k be a natural number. Then, for every state w of
(M k), we have (M k), w ↔l M, w, where l = k − height(w).
Proof. Take the identity relation on (M k). We leave the reader to work out the
details as Exercise 2.3.3. The following comment may be helpful: in essence this
lemma tells us that if we are only interested in the satisﬁability of modal formulas
of degree at most k, then generating submodels of height k sufﬁces to maintain
satisﬁability.
Putting together Proposition 2.31 and Lemma 2.33, we conclude that every satis-
ﬁable modal formula can be satisﬁed on a model of ﬁnite height. This is clearly
useful, but we are only halfway to our goal: the resulting model may still be inﬁ-
nite, as it may be inﬁnitely branching. We obtain the ﬁnite model we are looking
for by a further selection of points; in effect this discards unwanted branches and
leads to the desired ﬁnite model.
Theorem 2.34 (Finite Model Property – via Selection) Let τ be a modal simi-
larity type containing only diamonds, and let φ be a τ -formula. If φ is satisﬁable,
then it is satisﬁable on a ﬁnite model.
Proof. Fix a modal formula φ with deg(φ) = k. We restrict our modal simi-
larity type τ and our collection of proposition letters to the modal operators and
proposition letters actually occurring in φ. Let M1 , w1 be such that M1 , w1  φ.
By Proposition 2.15, there exists a tree-like model M2 with root w2 such that
M2 , w2  φ. Let M3 := (M2 k). By Lemma 2.33 we have M2 , w2 ↔k M3 , w2 ,
and by Proposition 2.31 it follows that M3 , w2  φ.
By induction on n ≤ k we deﬁne ﬁnite sets of states S0 , . . . , Sk and a (ﬁnal)
model M4 with domain S0 ∪ · · · ∪ Sk ; the points in each Sn will have height n.
Deﬁne S0 to be the singleton {w2 }. Next, assume that S0 , . . . , Sn have already
been deﬁned. Fix an element v of Sn . By Proposition 2.29 there are only ﬁnitely
many non-equivalent modal formulas whose degree is at most k − n, say ψ1 , . . . ,
ψm . For each such formula that is of the form aχ and holds in M3 at v, select
a state u from M3 such that Ra vu and M3 , u  χ. Add all these us to Sn+1 , and
repeat this selection process for every state in Sn . Sn+1 is deﬁned as the set of all
points that have been selected in this way.2.3 Finite Models
77
Finally, deﬁne M4 as follows. Its domain is S0 ∪· · ·∪Sk ; as each Si is ﬁnite, M4
is ﬁnite. The relations and valuation are obtained by restricting the relations and
valuation of M3 to the domain of M4 . By Exercise 2.3.4 we have that M4 , w2 ↔k
M3 , w2 , and hence M4 , w2  φ, as required.
How well does the selection method generalize to other modal languages? For
certain purposes it is ﬁne. For example, to deal with arbitrary modal similarity
types, the notion of a tree-like model needs to be adapted (in fact, we explained
how to do this in Exercise 2.1.7), but once this has been done we can prove a
general version of Proposition 2.15. Next, the notion of n-bisimilarity needs to
be adapted to other similarity types, but that too is straightforward (it is part of
Exercise 2.3.2). Finally, the selection process in the proof of Theorem 2.34 needs
adaptation, but this is unproblematic. In short, we can show that the ﬁnite model
property holds for arbitrary similarity types using the selection method.
The method has a drawback: the input model for our construction may satisfy
important relational properties (such as being symmetric), but the end result is al-
ways a ﬁnite tree-like model, and the desired relational properties may be (and
often are) lost. So if we want to establish the ﬁnite model property with respect
to a class of models satisfying additional properties – something that is very im-
portant in practice – we may have to do additional work once we have obtained
our ﬁnite tree-like model. In such cases, the selection method tends to be harder
to use than the ﬁltration method (which we discuss next). Nonetheless, the idea
of (intelligently!) selecting points to build submodels is important, and (as we will
see in Section 6.6 when we discuss NP-completeness) the idea really comes into
its own when the model we start with is already ﬁnite.
Finite models via ﬁltrations
We now examine the classic modal method for building ﬁnite models: ﬁltration.
Whereas the selection method builds ﬁnite models by deleting superﬂuous material
from large, possibly inﬁnite models, the ﬁltration method produces ﬁnite models
by taking a large, possibly inﬁnite model and identifying as many states as possible.
We ﬁrst present the ﬁltration method for the basic modal language.
Deﬁnition 2.35 A set of formulas Σ is closed under subformulas (or: subformula
closed) if for all formulas φ, φ : if φ ∨ φ ∈ Σ then so are φ and φ ; if ¬φ ∈ Σ then
so is φ; and if (φ1 , . . . , φn ) ∈ Σ then so are φ1 , . . . , φn . (For the basic modal
language, this means that if 3φ ∈ Σ, then so is φ.)
Deﬁnition 2.36 (Filtrations) We work in the basic modal language. Let M =
(W, R, V ) be a model and Σ a subformula closed set of formulas. Let Σ be the2 Models
78
'
0
s
&
$
1s
2
3
- s
4
- s. . .
1
qs

|0|

%
s

- s
 |1| 
Fig. 2.6. A model and its ﬁltration.
relation on the states of M deﬁned by:
w Σ v iff for all φ in Σ: (M, w  φ iff M, v  φ).
Note that Σ is an equivalence relation. We denote the equivalence class of a
state w of M with respect to Σ by |w|Σ , or simply by |w| if no confusion will
arise. The mapping w → |w| that sends a state to its equivalence class is called the
natural map.
Let WΣ = {|w|Σ | w ∈ W }. Suppose MfΣ is any model (W f , Rf , V f ) such
that:
(i) W f = WΣ .
(ii) If Rwv then Rf |w||v|.
(iii) If Rf |w||v| then for all 3φ ∈ Σ, if M, v  φ then M, w  3φ.
(iv) V f (p) = {|w| | M, w  p}, for all proposition letters p in Σ.
Then MfΣ is called a ﬁltration of M through Σ; we will often suppress subscripts
and write Mf instead of MfΣ .
Because of item (ii), the natural map associated with any ﬁltration is guaranteed to
be a homomorphism (see Deﬁnition 2.7). And at ﬁrst glance it may seem that it
is even guaranteed to be a bounded morphism (see Deﬁnition 2.10), for item (iii)
seems reminiscent of the back condition. Unfortunately, this is not the case, as the
following example shows.
Example 2.37 Let M be the model (N, R, V ), where R = {(0, 1), (0, 2), (1, 3)}∪
{(n, n + 1) | n ≥ 2}, and V has V (p) = N \ {0} and V (q) = {2}.
Further, assume that Σ = {3p, p}. Clearly Σ is subformula closed. Then,
the model N = ({|0|, |1|}, {(|0|, |1|), (|1|, |1|)}, V  ), where V  (p) = {|1|}, is a
ﬁltration of M through Σ. See Figure 2.6.
Clearly, N can not be a bounded morphic image of M: any bounded morphism
would have to preserve the formula q, and the natural map does not preserve q, and
need not, because q is not an element of our subformula closed set Σ.2.3 Finite Models
79
But in many other respects ﬁltrations are well-behaved. For a start, the method
gives us a bound (albeit an exponential one) on the size of the resulting ﬁnite model:
Proposition 2.38 Let Σ be a ﬁnite subformula closed set of basic modal formulas.
For any model M, if Mf is a ﬁltration of M through a subformula closed set Σ,
then Mf contains at most 2n nodes (where n denotes the size of Σ).
Proof. The states of Mf are the equivalence classes in WΣ . Let g be the function
with domain WΣ and range P(Σ) deﬁned by g(|w|) = {φ ∈ Σ | M, w  φ}. It
follows from the deﬁnition of Σ that g is well deﬁned and injective. Thus the
size of WΣ is at most 2n , where n is the size of Σ.
Moreover – crucially – ﬁltrations preserve satisfaction in the following sense.
Theorem 2.39 (Filtration Theorem) Consider the basic modal language. Let
Mf (= (WΣ , Rf , V f )) be a ﬁltration of M through a subformula closed set Σ.
Then for all formulas φ ∈ Σ, and all nodes w in M, we have M, w  φ iff
Mf , |w|  φ.
Proof. By induction on φ. The base case is immediate from the deﬁnition of V f .
The boolean cases are straightforward; the fact that Σ is closed under subformulas
allows us to apply the inductive hypothesis.
So suppose 3φ ∈ Σ and M, w  3φ. Then there is a v such that Rwv and
M, v  φ. As Mf is a ﬁltration, Rf |w||v|. As Σ is subformula closed, φ ∈ Σ,
thus by the inductive hypothesis Mf , |v|  φ. Hence Mf , |w|  3φ.
Conversely, suppose 3φ ∈ Σ and Mf , |w|  3φ. Thus there is a state |v| in
Mf such that Rf |w||v| and Mf , |v|  φ. As φ ∈ Σ, by the inductive hypothesis
M, v  φ. So the third clause in Deﬁnition 2.36 is applicable, and we conclude
that M, w  3φ.
Observe that clauses (ii) and (iii) of Deﬁnition 2.36 are designed to make the modal
case of the induction step go through in the proof above.
But we still have not done one vital thing: we have not actually shown that ﬁl-
trations exist! Observe that the clauses (ii) and (iii) in Deﬁnition 2.36 only impose
conditions on candidate relations Rf – but we have not yet shown that a suitable
Rf can always be found. In fact, there are always at least two ways to deﬁne binary
relations that fulﬁll the required conditions. Deﬁne Rs and Rl as follows:
(i) Rs |w||v| iff ∃w ∈ |w|∃v  ∈ |v| Rw v  .
(ii) Rl |w||v| iff for all formulas 3φ in Σ: M, v  φ implies M, w  3φ.
These relations – which are not necessarily distinct – give rise to the smallest and
largest ﬁltrations respectively.80
2 Models
Lemma 2.40 Consider the basic modal language. Let M be any model, Σ any
subformula closed set of formulas, WΣ the set of equivalence classes induced
by Σ , and V f the standard valuation on WΣ . Then both (WΣ , Rs , V f ) and
(WΣ , Rl , V f ) are ﬁltrations of M through Σ. Furthermore, if (WΣ , Rf , V f ) is
any ﬁltration of M through Σ then Rs ⊆ Rf ⊆ Rl .
Proof. We show that (WΣ , Rs , V f ) is a ﬁltration; the rest is left as an exercise.
It sufﬁces to show that Rs fulﬁlls clauses (ii) and (iii) of Deﬁnition 2.36. But
Rs satisﬁes clause (ii) by deﬁnition, so it remains to check clause (iii). Suppose
Rs |w||v|, and further suppose that 3φ ∈ Σ and M, v  φ. As Rs |w||v|, there exist
w ∈ |w| and v ∈ |v| such that Rw v  . As φ ∈ Σ and M, v  φ, then because
v Σ v  , we get M, v  φ. But Rw v  , so M, w  3φ. But 3φ ∈ Σ, thus as
w Σ w it follows that M, w  3φ.
Theorem 2.41 (Finite Model Property – via Filtrations) Let φ be a basic modal
formula. If φ is satisﬁable, then it is satisﬁable on a ﬁnite model. Indeed, it is
satisﬁable on a ﬁnite model containing at most 2m nodes, where m is the number
of subformulas of φ.
Proof. Assume that φ is satisﬁable on a model M; take any ﬁltration of M through
the set of subformulas of φ. That φ is satisﬁed in the ﬁltration is immediate from
Theorem 2.39. The bound on the size of the ﬁltration is immediate from Proposi-
tion 2.38.
There are several points worth making about ﬁltrations. The ﬁrst has to do with
the possible loss of properties when moving from a model to one of its ﬁltrations.
As we have already discussed, a drawback of the selection method is that it can be
hard to preserve such properties. Filtrations are far better in this respect – but they
certainly are not perfect. Let us consider the matter more closely.
Suppose (WΣ , Rf , V f ) is a ﬁltration of (W, R, V ). Now, clause (ii) of Deﬁni-
tion 2.36 means that the natural map from M to Mf is a surjective homomorphism
with respect to the accessibility relation R. Thus any property of relations which
is preserved under such maps will automatically be inherited by any ﬁltration. Ob-
vious examples include reﬂexivity and right unboundedness (∀x∃y Rxy).
However, many interesting relational properties are not preserved under homo-
morphisms: transitivity and symmetry are obvious counterexamples. Thus we need
to ﬁnd special ﬁltrations which preserve these properties. Sometimes this is easy;
for example, the smallest ﬁltration preserves symmetry. Sometimes we need new
ideas to ﬁnd a good ﬁltration; the classic example involves transitivity. Let us see
what this involves.
Lemma 2.42 Let M be a model, Σ a subformula closed set of formulas, and WΣ2.3 Finite Models
s
s
s
s
-
s
s
s
s
-
s
s
s
s
81
-
...
-
s
s
s
s
Fig. 2.7. Filtrating a model based on (Q, <).
the set of equivalence classes induced on M by Σ . Let Rt be the binary relation
on WΣ deﬁned by:
Rt |w||v| iff for all φ, if 3φ ∈ Σ and M, v  φ ∨ 3φ then M, w  3φ.
If R is transitive then (WΣ , Rt , V f ) is a ﬁltration and Rt is transitive.
Proof. Left as Exercise 2.3.5.
In short, ﬁltrations are ﬂexible – but it is not a matter of ‘plug and play.’ Creativity
is often required to exploit them.
The second point worth making is that ﬁltrations of an inﬁnite model through a
ﬁnite set manage to represent an inﬁnite amount of information in a ﬁnitary manner.
It seems obvious, at least from an intuitive point of view, that this can only be
achieved by identifying lots of points. As we have seen in Example 2.37, an inﬁnite
chain may be collapsed onto a single reﬂexive point by a ﬁltration. An even more
informative example is provided by models based on the rationals. For instance,
what happens to the density condition in the ﬁltration? Let M = (Q, <, V ); then
any (ﬁnite) ﬁltration of M has the form displayed in Figure 2.7. What is going
on here? Instead of viewing models as structures made up of states and relations
between them, in the case of ﬁltrations it can be useful to view them as sets of
states (namely, the sets of identiﬁed states) and relations between those sets. The
following deﬁnition captures this idea.
Deﬁnition 2.43 Let (W, R, V ) be a transitive frame. A cluster on (W, R, V ) is a
maximal, nonempty equivalence class under R. That is, C ⊆ W is a cluster if
the restriction of R to C is an equivalence relation, and this is not the case for any
subset D properly extending C.
A cluster is simple if it consists of a single reﬂexive point, and proper if it con-
tains more than one point.
As Figure 2.7 shows, a (ﬁnite) ﬁltration of (Q, <) can be thought of as resulting in
a ﬁnite linear sequence of clusters, perhaps interspersed with singleton irreﬂexive
points, no two of which can be adjacent. (Note: the displayed model is transitive,
even though we haven’t drawn in the arrows needed to indicate this.) The reader is
asked to check this claim in Exercise 2.3.9. Clusters will play an important role in
Section 4.5.82
2 Models
To conclude this section we brieﬂy indicate how the ﬁltration method can be
extended to other modal languages. Let us ﬁrst consider modal languages based
on arbitrary modal similarity types τ . Fix a τ -model M = (W , R, V )∈τ and a
f
subformula closed set Σ as in Deﬁnition 2.36. Suppose MfΣ = (WΣ , R
, V f )∈τ
f
is a τ -model where WΣ and V f are as in Deﬁnition 2.36, and for  ∈ τ , R
satisfy
(ii) if Rwv1 . . . vn then Rf |w||v1 | . . . |vn |,
(iii) if Rf |w||v1 | . . . |vn |, then for all φ1 , . . . , φn ∈ Σ, if (φ1 , . . . , φn ) ∈ Σ
and M, v1  φ1 , . . . , M, vn  φn , then M, w  (φ1 , . . . , φn ).
Then MfΣ is a τ -ﬁltration of M through Σ.
With this deﬁnition at hand, Proposition 2.38 and Theorem 2.39 can be reformu-
lated and proved for τ -ﬁltrations, and suitable versions of the smallest and largest
ﬁltrations can also be deﬁned, resulting in a general modal analog of Theorem 2.41,
the Finite Model Property.
What about basic temporal logic, PDL, and arrow logic? It turns out that the
ﬁltration method works well for all of these. For basic temporal logic we need to
issue the customary warning (we need to be explicit about what the ﬁltration does
to Rˇ), but with this observed, matters are straightforward. Exercise 2.3.7 asks the
reader to deﬁne transitive ﬁltrations for the basic temporal language.
Matters are far more interesting (and difﬁcult) with PDL – but here too, by mak-
ing use of a clever idea called the Fischer-Ladner closure, it is possible to use a
ﬁltration style argument to show that PDL has the ﬁnite model property; we will do
this in Section 4.8 as part of a completeness proof (Theorem 4.91). Exercise 2.3.10
deals with the ﬁnite model property for arrow logic.
Exercises for Section 2.3
2.3.1 Find two models M and M  and states w and w  in these models such that w ↔n w
for all n, but it is not the case that w ↔ w are bisimilar. (Hint: we drew a picture of such
a pair of models in the previous section.)
2.3.2 Generalize the deﬁnition of n-bisimulations (Deﬁnition 2.30) from diamond-only
to arbitrary modal languages. Then prove Proposition 2.31 (that n-bisimilarity for all n
implies modal equivalence and conversely) for arbitrary modal languages.
2.3.3 Lemma 2.33 tells us that if we are only interested in the satisﬁability of modal for-
mulas of degree at most k, we can delete all states that lie beyond the k-horizon without
affecting satisﬁability. Prove this.
2.3.4 The proof of Theorem 2.34 uses a selection-of-points argument to establish the ﬁnite
model property. But no proof details were given for the last (crucial) claim in the proof,
namely that M4 , w2 is k-bisimilar to M3 , w2 . Fill in this gap.2.4 The Standard Translation
83
2.3.5 First show that not every ﬁltration of a transitive model is transitive. Then prove
Lemma 2.42. That is, show that the relation R t deﬁned there is indeed a ﬁltration, and that
any ﬁltration of a transitive model that makes use of R t is guaranteed to be transitive.
2.3.6 Finish the proof of Lemma 2.40. That is, prove that the ﬁltrations R s and Rl are
indeed the smallest and the largest ﬁltration, respectively. In addition, give an example of
a model and a set of formulas for which R s and Rl coincide.
2.3.7 Show that every transitive model (W, R, V ) has a transitive temporal ﬁltration. (Take
care to specify what the ﬁltration does to R ˇ.)
2.3.8 Call a frame or model euclidean if it satisﬁes ∀xyz ((Rxy ∧ Rxz) → Ryz), and let
E be the class of euclidean models. Fix a formula ξ, and let Σ be the smallest subformula
closed set of formulas containing ξ that satisﬁes, for all formulas ψ: if 3ψ ∈ Σ, then
23ψ ∈ Σ. (Recall that 2 is an abbreviation of ¬3¬.) Note that in general, Σ will be
inﬁnite.
(a) Prove that E  3ψ → 23ψ.
(b) Prove that every euclidean model can be ﬁltrated through Σ to a euclidean model.
(c) Show that every euclidean model satisﬁes the following modal reduction principles:
333 ↔ 33, 332 ↔ 32, 323 ↔ 33 and 322 ↔ 32. That is, prove that
the formulas 333φ ↔ 33φ, . . . are true throughout every euclidean model.
Conclude that Σ is ﬁnite modulo equivalence on euclidean models.
(d) Prove that the basic modal similarity type has the ﬁnite model property with respect
to the class of euclidean models. Can you prove this result simply by ﬁltrating
through any subformula closed set of formulas containing ξ?
2.3.9 Let Mf be a ﬁnite, transitive ﬁltration of a model based on the rationals with their
usual ordering. Describe the possible shape of M f in terms of clusters and sets consisting
of a single, irreﬂexive point. In particular, show that there is a natural way to impose
a linear order on this collection of subsets of Q. Can M f have two adjacent singleton
clusters? Two adjacent singleton sets each consisting of an irreﬂexive point?
2.3.10 Consider the similarity type τ → of arrow logic.
(i) Show that τ→ has the ﬁnite model property with respect to the class of all arrow
models.
(ii) Consider the class of arrow models based on arrow frames F = (W, C, R, I) such
that for all s, t and u in W we have (i) Cstu iff Csut iff Ctus and (ii) Cstu and
Iu iff s = t. Prove that arrow formulas have the ﬁnite model property with respect
to this class of arrow models.
(iii) Prove that τ→ does not have the ﬁnite model property with respect to the class of all
square models. (Hint: try to express that the extension of the propositional variable
p is a dense, linear ordering.)
2.4 The Standard Translation
In the Preface we warned the reader against viewing modal logic as an isolated
formal system (remember Slogan 3?), yet here we are, halfway through Chapter 2,
and we still have not linked modal logic with the wider logical world. We now put84
2 Models
this right. We deﬁne a link called the standard translation. This paves the way
for the results on modal expressivity in the sections that follow, for the study of
frames in the following chapter, and for the introduction of the guarded fragment
in Section 7.4.
We ﬁrst specify our correspondence languages – that is, the languages we will
translate modal formulas into.
Deﬁnition 2.44 For τ a modal similarity type and Φ a collection of proposition
letters, let L1τ (Φ) be the ﬁrst-order language (with equality) which has unary pred-
icates P0 , P1 , P2 , . . . corresponding to the proposition letters p0 , p1 , p2 , . . . in
Φ, and an (n + 1)-ary relation symbol R for each (n-ary) modal operator  in
our similarity type. We write α(x) to denote a ﬁrst-order formula α with one free
variable, x.
We are now ready to deﬁne the standard translation.
Deﬁnition 2.45 (Standard Translation) Let x be a ﬁrst-order variable. The stan-
dard translation ST x taking modal formulas to ﬁrst-order formulas in L1τ (Φ) is
deﬁned as follows:
ST x (p) = P x,
ST x (⊥) = x = x,
ST x (¬φ) = ¬ST x (φ),
ST x (φ ∨ ψ) = ST x (φ) ∨ ST x (ψ),
ST x ((φ1 , . . . , φn )) = ∃y1 . . . ∃yn (Rxy1 . . . yn ∧
ST y1 (φ1 ) ∧ · · · ∧ ST yn (φn )),
where y1 , . . . , yn are fresh variables (that is, variables that have not been used so far
in the translation). When working with the basic modal language, the last clause
boils down to:
ST x (3φ) = ∃y (Rxy ∧ ST y (φ)).
Note that (to keep notation simple) we prefer to use R rather than R3 , and we
will continue to do this. We leave to the reader the task of working out what
ST x ((φ1 , . . . , φn )) is, but we will point out that for the basic modal language
the required clause is:
ST x (2φ) = ∀y (Rxy → ST y (φ)).
Example 2.46 Let us see how this works. Consider the formula 3(2p → q).
ST x (3(2p → q)) = ∃y1 (Rxy1 ∧ ST y1 (2p → q))2.4 The Standard Translation
85
= ∃y1 (Rxy1 ∧ (ST y1 (2p) → ST y1 (q)))
= ∃y1 (Rxy1 ∧ (∀y2 (Ry1 y2 → ST y2 (p)) → Qy1 ))
= ∃y1 (Rxy1 ∧ (∀y2 (Ry1 y2 → P y2 ) → Qy1 )).
Note that (this version of) the standard translation leaves the choice of fresh vari-
ables unspeciﬁed. For example, ∃y256 (Rxy256 ∧ (∀y14 (Ry256 y14 → P y14 ) →
Qy256 )) is a legitimate translation of 3(2p → q), and indeed there are inﬁnitely
many others, all differing only in the bound variables they contain. Later in the
section we remove this indeterminacy – elegantly.
It should be clear that the standard translation makes good sense: it is essentially
a ﬁrst-order reformulation of the modal satisfaction deﬁnition. For any modal for-
mula φ, ST x (φ) will contain exactly one free variable (namely x); the role of this
free variable is to mark the current state; this use of a free variable makes it pos-
sible for the global notion of ﬁrst-order satisfaction to mimic the local notion of
modal satisfaction. Furthermore, observe that modalities are translated as bounded
quantiﬁers, and in particular, quantiﬁers bounded to act only on related states; this
is the obvious way of mimicking the local action of the modalities in ﬁrst-order
logic. Because of its importance it is worth pinning down just why the standard
translation works.
Models for modal languages based on a modal similarity type τ and a collection
of proposition letters Φ can also be viewed as models for L1τ (Φ). For example,
if τ contains just a single diamond 3, then the corresponding ﬁrst-order language
L1τ (Φ) has a binary relation symbol R and a unary predicate symbol corresponding
to each proposition letter in Φ – and a ﬁrst-order model for this language needs to
provide an interpretation for these symbols. But a (modal) model M = (W, R, V )
supplies precisely what is required: the binary relation R can be used to interpret
the relation symbol R, and the set V (pi ) can be used to interpret the unary predicate
Pi . This should not come as a surprise. As we emphasized in Chapter 1 (especially
Sections 1.1 and 1.3) there is no mathematical distinction between modal and ﬁrst-
order models – both modal and ﬁrst-order models are simply relational structures.
Thus it makes perfect sense to write things like M |= STx (φ)[w], which means
that the ﬁrst-order formula ST x (φ) is satisﬁed (in the usual sense of ﬁrst-order
logic) in the model M when w is assigned to the free variable x.
Proposition 2.47 (Local and Global Correspondence on Models) Fix a modal
similarity type τ , and let φ be a τ -formula. Then:
(i) For all M and all states w of M: M, w  φ iff M |= STx (φ)[w].
(ii) For all M: M  φ iff M |= ∀x ST x (φ).
Proof. By induction on φ. We leave this to the reader as Exercise 2.4.1.86
2 Models
Summing up: when interpreted on models, modal formulas are equivalent to ﬁrst-
order formulas in one free variable. Fine – but what does that give us? Lots!
Proposition 2.47 is a bridge between modal and ﬁrst-order logic – and we can use
this bridge to import results, ideas, and proof techniques from one to the other.
Example 2.48 First-order logic has the compactness property: if Θ is a set of ﬁrst-
order formulas, and every ﬁnite subset of Θ is satisﬁable, then so is Θ itself. It also
has the downward Löwenheim-Skolem property: if a set of ﬁrst-order formulas has
an inﬁnite model, then it has a countably inﬁnite model.
It follows that modal logic must have both these properties (over models) too.
Consider compactness. Suppose Σ is a set of modal formulas every ﬁnite subset
of which is satisﬁable – is Σ itself satisﬁable? Yes. Consider the set {STx (φ) |
φ ∈ Σ}. As every ﬁnite subset of Σ has a model it follows (reading item (i) of
Proposition 2.47 left to right) that every ﬁnite subset of {STx (φ) | φ ∈ Σ} does
too, and hence (by ﬁrst-order compactness) that this whole set is satisﬁable in some
model, say M. But then it follows (this time reading item (i) of Proposition 2.47
right to left) that Σ is satisﬁable in M, hence modal satisﬁability over models is
compact.
And there is interesting trafﬁc from modal logic to ﬁrst-order logic too. For
example, a signiﬁcant difference between modal and ﬁrst-order logic is that modal
logic is decidable (over arbitrary models) but ﬁrst-order logic is not. By using
our understanding of modal decidability, it is possible to locate novel decidable
fragments of ﬁrst-order logic, a theme we will return to in Section 7.4 when we
discuss the guarded fragment.
Just as importantly, the standard translation gives us a new research agenda for
investigating modal expressivity: correspondence theory. The central aim of this
chapter is to explore the expressivity of modal logic over models – but how is ex-
pressivity to be measured? Proposition 2.47 suggests an interesting strategy: try to
characterize the fragment of ﬁrst-order logic picked out by the standard translation.
It is obvious on purely syntactic grounds that the standard translation is not
surjective (standard translations of modal formulas contain only bounded quan-
tiﬁers) – but could every ﬁrst-order formula (in the appropriate correspondence
language) be equivalent to the translation of a modal formula? No. This is very
easy to see: whereas modal formulas are invariant under bisimulations, ﬁrst-order
formulas need not be; thus any ﬁrst-order formula which is not invariant under
bisimulations cannot be equivalent to the translation of a modal formula. We have
seen such a formula in Section 2.2 (namely ∃y1 y2 y3 (y1 = y2 ∧ y1 = y3 ∧ y2 =
y3 ∧ Rxy1 ∧ Rxy2 ∧ Ry1 y3 ∧ Ry2 y3 )), and it is easy to ﬁnd simpler examples.
Thus the (ﬁrst-order formulas equivalent to) standard translations of model for-
mulas are a proper subset of the correspondence language. Which subset? Here2.4 The Standard Translation
87
is a nice observation. The standard translation can be reformulated so that it maps
every modal formula into a very small fragment of L1τ (Φ), namely a certain ﬁnite-
variable fragment. Suppose the variables of L1τ (Φ) have been ordered in some way.
Then the n-variable fragment of L1τ (Φ) is the set of L1τ (Φ) formulas that contain
only the ﬁrst n variables. As we will now see, by judicious reuse of variables, a
modal language with operators of arity at most n can be translated into the (n + 1)-
variable fragment of L1τ (Φ). (Reuse of variables is the name of the game when
working with ﬁnite variable fragments. For example, we can express the existence
of three different points in a linear ordering using only two variables as follows:
∃xy (x < y ∧ ∃x (y < x)).)
Proposition 2.49
(i) Let τ be a modal similarity type that only contains di-
amonds. Then, every τ -formula φ is equivalent to a ﬁrst-order formula
containing at most two variables.
(ii) More generally, if τ does not contain modal operators  whose arity ex-
ceeds n, all τ -formulas are equivalent to ﬁrst-order formulas containing at
most (n + 1) variables.
Proof. Assume τ contains only diamonds a, b, . . . ; proving the general case
is left as Exercise 2.4.2. Fix two distinct individual variables x and y. Deﬁne two
variants ST x and ST y of the standard translation as follows:
ST x (p) = P x
ST x (⊥) = x = x
ST x (¬φ) = ¬ST x (φ)
ST x (φ ∨ ψ) = ST x (φ) ∨ ST x (ψ)
ST x (aφ) = ∃y (Ra xy ∧ ST y (φ))
ST y (p) = P y
ST y (⊥) = y = y
ST y (¬φ) = ¬ST y (φ)
ST y (φ ∨ ψ) = ST y (φ) ∨ ST y (ψ)
ST y (aφ) = ∃x (Ra yx ∧ ST x (φ)).
Then, for any τ -formula φ, its ST x -translation contains at most the two variables
x and y, and STx (φ) is equivalent to the original standard translation of φ.
Example 2.50 Let us see how this modiﬁed standard translation works. Consider
again the formula 3(2p → q).
ST x (3(2p → q)) = ∃y (Rxy ∧ ST y (2p → q))
= ∃y (Rxy ∧ (∀x (Ryx → ST x (p)) → Qy))
= ∃y (Rxy ∧ (∀x (Ryx → P x) → Qy)).
That is, we just keep ﬂipping between the two variables x and y. The result is
a translation containing only two variables (instead of the three used in Exam-
ple 2.46). As a side effect, the indeterminacy associated with the original version
of the standard translation has disappeared.88
2 Models
This raises another question: is every ﬁrst-order formula α(x) in two variables
equivalent to the translation of a basic modal formula? Again the answer is no.
There is even a ﬁrst-order formula in a single variable x which is not equivalent
to any modal formula, namely Rxx. To see this, assume for the sake of a con-
tradiction that φ is a modal formula such that STx (φ) is equivalent to Rxx. Let
M be a singleton reﬂexive model and let w be the unique state in M; obviously
(irrespective of the valuation) M |= Rxx[w]. Let N be a model based on the strict
ordering of the integers; obviously (again, irrespective of the valuation), for every
integer v, N |= ¬Rxx[v]. Let Z be the relation which links every integer with the
unique state in M, and assume that the valuations in N and M are such that Z is
a bisimulation (for example, make all proposition letters true at all points in both
models). As M |= Rxx[w], it follows by Proposition 2.47 that M, w  φ (after all,
by assumption Rxx is equivalent to ST x (φ)). But for any integer v, we have that
w ↔ v, hence N, v  φ. Hence (again by Proposition 2.47 and our assumption
that ST x (φ) is equivalent to Rxx) we have that N |= Rxx[v], contradicting the
fact that N |= ¬Rxx[v].
We will not discuss correspondence theory any further here, but in Section 2.6
we will prove one of its central results, the van Benthem Characterization Theorem:
a ﬁrst-order formula is equivalent to the translation of a modal formula if and only
if it is invariant under bisimulations.
Proposition 2.47 is also going to help us investigate modal expressivity in other
ways, notably via the concept of deﬁnability.
Deﬁnition 2.51 Let τ be a modal similarity type, C a class of τ -models, and Γ a
set of formulas over τ . We say that Γ deﬁnes or characterizes a class K of models
within C if for all models M in C we have that M is in K iff M  Γ . If C is
the class of all τ -models, we simply say that Γ deﬁnes or characterizes K; we omit
brackets whenever Γ is a singleton. We will say that a formula φ deﬁnes a property
whenever φ deﬁnes the class of models satisfying that property.
It is immediate from Proposition 2.47 that if a class of models is deﬁnable by a set
of modal formulas, then it is also deﬁnable by a set of ﬁrst-order formulas – but
this is too obvious to be interesting. The important way in which Proposition 2.47
helps, is by making it possible to exploit standard model construction techniques
from ﬁrst-order model theory. For example, in Section 2.6 we will prove Theo-
rem 2.75 which says that a class of (pointed) models is modally deﬁnable if and
only if it is closed under bisimulations and ultraproducts (an important construc-
tion known from ﬁrst-order model theory; see Appendix A), and its complement
is closed under ultrapowers (another standard model theoretic construction). It
would be difﬁcult to overemphasize the importance of the standard translation; it
is remarkable that such a simple idea can lead to so much.2.4 The Standard Translation
89
To conclude this section, let us see how to adapt these ideas to the basic temporal
language, PDL, and arrow logic. The case of basic temporal logic is easy: all we
have to do is add a clause for translating the backward looking operator P :
ST x (P φ) = ∃y (Ryx ∧ ST y (φ)).
Note that we are using the more sophisticated approach introduced in the proof
of Proposition 2.49: ﬂipping between two translations STx and ST y . (Thus we
really need to add a mirror clause which ﬂips the variables back.) So, just like
the basic modal language, the basic temporal language can be mapped into a two
variable fragment of the correspondence language. Moreover (again, as with the
basic modal language) not every ﬁrst-order formula in two variables is equivalent
to (the translation of) a basic temporal formula (see Exercise 2.4.3).
Propositional dynamic logic calls for more drastic changes. Let us ﬁrst look at
the ∗-free fragment – that is, at PDL formulas without occurrences of the Kleene
star. In PDL both formulas and modalities are recursively structured, so we are go-
ing to need two interacting translation functions: one to handle the formulas, the
other to handle the modalities. The only interesting clause in the formula transla-
tion is the following:
ST x (πφ) = ∃y (ST xy (π) ∧ ST y (φ)).
That is, instead of returning a ﬁxed relation symbol (say R), the formula translation
ST x calls on STxy to start recursively decomposing the program π. Why does this
part of the translation require two free variables? Because its task is to deﬁne a
binary relation.
ST xy (a) = Ra xy (and similarly for other pairs of variables),
ST xy (π1 ∪ π2 ) = ST xy (π1 ) ∨ ST xy (π2 ),
ST xy (π1 ; π2 ) = ∃z (ST xz (π1 ) ∧ ST zy (π2 )).
It follows that we can translate the ∗-free fragment of PDL into a three variable
fragment of the correspondence language. The details are worth checking; see
Exercise 2.4.4.
But the really drastic change comes when we consider the full language of PDL
(that is, with Kleene star). Recall that a program α∗ is interpreted using the reﬂex-
ive, transitive closure of Rα . But the reﬂexive, transitive closure of an arbitrary
relation is not a ﬁrst-order deﬁnable relation (see Exercise 2.4.5). So the standard
translation for PDL needs to take us to a richer background logic than ﬁrst-order
logic, one that can express this concept. Which one should we use? There are
many options here, but to motivate our actual choice recall the deﬁnition of the
meaning of a PDL program α∗ :
Rα∗ =
n
(Rα )n ,2 Models
90
where Rαn is deﬁned by
R0 xy iff x = y and Rn+1 xy iff ∃z (Rn xz ∧ Rzy).
Thus, if we were allowed to write inﬁnitely long disjunctions, it would be easy to
capture the meaning of an iterated program α∗ :
(Rα )∗ xy iff (x = y) ∨ Rα xy ∨
∃z1 . . . zn (Rα xz1 ∧ · · · ∧ Rα zn y).
n≥1
In inﬁnitary logic we can do this. More precisely, in Lω1 ω we are allowed to form
formulas as in ﬁrst-order logic, and, in addition, to build countably inﬁnite dis-
junctions and conjunctions. We will take Lω1 ω as the target logic for the standard
translation of PDL. We have seen most of the clauses we need: we use the clauses
for the ∗-free fragment given above, and in addition the following clause to cater
for the Kleene star:
ST xy (α∗ ) =
(x = y) ∨ ST xy (α) ∨
∃z1 . . . zn (ST xz1 (α) ∧ · · · ∧ ST zn y (α)).
n≥1
This example of PDL makes an important point vividly: we cannot always hope
to embed modal logic into ﬁrst-order logic. Indeed in the following chapter we
will see that when it comes to analyzing the expressive power of modal logic at
the level of frames, the natural correspondence language (even for the basic modal
language) is second-order logic.
There is nothing particularly interesting concerning the standard translation for
the arrow language of Example 1.16. However, this changes when we turn to
square models: in Exercise 2.4.6 the reader is asked to prove that on this class of
models, the arrow language corresponds to a ﬁrst-order language with binary pred-
icate symbols, and that, in fact, it is expressively equivalent to the three variable
fragment of such a language.
Exercises for Section 2.4
2.4.1 Prove Proposition 2.47. That is, check that the standard translation really is correct.
2.4.2 Prove Proposition 2.49 for arbitrary modal languages. That is, show that if τ does
not contain modal operators  whose arity exceeds n, all τ -formulas are equivalent to
ﬁrst-order formulas containing at most (n + 1) variables.
2.4.3 Show that there are ﬁrst-order formulas α(x) using at most two variables that are not
equivalent to the standard translation of a basic temporal formula.
2.4.4 In this exercise you should ﬁll in some of the details for the standard translation for
PDL .2.5 Modal Saturation via Ultraﬁlter Extensions
91
(a) Check that the translation for the ∗-free fragment of PDL really does map all such
formulas into the three variable fragment of the corresponding ﬁrst-order language.
(b) Show that in fact, there is a translation into the two variable fragment of this corre-
sponding ﬁrst-order language.
2.4.5 The aim of this exercise is to show that taking the reﬂexive, transitive closure of a
binary relation is not a ﬁrst-order deﬁnable operation.
(a) Show that the class of connected graphs is not ﬁrst-order deﬁnable:
(i) For l ∈ N, let Cl be the graph given by a cycle of length l + 1:
Cl = ({0, . . . , l}, {(i, i + 1), (i + 1, i) | 0 ≤ i < l} ∪ {(0, l), (l, 0)})
Show that for every k ∈ N and l ≥ 2 k the graph C l satisﬁes the same ﬁrst-
order sentences of quantiﬁer rank at most k as the disjoint union C l  Cl .
(ii) Conclude that the class of connected graphs is not ﬁrst-order deﬁnable.
(b) Use item (a) to conclude that the reﬂexive transitive closure of a relation is not
ﬁrst-order deﬁnable.
2.4.6 Consider the class of square models for arrow logic. Observe that a square model
M = (SU , V ) can be seen as a ﬁrst-order model M ∗ = (U, V (p))p∈Φ if we let each
propositional variable p ∈ Φ correspond to a dyadic relation symbol P .
(a) Work out this observation in the following sense. Deﬁne a suitable translation (·) ∗
mapping an arrow formula φ to a formula φ ∗ (x0 , x1 ) in this ‘dyadic correspondence
language.’ Prove that this translation has the property that for all arrow formulas φ
and all square models M the following correspondence holds:
M, (a0 , a1 )  φ iff M∗ |= φ∗ (x0 , x1 )[a0 , a1 ].
(b) Show that this translation can be done within the three variable fragment of ﬁrst-
order logic.
(c) Prove that conversely, every formula α(x 0 , x1 ) that uses only three variables, in a
ﬁrst-order language with binary predicates only, is equivalent to the translation of
an arrow formula on the class of square models.
2.5 Modal Saturation via Ultraﬁlter Extensions
Bisimulations and the standard translation are two of the tools we need to under-
stand modal expressivity over models. This section introduces the third: ultraﬁlter
extensions. To motivate their introduction, we will ﬁrst discuss Hennessy-Milner
model classes and modally saturated models; both generalize ideas met in our ear-
lier discussion of bisimulations. We will then introduce ultraﬁlter extensions as a
way of building modally saturated models, and this will lead us to an elegant result:
modal equivalence implies bisimilarity-somewhere-else.
M-saturation
Theorem 2.20 tells us that bisimilarity implies modal equivalence, but we have
already seen that the converse does not hold in general (recall Figure 2.5). The92
2 Models
Hennessy-Milner Theorem shows that the converse does hold in the special case of
image-ﬁnite models. Let us try and generalize this theorem.
First, when proving Theorem 2.24, we exploited the fact that, between image-
ﬁnite models, the relation of modal equivalence itself is a bisimulation. Classes of
models for which this holds are evidently worth closer study.
Deﬁnition 2.52 (Hennessy-Milner Classes) Let τ be a modal similarity type, and
K a class of τ -models. K is a Hennessy-Milner class, or has the Hennessy-Milner
property, if for every two models M and M in K and any two states w, w of M
and M , respectively, w  w implies M, w ↔ M , w .
For example, by Theorem 2.24, the class of image-ﬁnite models has the Hennessy-
Milner property. On the other hand, no class of models containing the two models
in Figure 2.5 has the Hennessy-Milner property.
We generalize the notion of image-ﬁniteness; doing so leads us to the concept of
modally-saturated or (brieﬂy) m-saturated models. Suppose we are working in the
basic modal language. Let M = (W, R, V ) be a model, let w be a state in W , and
let Σ = {φ0 , φ1 , . . .} be an inﬁnite set of formulas. Suppose that w has successors
v0 , v1 , v2 , . . . where (respectively) φ0 , φ0 ∧ φ1 , φ0 ∧ φ1 ∧ φ2 , . . . hold. If there is no
successor v of w where all formulas from Σ hold at the same time, then the model
is in some sense incomplete. A model is called m-saturated if incompleteness of
this kind does not occur.
To put it another way: suppose that we are looking for a successor of w at
which every formula φi of the inﬁnite set of formulas Σ = {φ0 , φ1 , . . .} holds.
M-saturation is a kind of compactness property, according to which it sufﬁces to
ﬁnd satisfying successors of w for arbitrary ﬁnite approximations of Σ.
Deﬁnition 2.53 (M-saturation) Let M = (W, R, V ) be a model of the basic
modal similarity type, X a subset of W and Σ a set of modal formulas. Σ is
satisﬁable in the set X if there is a state x ∈ X such that M, x  φ for all φ in Σ;
Σ is ﬁnitely satisﬁable in X if every ﬁnite subset of Σ is satisﬁable in X.
The model M is called m-saturated if it satisﬁes the following condition for
every state w ∈ W and every set Σ of modal formulas:
If Σ is ﬁnitely satisﬁable in the set of successors of w,
then Σ is satisﬁable in the set of successors of w.
The deﬁnition of m-saturation for arbitrary modal similarity types runs as follows.
Let τ be a modal similarity type, and let M be a τ -model. M is called m-saturated
if, for every state w of M and every (n-ary) modal operator  ∈ τ and sequence
Σ1 , . . . , Σn of sets of modal formulas, we have the following:2.5 Modal Saturation via Ultraﬁlter Extensions
93
If for every sequence of ﬁnite subsets Δ1 ⊆ Σ1 , . . . , Δn ⊆ Σn there are
states v1 , . . . , vn such that Rwv1 . . . vn and v1  Δ1 , . . . , vn  Δn ,
then there are states v1 , . . . , vn in M such that Rwv1 . . . vn and v1  Σ1 ,
. . . , v n  Σn .
Proposition 2.54 Let τ be a modal similarity type. Then the class of m-saturated
τ -models has the Hennessy-Milner property.
Proof. We only prove the proposition for the basic modal language. Let M =
(W, R, V ) and M = (W  , R , V  ) be two m-saturated models. It sufﬁces to prove
that the relation  of modal equivalence between states in M and states in M is a
bisimulation. We conﬁne ourselves to a proof of the forth condition of a bisimula-
tion, since the condition concerning the propositional variables is trivially satisﬁed,
and the back condition is completely analogous to the case we prove.
So, assume that w, v ∈ W and w ∈ W  are such that Rwv and w  w .
Let Σ be the set of formulas true at v. It is clear that for every ﬁnite subset Δ of


Σ we have M, v  Δ, hence M, w  3 Δ. As w  w , it follows that


M , w  3 Δ, so w has an R -successor vΔ such that M , vΔ  Δ. In
other words, Σ is ﬁnitely satisﬁable in the set of successors of w ; but, then, by
m-saturation, Σ itself is satisﬁable in a successor v of w . Thus v  v .
Ultraﬁlter extensions
So the class of m-saturated models satisﬁes the Hennessy-Milner property – but
how do we actually build m-saturated models? To this end, we will now introduce
the last of the ‘big four’ model constructions: ultraﬁlter extensions. The ultraﬁlter
extension of a structure (model or frame) is a kind of completion of the original
structure. The construction adds states to a model in order to make it m-saturated.
Sometimes the result is a model isomorphic to the original (for example, when
the original model is ﬁnite) but when working with inﬁnite models, the ultraﬁlter
extension always adds lots of new points. In the deﬁnition of ultraﬁlter extension
we need operations on the power set algebra of a frame; we have already met one
of these operations in Section 1.4 when we introduced general frames.
Deﬁnition 2.55 Given an (n + 1)-ary relation R on a set W , we deﬁne the follow-
ing two n-ary operations mR and lR on the power set P(W ) of W :
mR (X1 , . . . , Xn ) := {w ∈ W | there exist w1 , . . . , wn such that
Rww1 . . . wn and wi ∈ Xi for all i},
lR (X1 , . . . , Xn ) := {w ∈ W | for all w1 , . . . , wn : if Rww1 . . . wn ,
then there is an i with wi ∈ Xi }.2 Models
94
For a binary relation R, mR (X) is the set of points that ‘can see’ a state in X, and
lR (X) is the set of points that ‘only see’ states in X. It follows that for any model
M = (W, R, V ) we have
V (3φ) = mR (V (φ)) and V (2φ) = lR (V (φ)).
Similar identities hold for modal operators of higher arity. Furthermore, for any
relation R, mR and lR are each other’s dual, in the following sense:
Proposition 2.56 Let R be a relation of arity n + 1 on the set W . Then, for every
n-tuple X1 , . . . , Xn of subsets of W we have
lR (X1 , . . . , Xn ) = W \ mR (W \ X1 , . . . , W \ Xn ).
Proof. Left to the reader.
We are ready to deﬁne ultraﬁlter extensions. As the name is meant to suggest, the
states of the ultraﬁlter extension of a model M are the ultraﬁlters over the universe
of M. Filters and ultraﬁlters are discussed in Appendix A. Readers encountering
this notion for the ﬁrst time, are advised to do Exercises 2.5.1–2.5.4.
Deﬁnition 2.57 (Ultraﬁlter Extension) Let τ be a modal similarity type, and
F = (W , R)∈τ a τ -frame. The ultraﬁlter extension ue F of F is deﬁned as
ue )
the frame (Uf (W ), R
∈τ . Here Uf (W ) is the set of ultraﬁlters over W and
ue
R u0 u1 . . . un holds for a tuple u0 , . . . , un of ultraﬁlters over W if we have that
mR (X1 , . . . , Xn ) ∈ u0 whenever Xi ∈ ui for all i with 1 ≤ i ≤ n.
The ultraﬁlter extension of a τ -model M = (F, V ) is the model ue M = (ue F,
V ue ) where V ue (pi ) is the set of ultraﬁlters of which V (pi ) is a member.
What are the intuitions behind this deﬁnition? First, note that the main ingredients
have a logical interpretation. Any subset of a frame can, in principle, be viewed as
(the extension or interpretation of) a proposition. A ﬁlter over the universe of the
frame can thus be seen as a theory, in fact as a logically closed theory, since ﬁlters
are both closed under intersection (conjunction) and upward closed (entailment).
Viewed this way, a proper ﬁlter is a consistent theory, for it does not contain the
empty set (falsum). Finally, an ultraﬁlter is a complete theory, or, as we will call it,
a state of affairs: for each proposition (subset of the universe) an ultraﬁlter chooses
between it and its negation (between the subset and its complementation).
How does this relate to ultraﬁlter extensions? In a given frame F not every state
of affairs needs to be ‘realized’, in the sense that there is a state satisfying all and
only the propositions belonging to the state of affairs; only the states of affairs that
correspond to the principal ultraﬁlters are realized, namely, as the points of the
frame. We build ue F by adding every state of affairs for F as a new element of the
domain – that is, ue F realizes every proposition in F.2.5 Modal Saturation via Ultraﬁlter Extensions
95
How should we relate these new elements in ue F to each other and to the original
ue u u . . . u if u
elements from F? The obvious choice is to stipulate that R
0 1
n
0
‘sees’ the n-tuple u1 , . . . , un . That is, whenever X1 , . . . , Xn are propositions of
u1 , . . . , un respectively, then u0 ‘sees’ this combination: that is, the proposition
mR (X1 , . . . , Xn ) is a member of u0 . The deﬁnition of the valuation V ue is self-
explanatory.
One ﬁnal comment: a special role in this section is played by the so-called prin-
cipal ultraﬁlters over W . Recall that, given an element w ∈ W , the principal
ultraﬁlter generated by w is the set πw = {X ⊆ W | w ∈ X}. By identifying a
state w of a frame F with the principal ultraﬁlter πw , it is easily seen that any frame
F is (isomorphic to) a submodel (but in general not a generated submodel) of its
ultraﬁlter extension. For we have the following equivalences, here proved for the
basic modal similarity type:
Rwv
iffw ∈ mR (X) for all X ⊆ W such that v ∈ X
iffmR (X) ∈ πw for all X ⊆ W such that X ∈ πv
(2.1)
ue
R πw πv .
iff
Let us make our discussion more concrete by considering an example.
Example 2.58 Consider the frame N = (N, <), the natural numbers in their usual
ordering (a transitive model, though we haven’t drawn in arrows to indicate this):
0
u
1
- u
2
- u
3
- u
4
- u
-
...
What is the ultraﬁlter extension of N? There are two kinds of ultraﬁlters over an
inﬁnite set: the principal ultraﬁlters that are in one-to-one correspondence with
the points of the set, and the non-principal ones which contain all co-ﬁnite sets,
and only inﬁnite sets, cf. Exercise 2.5.4. We have just remarked (see (2.1)) that
the principal ultraﬁlters form an isomorphic copy of the frame N inside ue N. So
where are the non-principal ultraﬁlters situated? The key fact here is that for any
pair u, u of ultraﬁlters, if u is non-principal, then Rue uu . To see this, let u be a
non-principal ultraﬁlter, and let X ∈ u . As X is inﬁnite, for any n ∈ N there is
an m such that n < m and m ∈ X. This shows that m< (X) = N. But N is an
element of every ultraﬁlter u.
This shows that the ultraﬁlter extension of N looks like a gigantic balloon at the
end of an inﬁnite string: it consists of a copy of N, followed by a large (uncount-
able) cluster consisting of all the non-principal ultraﬁlters (again, the following
diagram represents a transitive model):
0t
1
- t
2
- t
3
- t
4
- t
-
...


t
t
t
t
t
t
t
t
t
t
t

2 Models
96
We will prove two results concerning ultraﬁlter extensions. The ﬁrst one, Proposi-
tion 2.59, is an invariance result: any state in the original model is modally equiv-
alent to the corresponding principal ultraﬁlter in the ultraﬁlter extension. Then, in
Proposition 2.61 we show that ultraﬁlter extensions are m-saturated. Putting these
two facts together leads us to the main result of this section: two states are modally
equivalent iff their representatives in the ultraﬁlter extensions are bisimilar.
Proposition 2.59 Let τ be a modal similarity type, and M a τ -model. Then, for
any formula φ and any ultraﬁlter u over W , V (φ) ∈ u iff ue M, u  φ. Hence, for
every state w of M we have w  πw .
Proof. The second claim of the proposition is immediate from the ﬁrst one by the
observation that w  φ iff w ∈ V (φ) iff V (φ) ∈ πw .
The proof of the ﬁrst claim is by induction on φ. The basic case is immediate
from the deﬁnition of V ue . The proofs of the boolean cases are straightforward
consequences of the deﬁning properties of ultraﬁlters. As an example, we treat
negation; suppose that φ is of the form ¬ψ, then
V (¬ψ) ∈ u
iff
iff
iff
iff
W \ V (ψ) ∈ u
V (ψ) ∈ u
ue M, u  ψ
(induction hypothesis)
ue M, u  ¬ψ.
Next, consider the case where φ is of the form 3ψ (we only treat the basic modal
similarity type, leaving the general case as an exercise to the reader). Assume ﬁrst
that ue M, u  3ψ. Then, there is an ultraﬁlter u such that Rue uu and ue M, u 
ψ. The induction hypothesis implies that V (ψ) ∈ u , so by the deﬁnition of Rue ,
mR (V (ψ)) ∈ u. Now the result follows immediately from the observation that
mR (V (ψ)) = V (3ψ).
The left-to-right implication requires a bit more work. Assume that V (3ψ) ∈ u.
We have to ﬁnd an ultraﬁlter u such that V (ψ) ∈ u and Rue uu . The latter con-
straint reduces to the condition that mR (X) ∈ u whenever X ∈ u , or equivalently
(see Exercise 2.5.5):
u0 := {Y | lR (Y ) ∈ u} ⊆ u .
We will ﬁrst show that u0 is closed under intersection. Let Y , Z be members
of u0 . By deﬁnition, lR (Y ) and lR (Z) are in u. But then lR (Y ∩ Z) ∈ u, as
lR (Y ∩ Z) = lR (Y ) ∩ lR (Z), as a straightforward proof shows. This proves that
Y ∩ Z ∈ u0 .
Next we make sure that for any Y ∈ u0 , Y ∩V (ψ) = ∅. Let Y be an arbitrary el-
ement of u0 , then by deﬁnition of u0 , lR (Y ) ∈ u. As u is closed under intersection
and does not contain the empty set, there must be an element x in lR (Y ) ∩ V (3ψ).
But then x must have a successor y in V (ψ). Finally, x ∈ lR (Y ) implies y ∈ Y .2.5 Modal Saturation via Ultraﬁlter Extensions
97
From the fact that u0 is closed under intersection, and the fact that for any Y ∈

u0 , Y ∩ V (ψ) = ∅, it follows that the set u0 ∪ {V (ψ)} has the ﬁnite intersection
property. So the Ultraﬁlter Theorem (Fact A.14 in the Appendix) provides us with
an ultraﬁlter u such that u0 ∪ {V (ψ)} ⊆ u . This ultraﬁlter u has the desired
properties: it is clearly a successor of u, and the fact that ue M, u  ψ follows
from V (ψ) ∈ u and the induction hypothesis.
Example 2.60 As with the invariance results of Section 2.1 (disjoint unions, gen-
erated submodels, and bounded morphisms), our new invariance result can be used
to compare the relative expressive power of modal languages. Consider the modal
constant whose truth deﬁnition in a model for the basic modal language is
M, w 
iff M |= Rxx[v] for some v in M.
Can such a modality be deﬁned in the basic modal language? No – a bisimulation
based argument given at the end of the previous section already establishes this.
Alternatively, we can see this by comparing the pictures of the frame (N, <) and
its ultraﬁlter extension given in Example 2.58. The former is loop-free (thus in any
model over this frame, M, 0  ), but the latter contains uncountably many loops
(thus ue M, π0  ). So if we want we have to add it as a primitive.
Proposition 2.61 Let τ be a modal similarity type, and let M be a τ -model. Then
ue M is m-saturated.
Proof. We only prove the proposition for the basic modal similarity type. Let
M = (W, R, V ) be a model; we will show that its ultraﬁlter extension ue M is m-
saturated. Consider an ultraﬁlter u over W , and a set Σ of modal formulas which
is ﬁnitely satisﬁable in the set of successors of u. We have to ﬁnd an ultraﬁlter u
such that Rue uu and ue M, u  Σ. Deﬁne
Δ = {V (φ) | φ ∈ Σ  } ∪ {Y | lR (Y ) ∈ u},
where Σ  is the set of (ﬁnite) conjunctions of formulas in Σ. We claim that the
set Δ has the ﬁnite intersection property. Since both {V (φ) | φ ∈ Σ } and {Y |
lR (Y ) ∈ u} are closed under taking intersections, it sufﬁces to prove that for an
arbitrary φ ∈ Σ and an arbitrary set Y ⊆ W for which lR (Y ) ∈ u, we have
V (φ) ∩ Y = ∅. But if φ ∈ Σ  , then by assumption, there is a successor u of u
such that ue M, u  φ, or, in other words, V (φ) ∈ u . Then, lR (Y ) ∈ u implies
Y ∈ u by Exercise 2.5.5. Hence, V (φ) ∩ Y is an element of the ultraﬁlter u and,
therefore, cannot be identical to the empty set.
It follows by the Ultraﬁlter Theorem that Δ can be extended to an ultraﬁlter u .
Clearly, u is the required successor of u in which Σ is satisﬁed.2 Models
98
We have ﬁnally arrived at the main result of this section: a characterization of
modal equivalence as bisimilarity-somewhere-else – namely, between ultraﬁlter
extensions.
Theorem 2.62 Let τ be a modal similarity type, and let M and M be τ -models,
and w, w two states in M and M , respectively. Then
M, w  M , w iff ue M, πw ↔ ue M , πw .
Proof. Immediate by Propositions 2.59, 2.61 and 2.54.
Three remarks. First, it is easy to deﬁne ultraﬁlter extensions and prove an analog
of Theorem 2.62 for the basic temporal logic and arrow logic; see Exercises 2.5.8
and 2.5.9. With PDL the situation is a bit more complex; see Exercise 2.5.11. (The
problem is that the property of one relation being the reﬂexive transitive closure
of another is not preserved under taking ultraﬁlter extensions.) Second, we have
not seen the last of ultraﬁlter extensions. Like disjoint unions, generated submod-
els, and bounded morphisms, ultraﬁlter extensions are a fundamental modal model
construction technique, and we will make use of them when we discuss frames (in
Chapter 3) and algebras (in Chapter 5). We will shortly see that ultraﬁlter exten-
sions tie in neatly with ideas from ﬁrst-order model theory – and we will use this
to prove a second bisimilarity-somewhere-else result, Lemma 2.66. Finally, some
readers may still have the feeling that taking the ultraﬁlter extension of a model is
a far less natural construction than the other model operations that we have met.
These readers are advised to hold on until (or take a peek ahead towards) Chapter 5,
where we will see that ultraﬁlter extensions are indeed a very natural byproduct of
modal logic’s duality theory.
Exercises for Section 2.5
2.5.1 Let E be any subset of P(W ), and let F be the ﬁlter generated by E.
(a) Prove that indeed, F is a ﬁlter over W . (Show that in general, the intersection of a
collection of ﬁlters is again a ﬁlter.)
(b) Show that F is the set of all X ∈ P(W ) such that either X = W or for some Y 1 ,
. . . , Yn ∈ E,
Y1 ∩ · · · ∩ Yn ⊆ X.
(c) Prove that F is proper (that is: it does not coincide with P(W )) iff E has the ﬁnite
intersection property.
2.5.2 Let W be a non-empty set, and let w be an element of W . Show that the principal
ultraﬁlter generated by w, that is, the set {X ∈ P(W ) | w ∈ X}, is indeed an ultraﬁlter
over W .
2.5.3 Let F be a ﬁlter over W .2.5 Modal Saturation via Ultraﬁlter Extensions
99
(a) Prove that F is an ultraﬁlter if and only if it is proper and maximal, that is, it has
no proper extensions.
(b) Prove that F is an ultraﬁlter if and only if it is proper and for each pair of subsets
X, Y of W we have that X ∪ Y ∈ F iff X ∈ F or Y ∈ F .
2.5.4 Let W be an inﬁnite set. Recall that X ⊆ W is co-ﬁnite if W \ X is ﬁnite.
(a) Prove that the collection of co-ﬁnite subsets of W has the ﬁnite intersection prop-
erty.
(b) Show that there are ultraﬁlters over W that do not contain any ﬁnite set.
(c) Prove that an ultraﬁlter is non-principal if and only if it contains only inﬁnite sets
if and only if it contains all co-ﬁnite sets.
(d) Prove that any ultraﬁlter over W has uncountably many elements.
2.5.5 Given a model M = (W, R, V ) and two ultraﬁlters u and v over W , show that
Rue uv if and only if {Y | l R (Y ) ∈ u} ⊆ v.
2.5.6 Let B = (B, R) be the transitive binary tree; that is, B is the set of ﬁnite strings of
0s and 1s, and Rστ holds if σ is a proper initial segment of τ . The aim of this exercise is
to prove that any non-principal ultraﬁlter over B determines an inﬁnite string of 0s and 1s.
More precisely, let B ω be the set of ﬁnite and inﬁnite strings of 0s and 1s, and R ω the
relation on B ω given by R ω στ if either σ is ﬁnite and a proper initial segment of τ , or else
σ = τ . Deﬁne a bounded morphism f : ue B → B ω .
2.5.7 Give an example of a model M which is point-generated while its ultraﬁlter exten-
sion is not.
2.5.8 Develop a notion of ultraﬁlter extension for basic temporal logic, and establish an
analog of Theorem 2.62 for basic temporal logic.
2.5.9 Develop a notion of ultraﬁlter extension for the arrow language introduced in Exam-
ple 1.14, and establish an analog of Theorem 2.62 for this language.
2.5.10 Show that, in general, ﬁrst-order formulas are not preserved under ultraﬁlter ex-
tensions. That is, give a model M, a state w, and a ﬁrst-order formula α(x) such that
M |= α(x)[w], but ue M |= α(x)[πw ], where πw is the principal ultraﬁlter generated by
w.
2.5.11 Consider a modal similarity type with two diamonds, 3 and ∗, and take any
model M = (S, R, R∗ , V ) with
S
R
R∗
= N ∪ {∞},
= {(n + 1, n), (∞, n) | n ∈ N},
= {(m, n) | m, n ∈ N, m ≥ n} ∪ ({∞} × S).
Note that R∗ is the reﬂexive transitive closure of R.
(a) Show that M, ∞  2∗2⊥.
(b) Let u be an arbitrary non-principal ultraﬁlter over S. Prove that R ue π∞ u.
(c) Let u be an arbitrary non-principal ultraﬁlter over S. Prove that u has an R ue -
successor in ue M, and that each of its R ue -successors is again a non-principal
ultraﬁlter.100
2 Models
(d) Now suppose that we add a new diamond  to the language, and that in the
model ue M we take R to be the reﬂexive transitive closure of R ue . Show that
ue M, π∞  3[]3.
(e) Prove that R ∗ue = R . (Hint: use Proposition 2.59, and conclude that the ultraﬁlter
extension of a regular PDL-model need not be a regular PDL-model.)
(f) Prove that every non-principal ultraﬁlter over S has a unique R ue -successor.
2.6 Characterization and Deﬁnability
In Section 2.3 we posed two important questions about modal expressivity:
(i) What is the modal fragment of ﬁrst-order logic? That is, which ﬁrst-order
formulas are equivalent to the standard translation of a modal formula?
(ii) Which properties of models are deﬁnable by means of modal formulas?
In this, the ﬁrst advanced track section of the book, we answer both questions. Our
main tool will be a second characterization of modal equivalence as bisimilarity-
somewhere-else, the Detour Lemma. Unlike the characterization just proved (The-
orem 2.62), the Detour Lemma rests on a number of non-modal concepts and re-
sults, all of which are centered on saturated models (a standard concept of ﬁrst-
order model theory). We start by introducing saturated models and use them to
describe the modal fragment of ﬁrst-order logic. After that we show how to build
saturated models. As corollaries we obtain results on modally deﬁnable proper-
ties of models. For background information on ﬁrst-order model theory, see Ap-
pendix A.
The van Benthem Characterization Theorem
To deﬁne the notion of saturated models, we need the concept of α-saturation, but
before giving a formal deﬁnition of the latter, we provide an informal description,
which the reader may want to use as a ‘working’ deﬁnition.
Informally, then, the notion of α-saturation can be explained as follows. First of
all, let Γ (x) be a set of ﬁrst-order formulas in which a single individual variable
x may occur free – such a set of formulas is called a type. A ﬁrst-order model M
realizes Γ (x) if there is an element w in M such that for all γ ∈ Γ , M |= γ[w].
Next, let M be a model for a given ﬁrst-order language L1 with domain W .
For a subset A ⊆ W , L1 [A] is the language obtained by extending L1 with new
constants a for all elements a ∈ A. MA is the expansion of M to a structure for
L1 [A] in which each a is interpreted as a.
Assume that A is of size at most α. For the sake of our informal deﬁnition
of α-saturation, assume that α = 3 and A = {a1 , a2 }. Let Γ (a1 , a2 , x) be a
type of the language L1 [A]; it is not difﬁcult to see that Γ (a1, a2 , x) is consistent
with the ﬁrst-order theory of MA iff Γ (a1 , a2 , x) is ﬁnitely realizable in MA , (that2.6 Characterization and Deﬁnability
101
is, MA realizes every ﬁnite subset Δ of Γ (a1, a2 , x)). So, for this particular set
Γ (a1 , a2 , x), 3-saturation of M means that if Γ (a1, a2 , x) is ﬁnitely realizable in
MA , then Γ (a1, a2 , x) is realizable in MA .
Yet another way of looking at 3-saturation for this particular set of formulas is
the following. Consider a formula γ(a1 , a2 , x), and let γ(x1 , x2 , x) be the formula
with the fresh variables x1 and x2 replacing each occurrence in γ of a1 and a2 ,
respectively. Then we have the following equivalence:
MA realizes {γ(a1 , a2 , x)} iff there is a b such that M |= γ(x1 , x2 , x)[a1 , a2 , b].
So, a model is α-saturated iff the following holds for every n < α, and every set Γ
of formulas of the form γ(x1 , . . . , xn , x).
If (a1 , . . . , an ) is an n-tuple such that for every ﬁnite Δ ⊆ Γ there is a bΔ
such that M |= γ(x1 , . . . , xn , x)[a1 , . . . , an , bΔ ] for every γ ∈ Δ,
then we have that there is a b such that M |= γ(x1 , . . . , xn , x)[a1 , . . . , an , b]
for every γ ∈ Γ .
This way of looking at α-saturation is useful, for it makes the analogy with m-
saturation of the previous section clear. Both m-saturated and countably saturated
models are rich in the number of types Γ (x) they realize, but the latter are far richer
than the former: they realize the maximum number of types.
Now, for the ‘ofﬁcial’ deﬁnition of α-saturation.
Deﬁnition 2.63 Let α be a natural number, or ω. A model M is α-saturated if for
every subset A ⊆ W of size less than α, the expansion MA realizes every set Γ (x)
of L1 [A]-formulas (with only x occurring free) that is consistent with the ﬁrst-order
theory of MA . An ω-saturated model is usually called countably saturated.
Example 2.64 (i) Every ﬁnite model is countably saturated. For, if M is ﬁnite,
and Γ (x) is a set of ﬁrst-order formulas consistent with the ﬁrst-order theory of
M, there exists a model N that is elementarily equivalent to M and that realizes
Γ (x). But, as M and N are ﬁnite, elementary equivalence implies isomorphism,
and hence Γ (x) is realized in M.
(ii) The ordering of the rational numbers (Q, <) is countably saturated as well.
The relevant ﬁrst-order language L1 has < and =. Take a subset A of Q and
let Γ (x) be a set of formulas in the resulting expansion L1 [A] of this ﬁrst-order
language that is consistent with the theory of (Q, <, a)a∈A . Then there exists a
model N of the theory of (Q, <, a)a∈A that realizes Γ (x). Now take a countable
elementary submodel N of N that contains at least one object realizing Γ (x). Then
N is a countable dense linear ordering without endpoints, and hence the ordering
of N is isomorphic to (Q, <). The interpretations (in N) of the constants a for102
2 Models
elements a in A may be copied across to N . Hence, as N realizes Γ (x), so does
N , and hence, so does (Q, <), as required.
(iii) The ordering of the natural numbers (N, <) is not countably saturated. To
see this, consider the following set of formulas:
Γ (x) := {∃y1 (y1 < x), . . . , ∃y1 . . . yn (y1 < · · · < yn < x), . . .}.
Γ (x) is clearly consistent with the theory of (N, <) as each of its ﬁnite subsets is
realizable in (N, <). Yet Γ (x) is clearly not realizable in (N, <).
The following result explains why countably saturated models matter to us.
Theorem 2.65 Let τ be a modal similarity type. Any countably saturated τ -model
is m-saturated. It follows that the class of countably saturated τ -models has the
Hennessy-Milner property.
Proof. We only consider the basic modal language. Assume that M = (W, R, V ),
viewed as a ﬁrst-order model, is countably saturated. Let a be a state in W , and
consider a set Σ of modal formulas which is ﬁnitely satisﬁable in the successor set
of a. Deﬁne Σ  to be the set
Σ  = {Rax} ∪ ST x (Σ),
where ST x (Σ) is the set {ST x (φ) | φ ∈ Σ} of standard translations of formulas
in Σ. Clearly, Σ  is consistent with the ﬁrst-order theory of Ma : Ma realizes every
ﬁnite subset of Σ , namely in some successor of a. So, by the countable saturation
of M, Σ  itself is realized in some state b. By Ma |= Rax[b] it follows that b is a
successor of a. Then, by Proposition 2.47 and the fact that Ma |= STx (φ)[b] for
all φ ∈ Σ, it follows that M, b  Σ. Thus Σ is satisﬁable in a successor of a.
In fact, we only need 2-saturation for the proof of Theorem 2.65 to go through.
This is because we restricted ourselves to the basic modal similarity type. We
leave it to the reader to check to which extent the ‘amount of saturation’ needed to
make the proof of Theorem 2.65 go through depends on the rank of the operators
of the similarity type.
We have yet to show that countably saturated models actually exist; this issue
will be addressed below (see Theorem 2.74). For now, we merely want to record the
following important use of saturated models; you may want to recall the deﬁnition
of an elementary embedding before reading the result (see Appendix A).
Lemma 2.66 (Detour Lemma) Let τ be a modal similarity type, and let M and
N be τ -models, and w and v states in M and N, respectively. Then the following
are equivalent:
(i) For all modal formulas φ: M, w  φ iff N, v  φ.2.6 Characterization and Deﬁnability
103
(ii) There exists a bisimulation Z : ue M, πw ↔ ue N, πv .
(iii) There exist countably saturated models M∗ , w∗ and N∗ , v ∗ and elementary
embeddings f : M M∗ and g : N N∗ such that
(a) f (w) = w∗ and g(v) = v∗ ,
(b) M∗ , w∗ ↔ N∗ , v ∗ .
What does the Detour Lemma say in words? Obviously (i) ⇒ (ii) is just our old
bisimulation-somewhere-else result (Theorem 2.62). The key new part is the im-
plication (i) ⇒ (iii). This says that if M, w and N, v are modally equivalent, then
both can be extended – more accurately: elementarily extended – to countably sat-
urated models M∗ , w∗ and N∗ , v ∗ . As M, w and N, v were modally equivalent,
so are M∗ , w∗ and N∗ , v ∗ ; it follows by Theorem 2.65 that the latter two models
are bisimilar. In short, this is a second ‘bisimilarity-somewhere-else’ result, this
time the ‘somewhere else’ being ‘in some suitable ultrapower’. Notice that in or-
der to prove the Detour Lemma all we need to establish is that every model can be
elementarily embedded in a countably saturated model. There are standard ﬁrst-
order techniques for doing this, and we will introduce one in the second half of this
section.
With the help of the Detour Lemma, we can now precisely characterize the
relation between ﬁrst-order logic, modal logic, and bisimulations. To prove the
theorem we need to explicitly deﬁne a concept which we have already invoked
informally on several occasions.
Deﬁnition 2.67 A ﬁrst-order formula α(x) in L1τ is invariant for bisimulations if
for all models M and N, and all states w in M, v in N, and all bisimulations Z
between M and N such that wZv, we have M |= α(x)[w] iff N |= α(x)[v].
Theorem 2.68 (van Benthem Characterization Theorem) Let α(x) be a ﬁrst-
order formula in L1τ . Then α(x) is invariant for bisimulations iff it is equivalent to
the standard translation of a modal τ -formula.
Proof. The direction from right to left is a consequence of Theorem 2.20. To prove
the direction from left to right, assume that α(x) is invariant for bisimulations and
consider the set of modal consequences of α:
MOC(α) = {ST x (φ) | φ is a modal formula, and α(x) |= ST x (φ)}.
Our ﬁrst claim is that if MOC(α) |= α(x), then α(x) is equivalent to the translation
of a modal formula. To see why this is so, assume that MOC(α) |= α(x); then,
by the Compactness Theorem for ﬁrst-order logic, for some ﬁnite subset X ⊆


MOC(α) we have X |= α(x). So |= X → α(x). Trivially |= α(x) → X,

thus |= α(x) ↔ X. And as every β ∈ X is the translation of a modal formula,

so is X. This proves our claim.2 Models
104
So it sufﬁces to show that MOC(α) |= α(x). Assume M |= MOC(α)[w]; we
need to show that M |= α(x)[w]. Let
T (x) = {ST x (φ) | M |= ST x (φ)[w]}.
We claim that T (x) ∪ {α(x)} is consistent. Why? Assume, for the sake of con-
tradiction, that T (x) ∪ {α(x)} is inconsistent. Then, by compactness, for some


ﬁnite subset T0 (x) ⊆ T (x) we have |= α(x) → ¬ T0 (x). Hence ¬ T0 (x) ∈

MOC(α). But this implies M |= ¬ T0 (x)[w], which contradicts T0 (x) ⊆ T (x)
and M |= T (x)[w].
So, let N, v be such that N |= T (x) ∪ {α(x)}[v]. Observe that w and v are
modally equivalent: M, w  φ implies ST x (φ) ∈ T (x), which implies N, v  φ;
and likewise, if M, w  φ then M, w  ¬φ, and N, v  ¬φ. If modal equivalence
implied bisimilarity we would be done, because then M, w and N, v would be
bisimilar, and from this we would be able to deduce the desired conclusion M |=
α(x)[w] by invariance under bisimulation. But, in general, modal equivalence does
not imply bisimilarity, so this is not a sound argument.
However, we can use the Detour Lemma and make a detour through a Hennessy-
Milner class where modal equivalence and bisimilarity do coincide! More pre-
cisely, the Detour Lemma yields two countably saturated models M∗ , w∗ M, w
and N∗ , v ∗ N, v such that M∗ , w∗ ↔ N∗ , v ∗ :
M, w



N, v



M∗ , w∗ ↔ N∗ , v ∗ .
This is where we really need the new characterization of modal equivalence in
terms of bisimulation-somewhere-else that Theorem 2.74 gives us. We need to
‘lift’ the ﬁrst-order formula α(x) from the model N, v to the model N∗ , v ∗ . By
deﬁnition, the truth of ﬁrst-order formulas is preserved under elementary embed-
dings, so that this can indeed be done. However, ﬁrst-order formulas need not be
preserved under ultraﬁlter extensions (see Exercise 2.5.10), and for that reason we
cannot use the ultraﬁlter extension ue N, πv instead of N∗ , v ∗ .
Returning to the main argument, N |= α(x)[v] implies N∗ |= α(x)[v ∗ ]. As
α(x) is invariant for bisimulations, we get M∗ |= α(x)[w∗ ]. By invariance under
elementary embeddings, we have M |= α(x)[w]. This proves the theorem.
Ultraproducts
The preceding discussion left us with an important technical question: how do
we get countably saturated models? Our next aim is to answer this question and
thereby prove the Detour Lemma.2.6 Characterization and Deﬁnability
105
The fundamental construction underlying our proof is that of an ultraproduct.
Here we brieﬂy recall the basic ideas; further details may be found in Appendix A.
We ﬁrst apply the construction to sets, and then to models. Suppose I = ∅, U is

an ultraﬁlter over I, and for each i ∈ I, Wi is a non-empty set. Let C = i∈I Wi
be the cartesian product of those sets. That is: C is the set of all functions f with
domain I such that for each i ∈ I, f (i) ∈ Wi . For two functions f , g ∈ C we say
that f and g are U -equivalent (notation f ∼U g) if {i ∈ I | f (i) = g(i)} ∈ U .
The result is that ∼U is an equivalence relation on the set C.
Deﬁnition 2.69 (Ultraproduct of Sets) Let fU be the equivalence class of f mod-
ulo ∼U , that is: fU = {g ∈ C | g ∼U f }. The ultraproduct of Wi modulo U ,

denoted as U Wi , is the set of all equivalence classes of ∼U . So


U Wi = {fU | f ∈
i∈I Wi }.
In the case where all the sets are the same, say Wi = W for all i, the ultraproduct

is called the ultrapower of W modulo U , and written U W .
Following the general deﬁnition of the ultraproduct of ﬁrst-order models (Deﬁni-
tion A.17), we now deﬁne the ultraproduct of modal models.
Deﬁnition 2.70 (Ultraproduct of Models) Fix a modal similarity type τ , and let

Mi (i ∈ I) be τ -models. The ultraproduct U Mi of Mi modulo U is the model
described as follows:


(i) The universe WU of U Mi is the set U Wi , where Wi is the universe of
Mi .

(ii) Let Vi be the valuation of Mi . Then the valuation VU of U Mi is deﬁned
by
fU ∈ VU (p) iff {i ∈ I | f (i) ∈ Vi (p)} ∈ U.
(iii) Let  be a modal operator in τ , and Ri its associated relation in the model

Mi . The relation RU in U Mi is given by
RU fU1 . . . fUn+1 iff {i ∈ I | Ri f 1 (i) . . . f n+1 (i)} ∈ U.
In particular, for a diamond, item (iii) boils down to
R3U fU gU iff {i ∈ I | R3i f (i)g(i)} ∈ U.
To show that the above deﬁnition is consistent, we should check that VU and RU
depend only on the equivalence classes fU1 , . . . , fUn+1 .

Proposition 2.71 Let U M be an ultrapower of M. Then, for all modal formulas

φ we have M, w  φ iff U M, (fw )U  φ, where fw is the constant function such
that fw (i) = w, for all i ∈ I.106
2 Models
Proof. This is left as Exercise 2.6.1.
To build countably saturated models, we use ultraproducts based on a special kind
of ultraﬁlter. An ultraﬁlter is countably incomplete if it is not closed under count-
able intersections (of course, it will be closed under ﬁnite intersections).
Example 2.72 Consider the set of natural numbers N. Let U be an ultraﬁlter over
N that does not contain any singletons {n}. (The reader is asked to prove that such
ultraﬁlters exist in Exercise 2.5.4.) Then, for all n, (N \ {n}) ∈ U . But

∅ = n∈N (N \ {n}) ∈
/ U.
So U is countably incomplete.
Lemma 2.73 Let L be a countable ﬁrst-order language, U a countably incomplete

ultraﬁlter over a non-empty set I, and M an L-model. The ultrapower U M is
countably saturated.
Proof. A standard result. See Appendix A for a proof reference.
We are now ready to prove the Detour Lemma. In Theorem 2.62 we showed that
‘bisimulation-somewhere-else’ can mean ‘in the ultraﬁlter extension.’ Now we will
show that it can also mean: ‘in a suitable ultrapower of the original models.’
Theorem 2.74 Let τ be a modal similarity type, and let M and N be τ -models,
and w and v states in M and N, respectively. Then the following are equivalent:
(i) For all modal formulas φ: M, w  φ iff N, v  φ.


(ii) There exist ultrapowers U M and U N as well as a bisimulation Z :


↔ U N, (fv )U linking (fw )U and (fv )U , where fw (fv ) is
U M, (fw )U
the constant function mapping every index to w (v).
Proof. It is easy to see that (ii) implies (i). By Proposition 2.71 M, w  φ iff


U M, (fw )U  φ. By assumption this is equivalent to
U N, (fv )U  φ, and
the latter is equivalent to N, v  φ.
To prove the implication from (i) to (ii) we have to do some more work. Assume
that for all modal formulas φ we have M, w  φ iff N, v  φ. We need to create
bisimilar ultrapowers of M and N.
Take the set of natural numbers N as our index set, and let U be a countably
incomplete ultraﬁlter over N (cf. Example 2.72). By Lemma 2.73 the ultrapowers


Now (fw )U and (fv )U are modally
U M and
U N are countably saturated.


equivalent: for all modal formulas φ, U M, (fw )U  φ iff U N, (fv )U  φ.
This claim follows from the assumption that w and v are modally equivalent to-
gether with Proposition 2.71. Next, apply Theorem 2.65: as (fw )U and (fv )U are2.6 Characterization and Deﬁnability
107


modally equivalent and U M and U N are countably saturated, there exists a


bisimulation Z : U M, (fw )U ↔ U N, (fv )U . This proves the theorem.
We obtain the Detour Lemma as an immediate corollary of Theorem 2.74 and
Theorem 2.62.
Deﬁnability
Our next aim is to answer the second of the two questions posed at the start of this
section: which properties of models are deﬁnable by means of modal formulas?
Like the Detour Lemma, the answer is a corollary of Theorem 2.74. We formulate
the result in terms of pointed models. Given a modal similarity type τ , a pointed
model is a pair (M, w) where M is a τ -model and w is a state of M. Although
the results below can also be given for models, the use of pointed models allows
for a smoother formulation, mainly because pointed models reﬂect the local way
in which modal formulas are evaluated.
We need some further deﬁnitions. A class of pointed models K is said to be
closed under bisimulations if (M, w) in K and M, w ↔ N, v implies (N, v) in

K. K is closed under ultraproducts if any ultraproduct U (Mi , wi ) of a family of
pointed models (Mi , wi ) in K belongs to K. If K is a class of pointed τ -models, K
denotes the complement of K within the class of all pointed τ -models. Finally, K is
deﬁnable by a set of modal formulas if there is a set of modal formulas Γ such that
for any pointed model (M, w) we have (M, w) in K iff for all γ ∈ Γ , M, w  γ;
K is deﬁnable by a single modal formula iff it is deﬁnable by a singleton set.
By Theorem 2.20 deﬁnable classes of pointed models must be closed under
bisimulations, and by Proposition 2.47 and Corollary A.20 they must be closed
under ultraproducts as well. Theorems 2.75 and 2.76 below show that these two
closure conditions sufﬁce to completely describe the classes of pointed models that
are deﬁnable by means of modal formulas.
Theorem 2.75 Let τ be a modal similarity type, and K a class of pointed τ -models.
Then the following are equivalent:
(i) K is deﬁnable by a set of modal formulas.
(ii) K is closed under bisimulations and ultraproducts, and K is closed under
ultrapowers.
Proof. The implication from (i) to (ii) is easy. For the converse, assume K and K
satisfy the stated closure conditions. Observe that K is closed under bisimulations,
as K is. Deﬁne T as the set of modal formulas holding in K:
T = {φ | for all (M, w) in K: M, w  φ}.
We will show that T deﬁnes the class K. First of all, by deﬁnition every pointed108
2 Models
model (M, w) in K is a model satisfying T in the sense that M, w  T . Second,
assume that M, w  T ; to complete the proof of the theorem we show that (M, w)
must be in K.
Deﬁne Σ to be the modal theory of w; that is, Σ = {φ | M, w  φ}. It is
obvious that Σ is ﬁnitely satisﬁable in K; for suppose that the set {σ1 , . . . , σn } ⊆
Σ is not satisﬁable in K. Then the formula ¬(σ1 ∧ · · · ∧ σn ) would be true on all
pointed models in K, so it would belong to T , yet be false in M, w. But then the
following claim shows that Σ is satisﬁable in the ultraproduct of pointed models
in K.
Claim 1 Let Σ be a set of modal formulas, and K a class of pointed models in
which Σ is ﬁnitely satisﬁable. Then Σ is satisﬁable in some ultraproduct of models
in K.
Proof of Claim. Deﬁne an index set I as the collection of all ﬁnite subsets of Σ:
I = {Σ0 ⊆ Σ | Σ0 is ﬁnite}.
By assumption, for each i ∈ I there is a pointed model (Ni , vi ) in K such that
N , v  i. We now construct an ultraﬁlter U over I such that the ultraproduct
i i

U Ni has a state fU with
U Ni , fU  Σ.
For each σ ∈ Σ, let σ
 be the set of all i ∈ I such that σ ∈ i. Then the set
E = {
σ | σ ∈ Σ} has the ﬁnite intersection property because
{σ1 , . . . , σn } ∈ σ
1 ∩ · · · ∩ σ
n .

So, by Fact A.14, E can be extended to an ultraﬁlter U over I. This deﬁnes U Ni ;
for the deﬁnition of fU , let Wi denote the universe of the model Ni and consider

the function f ∈ i∈I Wi such that f (i) = vi .
It is left to prove that

(2.2)
U Ni , fU  Σ.
To prove (2.2), observe that for i ∈ σ
 we have σ ∈ i, and so Ni , vi  σ. Therefore,
for each σ ∈ Σ
{i ∈ I | Ni , vi  σ} ⊇ σ
 and σ
 ∈ U.
It follows that {i ∈ I | Ni , vi  σ} ∈ U , so by Theorem A.19,
This proves (2.2), and, hence, Claim 1.

U Ni , fU  σ.
It follows from Claim 1 and the closure of K under taking ultraproducts that Σ is
satisﬁable in some pointed model (N, v) in K. But N, v  Σ implies that v and
the state w from our original pointed model (M, w) are modally equivalent. So by
Theorem 2.74 there exists an ultraﬁlter U such that


↔ U  (M, w), (fw )U .
U  (N, v), (fv )U2.6 Characterization and Deﬁnability
109

By closure under ultraproducts, the pointed model ( U  (N, v), (fv )U ) belongs to

K. Hence by closure under bisimulations, ( U  (M, w), (fw )U ) is in K as well. By
closure of K under ultrapowers it follows that (M, w) is in K. This completes the
proof.
Theorem 2.76 Let τ be a modal similarity type, and K a class of pointed τ -models.
Then the following are equivalent:
(i) K is deﬁnable by means of a single modal formula.
(ii) Both K and K are closed under bisimulations and ultraproducts.
Proof. The direction from (i) to (ii) is easy. For the converse we assume that K,
K satisfy the stated closure conditions. Then both are closed under ultraproducts,
hence by Theorem 2.75 there are sets of modal formulas T1 , T2 deﬁning K and
K, respectively. Obviously their union is inconsistent in the sense that there is no
pointed model (M, w) such that (M, w)  T1 ∪ T2 . So then, by compactness,
there exist φ1 , . . . , φn ∈ T1 and ψ1 , . . . , ψm ∈ T2 such that for all pointed models
(M, w)
M, w  φ1 ∧ · · · ∧ φn → ¬ψ1 ∨ · · · ∨ ¬ψm .
(2.3)
To complete the proof we show that K is in fact deﬁned by the conjunction φ1 ∧
· · · ∧ φn . By deﬁnition, for any (M, w) in K we have M, w  φ1 ∧ · · · ∧ φn .
Conversely, if M, w  φ1 ∧ · · · ∧ φn , then, by (2.3), M, w  ¬ψ1 ∨ · · · ∨ ¬ψm .
Hence, M, w  T2 . Therefore, (M, w) does not belong to K, whence (M, w)
belongs to K.
Theorems 2.75 and 2.76 correspond to analogous deﬁnability results in ﬁrst-order
logic: to get the analogous ﬁrst-order results, simply replace closure under bisim-
ulations in 2.75 and 2.76 by closure under isomorphisms; see the Notes at the end
of the chapter for further details. This close connection to ﬁrst-order logic may
explain why the results of this section seem to generalize to any modal logic that
has a standard translation into ﬁrst-order logic. For example, all of the results of
this section can also be obtained for basic temporal logic.
Exercises for Section 2.6

2.6.1 Prove Proposition 2.71: Let  U M be an ultrapower of M. Then, for all modal
formulas φ we have M, w  φ iff U M, (fw )U  φ, where fw is the constant function
such that fw (i) = w, for all i ∈ I.
2.6.2 Give simple proofs of Theorem 2.75 and Theorem 2.76 using the analogous proof
for ﬁrst-order logic (see Theorem A.23).110
2 Models
2.6.3 Let I be an index set, and let {M i }i∈I and {Ni }i∈I be two collections of models
such that for each i ∈ I, M i ↔ Ni . Show
 that forany ultraﬁlter U over I, the ultraproducts
of the two collections are bisimilar: U Mi ↔ U Ni .
(a) Show that the ultraproduct of point-generated models need not be point-
generated.
(b) How is this for transitive models?
2.6.4
2.7 Simulation and Safety
Theorem 2.68 provided a result characterizing the modal fragment of ﬁrst-order
logic as the class of formulas invariant for bisimulations. In this section we present
two further results in the same spirit; we focus on these results not just because they
are interesting and typical of current work in modal model theory, but also because
they provide instructive examples of how to apply the tools and proof strategies we
have discussed. We ﬁrst look at a notion of simulation that has been introduced
in various settings, and characterize the modal formulas preserved by simulations.
We then examine a question that arises in the setting of dynamic logic and process
algebra: which operations on models preserve bisimulation? That is, if we have
the back and forth clauses holding for R, and we apply an operation O to R which
returns a new relation O(R), then under which conditions do we also have the back
and forth clauses for O(R)?
Simulations
A simulation is simply a bisimulation from which half of the atomic clause and the
back clause have been omitted.
Deﬁnition 2.77 (Simulations) Let τ be a modal similarity type. Let M = (W ,
 , V )
R, V )∈τ and M = (W  , R
∈τ be τ -models. A non-empty binary relation

Z ⊆ W × W is called a τ -simulation from M to M if the following conditions
are satisﬁed:
(i) If wZw and w ∈ V (p), then w ∈ V  (p).
(ii) If wZw and Rwv1 . . . vn then there are v1 , . . . , vn (in W  ) such that
 w v  . . . v  and for all i (1 ≤ i ≤ n) v Zv  .
R
i
n
1
i
Thus, simulations only require that atomic information is preserved and that the
forth condition holds.
If Z is a simulation from w in M to w in M , we write Z : M, w → M , w ;
if there is a simulation Z such that Z : M, w → M , w , we sometimes write
M, w → M , w .2.7 Simulation and Safety
111
A modal formula φ is preserved under simulations if for all models M and M ,
and all states w and w in M and M , respectively, M, w  φ implies M , w  φ,
whenever it is the case that M, w → M , w .
In various forms and under various names simulations have been considered in the-
oretical computer science. In the study of reﬁnement, → is interpreted as follows:
if M, w → M , w then (the system modeled by) M , w reﬁnes or implements (the
system modeled by) M, w. And in the database world one looks at simulations the
other way around: if M, w → M , w , then M , w constrains the structure of M, w
by only allowing those relational patterns that are present in M , w itself. Note that
if M, w → M , w then M , w cannot enforce the presence of patterns. (See the
Notes for references.) The following question naturally arises: which formulas
are preserved when passing from M, w to M , w along a simulation? Or, dually,
which constraints on M, w can be expressed by requiring that M, w → M , w ?
Clearly simulations do not preserve the truth of all modal formulas. In particular,
let M be a one-point model with domain {w} and empty relation; then, there is a
simulation from M, w to any state with the same valuation, no matter which model
it lives in. Using this observation it is easy to show that universal modal formulas of
the form 2(· · ·) or (· · ·) are not preserved under simulations. On the other hand,
by clause (ii) of Deﬁnition 2.77 existential modal formulas of the form 3(· · ·) or
(· · ·) are preserved under simulations. This leads to the conjecture that a modal
formula is preserved under simulations if and only if it is equivalent to a formula
that has been built from proposition letters, using only ∧, ∨ and existential modal
operators, that is, diamonds or triangles. Below we will prove this conjecture; our
proof follows the proof of Theorem 2.68 to a large extent but there is an important
difference. Since we are working within a modal language, and not in ﬁrst-order
logic, we can make do with a detour via (m-saturated) ultraﬁlter extensions rather
than the (countably saturated) ultrapowers needed in the proof of Theorem 2.68.
Call a modal formula positive existential if it has been built up from proposition
letters, using only ∧, ∨ and existential modal operators 3 and !.
Theorem 2.78 Let τ be a modal similarity type, and let φ be a τ -formula. Then φ
is preserved under simulations iff it is equivalent to a positive existential formula.
Proof. The easy inductive proof that positive existential formulas are preserved
under simulations is left to the reader. For the converse, assume that φ is preserved
under simulations, and consider the set of positive existential consequences of φ:
PEC(φ) = {ψ | ψ is positive existential and φ |= ψ}.
We will show that PEC(φ) |= φ; then, by compactness, φ is equivalent to a positive
existential modal formula. Assume that M, w  PEC(φ); we need to show that
M, w  φ. Let Γ = {¬ψ | ψ is positive existential and M, w  ψ}.2 Models
112
Our ﬁrst claim is that the set {φ}∪Γ is consistent. For, suppose otherwise. Then
there are formulas ¬ψ1 , . . . , ¬ψn ∈ Γ such that φ |= ψ1 ∨ · · · ∨ ψn . By deﬁnition
each formula ψi is a positive existential formula, hence, so is ψ1 ∨ · · · ∨ ψn . But
then M, w  ψ1 ∨ · · · ∨ ψn , by assumption; from this it follows that M, w  ψi
for some i (1 ≤ i ≤ n). This contradicts ¬ψi ∈ Γ .

As a corollary we ﬁnd a model N and a state v of N such that N, v  φ ∧ Γ .
Clearly, for every positive existential formula ψ, if N, v  ψ, then M, w  ψ.
It follows from Proposition 2.59 that for the ultraﬁlter extensions ue M and ue N
we have the same relation: for every positive existential formula ψ, if ue N, πv 
ψ, then ue M, πw  ψ. By exploiting the fact that ultraﬁlter extensions are m-
saturated (Proposition 2.61), it can be shown that this relation is in fact a simulation
from ue N, πv to ue M, πw ; see Exercise 2.7.1.
In a diagram we have now the following situation.
N, v



M, w



ue N, πv → ue M, πw .
We can carry φ around the diagram from N, v to M, w as follows. N, v  φ
implies ue N, πv  φ by Proposition 2.59. Since φ is preserved under simulations,
we get ue M, πw  φ. By Proposition 2.59 again we conclude M, w  φ.
Using Theorem 2.78 we can also answer the second of the two questions raised
above. Call a constraint φ expressible if whenever M, w satisﬁes φ and N, v →
M, w, then N, v also satisﬁes φ. By Theorem 2.78 the expressible constraints
(in ﬁrst-order logic) are precisely the ones that are (equivalent to) the standard
translations of negative universal modal formulas, that is, translations of modal
formulas built up from negated proposition letters using only ∨, ∧ and universal
modal operators 2 and .
Safety
Recall from Exercise 2.2.6 that bisimulations preserve the truth of formulas from
propositional dynamic logic. This result hinges on the fact that bisimulations not
only preserve the relations Ra corresponding to atomic programs, but also rela-
tions that are deﬁnable from these using PDL’s relational repertoire ∪, ; and ∗ . Put
differently, if the back and forth conditions in the deﬁnition of a bisimulation hold
for each relation Ra then they also hold for any relation that is deﬁnable from the
basic ones using ∪, ; and ∗ ; these operations are ‘safe’ for bisimulation.
In this part of the section we work with a modal similarity type τ having dia-
monds only.2.7 Simulation and Safety
113
Deﬁnition 2.79 Let τ be a modal similarity type having diamonds only, and let
α(x, y) denote an L1τ (Φ)-formula with at most two free variables. Then α(x, y) is
called safe for bisimulations if the following holds, for any bisimulation Z : M ↔
M :
if wZw and M |= α(x, y)[wv] for some state v of M,
then there is a state v of M such that M |= α(x, y)[w v  ] and vZv .
In words, α(x, y) is safe if the back and forth clauses hold for α(x, y) whenever
they hold for the atomic relations.
Example 2.80 (i) All PDL program constructors (∪, ; and ∗ ) are safe for bisim-
ulations (where we stretch the deﬁnition of safety to program constructors in an
obvious way). For instance, assume that wZw , where Z is a bisimulation, and
(w, v) ∈ (R ; S) in M. Then, there exists u with Rwu and Suv in M; hence by
the back and forth conditions for R and S, we ﬁnd u with uZu and R w u in M ,
and a state v with vZv and S  u v  in M . Then v is the required (R ;S)-successor
of w in M .
(ii) Atomic tests P ?, deﬁned by P ? := {(x, y) | x = y ∧ P y}, are safe. For,
assume that wZw , where Z is a bisimulation, and (w, v) ∈ P ?. Then w = v and
M |= P x[w]. By the atomic clause in the deﬁnition of bisimulation, this implies
M |= P x[w ]. Hence, (w , w ) ∈ P ?, as required.
(iii) Dynamic negation ∼R, deﬁned by ∼R = {(x, y) | x = y ∧ ¬∃z Rxz}, is
safe. For, assume that wZw , where Z is a bisimulation, and (w, v) ∈ ∼R in M.
Then, w = v and w has no R-successors in M. Now, suppose that w did have an
R -successor in M ; then, by the back and forth conditions, w would have to have
an R-successor in M – a contradiction.
(iv) Intersection of relations is not safe; see Exercise 2.7.2.
Which operations are safe for bisimulations? Below, we give a complete answer for
the restricted case where we consider ﬁrst-order deﬁnable operations and languages
with diamonds only. We need some preparations before we can prove this result.
First, in the remainder of this section we will use the term labeled tree models
for τ -models of the form (W, Ra , V )a∈τ such that (W, a Ra , V ) is a tree in the
sense of Deﬁnition 1.7.
Second, let p be a ﬁxed proposition letter. We write ↔ − to denote the existence
of a bisimulation for the modal language without the proposition letter p (exactly
which proposition letter is meant will always be clear from the context).
Third, we deﬁne a modal formula φ to be completely additive in the proposition
letter p if it satisﬁes the following:
For every family of non-empty sets {Xi }i∈I such that V (p) =
i Xi we2 Models
114
have (W, Ra , V )a∈τ , w  φ iff, for some i, (W, Ra , Vi )a∈τ , w  φ, where
Vi (p) = Xi and Vi (q) = V (q) for q = p.
Completely additive formulas have a nice syntactic characterization.
Lemma 2.81 A modal formula is completely additive in p iff it is equivalent to a
disjunction of path formulas, that is, formulas of the form
ψ0 ∧ a1 (ψ1 ∧ · · · ∧ an (ψn ∧ p) · · ·),
(2.4)
where p occurs in none of the formulas ψi .
Proof. We only prove the hard direction. Assume that φ is completely additive in
p. Deﬁne
COC(φ) :=
{ψ | ψ is of the form (2.4) and ψ  φ},
that is, COC(φ) is an inﬁnite disjunction of modal formulas. We will show that
φ  COC(φ); then, by compactness, φ is equivalent to a ﬁnite disjunction of
formulas of the form speciﬁed in (2.4), and this proves the lemma.
So, assume that M, w0  φ; we need to show that M, w0  COC(φ). As
the reader may verify by doing Exercise 2.7.3, we may assume that M is an m-
saturated, labeled tree model with root w0 . As φ is completely additive in p, we
may also assume that V (p) is just a singleton wn ; note that still, we may assume
M to be m-saturated with respect to the p free language. Since M is a labeled tree
with root w0 , there is a path w0 Ra1 · · · Ran wn from w0 to wn , see Figure 2.8.
B
B
p B
S
a
aaS
a
S
S

S
a
aa
S
a
S

S
a
aa
S
a
w0


B
 wn
Fig. 2.8. True at only one state
For 0 ≤ i ≤ n, let Ψi be the set of formulas in the p free language that hold at wi ,
and consider the following description of the above path leading up to wn :
Ψ
= {ψ | ψ is of the form (2.4), with for all i: ψi ∈ Ψi and Rai wi wi+1 }.
The remainder of the proof is devoted to showing that Ψ  φ, and this will do2.7 Simulation and Safety
115
to prove the lemma. For if Ψ  φ, then, for some ﬁnite subset Ψ ⊆ Ψ we have
 
Ψ  φ, by compactness. It is not difﬁcult to show that Ψ is closed (modulo

equivalence) under taking ﬁnite conjunctions, so Ψ  is equivalent to a formula
ψ ∈ Ψ . Hence, we have found our path formula satisfying M, w0  ψ and ψ  φ.
To show that Ψ  φ we proceed as follows. Take a model N with N, v0  Ψ ;
we need to show that N, v0  φ. Again, we may assume that N is an m-saturated,
labeled tree with root v0 . By m-saturation, there are points v1 , . . . , vn such that for
each 0 ≤ i ≤ n − 1 we have Rai vi vi+1 and N, vi  Ψi .
It follows from the deﬁnition of the Ψi that each wi and vi agree on all p free
modal formulas. So by m-saturation, there is a bisimulation Z : M, w0 ↔ − N, v0 .
It follows from Exercise 2.7.4 that there are extensions M and N of M and N
respectively, such that (M, w0 ) ↔ (M , w0 ) and (N, v0 ) ↔ (N , v0 ); we may also
conclude from this exercise that there is a bisimulation Z between M and N such
that for all i, the points wi and vi are only related to each other; see Figure 2.9.
'
$'
B
B
S
X
XXS
X
S
S

S
X
XX S
X
S
 w1
S
X
XXX
S
w0
&


T
T
B
B
 wn
$



T
]

vn J
J
 
J
 
J
]
J

J 


 
JJ
v1 ]J 
7



:

J
%&
v0
%
Fig. 2.9. Linking w i only to vi (1 ≤ i ≤ n)
Now we amend the models M and N as follows: We shrink the interpretations
of p so that p only holds at wn and vn , respectively. Then Z is a bisimulation
between the resulting models M and N with respect to the full language, and
further relations between the models are as indicated in (2.5) below:
(M, w0 )

↔ Z : ↔−(N, v0 )

↔

(M , w0 )


shrink V (p)Z : ↔ −(N , v0 )

shrink V (p)

(M , w0 ) Z  :↔
(N , v0 ),
(2.5)116
2 Models
We can chase φ around this diagram, from (M, w0 ) to (N, v0 ); see Exercise 2.7.5.
This proves the lemma.
Lemma 2.82 For any program a and any formulas φ and ψ, the following identi-
ties hold in any model:
(i) (¬φ)? = ∼(φ?),
(ii) (φ ∧ ψ)? = (φ)? ; (ψ)?,
(iii) (aφ)? = ∼∼(a ; φ?).
The proof of this lemma is left as Exercise 2.7.6.
Theorem 2.83 (Safety Theorem) Let τ be a modal similarity type containing only
diamonds, and let α(x, y) be a ﬁrst-order formula in L1τ (Φ). Then α(x, y) is safe
for bisimulations iff it can be deﬁned from atomic formulas Ra xy and atomic tests
P ? using only ∪, ; and ∼.
Proof. To see that the constructions mentioned are indeed safe, consult Exam-
ple 2.80. Now, to prove the converse, let α(x, y) be a safe ﬁrst-order operation, and
choose a new proposition letter p. Our ﬁrst observation is that ∃y (α(x, y) ∧ P y) is
preserved under bisimulations. So by Theorem 2.68, the formula ∃y (α(x, y)∧P y)
is equivalent to a modal formula φ.
Next we exploit special properties of φ to arrive at our conclusion. First, because
of its special form, ∃y (α(x, y) ∧ P y) is completely additive in P , in the obvious
sense, and hence, φ is completely additive in p. Therefore, by Lemma 2.81 it is
(equivalent to) a disjunction of the form speciﬁed in (2.4). Then, α(x, y) must be
deﬁnable using the corresponding union of relations (ψ0 )?;a1 ;(ψ1 )?;· · ·;an ;(ψn )?.
Finally, by using Lemma 2.82 all complex tests can be pushed inside until we get
a formula of the required form, involving only ∪, ;, ∼ and ?.
Exercises for Section 2.7
2.7.1 Assume that M and M  are m-saturated models and suppose that for every positive
existential formula φ it holds that M, w  φ only if M  , w  φ for some w and w  . Prove
that M, w → M , w .
2.7.2 Prove that intersection of relations is not an operation that is safe for bisimulations
(see Example 2.80).
(a) Suppose that Z is a bisimulation linking the models M and M  . Suppose
further that M is m-saturated and that Z is surjective (that is, every point in M  is
linked by Z to some point in M). Prove that M  is m-saturated as well.
(b) Let Σ be a set of formulas, and φ a formula. Prove that φ is a consequence of Σ
if and only if for every m-saturated, labeled tree model M with root w it holds that
M, w  Σ only if M, w  φ.
2.7.32.8 Summary of Chapter 2
117
2.7.4 Assume that Z : M, w0 ↔ − N, v0 , where M and N are labeled tree models with
roots w0 and v0 , respectively. Assume further that in M we have w 0 Ra1 · · · Ran wn and in
N, v0 Ra1 · · · Ran vn , while Z links wi (in M) to vi (in N) for each i (1 ≤ i ≤ n).
In this exercise the reader is asked to show that there are extensions (M  , w0 ) of (M, w0 )
and (N , v0 ) of (N, v0 ) (i.e., the universe of M is a subset of the universe of M  , and
likewise for N and N  ) such that
Z : ↔−(N, v0 )

↔

(M , w0 ) Z  : ↔ −(N , v0 ),
(M, w0 )

↔
where Z  is such that for any i (1 ≤ i ≤ n) we have that w i and vi are only related to each
other.
(a) Explain why we may assume that all bisimulation links (between M and N) occur
between states at the same height in the trees. (Hint: remove all links between
points of different heights and prove that the remaining links still form a bisimula-
tion.)
(b) Next, work your way up along the branch w 0 Ra1 · · · Ran wn and remove any dou-
ble bisimulation links involving the w i . More precisely, and starting at height 1, do
the following for each double link w 1 Zv. Add a copy of the submodel generated
by w1 to M, connect w0 to the copy w1v of w1 by Ra1 , and ‘divert’ the bisimulation
link w1 Zv to w1v Zv. Show that the resulting model M v satisﬁes M ↔ Mv and
Mv ↔ − N. Proceed in a similar way with points of larger height.
(c) Similar to the previous item, but now working up the branch v 0 Ra1 · · · Rn van in N
to eliminate any double bisimulation links ending in one of the v i s (1 ≤ i ≤ n).
(d) Prove the existence of the desired M  , N and Z  by putting together the previous
items.
2.7.5 Explain why we can chase φ around the diagram displayed in (2.5) to infer N, v 0  φ
from M, w0  φ.
2.7.6 Prove Lemma 2.82.
2.8 Summary of Chapter 2
 New Models from Old Ones: Taking disjoint unions, generated submodels, and
bounded morphic images are three important ways of building new models from
old that leave the truth values of modal formulas invariant.
 Bisimulations: Bisimulations offer a unifying perspective on model invariance,
and each of the constructions just mentioned is a kind of bisimulation. Bisimi-
larity implies modal equivalence, but the converse does not hold in general. On
image-ﬁnite models, however, bisimilarity and modal equivalence coincide.
 Using Bisimulations: Bisimulations can be used to establish non-deﬁnability
results (for example, to show that the global modality is not deﬁnable in the ba-
sic modal language), or to create models satisfying special relational properties
(for example, to show that every satisﬁable formula is satisﬁable in a tree-like
model).118
2 Models
 Finite Model Property: Modal languages have the ﬁnite model property (f.m.p.).
One technique for establishing the f.m.p. is by a selection-of-states argument
involving ﬁnite approximations to bisimulations. Another, the ﬁltration method,
works by collapsing as many states as possible.
 Standard Translation: The standard translation maps modal languages into clas-
sical languages (such as the language of ﬁrst-order logic) in a way that reﬂects
the satisfaction deﬁnition. Every modal formula is equivalent to a ﬁrst-order
formula in one free variable; if the similarity type is ﬁnite, ﬁnitely many vari-
ables sufﬁce to translate all modal formulas. Propositional dynamic logic has to
be mapped into a richer classical logic capable of expressing transitive closure.
 Ultraﬁlter Extensions: Ultraﬁlter extensions are built by using the ultraﬁlters
over a given model as the states of a new model, and deﬁning an appropriate re-
lation between them. This leads to the ﬁrst bisimilarity-somewhere-else result:
two states in two models are modally equivalent if and only if (their counterparts
in) the ultraﬁlter extensions of the two models are bisimilar.
 van Benthem Characterization Theorem: The Detour Lemma – a bisimilarity-
somewhere-else result in terms of ultrapowers – can be used to prove the van
Benthem Characterization Theorem: the modal fragment of ﬁrst-order logic is
the set of formulas in one free variable that are invariant for bisimulations.
 Deﬁnability: The Detour Lemma also leads to the following result: the modally
deﬁnable classes of (pointed) models are those that are closed under bisimula-
tions and ultraproducts, while their complements are closed under ultrapowers.
 Simulation: The modal formulas preserved under simulations are precisely the
positive existential ones.
 Safety: An operation on relations is safe for bisimulations if whenever the back
and forth conditions hold for the base relations, they also hold for the result
of applying the operation to the relations. The ﬁrst-order operations safe for
bisimulations are the ones that can be deﬁned from atoms and atomic tests,
using only composition, union, and dynamic negation.
Notes
Kripke, Kanger, Hintikka, and others introduced models to modal logic in the late
1950s and early 1960s, and relational semantics (or Kripke semantics as it was
usually called) swiftly became the standard way of thinking about modal logic.
In spite of this, much of the material discussed in this chapter dates not from the
1960s, or even the 1970s, but from the late 1980s and 1990s. Why? Because re-
lational semantics was not initially regarded as of independent interest, rather it
was thought of as a tool that lead to interesting modal completeness theory and
decidability results. Only in the early 1970s (with the discovery of the frame in-
completeness results) did modal expressivity become an active topic of researchNotes to Chapter 2
119
– and even then, such investigations were initially conﬁned to expressivity at the
level of frames rather than at the level of models. Thus the most fundamental level
of modal semantics was actually the last to be explored mathematically.
Generated submodels and bounded morphisms arose as tools for manipulating
the canonical models used in modal completeness theory (we discuss canonical
models in Chapter 4). Point-generated submodels, however, were already men-
tioned, under the name of connected model structures, in Kripke [284]. Bounded
morphisms go back to at least Segerberg [404] (a very similar, earlier, notion can be
found in de Jongh and Troelstra [249]) where they are called pseudo epimorphisms;
this soon got shortened down to p-morphism, which remains the most widely used
terminology. The name bounded morphism stems from Goldblatt [186]. Disjoint
unions and ultraﬁlter extensions seem to have ﬁrst been isolated when modal lo-
gicians started investigating modal expressivity over frames in the 1970s (along
with generated submodels and bounded morphisms they are the four constructions
needed in the Goldblatt-Thomason Theorem, which we discuss in the following
chapter). Neither construction is as useful as generated submodels and bounded
morphisms when it comes to proving completeness results, which is probably why
they were not noted earlier. However, both arise naturally in the context of modal
duality theory; see Goldblatt [184, 185]. Ultraﬁlter extensions independently came
about in the model-theoretic analysis of modal logic, see Fine [132]; the name
seems to be due to van Benthem. The unraveling construction (that is, unwind-
ing arbitrary models into trees; see Proposition 2.15) is helpful in many situations.
Surprisingly, it was ﬁrst used as early as in 1959, by Dummett and Lemmon [117],
but the method seems to have become widely known because of Sahlqvist’s use of
it in his classic 1975 paper [396].
Vardi [441] has stressed the importance of the tree model property of modal
logic: the property that a formula is satisﬁable iff it is satisﬁable at the root of a
tree-like model. The tree model property paves the way for the use of automata-
theoretic tools and tableaux-based proof methods. Moreover, it is essential for
explaining the so-called robust decidability of modal logic – the phenomenon that
the basic modal logic is decidable itself, and of reasonably low complexity, and that
these features are preserved when the basic modal logic is extended by a variety
of additional constructions, including counting, transitive closure, and least ﬁxed
points.
We discussed two ways of building ﬁnite models: the selection method and
ﬁltration. However, the use of ﬁnite algebras predates the use of ﬁnite models: they
were ﬁrst used in 1941 by McKinsey [322]; Lemmon [295] used and extended this
method in 1966. The use of model-theoretic ﬁltration dates back to Lemmon and
Scott’s long unpublished monograph An Introduction to Modal Logic [296] (which
began circulating in the mid 1960s); it was further developed in Segerberg’s An
Essay in Classical Modal Logic [404], which also seems to have given the method120
2 Models
its name (see also Segerberg [402]). We introduced the selection method via the
notion of ﬁnitely approximating a bisimulation, an idea which seems to have ﬁrst
appeared in 1985 in Hennessy and Milner [219].
The standard translation, in various forms, can be found in the work of a number
of writers on modal and tense logic in the 1960s – but its importance only became
fully apparent when the ﬁrst frame incompleteness results were proved. Thoma-
son [433], the paper in which frame incompleteness results was ﬁrst established,
uses the standard translation – and shows why the move to frames and validities
requires a second-order perspective (something we will discuss in the following
chapter). Thus the need became clear for a thorough investigation of the relation
between modal and classical logic, and correspondence theory was born. But al-
though other authors (notably Sahlqvist [396]) helped pioneer correspondence the-
ory, it was the work of van Benthem [36] which made clear the importance of sys-
tematic use of the standard translation to access results and techniques from classi-
cal modal theory. The observation that at most two variables are needed to translate
basic modal formulas into ﬁrst-order logic is due to Gabbay [149]. The earliest
systematic study of ﬁnite variable fragments seems to be due to Henkin [216] in
the setting of algebraic logic, and Immerman and Kozen [240] study the link with
complexity and database theory. Consult Otto [351] for more on ﬁnite variable
logics. Keisler [267] is still a valuable reference for inﬁnitary logic. A variety of
other translations from modal to classical logic have been studied, and for a wide
variety of purposes. For example, simply standardly translating modal logics into
ﬁrst-order logic and then feeding the result to a theorem prover is not an efﬁcient
way of automating modal theorem proving. But the idea of automating modal rea-
soning via translation is interesting, and a variety of translations more suitable for
this purpose have been devised; see Ohlbach et al. [345] for a survey.
Under the name of p-relations, bisimulations were introduced by Johan van Ben-
them in the course of his work on correspondence theory. Key references here are
van Benthem’s 1976 PhD thesis [36]; his 1983 book based on the thesis [36]; and
[43], his 1984 survey article on correspondence theory. In keeping with the spirit
of the times, most of van Benthem’s early work on correspondence theory dealt
with frame deﬁnability (in fact he devotes only 6 of the 227 pages in his book
to expressivity over models). Nonetheless, much of this chapter has its roots in
this early work, for in his thesis van Benthem introduced the concept of a bisim-
ulation (he used the name p-relation in [36, 42], and the name zigzag relation in
[43]) and proved the Characterization Theorem. His original proof differs from
the one given in the text: instead of appealing to saturated models, he employs an
elementary chains argument. Explicitly isolating the Detour Lemma (which brings
out the importance of ultrapowers) opens the way to Theorems 2.75 and 2.76 on
deﬁnability and makes explicit the interesting analogies with ﬁrst-order model the-
ory discussed below. On the other hand, the original proof is more concrete. BothNotes to Chapter 2
121
are worth knowing. The ﬁrst published proof using saturated models seems to be
due to Rodenburg [390], who used it to characterize the ﬁrst-order fragment corre-
sponding to intuitionistic logic.
The back and forth clauses of a bisimulation can be adapted to analyze the ex-
pressivity of a wide range of extended modal logics (such as those studied in Chap-
ter 7), and such analyses are now commonplace. Bisimulation based characteriza-
tions have been given for the modal mu-calculus by Janin and Walukiewicz [243],
for temporal logics with since and until by Kurtonina and de Rijke [288], for
subboolean fragments of knowledge representation languages by Kurtonina and
de Rijke [289], and for CTL∗ by Moller and Rabinovich [333]. Related model-
theoretic characterizations can be found in Immerman and Kozen [240] (for ﬁnite
variable logics) and Toman and Niwiński [438] (for temporal query languages).
Rosen [392] presents a version of the Characterization Theorem that also works
for the case of ﬁnite models; the proof given in the text breaks down in the ﬁnite
case as it relies on compactness and saturated models.
But bisimulations did not just arise in modal logic – they were independently
invented in computer science as an equivalence relation on process graphs. Park
[354] seems to have been the ﬁrst author to have used bisimulations in this way.
The classic paper on the subject is Hennessy and Milner [219], the key reference for
the Hennessy-Milner Theorem. The reader should be warned, however, that just as
the notion of bisimulation can be adapted to cover many different modal systems,
the notion of bisimulation can be adapted to cover many different concepts of pro-
cess – in fact, a survey of bisimulation in process algebra in the early 1990s lists
over 155 variants of the notion [173]! Our deﬁnitions do not exclude bisimulations
between a model and itself (auto-bisimulations); the quotient of a model with re-
spect to its largest auto-bisimulation can be regarded as a minimal representation
of this model. The standard method for computing the largest auto-bisimulation is
the so-called Paige-Tarjan algorithm; see the contributions to Ponse, de Rijke and
Venema [360] for relevant pointers and surveys.
More recently, bisimulations have become fundamental in a third area, non-well-
founded set theory. In such theories, the axiom of foundation is dropped, and sets
are allowed to be members of themselves. Sets are thought of as graphs, and two
sets are considered identical if and only if they are bisimilar. The classic source for
this approach is Aczel [2], who explicitly draws on ideas from process theory. A
recent text on the subject is Barwise and Moss [27], who link their work with the
modal tradition. For recent work on modal logic and non-well-founded set theory,
see Baltag [20].
The name ‘m-saturation’ stems from Visser [450], but the notion is older: its ﬁrst
occurrence in the literature seems to be in Fine [132] (under the name ‘modally
saturated2 ’). The concept of a Hennessy-Milner class is from Goldblatt [179] and
Hollenberg [233]. Theorem 2.62, that equivalence of models implies bisimilar-122
2 Models
ity between their ultraﬁlter extensions, is due to [233]. Chang and Keisler [91,
Chapters 4 and 6] is the classic reference for the ultraproduct construction; their
Chapters 2 and 5 also contain valuable material on saturated models. Doets and
van Benthem [112] give an intuitive explanation of the ultraproduct construction.
The results proved in this chapter are often analogs of standard results in ﬁrst-
order model theory, with bisimulations replacing partial isomorphisms. The Keis-
ler-Shelah Theorem (see Chang and Keisler [91, Theorem 6.1.15]) states that two
models are elementarily equivalent iff they have isomorphic ultrapowers; a weak-
ened form, due to Doets and van Benthem [112], replaces ‘isomorphic’ with ‘par-
tially isomorphic’. Theorem 2.74, which is due to de Rijke [380], is a modal analog
of this weakened characterization theorem. Proposition 2.31 is similar to charac-
terizations of logical equivalence for ﬁrst-order logic due to Ehrenfeucht [119] and
Fraı̈ssé [141]; in fact, bisimulations can be regarded as the modal cousins of the
model theoretic Ehrenfeucht-Fraı̈ssé games. We will return to the theme of analo-
gies between ﬁrst-order and modal model theory in Section 7.6 when we prove a
Lindström theorem for modal logic. See de Rijke [380] and Sturm [426] for further
work on modal model theory; de Rijke and Sturm [386] provide global counterparts
for the local deﬁnability results presented in Section 2.6. One can also characterize
modal deﬁnability of model classes using ‘modal’ structural operations only, that
is, bisimulations, disjoint unions and ultraﬁlter extensions; see Venema [447].
Sources for the use of simulations in reﬁnement are Henzinger et al. [221] and
He Jifeng [246], and for their use in a database setting, consult Buneman et al. [76];
see de Rijke [380] for Theorem 2.78. The Safety Theorem 2.83 is due to van
Benthem [48]. The text follows the original proof fairly closely; an alternative
proof has been given by Hollenberg [232], who also proves generalizations.
One ﬁnal remark. Given the importance of ﬁnite model theory, the reader may
be surprised to ﬁnd so little in this chapter on the topic. But we do not neglect
ﬁnite model theory in this book: virtually all the results proved in Chapter 6 re-
volve around ﬁnite models and the way they are structured. That said, the topic
of ﬁnite modal model theory has received less attention from modal logicians than
it deserves. In spite of Rosen’s [392] proof of the van Benthem characterization
theorem for ﬁnite models, and in spite of work on modal 0-1 laws (Halpern and
Kapron [204], Goranko and Kapron [191], and Grove et al. [200, 199]), ﬁnite
modal model theory is an area where many interesting questions remain.3
Frames
As we saw in Section 1.3, the concept of validity, which abstracts away from the
effects of particular valuations, allows modal languages to get to grips with frame
structure. As we will now see, this makes it possible for modal languages to deﬁne
classes of frames, and most of the chapter is devoted to exploring this idea.
The following picture will emerge. Viewed as tools for deﬁning frames, every
modal formula corresponds to a second-order formula. Although this second-order
formula sometimes has a ﬁrst-order equivalent, even quite simple modal formulas
can deﬁne classes of frames that no ﬁrst-order formula can. In spite of this, there
are extremely simple ﬁrst-order deﬁnable frame classes which no modal formula
can deﬁne. In short, viewed as frame description languages, modal languages ex-
hibit an unusual blend of ﬁrst- and second-order expressive powers.
The chapter has three main parts. The ﬁrst, consisting of the ﬁrst four sections,
introduces frame deﬁnability, explains why it is intrinsically second-order, presents
the four fundamental frame constructions and states the Goldblatt-Thomason The-
orem, and discusses ﬁnite frames. The second part, consisting of the next three
sections, is essentially a detailed exposition of the Sahlqvist Correspondence The-
orem, which identiﬁes a large class of modal formulas which correspond to ﬁrst-
order formulas. The ﬁnal part, consisting of the last section, studies further frame
constructions and gives a model-theoretic proof of the Goldblatt-Thomason Theo-
rem. With the exception of the last two sections, all the material in this chapter lies
on the basic track.
Chapter guide
Section 3.1: Frame Deﬁnability (Basic track). This section introduces frame de-
ﬁnability, and gives several examples of modally deﬁnable frame classes.
Section 3.2: Frame Deﬁnability and Second-Order Logic (Basic Track). We ex-
plain why frame deﬁnability is intrinsically second-order, and give exam-
123124
3 Frames
ples of frame classes that are modally deﬁnable but not ﬁrst-order deﬁn-
able.
Section 3.3: Deﬁnable and Undeﬁnable Properties (Basic track). We ﬁrst show
that validity is preserved under the formation of disjoint unions, generated
subframes and bounded morphic images, and anti-preserved under ultraﬁl-
ter extensions. We then use these constructions to give examples of frame
classes that are not modally deﬁnable, and state the Goldblatt-Thomason
Theorem.
Section 3.4: Finite Frames (Basic track). Finite frames enjoy a number of pleas-
ant properties. We ﬁrst prove a simple analog of the Goldblatt-Thomason
Theorem for ﬁnite transitive frames. We then introduce the ﬁnite frame
property, and show that a normal modal logic has the ﬁnite frame property
if and only if it has the ﬁnite model property.
Section 3.5: Automatic First-Order Correspondence (Basic track). Here we pre-
pare for the proof of the Sahlqvist Correspondence Theorem in the follow-
ing section. We introduce positive and negative formulas, and show that
their monotonicity properties can help eliminate second-order quantiﬁers.
Section 3.6: Sahlqvist Formulas (Basic track). In this section we prove the Sahl-
qvist Correspondence Theorem. Our approach is incremental. We ﬁrst
explore the key ideas in the setting of two smaller fragments, and then
state and prove the main result.
Section 3.7: More About Sahlqvist Formulas (Advanced track). We ﬁrst discuss
the limitations of the Sahlqvist Correspondence Theorem. We then prove
Kracht’s Theorem, which provides a syntactic description of the ﬁrst-order
formulas that can be obtained as translations of Sahlqvist formulas.
Section 3.8: Advanced Frame Theory (Advanced track). We ﬁnish off the chap-
ter with some advanced material on frame constructions, and prove the
Goldblatt-Thomason Theorem model-theoretically.
3.1 Frame Deﬁnability
This chapter is mostly about using modal formulas to deﬁne classes of frames. In
this section we introduce the basic ideas (deﬁnability, and ﬁrst- and second-order
frame languages), and give a number of examples of modally deﬁnable frames
classes. Most of these examples – and, indeed, most of the examples given in this
chapter – are important in their own right and will be used in later chapters.
Frame deﬁnability rests on the notion of a formula being valid on a frame, a
concept which was discussed in Section 1.3 (see in particular Deﬁnition 1.28). We
ﬁrst recall and extend this deﬁnition.
Deﬁnition 3.1 (Validity) Let τ be a modal similarity type. A formula φ (of this3.1 Frame Deﬁnability
125
similarity type) is valid at a state w in a frame F (notation: F, w  φ; here, of
course, F is a frame of type τ ) if φ is true at w in every model (F, V ) based on F; φ
is valid on a frame F (notation: F  φ) if it is valid at every state in F. A formula
φ is valid on a class of frames K (notation: K  φ) if it is valid on every frame F
in K. We denote the class of frames where φ is valid by Frφ .
These concepts can be extended to sets of formulas in the obvious way. In par-
ticular, a set Γ of modal formulas (of type τ ) is valid on a frame F (also of type
τ ) if every formula in Γ is valid on F; and Γ is valid on a class K of frames if Γ
is valid on every member of K. We denote the class of frames where Γ is valid by
FrΓ .
Now for the concept underlying most of our work in this chapter:
Deﬁnition 3.2 (Deﬁnability) Let τ be a modal similarity type, φ a modal formula
of this type, and K a class of τ -frames. We say that φ deﬁnes (or characterizes) K
if for all frames F, F is in K if and only if F  φ. Similarly, if Γ is a set of modal
formulas of this type, we say that Γ deﬁnes K if F is in K if and only if F  Γ .
A class of frames is (modally) deﬁnable if there is some set of modal formulas
that deﬁnes it.
In short, a modal formula deﬁnes a class of frames if the formula pins down pre-
cisely the frames that are in that class via the concept of validity. The following
generalization of this concept is sometimes useful:
Deﬁnition 3.3 (Relative Deﬁnability) Let τ be a modal similarity type, φ a modal
formula of this type, and C a class of τ -frames. We say that φ deﬁnes (or charac-
terizes) a class K of frames within C (or relative to C) if for all frames F in C we
have that F is in K if and only if F  φ.
Similarly, if Γ is a set of modal formulas of this type, we say that Γ deﬁnes a
class K of frames within C (or relative to C) if for all frames F in C we have that F
is in K if and only if F  Γ .
Note that when C is the class of all τ -frames, deﬁnability within C is our original
notion of deﬁnability. In Section 3.4 we will investigate which frames are deﬁnable
within the class of ﬁnite transitive frames, but for the most part we will work with
the ‘absolute’ notion of deﬁnability given in Deﬁnition 3.2.
We often say that a formula φ (or a set of formulas Γ ) deﬁnes a property (for
example, reﬂexivity) if it deﬁnes the class of frames satisfying that property. For
example, we will shortly see that p → 3p deﬁnes the class of reﬂexive frames; in
practice, we would often simply say that p → 3p deﬁnes reﬂexivity.
Up till now our discussion has been purely modal – but, of course, as frames are
just relational structures, we are free to deﬁne frame classes using a wide variety of126
3 Frames
non-modal languages. For example, the class of reﬂexive frames is simply the class
of all frames that make ∀x Rxx true. In this chapter, we are interested in comparing
modal languages with the following classical languages as tools for deﬁning frame
classes:
Deﬁnition 3.4 (Frame Languages) For any modal similarity type τ , the ﬁrst-
order frame language of τ is the ﬁrst-order language that has the identity symbol =
together with an (n+1)-ary relation symbol R for each n-ary modal operator  in
τ . We denote this language by L1τ . We often call it the ﬁrst-order correspondence
language (for τ ).
Let Φ be any set of proposition letters. The monadic second-order frame lan-
guage of τ over Φ is the monadic second-order language obtained by augmenting
L1τ with a Φ-indexed collection of monadic predicate variables. (That is, this lan-
guage has all the resources of L1τ , and in addition is capable of quantifying over
subsets of frames.) We denote this language by L2τ (Φ), though sometimes we sup-
press reference to Φ and write L2τ . Moreover, we often simply call it the second-
order frame language or the second-order correspondence language (for τ ), taking
it for granted that only monadic second-order quantiﬁcation is permitted.
Note that the second-order frame language is extremely powerful, even for the
basic modal similarity type. For example, if R is interpreted as the relation of set
membership, second-order Zermelo-Fraenkel (ZF) set theory can be axiomatized
by a single sentence of this language.
Deﬁnition 3.5 (Frame Correspondence) If a class of frames (or more informally,
a property) can be deﬁned by a modal formula φ and by a formula α from one of
these frame languages, then we say that φ and α are each others (global) frame
correspondents.
For example, the basic modal formula p → 3p and the ﬁrst-order sentence ∀xRxx
are correspondents, for we will shortly see that p → 3p deﬁnes reﬂexivity. Later
in this chapter we will show how to systematically ﬁnd correspondents of modal
formulas by adopting a slightly different perspective on the standard translation
introduced in Section 2.4.
In Deﬁnition 3.5 we did not mention the possibility that modal formulas corre-
spond to a set of ﬁrst-order formulas. Why not? The reason is that this situation
simply cannot occur, as we ask the reader to show in Exercise 3.8.3.
There are a number of practical reasons for being interested in frame deﬁnabil-
ity. First, some applications of modal logic are essentially syntactically driven;
their starting point is some collection of modal formulas expressing axioms, laws,
or principles which for some reason we ﬁnd interesting or signiﬁcant. Frame de-
ﬁnability can be an invaluable tool in such work, for by determining which frame3.1 Frame Deﬁnability
127
classes these formulas deﬁne we obtain a mathematical perspective on their con-
tent. On the other hand, some applications of modal logic are essentially seman-
tically driven; their starting point is some class of frames of interest. But here too
deﬁnability is a useful concept. For a start, can the modal language distinguish the
‘good’ frames from the ‘bad’ ones? And which properties can the modal language
express within the class of ‘good’ frames? Finally, many applied modal languages
contain several modalities, whose intended meanings are interrelated. Sometimes
it is clear that these relationships should validate certain formulas, and we want
to extract the frame-theoretic property they correspond to. On the other hand it
may be clear what the relevant frame-theoretic property is (for example, in the
basic temporal language we want the P and F operators to scan backwards and
forwards along the same relation) and we want to see whether there is a modal
formula that deﬁnes this property. In short, thinking in terms of frame deﬁnability
can be useful for a variety of reasons – and as the following examples will make
clear, modal languages can deﬁne some very interesting frame classes indeed.
Example 3.6 In Example 1.10 in Section 1.2 we mentioned the following reading
of the modalities: read 3φ as ‘it is possibly the case that φ’ and 2φ as ‘necessarily
φ.’ We also mentioned that a number of interesting looking principles concerning
necessity and possibility could be stated in the basic modal language. Here are
three important examples, together with their traditional names:
(T) p → 3p
(4) 33p → 3p
(5) 3p → 23p
But now the problems start. While the status of T seems secure (if p holds here-
and-now, p must be possible) but what about 4 and 5? When we have to deal with
embedded modalities, our intuitions tend to fade, even for such simple formulas as
4 and 5; it is not easy to say whether they should be accepted, and if we only have
our everyday understanding of the words ‘necessarily’ and ‘possibly’ to guide us, it
is difﬁcult to determine whether these principles are interrelated. What we need is
a mathematical perspective on their content, and that is what the frame deﬁnability
offers. So let us see what frame conditions these principles deﬁne.
Our ﬁrst claim is that for any frame F = (W, R), the axiom T corresponds to
reﬂexivity of the relation R:
F  T iff F |= ∀x Rxx.
(3.1)
The proof of the right to left direction of (3.1) is easy: let F be a reﬂexive frame,
and take an arbitrary valuation V on F, and a state w in F such that (F, V ), w  p.
We need to show that 3p holds at some state that is accessible from w – but as R
is reﬂexive, w is accessible from itself, and w  3p.3 Frames
128
For the other direction, we use contraposition: suppose that R is not reﬂexive,
that is, there exists a state w which is not accessible from itself. To falsify T in
F, it sufﬁces to ﬁnd a valuation V and a state v such that p holds at v, but 3p
does not. It is pretty obvious that we should choose v to be our irreﬂexive state
w. Now the valuation V has to satisfy two conditions: (1) w ∈ V (p) and (2)
{x ∈ W | Rwx} ∩ V (p) = ∅. Consider the minimal valuation V satisfying
condition (1), that is, take
V (p) = {w}.
Then it is immediate that (F, V ), w  p. Now let v be an R-successor of w. As
Rww does not hold in F, v must be distinct from w, so v  p. As v was arbitrary,
w  3p. This proves (3.1).
Likewise, one can prove that for any frame F = (W, R)
F4iffR is transitive, and(3.2)
F5iffR is euclidean,(3.3)
where a relation is euclidean if it satisﬁes ∀xyz ((Rxy ∧ Rxz) → Ryz). We leave
the proofs of (3.2) and the easy (right to left) direction of (3.3) to the reader. For
the left to right direction of (3.3), we again argue by contraposition. Assume that
F is a non-euclidean frame; then there must be states u, v and w such that Ruv,
Ruw, but not Rvw:
1




u u
PP
uv
H


H
PP
PP
P
q ?
P
u
w
We will try to falsify 5 in u; for this purpose we have to ﬁnd a valuation V such
that (F, V ), u  3p and (F, V ), u  23p. In other words, we have to make p true
at some R-successor x of u, and false at all R-successors of some R-successor y
of u. Some reﬂection shows that appropriate candidates for x and y are w and v,
respectively. Note that again the constraints on V are twofold: (1) w ∈ V (p) and
(2) {z | Rvz} ∩ V (p) = ∅.
Let us take a maximal V satisfying condition (2), that is, deﬁne
V (p) = {z ∈ W | it is not the case that Rvz}.
Now clearly v  3p, so u  23p. On the other hand we have w  p, since w
is in the set {z ∈ W | it is not the case that Rvz}. So u  3p. In other words,
we have indeed found a valuation V and a state u such that 5 does not hold in u.
Therefore, 5 is not valid in F. This proves (3.3).3.1 Frame Deﬁnability
129
Example 3.7 Suppose that we are working with the basic temporal language (see
Section 1.3 and in particular Example 1.25) and that we are interested in dense
bidirectional frames (that is, structures in which between every two points there is a
third). This property can be deﬁned using a ﬁrst-order sentence (namely ∀xy (x <
y → ∃z (x < z ∧ z < y)) but can the basic temporal language deﬁne it too?
It can. The following simple formula sufﬁces: F p → F F p. To see this, let
T = (T, <) be a frame such that T  F p → F F p. Suppose that a point t ∈ T has
a <-successor t . To show that t and t satisfy the density condition, consider the
following minimal valuation Vm guaranteeing that (T, Vm ), t  F p:
Vm (p) = {t }.
Now, under this valuation t  F p, and by assumption T  F p → F F p, hence
t  F F p. This means there is a point s such that t < s and s  F p. But as t is
the only state where p holds, this implies that s < t , so s is the intermediate point
we were looking for.
Conversely, let T = (T, <) be a dense frame, and assume that under some
valuation V , F p holds at some t ∈ T . Then there is a point t such that t < t and
t  p. But as T is dense, there is a point s such that t < s < t , hence s  F p and
hence t  F F p.
Note that nothing in the previous argument depended on the fact that we were
working with the basic temporal language; the previous argument also shows that
density is deﬁnable in the basic modal language using the formula 3p → 33p.
Note that this is the converse of the 4 axiom that deﬁnes transitivity.
Example 3.8 Here is a more abstract example. Suppose we are working with a
similarity type with three binary operators 1 , 2 and 3 , and that we are in-
terested in the class of frames in which the three ternary accessibility relations
(denoted by R1 , R2 and R3 , respectively), offer, so to speak, three ‘perspectives’
on the same relation. To put this precisely, suppose we want the condition
R1 stu iff R2 tus iff R3 ust
to hold for all s, t and u in such frames. Can we deﬁne this class of frames?
We can. We will show that for all frames F = (W, R1 , R2 , R3 ) we have
F  p ∧ (q1 r) → (q ∧ r2 p)1 r iff F |= ∀xyz (R1 xyz → R2 yzx).
(3.4)
(Recall that we use inﬁx notation for dyadic operation symbols.) The easy direction
is from right to left. Let F be a frame satisfying ∀xyz (R1 xyz → R2 yzx). Con-
sider an arbitrary valuation V on F and an arbitrary state s such that (F, V ), s 
p ∧ (q1 r). Then, s  p and there are states t and u with R1 stu, t  q and
u  r. From R1 stu we derive R2 tus. But then t  q ∧ r2 p, so by R1 stu we
have s  (q ∧ r2 p)1 r.3 Frames
130
For the other direction, suppose that the modal formula p ∧ (q1 r) → (q ∧
r2 p)1 r is valid in F, and consider states s, t and u in F with R1 stu. We will
show that R2 tus. Consider a valuation V with V (p) = {s}, V (q) = {t} and
V (r) = {u}. Then (F, V ), s  p∧q1 r, so by our assumption, s  (q∧r2 p)1 r.
Hence, there must be states t , u with R1 st u , t  q ∧ r2 p and u  r. From
t  q it follows that t = t , so we have t  r2 p. Again, using the truth deﬁnition
we ﬁnd states s , u with R2 tu s , u  r and s  p. The latter two facts imply
that u = u and s = s. But then we have R2 tus, as required.
From these examples the reader could easily get the impression that modal for-
mulas always correspond to frame properties that are deﬁnable in ﬁrst-order logic.
This impression is wrong, and in the next section we will see why.
Exercises for Section 3.1
3.1.1 Consider a language with two diamonds 1 and 2. Show that p → [2]1p is valid
on precisely those frames for the language that satisfy the condition ∀xy (R 2 xy → R1 yx).
What sort of frames does p → [1]1p deﬁne?
3.1.2 Consider a language with three diamonds 1, 2, and 3. Show that the modal
formula 3p ↔ 12p is valid on a frame for this language if and only if the frame
satisﬁes the condition ∀xy (R3 xy ↔ ∃z (R1 xz ∧ R2 zy)).
3.2 Frame Deﬁnability and Second-Order Logic
In this section we show that modal languages can get to grips with notions that
exceed the expressive power of ﬁrst-order logic, and explain why. We start by pre-
senting three well-known examples of modal formulas that deﬁne frame properties
which cannot be expressed in ﬁrst-order logic. Then, drawing on our discussion of
the standard translation in Section 2.4, we show that such results are to be expected:
as we will see, modal formulas standardly correspond to second-order frame con-
ditions. Indeed, the real mystery is not why they do so (this turns out to be rather
obvious), but why they sometimes correspond to simple ﬁrst-order conditions such
as reﬂexivity or transitivity (we discuss this more difﬁcult issue in Sections 3.5–
3.7).
Example 3.9 Consider the Löb formula 2(2p → p) → 2p, which we will call
L for brevity. This formula plays an essential role in provability logic, a branch of
modal logic where 2φ is read as ‘it is provable (in some formal system) that φ’.
The formula L is named after Löb, who proved L as a theorem of the provability
logic of Peano Arithmetic. We will ﬁrst show that L deﬁnes the class of frames
(W, R) such that R is transitive and R’s converse is well-founded. (A relation
R is well-founded if there is no inﬁnite sequence . . . Rw2 Rw1 Rw0 ; hence, R’s3.2 Frame Deﬁnability and Second-Order Logic
131
converse is well-founded if there is no inﬁnite R-path emanating from any state. In
particular, this excludes cycles and loops.)
We will then show that this is a class of frames that ﬁrst-order frame languages
cannot deﬁne; that is, we will show that this class is not elementary.
To see that L deﬁnes the stated property, assume that F = (W, R) is a frame
with a transitive and conversely well-founded relation R, and then suppose for the
sake of a contradiction that L is not valid in F. This means that there is a valuation
V and a state w such that (F, V ), w  2(2p → p) → 2p. In other words, w 
2(2p → p), but w  2p. Then w must have a successor w1 such that w1  p, and
as 2p → p holds at all successors of w, we have that w1  2p. This in turn implies
that w1 must have a successor w2 where p is false; note that by the transitivity of R,
w2 is also a successor of w. But now, simply by repeating our argument, we see that
w2 must have a p-falsifying successor w3 (which by transitivity must be a successor
of w1 ), that w3 has a successor w4 (which by transitivity must be a successor of
w1 ), and so on. In short, we have found an inﬁnite path wRw1 Rw2 Rw3 R . . .,
contradicting the converse well-foundedness of R. (Note that the points w1 , w2 ,
. . . need not all be distinct.)
u- u
ww1
- u
w2
- u
-
...
w3
For the other direction, we use contraposition. That is, we assume that either R
is not transitive or its converse is not well-founded; in both cases we have to ﬁnd
a valuation V and a state w such that (F, V ), w  L. We leave the case where
R is not transitive to the reader (hint: instead of L, consider the frame equivalent
formula 3p → 3(p ∧ ¬3p)) and only consider the second case. So assume that R
is transitive, but not conversely well-founded. In other words, suppose we have a
transitive frame containing an inﬁnite sequence w0 Rw1 Rw2 R . . .. We exploit the
presence of this sequence by deﬁning the following valuation V :
V (p) = W \ {x ∈ W | there is an inﬁnite path starting from x}.
We leave it to the reader to verify that under this valuation, 2p → p is true every-
where in the model, whence, certainly, (F, V ), w0  2(2p → p). The claim then
follows from the fact that (F, V ), w0  2p.
Finally, to show that the class of frames deﬁned by L is not elementary, an easy
compactness argument sufﬁces. Suppose for the sake of a contradiction that there
is a ﬁrst-order formula equivalent to L; call this formula λ. As λ is equivalent to L,
any model making λ true must be transitive. Let σn (x0 , . . . , xn ) be the ﬁrst-order
formula stating that there is an R-path of length n through x0 , . . . , xn :

Rxi xi+1 .
σn (x0 , . . . , xn ) =
0≤i<n3 Frames
132
Obviously, every ﬁnite subset of
Σ = {λ} ∪ {∀xyz ((Rxy ∧ Ryz) → Rxz)} ∪ {σn | n ∈ ω}
is satisﬁable in a ﬁnite linear order, and hence in the class of transitive, conversely
well-founded frames. Thus by the Compactness Theorem, Σ itself must have a
model. But it is clear that Σ is not satisﬁable in any conversely well-founded
frame – and λ, being equivalent to L, is supposed to deﬁne the class of transi-
tive, conversely well-founded frames. From this contradiction we conclude that L
cannot be equivalent to any ﬁrst-order formula.
Could L then perhaps be equivalent to an (inﬁnite) set of ﬁrst-order formulas?
No – we already mentioned (right after Deﬁnition 3.5) that this kind of correspon-
dence never occurs.
Our next example concerns propositional dynamic logic (PDL). Recall that this
language contains a family of diamonds {π | π ∈ Π} (where Π is a collection of
programs) and the program constructors ∪, ; and ∗ . In the intended frames for this
language (that is, the regular frames; see Example 1.26) we want the accessibility
relations for diamonds built using these constructors to reﬂect choice, composition,
and iteration of programs, respectively. Now, to reﬂect iteration we demanded that
the relation Rπ∗ used for the program π∗ be the reﬂexive, transitive closure of
the relation Rπ used for π. But it is well known that this constraint cannot be
expressed in ﬁrst-order logic (as with the Löb example, this can be shown using
a compactness argument, and the reader was asked to do this in Exercise 2.4.5).
Because of this, when we discussed PDL at the level of models in Section 2.4 we
used the inﬁnitary language Lω1 ω as the correspondence language for PDL; using
inﬁnite disjunctions enabled us to capture the ‘keep looking!’ force of ∗ that eludes
ﬁrst-order logic. But although ﬁrst-order logic cannot get to grips with ∗, PDL itself
can – via the concept of frame deﬁnability.
Example 3.10 PDL can be interpreted on any transition system of the form F =
(W, Rπ )π∈Π . Let us call such a frame ∗-proper if the transition relation Rπ∗ of
each program π∗ is the reﬂexive and transitive closure of the transition relation Rπ
of π. Can we single out, by modal means, the ∗-proper frames within the class of
all transition systems of the form (W, Rπ )π∈Π ? And can we then go on to single
out the class of all regular frames?
The answer to both questions is yes. Consider the following set of formulas
Δ = {[π ∗ ](p → [π]p) → (p → [π ∗ ]p), π ∗ p ↔ (p ∨ ππ ∗ p) | π ∈ Π}.
As we mentioned in Example 1.15, [π∗ ](p → [π]p) → (p → [π ∗ ]p) is called
Segerberg’s axiom, or the induction axiom. We claim that for any PDL-frame F:
F  Δ iff F is ∗-proper.
(3.5)3.2 Frame Deﬁnability and Second-Order Logic
133
The reader is asked to supply a proof of this in Exercise 3.2.1.
A straightforward consequence is that PDL is strong enough to deﬁne the class
of regular frames. The constraints on the relations interpreting ∪ and ; are simple
ﬁrst-order conditions, and
Γ = {π1 ; π2 p ↔ π1 π2 p, π1 ∪ π2 p ↔ π1 p ∨ π2 p | π ∈ Π}.
pins down down what is required. So Δ ∪ Γ deﬁnes the regular frames.
In the previous two examples we encountered modal formulas that expressed frame
properties that were, although not elementary, still relatively easy to understand.
(Note however that in order to formally express (converse) well-foundedness in a
classical language, one needs heavy machinery – the inﬁnitary language Lω1 ω does
not sufﬁce!) The next example shows that extremely simple modal formulas can
deﬁne second-order frame conditions that are not easy to understand at all.
Example 3.11 We will show that the McKinsey formula (M) 23p → 32p does
not correspond to a ﬁrst-order condition by showing that it violates the Löwenheim-
Skolem Theorem.
Consider the frame F = (W, R), where
W = {w} ∪ {vn , v(n,i) | n ∈ N, i ∈ {0, 1}} ∪ {zf | f : N → {0, 1}},
and
R = {(w, vn ), (vn , v(n,i) ), (v(n,i) , v(n,i) ) | n ∈ N, i ∈ {0, 1}} ∪
{(w, zf ), (zf , v(n,f (n)) ) | n ∈ N, f : N → {0, 1}}.
In a picture:
3

?
?

v
v

(n,0)
(n,1)
- u
u
iP
P
1


PP 

u



6vn





u
z
u f
w
Note that W contains uncountably many points, for the set of functions indexing
the z points is uncountable.
Our ﬁrst observation is that F  23p → 32p. We leave it to the reader to
verify that for all u different from w, F, u  23p → 32p. As to showing that134
3 Frames
F, w  23p → 32p, suppose that (F, V ), w  23p. Then, for each n ∈ N,
(F, V ), vn  3p. From this we get either (F, V ), v(n,0)  p or (F, V ), v(n,1)  p.
Choose f : N → {0, 1} such that (F, V ), v(n,f (n))  p, for each n ∈ N. Then
clearly, (F, V ), zf  2p, and so (F, V ), w  32p.
In order to show that 23p → 32p does not deﬁne a ﬁrst-order frame condition,
let us view the frame F as a ﬁrst-order model with domain W . By the downward
Löwenheim-Skolem Theorem (here we need the strong version of Theorem A.11)
there must be a countable elementary submodel F of F whose domain W  contains
w, and each vn , v(n,0) and v(n,1) . As W is uncountable and W  countable, there
must be a mapping f : N → {0, 1} such that zf does not belong to W  . Now,
if the McKinsey formula was equivalent to a ﬁrst-order formula it would be valid
on F (the Löwenheim-Skolem Theorem tells us that F and F are elementarily
equivalent). But we will show that the McKinsey formula is not valid on F , hence
it cannot be equivalent to a ﬁrst-order formula.
Let V  be a valuation on F such that V  (p) = {v(n,f (n)) | n ∈ N}; here f is a
mapping such that zf does not belong to W  . We will show that under V  , 23p is
true at w, but 32p is not.
It is easy to see that (F , V  ), w  32p. For a start, since p holds at exactly one
of v(n,0) and v(n,1) , 2p is false at each vn . Now consider an arbitrary element zg
in W  . Then g is distinct from f , so there must be an element n ∈ N such that
g(n) = f (n). So p is true at v(n,f (n)) and false at v(n,g(n)) ; this means that zg has
a successor where p is false, so (F , V  ), zg  2p. Hence, we have not been able
to ﬁnd a successor for w where 2p holds, so (F , V  ), w  32p.
In order to show that (F , V  ), w  23p we reason as follows. Note ﬁrst that
(F , V  ), vn  3p, for each state vn . Now consider an arbitrary element zg of W  .
Call two states zh and zk of F complementary if for all n, h(n) = 1 − k(n); the
reader should verify that this relation can be expressed in ﬁrst-order logic. Now
suppose that zg is complementary to zf ; since complementary states are unique,
the fact that F is an elementary submodel of F would imply that zf exists in F as
well. Clearly then, we may conclude that zg is not complementary to zf . Hence,
there exists some n ∈ N such that g(n) = f (n). Therefore, (F , V  ), zg  3p. But
then 3p holds at every successor of w.
Clearly then, modal languages can express many highly complex properties via the
notion of frame validity. In fact, as was shown by S.K. Thomason for the basic
modal similarity type, the consequence relation for the entire second-order lan-
guage L2τ can be reduced in a certain sense to the (global) consequence relation
over frames. More precisely, Thomason showed that there is a computable trans-
lation f taking L2 sentences α to modal formulas f (α), and a special ﬁxed modal
formula δ, such that for all sets of L2 sentences Σ, we have that
Σ |= α iff {δ} ∪ {f (σ) | σ ∈ Σ} g f (α).3.2 Frame Deﬁnability and Second-Order Logic
135
On the frame level, propositional modal logic must be understood as a rather strong
fragment of classical monadic second-order logic. We now face the question: why?
The answer turns out to be surprisingly simple. Recall from Deﬁnition 3.1 that
validity is deﬁned by quantifying over all states of the universe and all possible
valuations. But a valuation assigns a subset of a frame to each proposition let-
ter, and this means that when we quantify across all valuations we are implicitly
quantifying across all subsets of the frame. In short, monadic second-order quan-
tiﬁcation is hard-wired into the very deﬁnition of validity; it is hardly surprising
that frame-deﬁnability is such a powerful concept.
Let us make this answer more precise. In the previous chapter, we saw that at
the level of models, the modal language ML(τ, Φ) can be translated in a truth-
preserving way into the ﬁrst-order language L1τ (Φ) (see Proposition 2.47). Let us
adopt a slightly different perspective:
View the predicate symbol P that corresponds to the proposition letter p as a
monadic second-order variable that we can quantify over.
If we do this, we are in effect viewing the standard translation as a way of translat-
ing into the second-order frame language L2τ (Φ) introduced in Deﬁnition 3.4. And
if we view the standard translation this way we are led, virtually immediately, to
the following result:
Proposition 3.12 Let τ be a modal similarity type, and φ a τ -formula. Then for
any τ -frame F and any state w in F:
F, w  φiffF |= ∀P1 . . . ∀Pn ST x (φ)[w],
FφiffF |= ∀P1 . . . ∀Pn ∀x ST x (φ).
Here, the second-order quantiﬁers bind second-order variables Pi corresponding
to the proposition letters pi occurring in φ.
Proof. Let M = (F, V ) be any model based on F, and let w be any state in F.
Then we have that
(F, V ), w  φ iff F |= ST x (φ)[w, P1 , . . . , Pn ],
where the notation [w, P1 , . . . , Pn ] means ‘assign w to the free ﬁrst-order variable
x in ST x (φ), and V (p1 ), . . . , V (pn ) to the free monadic second-order variables.’
Note that this equivalence is nothing new; it is simply a restatement of Proposi-
tion 2.47 in second-order terms. But then we obtain the ﬁrst part of the theorem
simply by universally quantifying over the free variables P1 ,. . . ,Pn. The second
part follows from the ﬁrst by universally quantifying over the states of the frame
(as in Proposition 3.30).136
3 Frames
It is fairly common to refer to the L2τ (Φ) formula ∀P1 . . . ∀Pn ∀x ST x (φ) as the
standard translation of φ, since it is usually clear whether we are working at the
level of models or the level of frames. Nonetheless, we will try and reserve the
term standard translation to mean the L1τ (Φ) formula produced by the translation
process, and refer to ∀P1 . . . ∀Pn ∀x ST x (φ) as the second-order translation of φ.
Let us sum up what we have learned. That modal formulas can deﬁne second-
order properties of frames is neither mysterious nor surprising: because modal
validity is deﬁned in terms of quantiﬁcation over subsets of frames, it is intrinsi-
cally second-order, hence so is the notion of frame deﬁnability. Indeed, the real
mystery lies not with such honest, hard-working, formulas as Löb and McKinsey,
but with such lazy formulas as T, 4 and 5 discussed in the previous section. For
example, if we apply the second-order translation to T (that is, p → 3p) we obtain
∀P ∀x (P x → ∃y(Rxy ∧ P y)).
We already know that T deﬁnes reﬂexivity, so this must be a (somewhat baroque)
second-order way of expressing reﬂexivity – and it is fairly easy to see that this
is so. But this sort of thing happens a lot: 4 and 5 give rise to (fairly complex)
second-order expressions, yet the complexity melts away leaving a simple ﬁrst-
order equivalent behind. The contrast with the McKinsey formula is striking: what
is going on? This is an interesting question, and we discuss it in detail in Sec-
tions 3.5–3.7.
Another point is worth making: our discussion throws light on the somewhat
mysterious general frames introduced in Section 1.4. Recall that a general frame is
a frame together with a collection of valuations A satisfying certain modally natural
closure conditions. We claimed that general frames combined the key advantage
of frames (namely, that they support the key logical notion of validity) with the
advantage of models (namely, that they are concrete and easy to work with). The
work of this section helps explain why.
The key point is this. A general frame can be viewed as a generalized model
for (monadic) second-order logic. A generalized model for second-order logic is
a model in which the second-order quantiﬁers are viewed as ranging not over all
subsets, but only over a pre-selected sub-collection of subsets. And of course, the
collection of valuations A in a general frame is essentially such a sub-collection of
subsets. This means that the following equivalence holds:
(F, A)  φ iff (F, A) |= ∀P1 . . . ∀Pn ∀x ST x (φ).
Here the block of quantiﬁers ∀P1 . . . ∀Pn denotes not genuine second-order quan-
tiﬁcation, but generalized second-order quantiﬁcation (that is, quantiﬁcation over
the subsets in A). Generalized second-order quantiﬁcation is essentially a ﬁrst-
order ‘approximation’ of second-order quantiﬁcation that possesses many proper-
ties that genuine second-order quantiﬁcation lacks (such as Completeness, Com-3.2 Frame Deﬁnability and Second-Order Logic
137
pactness, and Löwenheim-Skolem). In short, one of the reasons general frames
are so useful is that they offer a ﬁrst-order perspective (via generalized models) on
what is essentially a second-order phenomenon (frame validity). This is not the
full story – the algebraic perspective on general frames is vital to modal logic – but
it should make clear that these unusual looking structures ﬁll an important logical
niche.
Exercises for Section 3.2
(a) Consider a modal language with two diamonds 1 and 2. Prove that the
class of frames in which R 1 is the reﬂexive transitive closure of R 2 is deﬁned by the
conjunction of the formulas 1p → (p ∨ 1(¬p ∧ 2p) and 1p ↔ (p ∨ 21p).
(b) Conclude that in the similarity type of PDL, the set Δ as deﬁned in Example 3.10
deﬁnes the class of ∗-proper frames.
(c) Consider the example of multi-agent epistemic logic; let {1, . . . , n} be the set of
agents. Suppose that one is interested in the operators E (Eφ stands for ‘everybody
knows φ’) and C (Cφ meaning that ‘it is common knowledge that φ’). The intended
relations modeling E and C are given by:

RE uv iff
1≤i≤n Ri uv,
RC uv iff there is a path u = x0 RE x1 RE . . . xn−1 RE xn = v.
3.2.1
Write down a set of (epistemic) formulas that characterizes the class of epistemic
frames where these conditions are met.
3.2.2 Show that Grzegorczyk’s formula, 2(2(p → 2p) → p) → p, characterizes the
class of frames F = (W, R) satisfying (i) R is reﬂexive, (ii) R is transitive and (iii) there
are no inﬁnite paths x 0 Rx1 Rx2 R . . . such that for all i, xi = xi+1 .
3.2.3 Consider the basic temporal language (see Example 1.25). Recall that a frame F =
(W, RF , RP ) for this language is called bidirectional if R P is the converse of R F .
(a) Prove that among the ﬁnite bidirectional frames, the formula G(Gp → p) → Gp
together with its converse, H(Hp → p) → Hp deﬁnes the transitive and irreﬂexive
frames.
(b) Prove that among the bidirectional frames that are transitive, irreﬂexive, and satisfy
∀xy (RF xy ∨ x = y ∨ RP xy), this same set deﬁnes the ﬁnite frames.
(c) Is there a ﬁnite set of formulas in the basic modal language that has these same
deﬁnability properties?
3.2.4 Consider the following formula in the basic similarity type:
ψ := 32p → 3(2(p ∧ q) ∨ 2(p ∧ ¬q)).
The aim of this exercise is to show that ψ does not deﬁne a ﬁrst-order condition on frames.
(a) To obtain some intuitions about the meaning of ψ, let us ﬁrst give a relatively simple
ﬁrst-order condition implying the validity of ψ:
α := ∀xy (Rxy → ∃z (Rxz ∧ ∀uv ((Rzu ∧ Rzv) → (u = v ∧ Ryu)))),
stating (in words) that for every pair (x, y) in R, x has a successor z which itself
has at most one successor, this point being also a successor of y.138
3 Frames
Show that ψ is valid in any frame satisfying α.
(b) Consider the frame F = (W, R) which we deﬁne as follows. Let u be a non-
principal ultraﬁlter over the set N of the natural numbers. Then W := {u} ∪ u ∪ N,
that is, the states of W are u itself, each subset of N that is a member of u and each
natural number. The relation R is the converse of the membership relation, that is,
Rst iff t ∈ s. Show that F  α and F  ψ.
(c) Prove that ψ does not have a ﬁrst-order correspondent by showing that ψ is in-
valid on all countable structures that are elementarily equivalent to F (that is, all
countable structures satisfying the same ﬁrst-order formulas as F).
3.3 Deﬁnable and Undeﬁnable Properties
We have seen that modal languages are a powerful tool for deﬁning frames: we
have seen examples of modally deﬁnable frame classes that are not ﬁrst-order de-
ﬁnable, and it is clear that validity is an inherently second-order concept. But what
are the limits of modal deﬁnability? For example, can modal languages deﬁne all
ﬁrst-order frame classes (the answer is no, as we will shortly see)? And anyway,
how should we go about showing that a class of frames is not modally deﬁnable?
After all, we cannot try out all possible formulas; something more sophisticated is
needed.
In this section we will answer these question by introducing four fundamental
frame constructions: disjoint unions, generated subframes, bounded morphic im-
ages, and ultraﬁlter extensions. The names should be familiar: these are the frame
theoretic analogs of the model-theoretic constructions studied in the previous chap-
ter, and they are going to do a lot of work for us, both here and in later chapters.
For a start, it is a more-or-less immediate consequence of the previous chapter’s
work that the ﬁrst three constructions preserve modal validity, while the fourth
anti-preserves it. But this means that these constructions provide powerful tests for
modal deﬁnability: by showing that some class of frames is not closed under one
of these constructions, we will be able to show that it cannot be modally deﬁnable.
Deﬁnition 3.13 The deﬁnitions of the disjoint union of a family of frames, a gen-
erated subframe of a frame, and a bounded morphism from one frame to another,
are obtained by deleting the clauses concerning valuations from Deﬁnitions 2.2,
2.5 and 2.10.
That is, for disjoint τ -frames Fi = (Wi , Ri )∈τ (i ∈ I), their disjoint union is
the structure i Fi = (W, R)∈τ such that W is the union of the sets Wi and for
each  ∈ τ , R is the union i∈I Ri . With frames that are not disjoint, proceed
as in Deﬁnition 2.2.
 )
We say that a τ -frame F = (W  , R
∈τ is a generated subframe of the frame

F = (W, R)∈τ (notation: F  F) whenever F is a subframe of F (with respect
to R for all  ∈ τ ), and the following heredity condition is fulﬁlled for all  ∈ τ3.3 Deﬁnable and Undeﬁnable Properties
139
if u ∈ W  and Ruu1 . . . un , then u1 , . . . , un ∈ W  .
Let X be a subset of the universe of a frame F; we denote by FX the subframe gen-
erated by X, that is, the generated subframe of F that is based on the smallest set
W  that contains X and satisﬁes the above heredity condition. If X is a singleton
{w}, we write Fw for the subframe generated by w; if a frame F is generated by a
singleton subset of its universe, we call it rooted or point-generated.
And ﬁnally, a bounded morphism from a τ -frame F = (W, R)∈τ to a τ -
 )

frame F = (W  , R
∈τ is a function from W to W satisfying the following two
conditions:
 f (w)f (v ) . . . f (v ).
(forth) For all  ∈ τ , Rwv1 . . . vn implies R
1
n
 f (w)v  . . . v  then there exist v . . . v such that R wv . . . v and
(back) If R
1
n

1
n
n
1
f (vi ) = vi (for 1 ≤ i ≤ n).
We say that F is a bounded morphic image of F, notation: F
surjective bounded morphism from F onto F .
F , if there is a
It is an essential characteristic of modal formulas that their validity is preserved
under the structural operations just deﬁned:
Theorem 3.14 Let τ be a modal similarity type, and φ a τ -formula.
(i) Let {Fi | i ∈ I} be a family of frames. Then
in I.
(ii) Assume that F  F. Then F  φ if F  φ.
(iii) Assume that F
F . Then F  φ if F  φ.
Fi  φ if Fi  φ for every i
Proof. We only prove (iii), the preservation result for taking bounded morphic
images, and leave the other cases to the reader as Exercise 3.3.1. So, assume that f
is a surjective bounded morphism from F onto F , and that F  φ. We have to show
that F  φ. So suppose that φ is not valid in F . Then there must be a valuation V 
and a state w such that (F , V  ), w  φ. Deﬁne the following valuation V on F:
V (pi ) = {x ∈ W | f (x) ∈ V  (pi )}.
This deﬁnition is tailored to make f a bounded morphism between the models
(F, V ) and (F , V  ) – the reader is asked to verify the details. Now we use the
fact that f is surjective to ﬁnd a w such that f (w) = w . It follows from Proposi-
tion 2.14 that (F, V ), w  φ. In other words, we have falsiﬁed φ in the frame F,
and shown the contrapositive of the desired result.
Think of these frame constructions as test criteria for the deﬁnability of frame
properties: if a property is not preserved under one (or more) of these frame con-
structions, then it cannot be modally deﬁnable. Let us consider some examples of
such testing.3 Frames
140
Example 3.15 The class of ﬁnite frames is not modally deﬁnable. For suppose
there was a set of formulas Δ (in the basic modal similarity type) characteriz-
ing the ﬁnite frames. Then Δ would be valid in every one-point frame Fi =
({wi }, {(wi , wi )}) (i < ω). By Theorem 3.14(i) this would imply that Δ was
also valid in the disjoint union i Fi :
'
w0  w1  w2  w3  
u
u
u
u
   
&
$
...
%
But clearly this cannot be the case, for i Fi is inﬁnite.
The class of frames having a reﬂexive point (∃x Rxx) does not have a modal
characterization either (again we work with the basic modal similarity type). For
suppose that the set Δ characterized this class. Consider the following frame F:

w u




v u
u
- u

As w is a reﬂexive state, F  Δ. Now consider the generated subframe Fv of F.
Clearly, Δ cannot be valid in Fv , since neither v nor u is reﬂexive. But this contra-
dicts the fact that validity of modal formulas is preserved under taking generated
subframes (Theorem 3.14(ii)).
The two ﬁnal examples involve the use of bounded morphisms. First, irreﬂexiv-
ity is not deﬁnable. To see this, simply note that the function which collapses the
set of natural numbers in their usual order to a single reﬂexive point is a surjec-
tive bounded morphism. As the former frame is irreﬂexive, while the latter is not,
irreﬂexivity cannot be modally deﬁnable.
Actually, a more sophisticated variant of this example lets us prove even more.
Consider the following two frames: F = (ω, S), the natural numbers with the
successor relation (Smn iff n = m + 1), and G = ({e, o}, {(e, o), (o, e)}) as
depicted below.
'
0
1
u
- u
$
2
- u
3
- u
4
- u
5
- u
&
-
...
'
?
e u
&
$
- ?
uo
%
...
%3.3 Deﬁnable and Undeﬁnable Properties
141
In Example 2.11 we saw that the map f sending even numbers to e and odd num-
bers to o is a surjective bounded morphism. By the same style of reasoning as in
the earlier examples, it follows that no property P is modally deﬁnable if F has P
and G lacks it. This shows, for example, that there is no set of formulas character-
izing the asymmetric frames (∀xy (Rxy → ¬Ryx)).
Now for the fourth frame construction. Recall that in Section 2.5 we introduced
the idea of ultraﬁlter extensions; see Deﬁnition 2.57 and Proposition 2.59. Once
again, simply by ignoring the parts of the deﬁnition that deal with valuations, we
can lift this concept to the level of frames, and this immediately provides us with
the following anti-preservation result:
Corollary 3.16 Let τ be a modal similarity type, F a τ -frame, and φ a τ -formula.
Then F  φ if ue F  φ.
Proof. Assume that φ is not valid in F. That is, there is a valuation V and a state
w such that (F, V ), w  ¬φ. By Proposition 2.59, ¬φ is true at uw in the ultraﬁlter
extension of M. But then we have refuted φ in ue F.
Once again, we can use this result to show that some frame properties are not
modally deﬁnable. For example, working in the basic modal similarity type, con-
sider the property that every state has a reﬂexive successor: ∀x∃y (Rxy ∧ Ryy).
We claim that this property is not modally deﬁnable, even though it is preserved
under taking disjoint unions, generated subframes and bounded morphic images.
To verify our claim, the reader is asked to consider the frame in Example 2.58.
It is easy to see that every state of ue F has a reﬂexive successor – take any non-
principal ultraﬁlter. But F itself clearly does not satisfy the property, as F has no
reﬂexive states. Now suppose that the property were modally deﬁnable, say by the
set of formulas Δ. Then we would have ue F  Δ, but F  Δ – a clear violation
of Corollary 3.16.
Note the direction of the preservation result in Corollary 3.16. It states that
modal validity is anti-preserved under taking ultraﬁlter extensions. This naturally
raises the question whether the other direction holds as well, that is, whether F  φ
implies ue F  φ. For a partial answer to this question, we need the following
theorem:
Theorem 3.17 Let τ be a modal similarity type, and F a τ -frame. Then F has an


ultrapower U F such that U F
ue F. In a diagram:

UF
Z
Z
F
Z
~
Z
~
ue F142
3 Frames
Proof. Advanced track readers will be asked to supply a proof of this theorem in
Exercise 3.8.1 below.
And now we have the following partial converse to Corollary 3.16:
Corollary 3.18 Let τ be a modal similarity type, and φ a τ -formula. If φ deﬁnes
a ﬁrst-order property of frames, then frame validity of φ is preserved under taking
ultraﬁlter extensions.
Proof. Let φ be a modal formula which deﬁnes a ﬁrst-order property of frames, and
let F be a frame such that F  φ. By the previous theorem, there is an ultrapower


ue F. As ﬁrst-order properties are preserved under
U F of F such that U F
taking ultrapowers, U F  φ. But then ue F  φ by Theorem 3.14.
We are on the verge of one of the best-known results in modal logic: the Goldblatt-
Thomason Theorem. This result tells us that – at least as far as ﬁrst-order deﬁn-
able frame classes are concerned – the four frame constructions we have discussed
constitute necessary and sufﬁcient conditions for a class of frames to be modally
deﬁnable. We are not going to prove this important result right away, but we will
take this opportunity to state it precisely. We use the following terminology: a class
of frames K reﬂects ultraﬁlter extensions if ue F ∈ K implies F ∈ K.
Theorem 3.19 (Goldblatt-Thomason Theorem) Let τ be a modal similarity type.
A ﬁrst-order deﬁnable class K of τ -frames is modally deﬁnable if and only if it
is closed under taking bounded morphic images, generated subframes, disjoint
unions and reﬂects ultraﬁlter extensions.
Proof. A model-theoretic proof will be given in Section 3.8 below; this proof lies
on the advanced track. An algebraic proof will be given in Chapter 5; this proof
lies on the basic track. In addition, a simple special case which holds for ﬁnite
transitive frames is proved in the following section.
In fact, we can weaken the condition of ﬁrst-order deﬁnability to closure under
ultrapowers, cf. Exercise 3.8.4 or Theorem 5.54.
Exercises for Section 3.3
(a) Prove that frame validity is preserved under taking generated subframes and
disjoint unions.
(b) Which of the implications in Theorem 3.14 can be replaced with an equivalence?
(c) Is frame validity preserved under taking ultraproducts?
3.3.1
3.3.2 Consider the basic modal language. Show that the following properties of frames
are not modally deﬁnable:
(a) antisymmetry (∀xy(Rxy ∧ Ryx → x = y)),3.4 Finite Frames
143
(b) |W | > 23,
(c) |W | < 23,
(d) acyclicity (there is no path from any x to itself),
(e) every state has at most one predecessor,
(f) every state has at least two successors.
3.3.3 Consider a language with three diamonds, 3 1 , 32 and 33 . For each of the frame
conditions on the corresponding accessibility relations below, ﬁnd out whether it is modally
deﬁnable or not:
(a) R1 is the union of R 2 and R3 ,
(b) R1 is the intersection of R 2 and R3 ,
(c) R1 is the complement of R 2 ,
(d) R1 is the composition of R 2 and R3 ,
(e) R1 is the identity relation,
(f) R1 is the complement of the identity relation.
3.3.4 Show that any frame is a bounded morphic image of the disjoint union of its rooted
generated subframes.
3.4 Finite Frames
In this section we prove two simple results about ﬁnite frames. First we state and
prove a version of the Goldblatt-Thomason Theorem for ﬁnite transitive frames.
Next we introduce the ﬁnite frame property, and show that a normal modal logic
has the ﬁnite frame property if and only if it has the ﬁnite model property.
Finite transitive frames
An elegant analog of the Goldblatt-Thomason Theorem holds for ﬁnite transitive
frames: within this class, closure under the three structural operations of (ﬁnite)
disjoint unions, generated subframes, and bounded morphisms is a necessary and
sufﬁcient condition for a class of frames to be modally deﬁnable. The proof is
straightforward and makes use of Jankov-Fine formulas.
Let F = (W, R) be a point-generated ﬁnite transitive frame for the basic modal
similarity type, and let w be a root of F. The Jankov-Fine formula φF,w is essen-
tially a description of F that has the following property: it is satisﬁable on a frame
G if and only if F is a bounded morphic image of a generated subframe of G.
We build Jankov-Fine formulas as follows. Enumerate the states of F as w0 , . . . ,
wn , where w = w0 . Associate each state wi with a distinct proposition letter pi .
Let φF,w be the conjunction of the following formulas:
(i) p0
(ii) 2(p0 ∨ · · · ∨ pn )
(iii) (pi → ¬pj ) ∧ 2(pi → ¬pj ), for each i, j with i = j ≤ n
(iv) (pi → 3pj ) ∧ 2(pi → 3pj ), for each i, j with Rwi wj144
3 Frames
(v) (pi → ¬3pj ) ∧ 2(pi → ¬3pj ), for each i, j with ¬Rwi wj
Note that as R is transitive, each node in F is accessible in one step from w. It fol-
lows that when formulas of the form ψ ∧ 2ψ are satisﬁed at w, ψ is true throughout
F. With this observed, the content of Jankov-Fine formulas should be clear: the
ﬁrst three conjuncts state that each node in F is uniquely labeled by some pi (with
p0 labelling w0 ) while the last two conjuncts use this labeling to describe the frame
structure.
Lemma 3.20 Let F be a transitive, ﬁnite, point-generated frame, let w be a root
of F, and let φF,w be the Jankov-Fine formula for F and w. Then for any transitive
frame G we have the following equivalence: there is a valuation V and a node v
such that (G, V ), v  φF,w if and only if there exists a bounded morphism from Gv
onto F.
Proof. Left to the reader as Exercise 3.4.1.
With the help of this lemma, it is easy to prove the following Goldblatt-Thomason
analog:
Theorem 3.21 Recall that τ0 denotes the basic modal similarity type. Let K be a
class of ﬁnite, transitive τ0 -frames. Then K is deﬁnable within the class of ﬁnite,
transitive τ0 -frames if and only if it is closed under taking (ﬁnite) disjoint unions,
generated subframes, and bounded morphic images.
Proof. The right to left direction is immediate: we know from the previous section
that any modally deﬁnable frame class is closed under these operations. So let us
consider the more interesting converse.
Assume that K is a class of ﬁnite, transitive τ0 -frames and satisﬁes the stated
closure conditions. Let ΛK be the logic of K; that is, ΛK = {φ | F  φ, for all
F ∈ K}. We will show that ΛK deﬁnes K. Clearly ΛK is valid on every frame in
K, so to complete the proof we need to show that if F  ΛK , where F is ﬁnite and
transitive, then F ∈ K. We split the proof into two cases.
First suppose that F is point-generated with root w. Consider the Jankov-Fine
formula φF,w for F and w. Clearly φF,w is satisﬁable in F at w, so ¬φF,w ∈
/ ΛK .
Hence there is some G ∈ K such that G  ¬φF,w ; in other words, for some
valuation V and state v we have (G, V ), v  φF,w . Thus by the previous lemma,
F is a bounded morphic image of the point-generated subframe Gv of G. By the
closure conditions on K, it follows that F ∈ K.
So suppose that F is not point-generated. But then as F  ΛK , so does each
point-generated subframe of F, hence by the work of the previous paragraph all
these subframes belong to K. But by Exercise 3.3.4, F is a bounded morphic image
of the disjoint union of its rooted generated subframes, so F belongs to K too.3.4 Finite Frames
145
The ﬁnite frame property
Our next result deals not with frame deﬁnability, but with the relationship between
normal modal logics and ﬁnite frames. Normal modal logics were introduced in
Section 1.6 (see in particular Deﬁnition 1.42). Recall that normal modal logics
are sets of formulas (containing certain axioms) that are closed under three simple
conditions (modus ponens, uniform substitution, and generalization). They are the
standard tool for capturing the notion of validity syntactically.
Now, in Section 2.3 we introduced the ﬁnite model property. We did not apply
the concept to normal modal logics – but as a normal logic is simply a set of
formulas, we can easily extend the deﬁnition to permit this:
Deﬁnition 3.22 A normal modal logic Λ has the ﬁnite model property with respect
to some class of models M if M  Λ and every formula not in Λ is refuted in a ﬁnite
model M in M. Λ has the ﬁnite model property if it has the ﬁnite model property
with respect to some class of models.
Informally, if a normal modal logic has the ﬁnite model property, it has a ﬁnite
semantic characterization: it is precisely the set of formulas that some collection of
ﬁnite models makes globally true. This is an attractive property, and as we will see
in Chapter 6 when we discuss the decidability of normal logics, a useful one too.
But something seems wrong. It is the level of frames, rather than the level of
models, which supports the key logical concept of validity. It certainly seems sen-
sible to try and semantically characterize normal logics in terms of ﬁnite structures
– but it seems we should do so using ﬁnite frames, not ﬁnite models. That is, the
following property seems more appropriate:
Deﬁnition 3.23 (Finite Frame Property) Let Λ be a normal modal logic and F a
class of ﬁnite frames. We say Λ has the ﬁnite frame property with respect to F if
and only if F  Λ, and for every formula φ such that φ ∈ Λ there is some F ∈ F
such that φ is falsiﬁable on F. We say Λ has the ﬁnite frame property if and only if
it has the ﬁnite frame property with respect to some class of ﬁnite frames.
Note that to establish the ﬁnite frame property of a normal modal logic Λ, it is not
sufﬁcient to prove that any formula φ ∈ Λ can be refuted on a model where Λ is
globally true: in addition one has to ensure that the underlying frame of the model
validates Λ. If a logic has the ﬁnite frame property (and many important ones do,
as we will learn in Chapter 6) then clearly there is no room for argument: it really
can be characterized semantically in terms of ﬁnite structures.
But now for a surprising result. The ﬁnite frame property is not stronger than the
ﬁnite model property: we will show that a normal modal logic has the ﬁnite frame
property if and only if it has the ﬁnite model property. This result will prove useful
at a number of places in Chapters 4 and 6. Moreover, while proving it we will meet146
3 Frames
some other concepts, notably deﬁnable variants and distinguishing models, which
will be useful when proving Bull’s Theorem in Section 4.9.
Deﬁnition 3.24 (Deﬁnable Variant) Let M = (W, R, V ) be a model and U ⊆ W .
We say U is deﬁnable in M if and only if there is a formula φU such that for all
states w ∈ W , M, w  φU iff w ∈ U .
Any model M based on the frame (W, R) is called a variant of M. A variant
(W, R, V  ) of M is deﬁnable in M if and only if for all proposition symbols p,
V  (p) is deﬁnable in M. If M is a variant of M that is deﬁnable in M, we call M
a deﬁnable variant of M.
Recall that normal modal logics are closed under uniform substitution, the process
of uniformly replacing propositional symbols with arbitrary formulas (see Sec-
tion 1.6), and that a formula obtained from φ by uniform substitution is called a
substitution instance of φ. Our intuitive understanding of uniform substitution suf-
ﬁces for most purposes, but in order to prove the following lemma we need to refer
to the precise concepts of Deﬁnition 1.18.
Lemma 3.25 Let M = (F, V ) be a model and M = (F, V  ) be a deﬁnable vari-
ant of M. For any formula φ, let φ be the result of uniformly replacing each atomic
symbol p in φ by φV  (p) , where φV  (p) deﬁnes V  (p) in M. Then for all formulas
φ, and all normal modal logics Λ:
(i) M , w  φ iff M, w  φ .
(ii) If every substitution instance of φ is true in M, then every substitution in-
stance of φ is true in M .
(iii) If M  Λ then M  Λ.
Proof. Item (i) follows by induction on φ. For the base case we have M , w 
p iff M, w  φV  (p) . As (¬φ) = ¬φ , (φ ∨ ψ) = φ ∨ ψ  , and (3φ) = 3φ
(cf. Deﬁnition 1.18) the inductive steps are immediate.
For item (ii), we show the contrapositive. Let ψ be a substitution instance of φ
and suppose that M  ψ. Thus there is some w in M such that M , w  ψ. By
item (i), M, w  ψ , which means that M  ψ . But as ψ is a substitution instance
of ψ, and ψ is a substitution instance of φ, we have that ψ is a substitution instance
of φ (see Exercise 1.2.5) and the result follows.
Item (iii) is an immediate consequence of item (ii), for normal modal logics are
closed under uniform substitution.
We now isolate a type of model capable of deﬁning all its variants:
Deﬁnition 3.26 (Distinguishing Model) A model M is distinguishing if the rela-
tion  of modal equivalence between states of M is the identity relation.3.4 Finite Frames
147
In other words, a model M is distinguishing if and only if for all states w and u
in M, if w = u, then there is a formula φ such that M, w  φ and M, u  φ.
Many important models are distinguishing. For example, all ﬁltrations (see Deﬁ-
nition 2.36) are distinguishing. Moreover, the canonical models introduced in Sec-
tion 4.2 are distinguishing too. And, and as we will now see, when a distinguishing
model is ﬁnite, it can deﬁne all its variants.
Lemma 3.27 Let M = (F, V ) be a ﬁnite distinguishing model. Then:
(i) For every state w in M there is a formula φw that is true at, and only at, w.
(ii) M can deﬁne any subset of F. Hence M can deﬁne all its variants.
(iii) If M  φ then F  φ.
Proof. For item (i), suppose that F = (W, R), and enumerate the states in W as
w1 ,. . . ,wn. For all pairs (i, j) such that 1 ≤ i, j ≤ n and i = j, choose φi,j to be a
formula such that M, wi  φi,j and M, wj  φi,j (such a formula exists, for M is
distinguishing) and deﬁne φwi to be φi,1 ∧ · · · ∧ φi,n . Clearly φwi is true at wi and
false everywhere else.

Item (ii) is an easy consequence. For let U be any subset of W . Then w∈U φw
deﬁnes U . Hence as M can deﬁne all subsets of W , it can deﬁne V  (p), for any
valuation V  on F and propositional symbol p.
As for item (iii), suppose M  φ. By item (iii) of the previous lemma we have
that M  φ, where M is any deﬁnable variant of M. But we have just seen that
M can deﬁne all its variants, hence F  φ.
Lemmas 3.25 and 3.27 will be important in their own right when we prove Bull’s
Theorem in Section 4.9. And with the help of a neat ﬁltration argument, they yield
the main result:
Theorem 3.28 A normal modal logic has the ﬁnite frame property iff it has the
ﬁnite model property.
Proof. The left to right direction is immediate. For the converse, suppose that Λ
is a normal modal logic with the ﬁnite model property. Since we will need to take
a ﬁltration through Λ, we have to be explicit about the set of proposition letters of
the formulas in Λ, so assume that Λ ⊆ Form(τ, Φ).
Take a formula in the language ML(τ, Φ) that does not belong to Λ. We will
show that φ can be refuted on a ﬁnite frame F such that F  Λ.
As Λ has the ﬁnite model property, there is a ﬁnite model M such that M  Λ
and M, w  φ for some state w in M. Let Σ be the set of all subformulas of
formulas in {φ} ∪ Λ, and let Mf be any ﬁltration of M through Σ. As M is ﬁnite,
so is Mf . As Mf is a ﬁltration, it is a distinguishing model. By the Filtration
Theorem (Theorem 2.39), Mf , |w|  φ. Moreover Mf  Λ, for as every state3 Frames
148
in M satisﬁes all formulas in Λ, so does every state in Mf (again, this follows
from the Filtration Theorem). Let F be the (ﬁnite) frame underlying Mf . By
Lemma 3.27 item (iii), F  Λ, and we have proved the theorem.
Note the somewhat unusual use of ﬁltrations in this proof. Normally we ﬁltrate
inﬁnite models through ﬁnite sets of formulas. Here we ﬁltrated a ﬁnite model
through an inﬁnite sets of formulas to guarantee that an entire logic remained true.
This result shows that the concepts of normal modal logics and frame validity
ﬁt together well in the ﬁnite domain: if a normal logic has a ﬁnite semantic char-
acterization in terms of models, then it is guaranteed to have a ﬁnite frame-based
semantic characterization as well. But be warned: one of the most striking re-
sults of the following chapter is that logics and frame validity do not always ﬁt
together so neatly. In fact, the frame incompleteness results will eventually lead
us (in Chapter 5) to the use of new semantic structures, namely modal algebras, to
analyze normal modal logics. But this is jumping ahead. It is time to revert to our
discussion of frame deﬁnability – but from a rather different perspective. So far,
our approach has been ﬁrmly semantical. This has taught us a lot: in particular, the
Goldblatt-Thomason Theorem has given us a model-theoretic characterization of
the elementary frame classes that are modally deﬁnable. Moreover, we will see in
Chapter 5 that the semantic approach has an important algebraic dimension. But it
is also possible to approach frame deﬁnability from a more syntactic perspective,
and that is what we are going to do now. This will lead us to the other main result
of the chapter: the Sahlqvist Correspondence Theorem.
Exercises for Section 3.4
3.4.1 Prove Lemma 3.20. That is, suppose that φ F,w is the Jankov-Fine formula for a
transitive ﬁnite frame F with root w. Show that for any frame G, φ F,w is satisﬁable on G
at a node v iff F is a bounded morphic image of G v .
3.4.2 Let M be a model, let M f be any ﬁltration of M through some ﬁnite set of formulas
Σ, and let f be the natural map associated with the ﬁltration. If u is a point in the ﬁltration,
show that f −1 [u] is deﬁnable in M.
3.5 Automatic First-Order Correspondence
We have learned a lot about frame deﬁnability in the previous sections. In partic-
ular, we have learned that frame deﬁnability is a second-order notion, and that the
second-order correspondent of any modal formula can be straightforwardly com-
puted using the second-order translation. Moreover, we know that many modal
formulas have ﬁrst-order correspondents, and that the Goldblatt-Thomason Theo-
rem gives us a model-theoretic characterization of the frame classes they deﬁne.
Nonetheless, there remains a gap in our understanding: although many modal3.5 Automatic First-Order Correspondence
149
formulas deﬁne ﬁrst-order conditions on frames, it is not really clear why they do
so. To put it another way, in many cases the (often difﬁcult to decipher) second-
order condition yielded by the second-order translation is equivalent to a much
simpler ﬁrst-order condition. Is there any system to this? Better, are there algo-
rithms that enable us to compute ﬁrst-order correspondents automatically, and if so,
how general are these algorithms? This section, and the two that follow, develop
some answers.
A large part of this work centers on a beautiful positive result: there is a large
class of formulas, the Sahlqvist formulas, each of which deﬁnes a ﬁrst-order con-
dition on frames which is effectively calculable using the Sahlqvist-van Benthem
algorithm; this is the celebrated Sahlqvist Correspondence Theorem, which we
will state and prove in the following section. The proof of this theorem sheds light
on why so many second-order correspondents turn out to be equivalent to a ﬁrst-
order condition. Moreover each Sahlqvist formula is complete with respect to the
class of ﬁrst-order frames it deﬁnes; this is the Sahlqvist Completeness Theorem,
which we will formulate more precisely in Theorem 4.42 and prove in Section 5.6.
All in all, the Sahlqvist fragment is interesting from both theoretical and practical
perspectives, and we devote a lot of attention to it.
In this section we lay the groundwork for the proof of the Sahlqvist Correspon-
dence Theorem. We are going to introduce two simple classes of modal formulas,
the closed formulas and the uniform formulas, and show that they deﬁne ﬁrst-order
conditions on frames. Along the way we are going to learn about positive and
negative formulas, what they have to do with monotonicity, and how they can help
us get rid of second-order quantiﬁers. These ideas will be put to work, in a more
sophisticated way, in the following section.
One other thing: in what follows we are going to work with a stronger notion of
correspondence. The concept of correspondence given in Deﬁnition 3.5 is global:
a modal and a (ﬁrst- or second-order) frame formula are called correspondents if
they are valid on precisely the same frames. But it is natural to demand that validity
matches locally:
Deﬁnition 3.29 (Local Frame Correspondence) Let φ be a modal formula in
some similarity type, and α(x) a formula in the corresponding ﬁrst- or second-
order frame language (x is supposed to be the only free variable of α). Then we
say that φ and α(x) are local frame correspondents of each other if the following
holds, for any frame F and any state w of F:
F, w  φ iff F |= α[w].
In fact, we have been implicitly using local correspondence all along. In Exam-
ple 3.6 we showed that p → 3p corresponds to ∀xRxx – but inspection of the
proof reveals we did so by showing that p → 3p locally corresponds to Rxx.3 Frames
150
Similarly, in Example 3.7 we showed that 3p → 33p corresponds to density by
showing that 3p → 33p locally corresponds to ∀y (Rxy → ∃z (Rxz ∧ Rzy)).
It should be clear from these examples that the local notion of correspondence is
fundamental, and that the following connection holds between the local and global
notions:
Proposition 3.30 If α(x) is a local correspondent of the modal formula φ, then
∀x α(x) is a global correspondent of φ. So if φ has a ﬁrst-order local correspon-
dent, then it also has a ﬁrst-order global correspondent.
Proof. Trivial.
What about the converse? In particular, suppose that the modal formula φ has a
ﬁrst order global correspondent; will it also have a ﬁrst-order local correspondent?
Intriguingly, the answer to this question is negative, as we will see in Example 3.57.
But until we come to this result, we will not mention global correspondence
much: it is simpler to state and prove results in terms of local correspondence,
relying on the previous lemma to guarantee correspondence in the global sense.
With this point settled, it is time to start thinking about correspondence theory
systematically.
Closed formulas
There is one obvious class of modal formulas guaranteed to correspond to ﬁrst-
order frame conditions: formulas which contain no proposition letters.
Example 3.31 Consider the basic temporal language. The formula P  deﬁnes
the property that there is no ﬁrst point of time. More precisely, P  is valid on
precisely those frames such that every point has a predecessor.
Now, obviously it is easy to prove this directly, but for present purposes the
following argument is more interesting. By Proposition 3.12, for any bidirectional
frame F and any point w in F we have that:
F, w  P  iff F |= ∀P1 . . . ∀Pn ST x (P )[w],
where P1 , . . . , Pn are the unary predicate variables corresponding to the proposi-
tion letters p1 , . . . , pn occurring in P . But P  contains no propositional vari-
ables, hence there are no second-order quantiﬁers, and hence:
F, w  P  iff F |= ST x (P )[w].
But ST x (P ) is ∃y (Ryx∧y = y), which is equivalent to ∃y Ryx. So P  locally
corresponds to ∃y Ryx (and thus globally corresponds to ∀x∃y Ryx).3.5 Automatic First-Order Correspondence
151
The argument used in this example is extremely simple, and obviously generalizes.
We will state and prove the required generalization, and then move on to richer
pastures.
Deﬁnition 3.32 A modal formula φ is closed if and only if it contains no proposi-
tion letters. Thus closed formulas are built up from , ⊥, and any nullary modali-
ties (or modal constants) the signature may contain.
Proposition 3.33 Let φ be a closed formula. Then φ locally corresponds to a ﬁrst-
order formula cφ (x) which is effectively computable from φ.
Proof. By Proposition 3.12 and the fact that φ contains no propositional variables
we have:
F, w  φ iff F |= ST x (φ)[w].
As it is easy to write a program that computes STx (φ), the claim follows immedi-
ately.
Closed formulas arise naturally in some applications (a noteworthy example is
provability logic), thus the preceding result is quite useful in practice.
Uniform formulas
Although the previous proposition was extremely simple, it does point the way to
the strategy followed in our approach to the Sahlqvist Correspondence Theorem:
we are going to look for ways of stripping off the initial block of monadic second-
order universal quantiﬁers in ∀P1 . . . ∀Pn ST x (φ), thus reducing the translation to
ST x (φ). The obvious way of getting rid of universal quantiﬁers is to perform
universal instantiation, and this is exactly what we will do. Both here, and in the
work of the next section, we will look for simple instantiations for the P1 , . . . , Pn ,
which result in ﬁrst-order formulas equivalent to the original. We will be able to
make this strategy work because of the syntactic restrictions placed on φ.
One of the restrictions imposed on Sahlqvist formulas invokes the idea of pos-
itive and negative occurrences of proposition letters. We now introduce this idea,
study its semantic signiﬁcance, and then, as an introduction to the techniques of
the following section, use a simple instantiation argument to show that the second-
order translations of uniform formulas are effectively reducible to ﬁrst-order con-
ditions on frames.
Deﬁnition 3.34 An occurrence of a proposition letter p is a positive occurrence if
it is in the scope of an even number of negation signs; it is a negative occurrence if
it is in the scope of an odd number of negation signs. (This is one of the few places
in the book where it is important to think in terms of the primitive connectives.3 Frames
152
For example, the occurrence of p in 3(p → q) is negative, for this formula is
shorthand for 3(¬p ∨ q).) A modal formula φ is positive in p (negative in p) if all
occurrences of p in φ are positive (negative). A formula is called positive (negative)
if it is positive (negative) in all proposition letters occurring in it.
Analogous concepts are deﬁned for the corresponding second-order language.
That is, an occurrence of a unary predicate variable P in a second-order formula is
positive (negative) if it is in the scope of an even (odd) number of negation signs. A
second-order formula φ is positive in P (negative in P ) if all occurrences of P in φ
are positive (negative), and it is called positive (negative) if it is positive (negative)
in all unary predicate variables occurring in it.
Lemma 3.35 Let φ be a modal formula.
(i) φ is positive in p iff ST x (φ) is positive in the corresponding unary predicate
P.
(ii) If φ is positive (negative) in p, then ¬φ is negative (positive) in p.
Proof. Virtually immediate.
Positive and negative formulas are important because of their special semantic
properties. In particular, they exhibit a useful form of monotonicity.
Deﬁnition 3.36 Fix a modal language ML(τ, Φ), and let p ∈ Φ. A modal for-
mula φ is upward monotone in p if its truth is preserved under extensions of
the interpretation of p. More precisely, φ is upward monotone in p if for ev-
ery model (W, R, V )∈τ , every state w ∈ W , and every valuation V  such that
V (p) ⊆ V  (p) and for all q = p, V (q) = V  (q), the following holds:
if (W, R, V )∈τ , w  φ, then (W, R, V  )∈τ , w  φ.
In short, extending V (p) (while leaving the interpretation of other proposition let-
ters unchanged) has the effect of extending V (φ) (or keeping it the same).
Likewise, a formula φ is downward monotone in p if its truth is preserved under
shrinkings of the interpretation of p. That is, for every model (W, R, V )∈τ ,
every state w ∈ W , and every valuation V  such that V  (p) ⊆ V (p) and for all
q = p, V (q) = V  (q), the following holds:
if (W, R, V )∈τ , w  φ, then (W, R, V  )∈τ , w  φ.
The notions of a second-order formula being upward and downward monotone in
a unary predicate variable P are deﬁned analogously; we leave this task to the
reader.
Lemma 3.37 Let φ be a modal formula.
(i) If φ is positive in p, then it is upward monotone in p.3.5 Automatic First-Order Correspondence
153
(ii) If φ is negative in p, then it is downward monotone in p.
Proof. Prove both parts simultaneously by induction on φ; see Exercise 3.5.3.
But what do upward and downward monotonicity have to do with frame deﬁnabil-
ity? The following example is instructive:
Example 3.38 The formula 32p locally corresponds to a ﬁrst-order formula. For
suppose F, w  32p. Regardless of the valuation, the formula 32p holds at w.
So consider a minimal valuation (for p) on F; that is, choose any Vm such that
Vm (p) = ∅. Then as w  32p, there must be a successor v of w such that 2p
holds at v. However, there are no p-states, so v must be blind (that is, without
successors). In other words, we have shown that
(F, Vm ), w  32p only if F |= ∃y (Rxy ∧ ¬∃z Ryz)[w].
Now for the interesting direction: assume that the state w in the frame F has a
blind successor. It follows immediately that (F, Vm ), w  32p, where Vm is any
minimal valuation (for p). We claim that the formula 32p is valid at w. To see this,
consider an arbitrary valuation V and a point w of F. By item (i) of Lemma 3.37,
32p is upward monotone in p. Hence it follows from the fact that Vm (p) ⊆ V (p)
that (F, V ), w  32p. As V was arbitrary, 32p is valid on F at w.
The key point is the last part of the argument: the use of a minimal valuation fol-
lowed by an appeal to monotonicity to establish a result about all valuations. But
now think about this argument from the perspective of the second-order correspon-
dence language: in effect, we instantiated the predicate variable corresponding to
p with the smallest subset of the frame possible, and then used a monotonicity
argument to establish a result about all assignments to P .
This simple idea lies behind much of our work on the Sahlqvist fragment. To
illustrate the style of argumentation it leads to, we will now use an instantiation
argument to show that all uniform modal formulas deﬁne ﬁrst-order conditions on
frames.
Deﬁnition 3.39 A proposition letter p occurs uniformly in a modal formula if it
occurs only positively, or only negatively. A predicate variable P occurs uniformly
in a second-order formula if it occurs only positively, or only negatively. A modal
formula is uniform if all the proposition letters it contains occur uniformly. A
second-order formula is uniform if all the unary predicate variables it contains
occur uniformly.
Theorem 3.40 If φ is a uniform modal formula, then φ locally corresponds to a
ﬁrst-order formula cφ (x) on frames. Moreover, cφ is effectively computable from
φ.3 Frames
154
Proof. Consider the universally quantiﬁed second-order equivalent of φ:
∀P1 . . . ∀Pn ST x (φ),
(3.6)
where P1 , . . . , Pn are second-order variables corresponding to the proposition let-
ters in φ. Our aim is to show that (3.6) is equivalent to a ﬁrst-order formula by per-
forming appropriate instantiations for the universally quantiﬁed monadic second-
order variables P1 , . . . , Pn .
As φ is uniform, by Lemma 3.35 so is ST x (φ). We will instantiate the unary
predicates that occur positively with a predicate denoting as small a set as possi-
ble (that is, the empty set), and the unary predicates that occur negatively with a
predicate denoting as large a set as possible (that is, all the states in the frame). We
will use Church’s λ-notation for the required substitution instance providing the
formulas that deﬁne these predicates. For every P occurring in STx (φ), deﬁne
λu. u = u, if ST x (φ) is positive in P ,
λu. u = u, if ST x (φ) is negative in P .
σ(P ) ≡
Of course, the idea is that instantiating a universal second-order formula according
to this substitution σ simply means (i) removing the second-order quantiﬁers and
(ii) replacing every atomic subformula P y with the formula σ(P )(y), that is, with
either y = y or y = y (as given by the deﬁnition).1
Now consider the following instance of (3.6) in which every unary predicate P
has been replaced by σ(P ):
[σ(P1 )/P1 , . . . , σ(Pn )/Pn ] ST x (φ).
(3.7)
We will show that (3.7) is equivalent to (3.6). It is immediate that (3.6) implies
(3.7), for the latter is an instantiation of the former. For the converse implication
we assume that
M |= [σ(P1 )/P1 , . . . , σ(Pn )/Pn ] ST x (φ)[w],
(3.8)
and we have to show that
M |= ∀P1 . . . ∀Pn ST x (φ)[w].
By the choice of σ(P ), for predicates P that occur only positively in STx (φ) we
have that M |= ∀y (σ(P )(y) → P (y)), and for predicates P that occur only neg-
atively in ST x (φ), we have that M |= ∀y (P (y) → σ(P )(y)). (Readers familiar
with λ-notation will realize that we have implicitly appealed to β-conversion here.
Readers unfamiliar with λ-notation should simply note that when σ(P ) is a predi-
cate denoting the empty set, then σ(P )(y) is false no matter what y denotes, while
1
If you are unfamiliar with λ-notation, all you really need to know to follow the proof is that λu. u = u and
λu. u = u are predicates denoting the empty set and the set of all states respectively. Some explanatory
remarks on λ-notation are given following the proof.3.5 Automatic First-Order Correspondence
155
if σ(P ) denotes the set of all states, σ(P )(y) is guaranteed to be true.) Hence,
as ST x (φ) is positive or negative in all unary predicates P occurring in it, (3.8)
together with Lemma 3.37 imply that for any choice of P1 , . . . , Pn ,
(M, P1 , . . . , Pn ) |= ST x (φ)[w],
which means that M |= ∀P1 . . . ∀Pn ST x (φ) as required. Finally, in any program-
ming language with decent symbol manipulation facilities it is straightforward to
write a program which, when given a uniform formula φ, produces STx (φ) and
carries out the required instantiations. Hence the ﬁrst-order correspondents of uni-
form formulas are computable.
On λ-notation
Although it is not essential to use λ-notation, it is convenient and we will apply it
in the following section. For readers unfamiliar with it, here is a quick introduction
to the fundamental ideas.
We have used Church’s λ-notation as a way of writing predicates, that is, enti-
ties which denote subsets. But lambda expressions do not denote subsets directly;
rather they denote their characteristic functions. Suppose we are working with a
frame (W, R). Let S ⊆ W . Then the characteristic function of S (with respect
to W ) is the function χS with domain W and range {0, 1} such that χS (s) = 1 if
s ∈ S and χS (s) = 0 otherwise. Reading 1 as true and 0 as false, χS is simply the
function that says truthfully of each element of W whether it belongs to S or not.
Lambda expressions pick out characteristic functions in the obvious way. For
example, when working with a frame (W, R), λu. u = u denotes the function
from W to {0, 1} that assigns 1 to every element w ∈ W that satisﬁes u = u and
0 to everything else. But for no choice of w is it the case that w = w; hence, as
we stated in the previous proof, λu. u = u denotes the characteristic function of
the empty set. Similarly, λu. u = u denotes the characteristic function of W , for
w = w for every w ∈ W .
Lambda expressions take the drudgery out of dealing with substitutions. Con-
sider the second-order formula P x. This is satisﬁed in a model if and only if the
element assigned to x belongs to the subset assigned to P . For example, if P is as-
signed the empty set, P x will be false no matter what x is assigned. Now suppose
we substitute (λu. u = u) for P in P x. This yields the expression (λu. u = u)x.
Read this as ‘apply the function denoted by λu. u = u to the state denoted by x.’
Clearly this yields the value 0 (that is, false). The process of β-conversion men-
tioned in the proof is essentially a way of rewriting such functional applications
to simpler but equivalent forms; for more details, consult one of the introductions
cited in the Notes. Newcomers to λ-notation should try Exercise 3.5.1 right away.3 Frames
156
Exercises for Section 3.5
3.5.1 Explain why we could have used the following predicate deﬁnitions in the proof of
Example 3.38: for every P occurring in ST x (φ), deﬁne
σ(P ) ≡
λu. ⊥, if ST x (φ) is positive in P ,
λu. , if ST x (φ) is negative in P .
If you have difﬁculties with this, consult one of the introductions to λ-calculus cited in the
notes before proceeding further.
3.5.2 Let φ be a modal formula which is positive in all proposition letters. Prove that φ
can be rewritten into a normal form which is built up from proposition letters, using ∧, ∨,
3 and 2 only.
3.5.3 Prove Lemma 3.37. That is, show that if a modal formula φ is positive in p, then it
is upward monotone in p, and that if it is negative in p, then it is downward monotone in p.
3.6 Sahlqvist Formulas
In the proof of Theorem 3.40 we showed that uniform formulas correspond to ﬁrst-
order conditions by ﬁnding a suitable instantiation for the universally quantiﬁed
monadic second-order variables in their second-order translation and appealing to
monotonicity. This is an important idea, and the rest of this section is devoted to
extending it: the Sahlqvist fragment is essentially a large class of formulas to which
this style of argument can be applied.
Very simple Sahlqvist formulas
Roughly speaking, Sahlqvist formulas are built up from implications φ → ψ,
where ψ is positive and φ is of a restricted form (to be speciﬁed below) from which
the required instantiations can be read off. We now deﬁne a limited version of the
Sahlqvist fragment for the basic modal language; generalizations and extensions
will be discussed shortly.
Deﬁnition 3.41 We will work in the basic modal language. A very simple Sahl-
qvist antecedent over this language is a formula built up from , ⊥ and proposi-
tion letters, using only ∧ and 3. A very simple Sahlqvist formula is an implication
φ → ψ in which ψ is positive and φ is a very simple Sahlqvist antecedent.
Examples of very simple Sahlqvist formulas include p → 3p and (p ∧ 33q) →
23(p ∧ q).
The following theorem is central for understanding what Sahlqvist correspon-
dence is all about. Its proof describes and justiﬁes an algorithm for converting very
simple Sahlqvist formulas into ﬁrst-order formulas; the algorithms given later for3.6 Sahlqvist Formulas
157
richer Sahlqvist fragments elaborate on ideas introduced here. Examples of the al-
gorithm in action are given below; it is a good idea to refer to these while studying
the proof.
Theorem 3.42 Let χ = φ → ψ be a very simple Sahlqvist formula in the basic
modal language ML(τ0 , Φ). Then χ locally corresponds to a ﬁrst-order formula
cχ (x) on frames. Moreover, cχ is effectively computable from χ.
Proof. Our starting point is the formula ∀P1 . . . ∀Pn (ST x (φ) → ST x (ψ)), which
is the local second-order translation of χ. We assume that this translation has
undergone a pre-processing step to ensure that no two quantiﬁers bind the same
variable, and no quantiﬁer binds x. Let us denote STx (ψ) by POS; that is, we
have a translation of the form:
∀P1 . . . ∀Pn (ST x (φ) → POS).
(3.9)
We will now rewrite (3.9) to a form from which we can read off the instantiations
that will yield its ﬁrst-order equivalent.
Step 1. Pull out diamonds.
Use equivalences of the form
(∃xi α(xi ) ∧ β) ↔ ∃xi (α(xi ) ∧ β),
and
(∃xi α(xi ) → β) ↔ ∀xi (α(xi ) → β),
(in that order) to move all existential quantiﬁers in the antecedent STx (φ) of (3.9)
to the front of the implication. Note that by our deﬁnition of Sahlqvist antecedents,
the existential quantiﬁers only have to cross conjunctions before they reach the
main implication. Of course, the above equivalences are not valid if the variable
xi occurs freely in β, but by our assumption on the pre-processing of the formula,
this problem does not arise.
Step 1 results in a formula of the form
∀P1 . . . ∀Pn ∀x1 . . . ∀xm (REL ∧ AT → POS),
(3.10)
where REL is a conjunction of atomic ﬁrst-order statements of the form Rxi xj cor-
responding to occurrences of diamonds, and AT is a conjunction of (translations of)
proposition letters. It may be helpful at this point to look at the concrete examples
given below.
Step 2. Read off instances.
We can assume that every unary predicate P that occurs in the consequent of the
matrix of (3.10), also occurs in the antecedent of the matrix of (3.10): otherwise
(3.10) is positive in P and we can substitute λu. u = u for P (that is, make use of158
3 Frames
the substitution used in the proof of Theorem 3.40) to obtain an equivalent formula
without occurrences of P .
Let Pi be a unary predicate occurring in (3.10), and let Pi xi1 , . . . , Pi xik be all
the occurrences of the predicate Pi in the antecedent of (3.10). Deﬁne
σ(Pi ) ≡ λu. (u = xi1 ∨ · · · ∨ u = xik ).
Note that σ(Pi ) is the minimal instance making the antecedent REL ∧ AT true; this
lambda expression says that if a node u has property Pi , then u must be one of the
nodes xi1 , xi2 , . . . , xik explicitly stated to have property Pi in the antecedent. But
this is nothing else than saying that if some model M makes the formula AT true
under some assignment, then the interpretation of the predicate P must extend the
set of points where σ(P ) holds:
M |= AT[ww1 . . . wm ] implies M |= ∀y (σ(Pi )(y) → Pi y)[ww1 . . . wm ] (3.11)
This observation, in combination with the positivity of the consequent of the Sahl-
qvist formula, forms the key to understanding why Sahlqvist formulas have ﬁrst-
order correspondents.
Step 3. Instantiating.
We now use the formulas of the form σ(Pi ) found in Step 2 as instantiations; we
substitute σ(Pi ) for each occurrence of Pi in the ﬁrst-order matrix of (3.10). This
results in a formula of the form
[σ(P1 )/P1 , . . . , σ(Pn )/Pn ]∀x1 . . . ∀xm (REL ∧ AT → POS).
Now, there are no occurrences of monadic second-order variables in REL. Further-
more, observe that by our choice of the substitution instances σ(P ), the formula
[σ(P1 )/P1 , . . . , σ(Pn )/Pn ]AT will be trivially true. So after carrying out these
substitutions we end up with a formula that is equivalent to one of the form
∀x1 . . . ∀xm (REL → [σ(P1 )/P1 , . . . , σ(Pn )/Pn ]POS).
(3.12)
As we assumed that every unary predicate occurring in the consequent of (3.10)
also occurs in its antecedent, (3.12) must be a ﬁrst-order formula involving only =
and the relation symbol R. So, to complete the proof of the theorem it sufﬁces to
show that (3.12) is equivalent to (3.10). The implication from (3.10) to (3.12) is
simply an instantiation. To prove the other implication, assume that (3.12) and the
antecedent of (3.10) are true. That is, assume that
M |= ∀x1 . . . ∀xm (REL → [σ(P1 )/P1 , . . . , σ(Pn )/Pn ]POS)
and
M |= REL ∧ AT[ww1 . . . wm ].3.6 Sahlqvist Formulas
159
We need to show that M |= POS[ww1 . . . wm ]. First of all, it follows from the
above assumptions that
M |= [σ(P1 )/P1 , . . . , σ(Pn )/Pn ]POS[ww1 . . . wm ].
As POS is positive, it is upwards monotone in all unary predicates occurring in
it, so it sufﬁces to show that M |= ∀y (σ(Pi )(y) → Pi y)[ww1 . . . wm ]. But, by
the essential observation (3.11) in Step 2, this is precisely what the assumption
M |= AT[ww1 . . . wm ] amounts to.
Example 3.43 First consider the formula p → 3p. Its second-order translation is
the formula
∀P (
P x → ∃z (Rxz ∧ P z)).
AT
There are no diamonds to be pulled out here, so we can read off the minimal in-
stance σ(P ) ≡ λu. u = x immediately. Instantiation gives
(λu. u = x)x → ∃z (Rxz ∧ (λu. u = x)z),
which (either by β-conversion or semantic reasoning) yields the following ﬁrst-
order formula.
x = x → ∃z (Rxz ∧ z = x).
Note that this is equivalent to Rxx.
Our second example is the density formula 3p → 33p, which has
∀P (∃x1 (Rxx1 ∧ P x1 ) → ∃z0 (Rxz0 ∧ ∃z1 (Rz0 z1 ∧ P z1 ))).
as its second-order translation. Here we can pull out the diamond ∃x1 :
∀P ∀x1 (Rxx1 ∧ P x1 → ∃z0 (Rxz0 ∧ ∃z1 (Rz0 z1 ∧ P z1 ))).
   
REL
AT
Instantiating with σ(P ) ≡ λu. u = x1 gives
∀x1 (Rxx1 ∧ x1 = x1 → ∃z0 (Rxz0 ∧ ∃z1 (Rz0 z1 ∧ z1 = x1 ))),
which can be simpliﬁed to ∀x1 (Rxx1 → ∃z0 (Rxz0 ∧ Rz0 x1 )).
Our last example of a very simple Sahlqvist formula is (p ∧ 33p) → 3p. Its
second-order translation is
∀P (P x ∧ ∃x1 (Rxx1 ∧ ∃x2 (Rx1 x2 ∧ P x2 )) → ∃z0 (Rxz0 ∧ P z0 )).
Pulling out the diamonds ∃x1 and ∃x2 results in
∀P ∀x1 ∀x2 (Rxx1 ∧ Rx1 x2 ∧ P x ∧ P x2 → ∃z0 (Rxz0 ∧ P z0 )).


   
REL
AT3 Frames
160
Our minimal instantiation here is: σ(P ) ≡ λu. (u = x ∨ u = x2 ). After instanti-
ating we obtain
∀x1 ∀x2 (Rxx1 ∧ Rx1 x2 ∧ (x = x ∨ x = x2 ) ∧ (x2 = x ∨ x2 = x2 ) →
∃z0 (Rxz0 ∧ (z0 = x ∨ z0 = x2 ))).
This formula simpliﬁes to ∀x1 ∀x2 (Rxx1 ∧ Rx1 x2 → (Rxx ∨ Rxx2 )).
Simple Sahlqvist formulas
What is the crucial observation we need to make about the preceding proof? Sim-
ply this: the algorithm for very simple Sahlqvist formulas worked because we were
able to ﬁnd a minimal instantiation for their antecedents. We now show that min-
imal instantiations can be found for more complex Sahlqvist antecedents. First a
motivating example.
Example 3.44 Consider the formula 31 22 p → 22 31 p; we will show that this
formula locally corresponds to a kind of local conﬂuence (or Church-Rosser) prop-
erty of R1 and R2 :
∀x1 z0 (R1 xx1 ∧ R2 xz0 → ∃z1 (R2 x1 z1 ∧ R1 z0 z1 )).
The reason for the apparently unnatural choice of variable names will soon become
clear, as will the somewhat roundabout approach to the proof that we take. The
name ‘conﬂuence’ is explained by the following picture:
ux1
*

1 

H

x u
HH
H2
H

H
1
2 H

j u
H
H uz1
j
*

z0
Let F = (W, R1 , R2 ) be a frame and w a state in F such that F, w  31 22 p →
22 31 p, and let v be a state in F such that R1 wv. A sufﬁcient condition for a
valuation to make 31 22 p true at w would be that p holds at all R2 -successors of
v. So a minimal such valuation can be deﬁned as
Vm (p) = {x ∈ W | R2 vx}.
That is, Vm makes p true at precisely the R2 -successors of v. As F, w  31 22 p →
22 31 p, we have (F, Vm ), w  22 31 p, but what does this tell us about the (ﬁrst-
order) properties of F? The crucial observation is that by the choice of Vm :
(F, Vm ), w  22 31 p iff
(F, Vm ) |= ∀z0 (R2 xz0 → ∃z1 (R2 x1 z1 ∧ R1 z0 z1 ))[wv],
(3.13)3.6 Sahlqvist Formulas
161
which yields that F |= ∀x1 z0 (R1 xx1 ∧ R2 xz0 → ∃z1 (R2 x1 z1 ∧ R1 z0 z1 ))[w].
Conversely, assume that F has the conﬂuence property at w. In order to show that
F, w  31 22 p → 22 31 p, let V be a valuation on F such that (F, V ), w  31 22 p.
We have to prove that w  22 31 p. By the truth deﬁnition of 31 , w has an R1 -
successor v satisfying v  22 p. Now we use the minimal valuation Vm again; ﬁrst
note that by the deﬁnition of Vm , we have Vm (p) ⊆ V (p). Therefore, Lemma 3.37
ensures that it sufﬁces to show that 22 31 p holds at w under the valuation Vm . But
this is immediate by the assumption that F is conﬂuent and (3.13).
This example inspires the following deﬁnitions:
Deﬁnition 3.45 Let τ be a modal similarity type. A boxed atom is a formula of the
form 2i1 · · · 2ik p (k ≥ 0), where 2i1 , . . . , 2ik are (not necessarily distinct) boxes
of the language. In the case where k = 0, the boxed atom 2i1 · · · 2ik p is just the
proposition letter p.
Convention 3.46 In the sequel, it will be convenient to treat sequences of boxes
as single boxes. We will therefore denote the formula 2i1 · · · 2ik p by 2β p, where
β is the sequence i1 . . . ik of indices. Analogously, we will pretend to have a
corresponding binary relation symbol Rβ in the frame language L1τ . Thus the
expression Rβ xy abbreviates the formula
∃y1 (Ri1 xy1 ∧ ∃y2 (Ri2 y1 y2 ∧ · · · ∧ ∃yk−1 (Rik−1 yk−2 yk−1 ∧ Rik yk−1 y) . . .)).
Note that this convention allows us to write the second-order translation of the
boxed atom 2β p as ∀y (Rβ xy → P y).
If k = 0, β is the empty sequence ; in this case the formula R xy should be read
as x = y. Note that the second-order translation of 2 p (that is, of the proposition
letter p) can indeed be written as ∀y (R xy → P y).
Deﬁnition 3.47 Let τ be a modal similarity type. A simple Sahlqvist antecedent
over this similarity type is a formula built up from , ⊥ and boxed atoms, using
only ∧ and existential modal operators (3 and ). A simple Sahlqvist formula is
an implication φ → ψ in which ψ is positive (as before) and φ is a simple Sahlqvist
antecedent.
Example 3.48 Typical examples of simple Sahlqvist formulas are 3p → 33p,
2p → 22p, 21 22 p → 23 p, 31 22 p → 22 31 p and (21 22 p)(33 p∧22 21 q) →
33 (qp).
Typically forbidden in a simple Sahlqvist antecedent are:
(i) boxes over disjunctions, as in H(r ∨ F q) → G(P r ∧ P q),
(ii) boxes over diamonds, as in 23p → 32p,3 Frames
162
(iii) dual-triangled atoms, as in p  p → p.
Theorem 3.49 Let τ be a modal similarity type, and let χ = φ → ψ be a simple
Sahlqvist formula over τ . Then χ locally corresponds to a ﬁrst-order formula cχ (x)
on frames. Moreover, cχ is effectively computable from χ.
Proof. The proof of this theorem is an adaptation of the proof of Theorem 3.42.
Consider the universally quantiﬁed second-order transcription of χ:
∀P1 . . . ∀Pn (ST x (φ) → ST x (ψ)).
(3.14)
Again, we ﬁrst make sure that no two quantiﬁers bind the same variable, and that
no quantiﬁer binds x. As before, the idea of the algorithm is to rewrite (3.14) to a
formula from which we can easily read off instantiations which yield a ﬁrst-order
equivalent of (3.14).
Step 1. Pull out diamonds.
This is the same as before. This process results in a formula of the form
∀P1 . . . ∀Pn ∀x1 . . . ∀xm (REL ∧ BOX-AT → ST x (ψ)),
(3.15)
where REL is a conjunction of atomic ﬁrst-order statements of the form Rxi xj cor-
responding to occurrences of diamonds, and BOX-AT is a conjunction of (transla-
tions of) boxed atoms, that is, formulas of the form ∀y (Rβ xi y → P y).
Step 2. Read off instances.
Let P be a unary predicate occurring in (3.15), and let π1 (xi1 ), . . . , πk (xik ) be
all the (translations of the) boxed atoms in the antecedent of (3.10) in which the
predicate P occurs. Observe that every πj is of the form ∀y (Rβj xij y → P y),
where βj is a sequence of diamond indices (recall Convention 3.46). Deﬁne
σ(P ) ≡ λu. (Rβ1 xi1 u ∨ · · · ∨ Rβk xik u).
Again, σ(P1 ), . . . , σ(Pn ) form the minimal instances making the antecedent REL∧
BOX-AT true.
The remainder of the proof is the same as the proof of Theorem 3.42, with the
proviso that all occurrences of ‘AT’ should be replaced by ‘BOX-AT’.
As in the case of very simple Sahlqvist formulas, the algorithm is best understood
by inspecting some examples:
Example 3.50 Let us investigate some of the formulas given in Example 3.48. The
simple Sahlqvist formula 21 22 p → 23 p has the following second-order transla-
tion:
∀P (∀y (R12 xy → P y) → ∀z (R3 xz → P z)).



BOX-AT3.6 Sahlqvist Formulas
163
There are no diamonds to be pulled out here, so we can read off the required sub-
stitution instance σ(P ) ≡ λu. R12 xu immediately. Carrying out the substitution
we obtain
∀y (R12 xy → R12 xy) → ∀z (R3 xz → R12 xz),
which is equivalent to ∀z (R3 xz → R12 xz).
Next we consider the conﬂuence formula 31 22 p → 22 31 p, whose second-
order translation is
∀P (∃x1 (R1 xx1 ∧ ∀y (R2 x1 y → P y)) → ∀z0 (R2 xz0 → ∃z1 (R1 z0 z1 ∧ P z1 ))).
Pulling out the existential quantiﬁcation ∃x1 yields
∀P ∀x1 (R1 xx1 ∧ ∀y (R2 x1 y → P y) → ∀z0 (R2 xz0 → ∃z1 (R1 z0 z1 ∧ P z1 ))).
   


REL
BOX-AT
The minimal instance making BOX-AT true is σ(P ) ≡ λu. R2 x1 u. After instanti-
ating we obtain
∀x1 (R1 xx1 ∧∀y (R2 x1 y → R2 x1 y) → ∀z0 (R2 xz0 → ∃z1 (R1 z0 z1 ∧R2 x1 z1 ))),
which can be simpliﬁed to
∀x1 ∀z0 (R1 xx1 ∧ R2 xz0 → ∃z1 (R1 z0 z1 ∧ R2 x1 z1 )).
As our ﬁnal example, let us treat a formula using a dyadic modality :
(21 22 p)(33 p ∧ 22 21 q) → 33 (qp).
We use a ternary relation symbol T for the triangle . Its second-order translation
is the rather formidable looking
∀P ∀Q (∃x1 x2 (T xx1 x2 ∧ ∀y (R12 x1 y → P y) ∧
∃x3 (R3 x2 x3 ∧ P x3 ) ∧ ∀y (R21 x2 y → Qy))
→ ∃z (R3 xz ∧ ∃z1 z2 (T zz1 z2 ∧ Qz1 ∧ P z2 ))),
from which we can pull out the diamonds ∃x1 , ∃x2 and ∃x3 . This leads to
REL



∀P ∀Q∀x1 x2 ∀x3 (T xx1 x2 ∧ R3 x2 x3 ∧
BOX−AT



∀y (R12 x1 y → P y) ∧ P x3 ∧ ∀y (R21 x2 y → Qy) →
∃z (R3 xz ∧ ∃z1 z2 (T zz1 z2 ∧ Qz1 ∧ P z2 ))).
Now we can easily read off the required instantiations:
σ(P ) ≡ λu. (R12 x1 u ∨ u = x3 ),
σ(Q) ≡ λu. (R21 x2 u).3 Frames
164
Performing the substitution [σ(P )/P, σ(Q)/Q] and deleting the tautological parts
from the antecedent gives
∀x1 x2 ∀x3 (T xx1 x2 ∧ R3 x2 x3 →
∃z (R3 xz ∧ ∃z1 z2 (T zz1 z2 ∧ R21 x2 z1 ∧ (R12 x1 z2 ∨ z2 = x3 ))).
Sahlqvist formulas
We are now ready to introduce the full Sahlqvist fragment and the full version of
the Sahlqvist-van Benthem algorithm.
Deﬁnition 3.51 Let τ be a modal similarity type. A Sahlqvist antecedent over τ is
a formula built up from , ⊥, boxed atoms, and negative formulas, using ∧, ∨ and
existential modal operators (3 and ). A Sahlqvist implication is an implication
φ → ψ in which ψ is positive and φ is a Sahlqvist antecedent.
A Sahlqvist formula is a formula that is built up from Sahlqvist implications by
freely applying boxes and conjunctions, and by applying disjunctions only between
formulas that do not share any proposition letters.
Example 3.52 Both simple and very simple Sahlqvist formulas are examples of
Sahlqvist formulas, as are (p → 3p), p ∧ 3¬p → 3p, and (31 2 p →
2 31 p) ∧ 1 (p → 32 p). As with simple Sahlqvist formulas, typically forbidden
combinations in Sahlqvist antecedent are ‘boxes over disjunctions,’ ‘boxes over di-
amonds,’ and ‘dual-triangled atoms’ as in p  p → p (see Example 3.48).
The following lemma is instrumental in reducing the correspondence problem for
arbitrary Sahlqvist formulas, ﬁrst to that of Sahlqvist implications, and then to that
of simple Sahlqvist formulas.
Lemma 3.53 Let τ be a modal similarity type, and let φ and ψ be τ -formulas.
(i) If φ and α(x) are local correspondents, then so are β φ and ∀y (Rβ xy →
[y/x]α).
(ii) If φ (locally) corresponds to α, and ψ (locally) corresponds to β, then φ∧ψ
(locally) corresponds to α ∧ β.
(iii) If φ locally corresponds to α, ψ locally corresponds to β, and φ and ψ have
no proposition letters in common, then φ ∨ ψ locally corresponds to α ∨ β.
Proof. Left as Exercise 3.6.3.
The local perspective in parts one and three of the lemma is essential. For instance,
one can ﬁnd a modal formula φ that globally corresponds to a ﬁrst-order condition
∀x α(x) without 2φ globally corresponding to the formula ∀x∀y (Rxy → α(y));
see Exercise 3.6.3.3.6 Sahlqvist Formulas
165
Theorem 3.54 Let τ be a modal similarity type, and let χ be a Sahlqvist formula
over τ . Then χ locally corresponds to a ﬁrst-order formula cχ (x) on frames. More-
over, cχ is effectively computable from χ.
Proof. The proof of the theorem is virtually the same as the proof of Theorem 3.49,
with the exception of the use of Lemma 3.53 and of the fact that we have to do some
pre-processing of the formula χ.
By Lemma 3.53 it sufﬁces to show that the theorem holds for all Sahlqvist im-
plications. So assume that χ has the form φ → ψ where φ is a Sahlqvist antecedent
and ψ a positive formula. Proceed as follows.
Step 1. Pull out diamonds and pre-process.
Using the same strategy as in the proof of Theorem 3.49 together with equivalences
of the form
((α ∨ β) → γ) ↔ ( (α → γ) ∧ (β → γ) )
and
∀ . . . (α ∧ β) ↔ ( ∀ . . . α ∧ ∀ . . . β ),
we can rewrite the second-order translation of φ → ψ into a conjunction of formu-
las of the form
∀P1 . . . ∀Pn ∀x1 . . . ∀xm (REL ∧ BOX-AT ∧ NEG → ST x (ψ)),
(3.16)
where REL is a conjunction of atomic ﬁrst-order statements of the form Rx cor-
responding to occurrences of diamonds and triangles, BOX-AT is a conjunction of
(translations of) boxed atoms, and NEG is a conjunction of (translations of) neg-
ative formulas. By Lemma 3.53(ii) it sufﬁces to show that each formula of the
form displayed in (3.16) has a ﬁrst-order equivalent. This is done by using the
equivalence
(α ∧ NEG → β) ↔ (α → β ∨ ¬NEG),
where ¬NEG is the positive formula that arises by negating the negative formula
NEG. Using this equivalence we can rewrite (3.16) to obtain a formula of the form
∀P1 . . . ∀Pn ∀x1 . . . ∀xm (REL ∧ BOX-AT → POS),
and from here on we can proceed as in Step 2 of the proof of Theorem 3.49.
Example 3.55 By way of example we determine the local ﬁrst-order correspon-
dents of two of the modal formulas given in Example 3.52. To determine the
ﬁrst-order correspondent of the Sahlqvist formula (p → 3p) we ﬁrst recall that
the local ﬁrst-order correspondent of p → 3p is Rxx. So, by Lemma 3.53(i)
(p → 3p) locally corresponds to ∀y (Rxy → Ryy).3 Frames
166
Next we consider the Sahlqvist formula (p ∧ 3¬p) → 3p. Its translation is
∀P (P x ∧ ∃y (Rxy ∧ ¬P y) → ∃z (Rxz ∧ P z)).
Pulling out the diamond produces
∀P ∀y ( P x ∧ Rxy ∧ ¬P y → ∃z (Rxz ∧ P z)),
  



BOX-AT
REL
NEG
POS
and moving the negative part ¬P y to the consequent we get
∀P ∀y ( P x ∧ Rxy → P y ∨ ∃z (Rxz ∧ P z)).
 



BOX-AT
REL
POS
The minimal instantiation to make P x true is λu. u = x. After instantiation we
obtain
∀y (Rxy → y = x ∨ ∃z (Rxz ∧ z = x)),
which can be simpliﬁed to ∀y (Rxy ∧ x = y → Rxx).
Exercises for Section 3.6
3.6.1 Compute the ﬁrst-order formulas locally corresponding to the following Sahlqvist
formulas:
(a) 31 32 p → 32 31 p,
(b) (p ∧ 2p ∧ 22p) → 3p,
(c) 3k 2l p → 2m 3n p, for arbitrary natural numbers k, l, m and n,
(d) (2p)(2p) → pp,
(e) 3(¬p ∧ 3(p ∧ q)) → 3(p ∧ q),
(f) 2((p ∧ 2¬p ∧ q) → 3q)).
(a) Show that the formula 2(p ∨ q) → 3(2p ∨ 2q) does not locally correspond
to a ﬁrst-order formula on frames. (Hint: modify the frame of Example 3.11.)
(b) Use this example to show that dual-triangled atoms cannot be allowed in Sahlqvist
antecedents.
3.6.2
3.6.3 Prove Lemma 3.53:
(a) Show that if φ and α(x) locally correspond, so do  β φ and ∀y (Rβ xy → α(y)).
(b) Prove that if φ (locally) corresponds to α(x), and ψ (locally) corresponds to β(x),
then φ ∧ ψ (locally) corresponds to α(x) ∧ β(x).
(c) Show that if φ locally corresponds to α(x), ψ locally corresponds to β(x), and φ
and ψ have no proposition letters in common, then φ ∨ ψ locally corresponds to
α(x) ∨ β(x).
(d) Prove that (a) and (c) do not hold for global correspondence, and that the condition
on the proposition letters in (c) is necessary as well. (Hint: for (a), think of the
modal formula 33p → 3p and the ﬁrst-order formula ∀xyz (Ryz ∧ Rzx →
Ryx).)3.7 More about Sahlqvist Formulas
167
3.7 More about Sahlqvist Formulas
It is time to step back and think more systematically about the Sahlqvist fragment,
for a number of questions need addressing. For a start, does this fragment con-
tain all modal formulas with ﬁrst-order correspondents? And why did we forbid
disjunctions in the scope of boxes, and occurrences of nested duals of triangles
in Sahlqvist antecedents, while we allowed boxed atoms? Most interesting of all,
which ﬁrst-order conditions are expressible by means of Sahlqvist formulas? That
is, is it possible to prove some sort of converse to the Sahlqvist Correspondence
Theorem?
Limitative results
To set the stage for our discussion, we ﬁrst state (without proof) the principal limi-
tative result in this area: Chagrova’s Theorem. Good presentations of the proof are
available in the literature; see the Notes for references.
Theorem 3.56 (Chagrova’s Theorem) It is undecidable whether an arbitrary ba-
sic modal formula has a ﬁrst-order correspondent.
This implies that, even for the basic modal language, it is not possible to write
a computer program which, when presented with an arbitrary modal formula as
input, will terminate after ﬁnitely many steps, returning the required ﬁrst-order
correspondent (if there is one) or saying ‘No!’ (if there is not).
Quite apart from its intrinsic interest, this result immediately tells us that the
Sahlqvist fragment cannot possibly contain all modal formulas with ﬁrst-order cor-
respondents. For it is straightforward to decide whether a modal formula is a Sahl-
qvist formula, and to compute the ﬁrst-order correspondents of Sahlqvist formulas.
Hence if all modal formulas with ﬁrst-order correspondents were Sahlqvist, this
would contradict Chagrova’s Theorem.
But a further question immediately presents itself: is every modal formula with
a ﬁrst-order correspondent equivalent to a Sahlqvist formula? (The preceding ar-
gument does not rule this out.) The answer is no: there are modal formulas corre-
sponding to ﬁrst-order frame conditions which are not equivalent to any Sahlqvist
formula.
Example 3.57 Consider the conjunction of the following two formulas:
(M)
(4)
3p → 3p,
33q → 3q.
(M) is the McKinsey formula we discussed in Example 3.11, and (4) is the transitiv-
ity axiom. It is obvious that M itself is not a Sahlqvist axiom, and by Example 3.11
it does not express a ﬁrst-order condition.168
3 Frames
It requires a little argument to show that the conjunction M ∧ 4 is not equivalent
to a Sahlqvist formula. One way to do so is by proving that M ∧ 4 does not have a
local ﬁrst-order correspondent (cf. Exercise 3.7.1).
Nevertheless, the conjunction M∧4 does have a global ﬁrst-order correspondent,
as we can prove the following equivalence for all transitive frames F:
F  M iff F |= ∀x∃y (Rxy ∧ ∀z (Ryz → z = y)).
(3.17)
We leave the right to left direction as an exercise to the reader. To prove the other
direction, assume for contradiction that there is a transitive frame F = (W, R) on
which the McKinsey formula is valid, but which does not satisfy the ﬁrst-order
formula given in (3.17). Let r be a state witnessing that the ﬁrst-order formula
in (3.17) does not hold in F. That is, assume that each successor s of r has a
successor distinct from it. We may assume that the frame is generated from r, so
that F |= ∀y∃z (Ryz ∧ y = z).
In order to derive a contradiction from this, we need to introduce some terminol-
ogy. Call a subset X of W coﬁnal in W if for all w ∈ W there is an x ∈ X such
that Rwx. We now claim that
W has a subset X such that both X and W \ X are coﬁnal in W .
(3.18)
From (3.18) we can immediately derive a contradiction by considering the valua-
tion V given by V (p) = X. For, coﬁnality of X implies that (F, V ), r  23p,
while coﬁnality of W \ X likewise gives (F, V ), r  23¬p. But then (F, V ), r 
M.
To prove (3.18), consider the collection C of all pairs of disjoint non-empty
subsets Y , Z ⊂ W satisfying ∀y ∈ Y ∃z ∈ Z Ryz and ∀z ∈ Z∃y ∈ Y Rzy.
We ﬁrst prove that this collection is non-empty. From F |= ∀y∃z (Ryz ∧ y = z)
it follows that there is a path w0 Rw1 Rw2 R . . . such that wi = wi+1 for all i.
Let n be the ﬁrst index such that wn ∈ {w0 , . . . , wn−1 }, or n = ω if there is
no such index. It is then an easy exercise to verify that the pair consisting of
Y0 := {w2i | 2i < n} and Y1 := {w2i+1 | 2i + 1 < n} belongs to C.
Order C under coordinate-wise inclusion. It is obvious that every chain in this
partial ordering is bounded above; hence, we may apply Zorn’s Lemma and obtain
a maximal such pair Z0 , Z1 . We claim that
Z0 ∪ Z1 = W.
(3.19)
Since Z0 and Z1 are disjoint, this implies that Z1 = W \ Z0 and thus proves (3.18).
Suppose that (3.19) does not hold. Then there is an element w ∈ W which
belongs neither to Z0 nor to Z1 . If w has successor in Z0 ∪ Z1 then (by transitivity
of R) the pair (Z0 ∪ {w}, Z1 ) would belong to C, contradicting the maximality
of (Z0 , Z1 ) in the ordering of C. But if w has no successor in Z0 ∪ Z1 then by
transitivity of R, the subframe Fw of F is disjoint from Z0 ∪ Z1 . With the argument3.7 More about Sahlqvist Formulas
169
used above to show that C = ∅ we can construct a pair (Y0 , Y1 ) ∈ C such that Y0
and Y1 fall entirely within Fw , and thus satisfy (Y0 ∪ Y1 ) ∩ (Z0 ∪ Z1 ) = ∅. It is
then straightforward to check that the pair (Y0 ∪ Y1 , Z0 ∪ Z1 ) belongs to C; but this
membership would contradict the maximality of (Z0 , Z1 ). This proves (3.19).
Of course, this example begs the question whether there is a modal formula that
locally corresponds to a ﬁrst-order formula without being equivalent to a Sahlqvist
formula. However, the answer to this is also afﬁrmative: the formula 2M ∧ 4 is an
example. In Exercise 3.7.1 the reader is asked to show that it has a local ﬁrst-order
correspondent; in Chapter 5 we will develop the techniques needed to prove that
the formula is not equivalent to a Sahlqvist formula, see Exercise 5.6.2.
Thus the Sahlqvist fragment does not contain all modal formulas with ﬁrst-order
correspondents. So the next question is: can the Sahlqvist fragment be further
extended? The answer is yes – but we should reﬂect a little on what we hope
to achieve through such extensions. The Sahlqvist fragment is essentially a good
compromise between the demands of generality and simplicity. By adding further
restrictions it is possible to extend it further, but it is not obvious that the resulting
loss of simplicity is really worth it. Moreover, the Sahlqvist fragment also gives
rise to a matching completeness theorem; we would like proposed extensions to do
so as well. We do not know of simple generalizations of the Sahlqvist fragment
which manage to do this. In short, while there is certainly room for experiment
here, it is unclear whether anything interesting is likely to emerge.
However, one point is worth stressing once more: the Sahlqvist fragment cannot
be further extended simply by dropping some of the restrictions in the deﬁnition
of a Sahlqvist formula. We forbid disjunctions in the scope of boxes and nested
duals of triangles in Sahlqvist antecedents for a very good reason: these forbidden
combinations easily lead to modal formulas that have no ﬁrst-order correspondent,
as we have seen in Example 3.11 and Exercise 3.6.2.
Kracht’s Theorem
Let us turn to a nice positive result. As has already been mentioned, not only
does each Sahlqvist formula deﬁne a ﬁrst-order class of frames, but when we use
one as an axiom in a normal modal logic, that logic is guaranteed to be complete
with respect to the elementary class of frames the axiom deﬁnes. (This is the
content of the Sahlqvist Completeness Theorem; see Theorem 4.42 for a precise
statement.) So it would be very pleasant to know which ﬁrst-order conditions are
the correspondents of Sahlqvist formulas. Kracht’s Theorem is a sort of converse
to the Sahlqvist Correspondence Theorem which gives us this information.
Before we can deﬁne the fragment of ﬁrst-order logic corresponding to Sahl-
qvist formulas we need some auxiliary deﬁnitions; we also introduce some helpful170
3 Frames
notation. For reasons of notational simplicity, we work in the basic modal similar-
ity type. First of all, we will abbreviate the ﬁrst-order formula ∀y (Rxy → α(y))
to (∀yx)α(y), speaking of restricted quantiﬁcation and calling x the restrictor
of y. Likewise ∃y (Rxy ∧ α(y)) is abbreviated to (∃yx)α(y). We will call the
constructs (∀yx) and (∃yx) restricted quantiﬁers. If we wish not to specify
the restrictor of a restricted quantiﬁer we will write ∀r y or ∃r y. Moreover, if we
do not wish to specify whether a quantiﬁer is existential or universal we denote it
by Q (Qr in the restricted case). Second, for the duration of this subsection it will
be convenient for us to consider formulas of the form u = u as atomic. Third, in
this subsection we will work exclusively with formulas in which no variable occurs
both free and bound, and in which no two distinct (occurrences of) quantiﬁers bind
the same variable; we will call such formulas clean.
Now we call a formula restrictedly positive if it is built up from atomic formu-
las, using ∧, ∨ and restricted quantiﬁers only; observe that monadic predicates oc-
cur positively in restrictedly positive formulas. Finally, we assume that the reader
knows how to rewrite an arbitrary positive propositional formula to a disjunctive
normal form or DNF (that is, to an equivalent disjunction of conjunctions of atomic
formulas) and to a conjunctive normal form or CNF (that is, to an equivalent con-
junction of disjunctions of atomic formulas).
The crucial notion in this subsection is that of a variable occurring inherently
universally in a ﬁrst-order formula.
Deﬁnition 3.58 We say that an occurrence of the variable y in the (clean!) formula
α is inherently universal if either y is free, or else y is bound by a restricted quan-
tiﬁer of the form (∀yx)β which is not in the scope of an existential quantiﬁer.
A formula α(x) in the basic ﬁrst-order frame language is called a Kracht formula
if α is clean, restrictedly positive and, furthermore, every atomic formula is either
of the form u = u or u = u, or else it contains at least one inherently universal
variable.
Restricted quantiﬁcation is obviously the modal face of quantiﬁcation in ﬁrst-order
logic; indeed, we could have deﬁned the standard translation of a modal formula
using this notion. As for Kracht formulas, ﬁrst observe that every universal re-
stricted ﬁrst-order formula satisﬁes the deﬁnition. A second example of a Kracht
formula is (∀wv)(∀xv)(∃yw)Rxy: note that it does not matter that the ‘x’
in Rxy falls within the scope of an existential quantiﬁer; what matters is that the
universal quantiﬁer that binds x does not occur within the scope of any existen-
tial quantiﬁcation. On the other hand, the formula (∃wv)(∀xv)w = x is not
a Kracht formula since the occurrence of neither w nor x in w = x is inherently
universal: w is disqualiﬁed because it is bound by an existential quantiﬁer and x
because it is bound within the scope of the existential quantiﬁer (∃wv).3.7 More about Sahlqvist Formulas
171
The following result states that Kracht formulas are the ﬁrst-order counterparts
of Sahlqvist formulas – but not only that. As will become apparent from its proof,
from a given Kracht formula we can compute a Sahlqvist formula locally corre-
sponding to it. The reader is advised to glance at the examples provided below
while reading the proof.
Theorem 3.59 Any Sahlqvist formula locally corresponds to a Kracht formula;
and conversely, every Kracht formula is a local ﬁrst-order correspondent of some
Sahlqvist formula which can be effectively obtained from the Kracht formula.
Proof. For the left to right direction, we leave it as an exercise to the reader to show
that the algorithm discussed in the sections 3.5 and 3.6 in fact produces, given a
Sahlqvist formula, a ﬁrst-order correspondent within the Kracht fragment. We will
give the proof of the other direction: we will show how rewrite a given Kracht
formula to an equivalent Sahlqvist formula.
Our ﬁrst step is to provide special prenex formulas as normal forms for Kracht
formulas. Deﬁne a type 1 formula to be of the form
∀r x1 . . . ∀r xn Qr1 y1 . . . Qrm ym β(x0 , . . . , xn , y1 , . . . , ym )
such that n, m ≥ 0 and each variable is restricted by an earlier variable (that is, the
restrictor of any xi is some xj with j < i and the restrictor of any yi is either some
xk or some yj with j < i. Furthermore we require that β is a DNF of formulas
u = u, u = u, Rux, u = x and Rxu (that is, we allow all atomic formulas that are
not of the form Ryy or y = y  ). Here and in the remainder of this proof we use
the convention that u and z denote arbitrary variables in {x0 , . . . , xn , y1 , . . . , ym }
and x an arbitrary variable in {x0 , . . . , xn }.
Clearly then, type 1 formulas form a special class of Kracht formulas. This
inclusion is not proper (modulo equivalence), since we can prove the following
claim.
Claim 1 Every Kracht formula can be effectively rewritten into an equivalent type
1 formula.
Proof of Claim. Let α(x0 ) be a Kracht formula. By deﬁnition it is built up from
atomic formulas using ∧, ∨ and restricted quantiﬁers. Furthermore, since α(x0 ) is
clean, in a subformula of the form Qr v β the variable v may not occur outside of
β. Hence, we may use the equivalences
(Qr v β) ♥ γ ↔ Qr v (β ♥ γ)
(3.20)
(where ♥ uniformly denotes either ∧ or ∨) to pull out quantiﬁers to the front.
However, if we want to remain within the Kracht fragment we have to take care
about the order in which we pull out quantiﬁers.172
3 Frames
Without loss of generality we may assume that each inherently universal variable
is named xi for some i, while each of the remaining variables is named yj for some
j. This ensures that no atomic subformula of α(x0 ) is of the form Ryy or y = y 
(with distinct variables y and y ).
Observe also that in every subformula of the form ((∀xu)β)♥γ, the variable
u occurs free. If this u is not the variable x0 then it is a bound variable of α; hence,
the mentioned subformula must occur in the scope of a quantiﬁer (Qr u  x ). This
quantiﬁcation must have been universal, for, otherwise, the variable x could not
have been among the inherently universal ones. But this means that the variable
u itself must be inherently universal as well, so u is some xi . This shows that
by successively pulling out restricted universal quantiﬁers ∀r x we end up with a
Kracht formula of the form
∀r x1 . . . ∀r xn α (x0 , . . . , xn , y1 , . . . , ym ),
such that each atomic formula of α is of the form u = u or u = u, or else it
contains some occurrence of a variable xi . Furthermore, the restrictor of each xi is
some xj with j < i.
It remains to pull out the other restricted quantiﬁers from α . But this can easily
be done using the equivalences of (3.20), since we do not have to worry anymore
about the order in which we pull out the quantiﬁers. In the end, we arrive at a
formula of the form
∀r x1 . . . ∀r xn Qr1 y1 . . . Qrm ym α (x0 , . . . , xn , y1 , . . . , ym )
such that the atomic subformulas of α satisfy the same condition of those in α
(in fact, they are the very same formulas), while in addition, α is quantiﬁer free.
Hence, if we rewrite α into disjunctive normal form, we are ﬁnished.
Enter diamonds and boxes. A type 2 formula is a formula in the second-order frame
language of the form
⎛
⎞

˜ 0 . . . ∀P
˜ 0 . . . ∀Q
˜ n ∀Q
˜ n ∀ r x1 . . . ∀ r xn ⎝
∀P
ST xi (σi ) → β ⎠
0≤i≤n
such that each σi is a conjunction of boxed atoms in pi and qi , whereas β is a DNF
of formulas ST x (ψ), with ψ some modal formula which is positive in each pi , qj .
Claim 2 Every type 1 formula can be effectively rewritten into an equivalent type
2 formula.
Proof of Claim. Now the prominent role of the inherently universal formulas will
come out: they determine the proposition letters of the Sahlqvist formula and the3.7 More about Sahlqvist Formulas
173
‘BOX-AT’ part of its antecedent. Consider the type 1 formula
∀r x1 . . . ∀r xn Qr1 y1 . . . Qrm ym β(x0 , . . . , xn , y1 , . . . , ym ).
We abbreviate the sequence ∀r x1 . . . ∀r xn by ∀r x̄, and use similar abbreviations for
other sequences of quantiﬁers. Recall that β is a DNF of formulas u = u, u = u,
u = xi , Ruxi and Rxi u. Our ﬁrst move is to replace such subformulas with the
formulas ST u (), ST u (⊥), ST u (pi ), ST u (3pi ) and ST u (qi ), respectively; call
the resulting formula β .
Our ﬁrst claim is that
∀r x̄ Qr ȳ β is equivalent to
⎞
⎛

˜P̄ Q̄ ∀r x̄ ⎝
∀
ST xi (pi ∧ 2qi ) → Qr ȳ β  ⎠ .
(3.21)
0≤i≤n
Forbidding as (3.21) may look, its proof is completely analogous to proofs in Sec-
tions 3.5 and 3.6: the direction from right to left is immediate by instantiation,
while the other direction simply follows from the fact that β is monotone in each
predicate symbol Pi and Qi .
Two remarks are in order here. First, since β may contain atomic formulas of the
form Rxi xj and xi = xj (that is, with both variables being inherently universal),
there is some choice here. For instance, the formula Rxi xj may be replaced with
either ST xi (3pj ) or with ST xj (qj ). Having this choice can sometimes be of use if
one wants to ﬁnd Sahlqvist correspondents satisfying some additional constraints.
Related to this is our second remark: we do not need to introduce both proposi-
tion letters pi and qi for each xi . We can do with any supply of proposition letters
that is sufﬁcient to replace all atomic formulas of β with the standard translation of
either ST u (pi ), ST u (3pi ) or ST u (qi ). A glance at the examples below will make
this point clear.
We are now halfway through the proof of Claim 2: observe that β is already a
DNF of formulas ST u (ψ) with ψ positive in each pi , qj . It remains to eliminate
the quantiﬁer sequence Qr ȳ. This will be done step by step, using the following
procedure:
Consider the formula
⎛
⎞

(∃yi+1 z) ⎝
ST ukl (ψkl )⎠ ,
(3.22)
k≤K l≤Lk
where each modal formula ψkl is positive in all variables pi , qj ; z is either an x or
a yj with j ≤ i; and each u is either an x or a yj with j ≤ i + 1. We ﬁrst distribute3 Frames
174
the existential quantiﬁer over the disjunction, yielding a disjunction of formulas

(∃yi+1 z)
ST ukl (ψkl ).
(3.23)
l≤Lk
We may assume all these variables u to be distinct (otherwise, replace STu (ψ  ) ∧
ST u (ψ  ) with ST u (ψ  ∧ ψ  )); we may also assume that yi+1 is the variable ulLk
(if yi+1 does not occur among the us, add a conjunct STyi+1 ()). But then (3.23)
is equivalent to the formula

ST z (3ψkLk ) ∧
ST ukl (ψkl ),
l<Lk
whence (3.22) is equivalent to a disjunction of such formulas. Observe further that
yi+1 does not occur in these formulas.
This shows how to get rid of an existential innermost restricted quantiﬁer of the
prenex K r ȳ. A universal innermost restricted quantiﬁer can be removed dually, by
ﬁrst converting the matrix β into a conjunctive normal form; details are left to the
reader. In any case, it will be clear that by this procedure we can rewrite any type
1 formula into an equivalent type 2 formula.
We are now almost through with the proof of Theorem 3.59. All we have to do
now is show how to massage arbitrary type 2 formulas into Sahlqvist shape.
Claim 3 Any type 2 formula can be effectively rewritten into an equivalent Sahl-
qvist formula.
Proof of Claim. Let
⎛
˜P̄ Q̄ ∀r x̄ ⎝
∀

⎞
ST xi (σi ) → β ⎠
(3.24)
0≤i≤n
be an arbitrary type 2 formula.
First we rewrite β into conjunctive normal form, and we distribute the implica-
tion and the prenex of universal quantiﬁers over the conjunctions. Thus we obtain
a conjunction of formulas of the form
⎞
⎛

˜P̄ Q̄∀r x̄ ⎝
∀
(3.25)
ST xi (σi ) → β  ⎠ ,
0≤i≤n
where β  is a disjunction of formulas of the form STx (ψ) with each ψ positive in
all pi and qj . As before, we may assume that each xi occurs in exactly one disjunct3.7 More about Sahlqvist Formulas
of β  , so (3.25) is equivalent to a formula
⎛

˜P̄ Q̄ ∀r x̄ ⎝
∀
ST xi (σi ) →
0≤i≤n
175
⎞
ST xi (ψi )⎠ ,
0≤i≤n
where each σi is a Sahlqvist antecedent and each ψi is positive. But clearly then,
(3.25) is equivalent to the formula

˜P̄ Q̄¬∃r x̄
∀
ST xi (σi ∧ ¬ψi ).
0≤i≤n
Observe that each modal formula σi ∧ ¬ψi is a Sahlqvist antecedent.
But now, as before, working inside out we may eliminate all remaining restricted
quantiﬁers, step by step. For, observe that the formula

∃r x1 . . . ∃r xk−1 (∃xk xj )
ST xi (χi )
0≤i≤k
is equivalent to
⎛
∃r x1 . . . ∃r xk−1 ⎝ST xj (χj ∧ 3χk ) ∧

⎞
ST xi (χi )⎠ .
0≤i<k,i=j
Note that χj ∧ 3χk+1 is a Sahlqvist antecedent if χj and χk+1 are.
It turns out that for some Sahlqvist antecedent φ, (3.25) is equivalent to the
second-order formula
˜P̄ Q̄ ¬ST x (φ).
∀
0
But then (3.24) is equivalent to a conjunction of such formulas, and thus equivalent
to a formula


˜P̄ Q̄ ST x
∀
0
φl → ⊥ ,
l
which is the local second-order frame correspondent of the formula
which is obviously in Sahlqvist form.

l φl → ⊥,
This completes the proof of the third claim, and hence of the theorem.
Example 3.60 Consider the formula
α(x0 ) ≡ (∀x1 x0 )(∃y1 x0 )(∃y2 y1 ) Rx1 y2 .
This is already a type 1 Kracht formula, so we proceed by the procedure described
in the proof of Claim 2 in the proof of Theorem 3.59. According to (3.21), α(x0 )
is equivalent to the second order formula
˜ 1 (∀x1 x0 ) (ST x (2q1 ) → (∃y1 x0 )(∃y2 y1 )ST y (q1 )).
∀Q
1
23 Frames
176
Then, using the equivalences described further on in the proof of Claim 2 we obtain
the following sequences of formulas that are equivalent to α(x0 ):
˜ 1 (∀x1 x0 ) (ST x (2q1 ) → (∃y1 x0 )(∃y2 y1 )ST y (q1 ))
∀Q
1
2
˜ 1 (∀x1 x0 ) (ST x (2q1 ) → (∃y1 x0 )ST y (3q1 ))
⇔ ∀Q
1
1
˜ 1 (∀x1 x0 ) (ST x (2q1 ) → ST x (33q1 )).
⇔ ∀Q
1
0
The last formula is a type 2 formula. Hence, the only thing left to do is to rewrite
it to an equivalent Sahlqvist formula; this we do via the sequence of equivalent
formulas below, following the pattern of the proof of Claim 3:
˜ 1 ( (∀x1 x0 ) (ST x (2q1 ) → ST x (33q1 )) )
∀Q
1
0
˜
⇔ ∀Q1 ( (∀x1 x0 ) ¬(ST x (2q1 ) ∧ ¬ST x (33q1 )) )
1
0
˜ 1 ( (∀x1 x0 ) ¬(ST x (2q1 ) ∧ ST x (¬33q1 )) )
⇔ ∀Q
1
0
˜
⇔ ∀Q1 ( ¬(∃x1 x0 ) (ST x1 (2q1 ) ∧ ST x0 (¬33q1 )) )
˜ 1 ( ¬((∃x1 x0 )ST x (2q1 ) ∧ ST x (¬33q1 )) )
⇔ ∀Q
1
0
˜ 1 ( ¬(ST x (32q1 ) ∧ ST x (¬33q1 )) )
⇔ ∀Q
0
0
˜
⇔ ∀Q1 ( ¬ST x (32q1 ∧ ¬33q1 ) )
0
˜ 1 ( ST x ((32q1 ∧ ¬33q1 ) → ⊥) ).
⇔ ∀Q
0
This means that α(x0 ) locally corresponds to the Sahlqvist formula (32q1 ∧
¬33q1 ) → ⊥, or to the equivalent formula 32q1 → 33q1 .
Example 3.61 Consider the Kracht formula
α(x0 ) ≡ (∀x1 x0 )(∀x2 x0 ) (Rx1 x2 ∨ Rx2 x1 ∨ x1 = x2 ).
According to (3.21), α(x0 ) is equivalent to
˜ 1 ∀Q
˜ 1 (∀x1 x0 )(∀x2 x0 ) (ST x (p1 ∧ 2q1 )
∀P
1
→ (ST x2 (q1 ) ∨ ST x2 (3p1 ) ∨ ST x2 (p1 )))
and to
˜ 1 ∀Q
˜ 1 (∀x1 x0 )(∀x2 x0 ) (ST x (p1 ∧ 2q1 ) → ST x (q1 ∨ 3p1 ∨ p1 )).
∀P
1
2
The latter is a type 2 formula; in order to ﬁnd a Sahlqvist equivalent for it, we
proceed as follows:
˜ 1 ∀Q
˜ 1 (∀x1 x0 )(∀x2 x0 ) (ST x (p1 ∧ 2q1 ) → ST x (q1 ∨ 3p1 ∨ p1 ))
∀P
1
2
˜
˜
⇔ ∀P1 ∀Q1 (∀x1 x0 )(∀x2 x0 ) ¬(ST x (p1 ∧ 2q1 ) ∧
1
¬ST x2 (q1 ∨ 3p1 ∨ p1 ))
˜ 1 ∀Q
˜ 1 (∀x1 x0 )(∀x2 x0 ) ¬(ST x (p1 ∧ 2q1 ) ∧
⇔ ∀P
13.7 More about Sahlqvist Formulas
177
ST x2 (¬(q1 ∨ 3p1 ∨ p1 )))
˜ 1 ∀Q
˜ 1 ¬(∃x1 x0 )(∃x2 x0 ) (ST x (p1 ∧ 2q1 ) ∧
⇔ ∀P
1
ST x2 (¬(q1 ∨ 3p1 ∨ p1 )))
˜
˜
⇔ ∀P1 ∀Q1 ¬(∃x1 x0 ) (ST x1 (p1 ∧ 2q1 ) ∧
(∃x2 x0 )ST x2 (¬(q1 ∨ 3p1 ∨ p1 )))
˜ 1 ∀Q
˜ 1 ¬(∃x1 x0 ) (ST x (p1 ∧ 2q1 ) ∧ ST x (3¬(q1 ∨ 3p1 ∨ p1 )))
⇔ ∀P
1
0
˜
˜
⇔ ∀P1 ∀Q1 ¬((∃x1 x0 )ST x (p1 ∧ 2q1 ) ∧ ST x (3¬(q1 ∨ 3p1 ∨ p1 )))
1
0
˜ 1 ∀Q
˜ 1 ¬(ST x (3(p1 ∧ 2q1 )) ∧ ST x (3¬(q1 ∨ 3p1 ∨ p1 )))
⇔ ∀P
0
0
˜ 1 ∀Q
˜ 1 ¬(ST x (3(p1 ∧ 2q1 ) ∧ 3¬(q1 ∨ 3p1 ∨ p1 ))).
⇔ ∀P
0
From this, the fastest way to proceed is by observing that the last formula is equiv-
alent to
˜ 1 ∀Q
˜ 1 (ST x (3(p1 ∧ 2q1 ) → ¬3¬(q1 ∨ 3p1 ∨ p1 ))),
∀P
0
and hence, to the Sahlqvist formula
3(p1 ∧ 2q1 ) → 2(q1 ∨ 3p1 ∨ p1 ).
Example 3.62 Consider the type 1 Kracht formula
α(x0 ) ≡ (∀x1 x0 )(∃y1 x1 ) y1 = y1 .
According to (3.21), we can rewrite α(x0 ) into the equivalent
˜ 0 (∀x1 x0 ) (ST x (p0 ) → (∃y1 x1 )ST y (⊥))
∀P
0
1
and, hence, to
˜ 0 (∀x1 x0 ) (ST x (p0 ) → ST x (3⊥)).
∀P
0
1
This is a type 2 formula for which we can ﬁnd a Sahlqvist equivalent as follows:
˜ 0 (∀x1 x0 ) (ST x (p0 ) → ST x (3⊥))
∀P
0
1
˜
⇔ ∀P0 (∀x1 x0 ) ¬(ST x (p0 ) ∧ ¬ST x (3⊥))
0
1
˜ 0 ¬(∃x1 x0 ) (ST x (p0 ) ∧ ST x (¬3⊥))
⇔ ∀P
0
1
˜ 0 ¬ (ST x (p0 ) ∧ (∃x1 x0 )ST x (¬3⊥))
⇔ ∀P
0
1
˜ 0 ¬ (ST x (p0 ) ∧ ST x (3¬3⊥))
⇔ ∀P
0
0
˜ 0 (ST x (¬(p0 ∧ 3¬3⊥)).
⇔ ∀P
0
The latter formula is equivalent to the Sahlqvist formula p0 → 23⊥. (Obviously,
the latter formula is equivalent to 23⊥ and, hence, to 2⊥. Our algorithm will not
always provide the simplest correspondents!)3 Frames
178
This ﬁnishes our discussion of Sahlqvist correspondence. In the next chapter we
will see that Sahlqvist formulas also have very nice completeness properties, in
that any modal logic axiomatized by Sahlqvist formulas is complete with respect
to the class of frames deﬁned by (the global ﬁrst-order correspondents of) the for-
mulas. Here Kracht’s Theorem can be useful: if we want to axiomatize a class of
frames deﬁned by formulas of the form ∀x α(x) with α(x) a Kracht formula, then
it sufﬁces to compute the Sahlqvist correspondents of these formulas and add these
as axioms to the basic modal logic.
Exercises for Section 3.7
(a) Prove that the conjunction M ∧ 4 of McKinsey’s formula 23p → 32p and
the transitivity formula 3p → 33p does not have a local ﬁrst-order correspondent.
Conclude that this conjunction is not equivalent to a Sahlqvist formula.
(b) Show that on the other hand, the formula 2M ∧ 4 does have a local ﬁrst-order
correspondent.
3.7.1
3.7.2 Prove that the local correspondent of a Sahlqvist formula is a Kracht formula.
3.7.3 Find Sahlqvist formulas that locally correspond to the following formulas:
(a) (∀yx) Ryy,
(b) (∀y1 x)(∀y2 x)(∀y3 x) (y1 = y2 ∨ y1 = y3 ∨ y2 = y3 ),
(c) (∀y1 x)(∀y2 y1 ) (y1 = y2 ∨ ∃z (Rxz ∨ (Ry1 z ∧ Ry2 z))),
(d) (∀x1 x)(∃y1 x)(∀y2 y1 ) (Ry1 x1 ∨ (Rxy2 ∧ Ry2 x1 )).
3.7.4 Prove that if φ → ψ is a simple Sahlqvist formula, then 2(φ → ψ) is equivalent to
a simple Sahlqvist formula.
3.7.5 Consdier the basic temporal similarity type. Show that over the class of bidirectional
frames, every simple Sahlqvist formula is equivalent to a very simple Sahlqvist formula.
(Hint: ﬁrst ﬁnd a very simple Sahlqvist formula that is equivalent to the formula F Gp →
GF p.)
3.8 Advanced Frame Theory
The main aim of this section is to prove Theorem 3.19, the Goldblatt-Thomason
Theorem, characterizing the elementary frame classes that are modally deﬁnable.
We will also prove a rather technical result needed in our later work on algebras.
We will start by proving the Goldblatt-Thomason Theorem.
Theorem 3.19 Let τ be a modal similarity type. A ﬁrst-order deﬁnable class K of τ -
frames is modally deﬁnable if and only if it is closed under taking bounded morphic
images, generated subframes, disjoint unions and reﬂects ultraﬁlter extensions.3.8 Advanced Frame Theory
179
Proof. The preservation direction follows from earlier results. For the other di-
rection let K be a class of frames which is elementary (hence, closed under taking
ultraproducts), closed under taking bounded morphic images, generated subframes
and disjoint unions, and reﬂecting ultraﬁlter extensions. Let ΛK be the logic of K;
that is, ΛK = {φ | F  φ, for all F ∈ K}. We will show that ΛK deﬁnes K. In order
to avoid cumbersome notation we restrict ourselves to the basic modal similarity
type.
Let F = (W, R) be a frame such that F  ΛK . We need to show that F is a
member of K. This we will do by moving around lots of structures; here is a map
of where we are heading for in the proof:
{Fa | a ∈ W }
ue F
1FF
G
HH
5
HH
6
HH
{Gδ | δ ⊆f in Δ}
aa
4
G
aa3
2
aa
a
a

U Gδ
First, we can assume without loss of generality that F is point-generated. For if F
validates ΛK , then each of its point-generated subframes does so as well. And if we
can prove that each point-generated subframe of F is in K, then the membership in
K of F itself follows immediately from the closure properties of K and the fact that
any frame is a bounded morphic image of the disjoint union of its point-generated
subframes (as the reader was asked to show in Exercise 3.3.4). So from now on we
assume that F is generated by the point w.
Now for (one of) the main idea(s) of the proof. Let Φ be a set of proposition
letters containing a proposition letter pA for each subset A of W . This may be a
huge language: if W is inﬁnite, then Φ will be uncountable. We will look at the
model M = (F, V ) where V is the natural valuation given by V (pA ) = A. Now
let Δ be the modal type of w; that is, Δ = {φ ∈ ML(τ, Φ) | M, w  φ}. We claim
that
Δ is satisﬁable in K.
(3.26)
In order to prove this, we ﬁrst show that Δ is ﬁnitely satisﬁable in K. Let δ be a
ﬁnite subset of Δ. It is easy to see that δ is satisﬁable in K: if it were not, then


¬ δ would belong to ΛK whence we would have F  ¬ δ. (Note that whereas
Δ is written in a particular language, namely, the one having a proposition letter
for each subset of W , when we are talking about ΛK we are not really interested

in a speciﬁc language. This is why we simply assume that ‘¬ δ would belong
to ΛK ’ even though we have not veriﬁed that this formula uses only proposition


letters that occur in ΛK .) But F  ¬ δ would contradict that M, w  δ. Thus
each ﬁnite δ ⊂ Δ is ﬁnitely satisﬁable in some frame Gδ in K, so Δ is satisﬁable
in some ultraproduct of these frames (the reader is asked to supply a proof of this3 Frames
180
in Exercise 3.8.2 below). Since K is closed under ultraproducts by assumption, this
proves (3.26).
But to say that Δ is satisﬁable in K amounts to the following. There is a model
N = (X, S, U ) and a point b in X such that the underlying frame G = (X, S)
is in K and N, b  Δ. Since K is closed under (point-)generated subframes and
modal truth is preserved under taking generated subframes, we may assume that
the frame G is generated from b.
The only thing left to do is to link up G with our original frame F. This link is
as follows:
ue F is a bounded morphic image of some ultrapower of G.
(3.27)
We ﬁrst ensure the existence of an m-saturated ultrapower of N. Note that we may
view N as a ﬁrst-order structure for the language L1τ (Φ), analogous to the per-
spective in the previous chapter. Now consider a countably saturated ultrapower of
this ﬁrst-order structure, which we see again as a modal model N = (X  , S  , U  ).
Note that the existence of such an ultrapower is not guaranteed by Lemma 2.73,
since the ﬁrst-order language L1τ,F may not be countable. We need some heavier
model-theoretic equipment here; the reader is referred to Theorems 6.1.4 and 6.1.8
in [91]. In any case, N is m-saturated and also has the property that every set Σ
that is ﬁnitely satisﬁable in N is satisﬁable in N .
How are we going to deﬁne the bounded morphism? That is, given an element s
of X  , which ultraﬁlter over W (the universe of our original frame F) are we going
to assign to it? Recall that an ultraﬁlter over W is some collection of subsets of
W ; this means that given s, we have to decide for each subset of W whether to put
it in f (s) or not. But now it will become clear that there is only one natural choice
for f (s): simply put a subset A of W in f (s) if pA is true at s in the model N :
f (s) = {A ⊆ W | N , s  pA }.
We will now show that f indeed maps points in N to ultraﬁlters over W , that f
is a bounded morphism, and that f is onto ue F. In these proofs, the following
equivalence comes in handy:
for all formulas φ ∈ ML(τ, Φ), M  φ iff N  φ.
(3.28)
The proof of (3.28) is by the following chain of equivalences:
Mφ
⇔
⇔
⇔
⇔
⇔
This proves (3.28).
M, w  2n φ for all n ∈ N
2n φ ∈ Δ for all n ∈ N
N, b  2n φ for all n ∈ N
Nφ
N  φ
(M is generated from w)
(deﬁnition of Δ)
(deﬁnition of N and b)
(N is generated from b)
(N is an ultrapower of N).3.8 Advanced Frame Theory
181
Let us now ﬁrst check that for all s ∈ X , f (s) is indeed an ultraﬁlter over W .
We will only check the condition that f (s) is closed under intersection, leaving the
other conditions as exercises for the reader. Suppose that A and B are subsets of W
that both belong to f (s). Hence, by the deﬁnition of f (s) we have that N , s  pA
and N , s  pB . It is easy to see that the formula pA ∧pB ↔ pA∩B holds throughout
the original model M. It then follows from (3.28) that N  pA ∧ pB ↔ pA∩B . In
particular, this formula is true at s, so we ﬁnd that N , s  pA∩B . Hence, by the
deﬁnition of f , A ∩ B belongs to f (s).
In order to show that f is a bounded morphism, we will prove that for all ultra-
ﬁlters u over W and all points s in X , we have that u = f (s) if and only if u (in
ue M) and s (in N ) satisfy the same formulas. This sufﬁces, by Proposition 2.54
and the m-saturation of ue M and N . The right to left direction of the equivalence
is easy to prove. If the same formulas hold in s and u, then in particular we have for
each A ⊆ W that N , s  pA iff ue M, u  pA . But by deﬁnition of the valuation
on ue M we have that ue M, u  pA iff A = V (pA ) ∈ u. Hence, we ﬁnd that
N , s  pA iff A ∈ u. This immediately yields u = f (s).
For the other direction, it sufﬁces to show that for each formula φ ∈ ML(τ, Φ)
and each point s in N , ue M, f (s)  φ only if N , s  φ. Suppose that φ holds at
f (s) in ue M. By Proposition 2.59 we have that V (φ) ∈ f (s). Thus by deﬁnition
of f we obtain that N , s  pV (φ) . It follows easily from the deﬁnition of V that
M  φ ↔ pV (φ) , so by (3.28) we have that N  φ ↔ pV (φ) . But then we may
immediately infer that N , s  φ.
Finally, we have to show that f is surjective; that is, each ultraﬁlter over W
should belong to its range. Let u be such an ultraﬁlter; we claim that the set Σ =
{pA | A ∈ u} is ﬁnitely satisﬁable in N . Let σ be a ﬁnite subset of Σ. To
start with, σ is satisﬁable in M. Since M is generated from w, this shows that

M, w  3n σ for some natural number n. From the deﬁnition of N and b it

follows that N, b  3n σ, so from the fact that N is point-generated from b we

obtain that σ is satisﬁable in N. Now N is an ultrapower of N, so we have that

σ is also satisﬁable in N . But N is countably saturated; so Σ, being ﬁnitely
satisﬁable in N , is satisﬁable in some point s of N . It is then immediate that
f (s) = u.
This proves (3.27), but why does that mean that F belongs to K? Here we use the
closure properties of K. Recall that G is the underlying frame of the model N in
which we assumed that the set Δ is satisﬁable. Since G is in K by assumption, G
belongs to K by closure under ultraproducts; ue F is in K as it is a bounded morphic
image of G ; and ﬁnally, F is in K since K reﬂects ultraﬁlter extensions.
The following proposition, which is of a rather technical nature, will be put to good
use in Chapter 5.182
3 Frames
Proposition 3.63 Let τ be a modal similarity type, and K a class of τ -frames.
Suppose that G is an ultrapower of the disjoint union i∈I Fi , where {Fi | i ∈ I}
is a family of frames in K. Then G is a bounded morphic image of a disjoint union
of ultraproducts of frames in K.
Proof. Let F = (W, R) denote the disjoint union i∈I Fi , and assume that G is

some ultrapower of F, say G = U F, where U is an ultraﬁlter over some index
set J. We assume that τ contains only one operator , of arity n. This allows us
to write F = (W, R) and Fi = (Wi , Ri ) (that is, the subscript i refers to an index
element of I, not to an operator from the similarity type).
Consider an arbitrary state t of G. By the deﬁnition of ultrapowers, there exists

a sequence ft ∈ j∈J W such that

t = (ft )U = {g ∈ j∈J W | ft ∼U g}.
As W is the disjoint union of the universes Wi , for each j ∈ J there exists an
element ij ∈ I such that ft (j) is an element of Wij . Form the ultraproduct

Ft := U Fij .
Clearly this frame is an ultraproduct of frames in K.
We will now deﬁne a map θt sending states of the frame Ft to states of the frame
G, and show that θt is a bounded morphism with t in its range. From this it easily
follows that G is a bounded morphic image of the disjoint union t∈X Ft , where
X is the universe of G. Observe that a typical element of Ft has the form

gU := {h ∈ j∈J Wij | g ∼U h}



for some g ∈ j∈J Wij . Since j∈J Wij ⊆ j∈J W , we have that gU ⊆ gU .
Note that in general these two equivalence classes will not be identical, since gU
may contain elements h for which h(j ) ∈ W \ Wij for some index j . However,

it is evident that if both g and h are in j∈J Wij , then we ﬁnd that gU = hU iff
g ∼U h iff gU = hU . This means that if we put
θt (gU ) := gU ,
we have found a well-deﬁned map from the universe of Ft to the universe X of G
(in fact, this map is injective).

Now consider the element ft ∈ j∈J W . By deﬁnition of the indices ij , we

must have ft ∈ j∈J Wij . It follows that ftU is in the domain of θt . Now
θt (ftU ) = (ft )U = t.
It remains to be proved that θt is a bounded morphism. However, this follows by a
straightforward argument using standard properties of ultraﬁlters.3.9 Summary of Chapter 3
183
Exercises for Section 3.8
3.8.1 Let τ be an arbitrary modal similarity type and F a τ -frame. Prove that the ultraﬁlter
extension of F is the bounded morphic image of some ω-saturated ultrapower of F; in other
words, supply a proof for Theorem 3.17. (Hint: use an argument analogous to one in the
proof of Theorem 3.19. That is, consider a language having a proposition letter p A for
each subset A of the universe of F, and take a countably saturated ultrapower of the model
M = (F, V ), where V is the natural valuation mapping p A to A for each variable p A .)
3.8.2 Let K be some class of frames, and Δ a set of formulas which is ﬁnitely satisﬁable
in K. Show that Δ is satisﬁable in an ultraproduct of frames in K.
(a) Show that the complement of a modally deﬁnable class is closed under taking
ultrapowers.
Now suppose that the class K of frames is deﬁnable by a single formula φ.
3.8.3
(b) Show that the complement of K is closed under taking ultraproducts. (Hint: let
Γ (φ) be the set of ﬁrst-order sentences that are semantic consequences of φ, in the
sense that for any frame F we have that F  φ only if F |= Γ (φ). In other words,
Γ (φ) is the ﬁrst-order theory of K.)
(c) Prove that φ is a semantic consequence of Γ (φ). (Hint: reason by contraposition
and use (b).)
(d) Prove that φ is a semantic consequence of a ﬁnite subset of Γ (φ). (Hint: prove that
Γ (φ) |= ∀x ST x (φ), and use compactness.)
(e) Conclude that if a modal formula φ deﬁnes an elementary frame class, then φ cor-
responds to a (single) ﬁrst-order formula.
3.8.4 Prove the strong version of the Goldblatt-Thomason Theorem which applies to any
frame class that is closed under taking ultrapowers. (Hint: strengthen the result of Exer-
cise 3.8.2 by showing that any set of modal formulas that is ﬁnitely satisﬁable in a frame
class K is itself satisﬁable in an ultrapower of a disjoint union of frames in K.)
3.8.5 Point out where, in the picture summarizing the proof of Theorem 3.19, we use
which closure conditions on K. (For instance: in step 2 we need the fact that K is closed
under taking ultraproducts.)
3.9 Summary of Chapter 3
 Frame Deﬁnability: A modal formula is valid on a frame if and only if it is
satisﬁed at every point in the frame, no matter which valuation is used. A modal
formula deﬁnes a class of frames if and only if it is valid on precisely the frames
in that class.
 Frame Deﬁnability is Second-Order: Because the deﬁnition of validity quan-
tiﬁes across all possible valuations, and because valuations are assignments of
subsets of frames, the concept of validity, and hence frame deﬁnability, is in-
trinsically second-order.
 Frame Languages: Every modal formula can be translated into the appropri-
ate second-order frame language. Such languages have an (n + 1)-place rela-
tion symbol for every n-place modality. Proposition letters correspond to unary184
3 Frames
predicate variables. The required translation is called the second-order transla-
tion. This is simply the standard translation modiﬁed to send proposition letters
to (unary) predicate variables rather than predicate constants.
 Correspondence: Sometimes the second-order formulas obtained using this
translation are equivalent to ﬁrst-order formulas. But often they correspond to
genuinely second-order formulas. This can sometimes be shown by exhibiting
a failure of Compactness or the Löwenhein-Skolem property.
 Frame Constructions: The four fundamental model constructions discussed in
the previous chapter have obvious frame-theoretic counterparts. Moreover, va-
lidity is preserved under the formation of disjoint unions, generated subframes
and bounded morphic images, and anti-preserved under ultraﬁlter extensions.
 Goldblatt-Thomason Theorem: A ﬁrst-order deﬁnable frame class is modally
deﬁnable if and only if it is closed under disjoint unions, generated subframes
and bounded morphic images, and reﬂects ultraﬁlter extensions.
 Modal Deﬁnability on Finite Transitive Frames: A class of ﬁnite transitive
frames is modally deﬁnable if and only if it is preserved under (ﬁnite) disjoint
unions, generated subframes and bounded morphic images.
 The Finite Frame Property: A normal modal logic Λ has the ﬁnite frame prop-
erty if and only if any formula that does not belong to Λ can be falsiﬁed on a
ﬁnite frame that validates all the formulas in Λ. A normal logic has the ﬁnite
frame property if and only if it has the ﬁnite model property.
 The Sahlqvist Fragment: Formulas in the Sahlqvist fragment have the property
that the second-order formula obtained via the second-order translation can be
reduced to an equivalent ﬁrst-order formula. The Sahlqvist-van Benthem algo-
rithm is an effective procedure for carrying out such reductions.
 Why Sahlqvist Formulas have First-Order Correspondents: Syntactically, the
Sahlqvist fragment forbids universal operators to take scope over existential or
disjunctive connectives in the antecedent. Semantically, this guarantees that we
will always be able to ﬁnd a unique minimal valuation that makes the antecedent
true. This ensures that Sahlqvist formulas have ﬁrst-order correspondents.
 Negative Results: There are non-Sahlqvist formulas that deﬁne ﬁrst-order con-
ditions. Moreover, Chagrova’s Theorem tells us that it is undecidable whether a
modal formula has a ﬁrst-order equivalent.
 Kracht’s Theorem: Kracht’s Theorem takes us back from ﬁrst-order languages
to modal languages. It identiﬁes a class of ﬁrst-order formulas that are the ﬁrst-
order correspondents of Sahlqvist formulas.
 Frames and their Ultraﬁlter Extensions: The ultraﬁlter extension of a frame
may be obtained as a bounded morphic image of an ultrapower of the frame.
 Ultrapowers of Disjoint Unions: Ultrapowers of a disjoint union may be ob-
tained as bounded morphic images of disjoint unions of ultraproducts.Notes to Chapter 3
185
Notes
The study of frames has been central to modal logic since the dawn of the classical
era (see the Historical Overview in Chapter 1), but the way frames have been stud-
ied has changed dramatically over this period. The insight that gave birth to the
classical era was that simple properties of frames (such as transitivity and reﬂex-
ivity) could be used to characterize normal modal logics, and most of the 1960s
were devoted to exploring this topic. It is certainly an important topic. For ex-
ample, in the ﬁrst half of the following chapter we will see that most commonly
encountered modal logics can be given simple, intuitively appealing, frame-based
characterizations. But the very success of this line of work meant that for a decade
modal logicians paid little attention to modal languages as tools for describing
frame structure. Frames were simply tools for analyzing normal logics. The notion
of frame deﬁnability, and the systematic study of modal expressivity over frames,
only emerged as a research theme after the frame incompleteness results showed
that not all normal logics could be given frame-based characterizations. The ﬁrst
incompleteness result (shown for the basic temporal language) was published in
1972 by S.K. Thomason [433]. The ﬁrst incompleteness results for the basic modal
language were published in 1974 by S.K. Thomason [434] and Kit Fine [129].
The frame incompleteness theorems and the results which accompanied them
decisively changed the research agenda of modal logic, essentially because they
made it clear that the modal perspective on frames was intrinsically second-order.
We have seen ample evidence for this in this chapter: as we saw in Example 3.11
a formula as innocuous looking as McKinsey’s 23p → 32p deﬁnes a non-
elementary class of frames. This was proved independently by Goldblatt [183]
and van Benthem [35]. The proof given in the text is from Theorem 10.2 of van
Benthem [42]. It was shown by S.K. Thomason [436] that on the level of frames,
modal logic is expressive enough to capture the semantic consequence relation for
L2 . Moreover, in unpublished work, Doets showed that modal formulas can act as
a reduction class for the theory of ﬁnite types; see van Benthem [42, pages 23–24]
for further discussion.
So by the mid 1970s it was clear that modal logic embodied a substantial frag-
ment of second-order logic, and a radically different research program was well
under way. One strand of this program was algebraic: these years saw the (re)-
emergence of algebraic semantics together with a belated appreciation of the work
of Jónsson and Tarski [255, 256]; this line of work is treated in Chapter 5. The
other strand was the emergence of correspondence theory.
Given that modal logic over frames is essentially second-order logic in disguise,
it may seem that the most obvious way to develop correspondence theory would be
to chart the second-order powers of modal logic. In fact, examples of modal for-
mulas that deﬁne second-order classes of frames were known by the early 1970s186
3 Frames
(for example, Johan van Benthem proved that the Löb formula deﬁned the class
of transitive and converse well-founded frames using the argument given in Exam-
ple 3.9). And there is interesting work on more general results on second-order
frame deﬁnability, much of which may be found in Chapters XVII–XIX of van
Benthem [42]. Nonetheless, most work on correspondence theory for frames has
concentrated on its ﬁrst-order aspects. There are two main reasons for this. First,
second-order model theory is less well understood than ﬁrst-order model theory, so
investigations of second-order correspondences have fewer useful results to draw
on. Second, there is a clear sense that it is the ﬁrst-order aspects of frame deﬁn-
ability which are truly mysterious (this has long been emphasized by Johan van
Benthem). With the beneﬁt of hindsight, the second-order nature of validity is
obvious; understanding when – and why – it is sometimes ﬁrst-order is far harder.
In this chapter we examined the two main strands in ﬁrst-order correspondence
theory (for frames): the semantic, exempliﬁed by the Goldblatt-Thomason The-
orem, and the syntactic, exempliﬁed by the Sahlqvist Correspondence Theorem.
(Incidentally, as we will learn in Chapter 5, both results have a substantial alge-
braic dimension.)
What we call the Goldblatt-Thomason Theorem was actually proved by Gold-
blatt. His result was in fact stronger than our Theorem 3.19, applying to any frame
class that is closed under elementary equivalence. This theorem was published in
a joint paper [188] with S.K. Thomason, who added a more general result which
applies to all deﬁnable frame classes but has a less appealing frame construction.
The model-theoretic proof of the theorem that we supplied in this chapter is due
to van Benthem [46], who also proved the ﬁnite transitive version we recorded as
Theorem 3.21. Barwise and Moss [28] obtain correspondence results for models
as opposed to frames; their main result is that if a modal formula φ has a ﬁrst-
order frame correspondent cφ , then for all models M, M satisﬁes all substitution
instances of φ in inﬁnitary modal logic iff a certain frame underlying M satisﬁes
cφ .
Concerning the identiﬁcation of syntactic classes of modal formulas that corre-
spond to ﬁrst-order formulas, Sahlqvist’s result was not the ﬁrst. As early as in the
Jónsson-Tarski papers [255, 256] particular examples such as reﬂexivity and transi-
tivity were known. And an article by Fitch [136] was a stimulus for van Benthem’s
investigations in this area, which lead to van Benthem (unaware of Sahlqvist’s ear-
lier work) proving what is now known as Sahlqvist’s Theorem. But Sahlqvist’s
paper [396] (essentially a presentation of results contained in his Masters thesis)
remains the classic reference in the area. It greatly generalized all previous known
results in the area and drew a beautiful link between deﬁnability and completeness.
Kracht isolated the ﬁrst-order formulas that are the correspondents of Sahlqvist
formulas in [276], as an application of his so-called calculus of internal describa-Notes to Chapter 3
187
bility. This calculus relates modal and ﬁrst-order formulas on the level of general
frames; see also [279].
During the 1990s a number of alternative correspondence languages have been
considered for the basic modal language. In the so-called functional translation the
accessibility relations are replaced by certain terms which can be seen as functions
mapping worlds to accessible worlds. From a certain point of view this functional
language is more expressive than the relational language, and certain second-order
frame properties can be mapped to formulas expressed in the functional language
– but this is not too surprising: in the functional language one can quantify over
functions; this additional expressive power allows one to do without quantiﬁca-
tion over unary predicate variables; see Ohlbach and Schmidt [346] and Ohlbach
et al. [344] and Simmons [414].
As with ﬁnite model theory, the theory of ﬁnite frames is rather underdeveloped.
However, some of the basic results have been known a long time. We showed in
Theorem 3.28 that a normal logic has the ﬁnite model property if and only if it has
the ﬁnite frame property. This result is due to Segerberg [404, Corollary 3.8, page
33]. For some interesting results concerning frame correspondence theory over the
class of ﬁnite frames the reader should consult the dissertation of Doets [110].
To conclude these Notes, we will tidy up a few loose ends. Exercise 3.6.2 is
due to van Benthem [42, Theorem 10.4]. Exercise 3.2.4 is based on a result in
Fine [132]. Second, we mentioned Chagrova’s Theorem [89] that it is undecidable
whether a modal formula has a ﬁrst-order equivalent. For pointers to, and a brief
discussion of, extensions of this line of work, see Chagrov and Zakharyaschev [88,
Chapter 17]. At the end of Section 3.2 we remarked that general frames can be seen
as a model version of the generalized models or Henkin models for second-order
logic. Henkin [217] introduced such models, and good discussions of them can be
found in Doets and van Benthem [112] or Manzano [314]. Finally, for more on the
lambda calculus see Barendregt [24] or Hindley and Seldin [223].4
Completeness
This chapter is about the completeness – and incompleteness – of normal modal
logics. As we saw in Section 1.6, normal modal logics are collections of formulas
satisfying certain simple closure conditions. They can be speciﬁed either syntac-
tically or semantically, and this gives rise to the questions which dominate the
chapter: Given a semantically speciﬁed logic, can we give it a syntactic characteri-
zation, and if so, how? And: Given a syntactically speciﬁed logic, can we give it a
semantic characterization (and in particular, a characterization in terms of frames),
and if so, how? To answer either type of question we need to know how to prove
(soundness and) completeness theorems, and the bulk of the chapter is devoted to
developing techniques for doing so.
The chapter has two major parts. The ﬁrst, comprising the ﬁrst four sections,
is an introduction to basic completeness theory. It introduces canonical models,
explains and applies the completeness-via-canonicity proof technique, discusses
the Sahlqvist Completeness Theorem, and proves two fundamental limitative re-
sults. The material introduced in these sections (which are all on the basic track) is
needed to follow the second part and the algebraic investigations of Chapter 5.
In the second part of the chapter we turn to the following question: what are we
to do when canonicity fails? (As will become clear, canonicity failure is a fact of
life for temporal logic, propositional dynamic logic, and other applied modal lan-
guages.) This part of the chapter is technique oriented: it introduces ﬁve important
ways of dealing with such difﬁculties.
Chapter guide
Section 4.1: Preliminaries (Basic track). This section introduces the fundamental
concepts: normal modal logics, soundness, and completeness.
Section 4.2: Canonical Models (Basic track). Canonical models are introduced,
and the fundamental Canonical Model Theorem is proved.
Section 4.3: Applications (Basic track). This section discusses the key concept of
1884.1 Preliminaries
189
canonicity, and uses completeness-via-canonicity arguments to put canoni-
cal models to work. We prove completeness results for a number of modal
and temporal logics, and ﬁnish with a discussion of the Sahlqvist Com-
pleteness Theorem.
Section 4.4: Limitative Results (Basic track). We prove two fundamental limita-
tive results: not all normal logics are canonical, and not all normal logics
are characterized by some class of frames. This section concludes our in-
troduction to basic completeness theory.
Section 4.5: Transforming the Canonical Model (Basic track). Often we need to
build models with properties for which we lack a canonical formula. What
are we to do in such cases? This section introduces one approach: use
transformation methods to try and massage the ‘faulty’ canonical model
into the required shape.
Section 4.6: Step by Step (Basic track). Sometimes we can cope with canonicity
failure using the step-by-step method. This is a technique for building
models with special properties inductively.
Section 4.7: Rules for the Undeﬁnable (Basic track). Special proof rules (that in
a certain sense manage to express undeﬁnable properties of models and
frames) sometimes allow us to construct special canonical models con-
taining submodels with undeﬁnable properties.
Section 4.8: Finitary Methods I (Basic track). We discuss a method for proving
weak completeness results for non-compact logics: ﬁnite canonical mod-
els. We use such models to prove the completeness of propositional dy-
namic logic.
Section 4.9: Finitary Methods II (Advanced track). This section further explores
ﬁnitary methods, this time the direct use of ﬁltrations. We illustrate this
with an analysis of the normal logics extending S4.3.
4.1 Preliminaries
In this section we introduce some of the fundamental concepts that we will use
throughout the chapter. We begin by deﬁning modal logics – these could be de-
scribed as propositional logics in a modal language.
Throughout the chapter we assume we are working with a ﬁxed countable lan-
guage of proposition letters.
Deﬁnition 4.1 (Modal Logics) A modal logic Λ is a set of modal formulas that
contains all propositional tautologies and is closed under modus ponens (that is, if
φ ∈ Λ and φ → ψ ∈ Λ then ψ ∈ Λ) and uniform substitution (that is, if φ belongs
to Λ then so do all of its substitution instances). If φ ∈ Λ we say that φ is a theorem
of Λ and write Λ φ; if not, we write Λ φ. If Λ1 and Λ2 are modal logics such190
4 Completeness
that Λ1 ⊆ Λ2 , we say that Λ2 is an extension of Λ1 . In what follows, we usually
drop the word ‘modal’ and talk simply of ‘logics.’
Note that modal logics contain all substitution instances of the propositional tau-
tologies: for example, 3p ∨ ¬3p, belongs to every modal logic. Even though
such substitution instances may contain occurrences of 3 and 2, we still call them
tautologies. Clearly tautologies are valid in every class of models.
Example 4.2
(i) The collection of all formulas is a logic, the inconsistent
logic.

(ii) If {Λi | i ∈ I} is a collection of logics, then i∈I Λi is a logic.
(iii) Deﬁne ΛS to be {φ | S  φ, for all structures S ∈ S}, where S is any class
of frames or any class of general frames. ΛS is a logic. If S is the singleton
class {S}, we usually call this logic ΛS, rather than Λ{S} .
(iv) If M is a class of models, then ΛM need not be a logic. Consider a model
M in which p is true at all nodes but q is not. Then p ∈ ΛM, but q ∈ ΛM.
But q is obtainable from p by uniform substitution.
It follows from Examples 4.2(i) and 4.2(ii) that there is a smallest logic containing
any set of formulas Γ ; we call this the logic generated by Γ . For example, the logic
generated by the empty set contains all the tautologies and nothing else; we call it
PC and it is a subset of every logic. This generative perspective is essentially syn-
tactic. However, as Example 4.2(iii) shows, there is a natural semantic perspective
on logics: both frames and general frames give rise to logics in an obvious way.
Even the empty class of frames gives rise to a logic, namely the inconsistent logic.
Finally, Example 4.2(iv) shows that models may fail to give rise to logics. This
‘failure’ is actually the behavior we should expect: as we discussed in Section 1.6,
genuine logics arise at the level of frames, via the concept of validity.
Deﬁnition 4.3 Let ψ1 , . . . , ψn , φ be modal formulas. We say that φ is deducible
in propositional calculus from assumptions ψ1 , . . . , ψn if (ψ1 ∧ · · · ∧ ψn ) → φ is
a tautology.
All logics are closed under deduction in propositional calculus: if φ is deducible
in propositional calculus from assumptions ψ1 , . . . , ψn , then Λ ψ1 , . . . , Λ ψn
implies Λ φ.
Deﬁnition 4.4 If Γ ∪ {φ} is a set of formulas then φ is deducible in Λ from Γ (or:
φ is Λ-deducible from Γ ) if Λ φ or there are formulas ψ1 ,. . . , ψn ∈ Γ such that
Λ (ψ1 ∧ · · · ∧ ψn ) → φ.4.1 Preliminaries
191
If this is the case we write Γ Λ φ, if not, Γ Λ φ. A set of formulas Γ is Λ-
consistent if Γ Λ ⊥, and Λ-inconsistent otherwise. A formula φ is Λ-consistent if
{φ} is Λ-consistent; otherwise φ is Λ-inconsistent.
It is a simple exercise in propositional logic to check that a set of formulas Γ is
Λ-inconsistent if and only if there is a formula φ such that Γ Λ φ ∧ ¬φ if and
only if for all formulas ψ, Γ Λ ψ. Moreover, Γ is Λ-consistent if and only if
every ﬁnite subset of Γ is. (That is, our notion of deducibility has the compact-
ness property.) From now on, when Λ is clear from context or irrelevant, we drop
explicit references to it and talk simply of ‘theorems’, ‘deducibility’, ‘consistency’
and ‘inconsistency’, and use the notation  φ, Γ  φ, and so on.
The preceding deﬁnitions merely generalize basic ideas of propositional calculus
to modal languages. Now we come to a genuinely modal concept: normal modal
logics. These logics are the focus of this chapter’s investigations. We initially
restrict our discussion to the basic modal language; the full deﬁnition is given at
the end of the section. As we discussed in Section 1.6, the following deﬁnition is
essentially an abstraction from Hilbert-style approaches to modal proof theory.
Deﬁnition 4.5 A modal logic Λ is normal if it contains the formulas:
(K)
(Dual)
2(p → q) → (2p → 2q),
3p ↔ ¬2¬p,
and is closed under generalization (that is, if Λ φ then Λ 2φ).
Syntactic issues do not play a large role in this book; nonetheless, readers new to
modal logic should study the following lemma and attempt Exercise 4.1.2.
Lemma 4.6 For any normal logic Λ, if Λ φ ↔ ψ then Λ 3φ ↔ 3ψ.
Proof. Suppose Λ φ ↔ ψ. Then Λ φ → ψ and Λ ψ → φ. If we can show that
Λ 3φ → 3ψ and Λ 3ψ → 3φ, the desired result follows. Now, as Λ φ → ψ,
we have Λ ¬ψ → ¬φ, hence by generalization Λ 2(¬ψ → ¬φ). By uniform
substitution into the K axiom we obtain Λ 2(¬ψ → ¬φ) → (2¬ψ → 2¬φ). It
follows by modus ponens that Λ 2¬ψ → 2¬φ. Therefore, Λ ¬2¬φ → ¬2¬ψ,
and two uses of Dual yield Λ 3φ → 3ψ, as desired. As  ψ → φ, an analogous
argument shows that Λ 3ψ → 3φ, and the result follows.
Remark 4.7 The above deﬁnition of normal logics (with or without Dual, depend-
ing on the choice of primitive operators) is probably the most popular way of stip-
ulating what normal logics are. But it is not the only way. Here, for example, is
a simple diamond-based formulation of the concept, which will be useful in our
later algebraic work: a logic Λ is normal if it contains the axioms 3⊥ ↔ ⊥ and
3(p ∨ q) ↔ 3p ∨ 3q, and is closed under the following rule: Λ φ → ψ implies192
4 Completeness
Λ 3φ → 3ψ. This formulation is equivalent to Deﬁnition 4.5, as the reader is
asked to show in Exercise 4.1.2.
Example 4.8
(i) The inconsistent logic is a normal logic.
(ii) PC is not a normal logic.

(iii) If {Λi | i ∈ I} is a collection of normal logics, then i∈I Λi is a normal
logic.
(iv) If F is any class of frames, then ΛF is a normal logic.
(v) If G is any class of general frames, then ΛG is a normal logic. (The reader
is asked to prove this in Exercise 4.1.1.)
Examples 4.8(i) and 4.8(iii) guarantee that there is a smallest normal modal logic
containing any set of formulas Γ . We call this the normal modal logic generated
or axiomatized by Γ . The normal modal logic generated by the empty set is called
K, and it is the smallest (or minimal) normal modal logic: for any normal modal
logic Λ, K ⊆ Λ. If Γ is a non-empty set of formulas we usually denote the
normal logic generated by Γ by KΓ. Moreover, we often make use of Hilbert
axiomatization terminology, referring to Γ as axioms of this logic, and say that the
logic was generated using the rules of proof modus ponens, uniform substitution,
and generalization. We justiﬁed this terminology in Section 1.6, and also asked the
reader to prove that the logic KΓ consists of precisely those formulas that can be
proved in a Hilbert-style derivation from the axioms in Γ using the standard modal
proof rules (see Exercise 1.6.6).
Deﬁning a logic by stating which formulas generate it (that is, extending the
minimal normal logic K with certain axioms of interest) is the usual way of syn-
tactically specifying normal logics. Much of this chapter explores such axiomatic
extensions. Here are some of the better known axioms, together with their tradi-
tional names:
(4)
(T)
(B)
(D)
(.3)
(L)
33p → 3p
p → 3p
p → 23p
2p → 3p
3p ∧ 3q → 3(p ∧ 3q) ∨ 3(p ∧ q) ∨ 3(q ∧ 3p)
2(2p → p) → 2p.
There is a convention for talking about the logics generated by such axioms: if
A1 , . . . , An are axioms then KA1 . . . An is the normal logic generated by A1 , . . . ,
An . But irregularities abound. Many historical names are ﬁrmly entrenched, thus
modal logicians talk of T, B, S4, S4.3, and S5 instead of KT, KB, KT4, KT4.3, and
KT4B respectively. Moreover, many axioms have multiple names. For example,4.1 Preliminaries
K
K4
T
B
KD
S4
S5
K4.3
S4.3
KL
193
the class of all frames
the class of transitive frames
the class of reﬂexive frames
the class of symmetric frames
the class of right-unbounded frames
the class of reﬂexive, transitive frames
the class of frames whose relation is an equivalence relation
the class of transitive frames with no branching to the right
the class of reﬂexive, transitive frames with no branching to the right
the class of ﬁnite transitive trees (weak completeness only)
Table 4.1. Some Soundness and Completeness Results
the axiom we call L (for Löb) is also known as G (for Gödel) and W (for well-
founded); and the axiom we call .3 has also been called H (for Hintikka). We adopt
a fairly relaxed attitude towards naming logics, and use the familiar names as much
as possible.
Now that we know what normal modal logics are, we are ready to introduce the
two fundamental concepts linking the syntactic and semantic perspectives: sound-
ness and completeness.
Deﬁnition 4.9 (Soundness) Let S be a class of frames (or models, or general
frames). A normal modal logic Λ is sound with respect to S if Λ ⊆ ΛS . (Equiva-
lently: Λ is sound with respect to S if for all formulas φ, and all structures S ∈ S,
Λ φ implies S  φ.) If Λ is sound with respect to S we say that S is a class of
frames (or models, or general frames) for Λ.
Table 4.1 lists a number of well-known logics together with classes of frames for
which they are sound. Recall that a right-unboundedness frame (W, R) is a frame
such that ∀x∃y Rxy. Also, a frame (W, R) satisfying ∀x∀y∀z (Rxy ∧ Rxz →
(Ryz ∨ y = z ∨ Rzy)) is said to have no branching to the right.
The soundness claims made in Table 4.1 (with the exception of the last one,
which was shown in Example 3.9) are easily demonstrated. In all cases one shows
that the axioms are valid, and that the three rules of proof (modus ponens, gen-
eralization, and uniform substitution) preserve validity on the class of frames in
question. In fact, the proof rules preserve validity on any class of frames or general
frames (see Exercise 4.1.1), so proving soundness boils down to checking the va-
lidity of the axioms. Soundness proofs are often routine, and when this is the case
we rarely bother to explicitly state or prove them. But the concept of completeness
leads to the problems that will occupy us for the remainder of the chapter.
Deﬁnition 4.10 (Completeness) Let S be a class of frames (or models, or general194
4 Completeness
frames). A logic Λ is strongly complete with respect to S if for any set of formulas
Γ ∪ {φ}, if Γ S φ then Γ Λ φ. That is, if Γ semantically entails φ on S (recall
Deﬁnition 1.35) then φ is Λ-deducible from Γ .
A logic Λ is weakly complete with respect to S if for any formula φ, if S  φ then
Λ φ. Λ is strongly complete (weakly complete) with respect to a single structure
S if Λ is strongly complete (weakly complete) with respect to {S}.
Note that weak completeness is the special case of strong completeness in which Γ
is empty, thus strong completeness with respect to some class of structures implies
weak completeness with respect to that same class. (The converse does not hold,
as we will later see.) Note that the deﬁnition of weak completeness can be refor-
mulated to parallel the deﬁnition of soundness: Λ is weakly complete with respect
to S if ΛS ⊆ Λ. Thus, if we prove that a syntactically speciﬁed logic Λ is both
sound and weakly complete with respect to some class of structures S, we have
established a perfect match between the syntactical and semantical perspectives:
Λ = ΛS . Given a semantically speciﬁed logic ΛS (that is, the logic of some class
of structures S of interest) we often want to ﬁnd a simple collection of formulas Γ
such that ΛS is the logic generated by Γ ; in such a case we sometimes say that Γ
axiomatizes S.
Example 4.11 With the exception of KL, all the logics mentioned in Table 4.1 are
strongly complete with respect to the corresponding classes of frames. However,
KL is only weakly complete with respect to the class of ﬁnite transitive trees. As
we will learn in section 4.4, KL is not strongly complete with respect to this class
of frames, or indeed with respect to any class of frames whatsoever.
These completeness results are among the best known in modal logic, and we will
soon be able to prove them. Together with their soundness counterparts, they con-
stitute perspicuous semantic characterizations of important logics. K4, for exam-
ple, is not just the logic obtained by enriching K with some particular axiom: it is
precisely the set of formulas valid on all transitive frames. There is always some-
thing arbitrary about syntactic presentations; it is pleasant (and useful) to have
these semantic characterizations at our disposal.
We make heavy use, usually without explicit comment, of the following result:
Proposition 4.12 A logic Λ is strongly complete with respect to a class of struc-
tures S iff every Λ-consistent set of formulas is satisﬁable on some S ∈ S. Λ
is weakly complete with respect to a class of structures S iff every Λ-consistent
formula is satisﬁable on some S ∈ S.
Proof. The result for weak completeness follows from the one for strong complete-
ness, so we examine only the latter. To prove the right to left implication we argue4.1 Preliminaries
195
by contraposition. Suppose Λ is not strongly complete with respect to S. Thus
there is a set of formulas Γ ∪ {φ} such that Γ S φ but Γ Λ φ. Then Γ ∪ {¬φ}
is Λ-consistent, but not satisﬁable on any structure in S. The left to right direction
is left to the reader.
To conclude this section, we extend the deﬁnition of normal modal logics to arbi-
trary similarity types.
Deﬁnition 4.13 Assume we are working with a modal language of similarity type
τ . A modal logic in this language is (as before) a set of formulas containing all
tautologies that is closed under modus ponens and uniform substitution. A modal
logic Λ is normal if for every operator  it contains the axiom Ki (for all i such
that 1 ≤ i ≤ ρ()) and the axiom Dual, and is closed under the generalization
rules described below.
The required axioms are obvious polyadic analogs of the earlier K and Dual
axioms:
(r1 , . . ., p → q, . . . , rρ() ) →
→ (r1 , . . . , p, . . . , rρ() ) → (r1 , . . . , q, . . . , rρ() ) .
(Dual) (r1 , . . . , rρ() ) ↔ ¬(¬r1 , . . . , ¬rρ() ).
(Ki)
(Here p, q, r1 , . . . , rρ() are distinct propositional variables, and the occurrences
in Ki of p and q occur in the i-th argument place of .) Finally, for a polyadic
operator , generalization takes the following form:
Λ σ implies Λ (⊥, . . . , σ, . . . , ⊥).
That is, an n-place operator  is associated with n generalization rules, one for
each of its n argument positions.
Note that these axioms and rules do not apply to nullary modalities. Nullary
modalities are rather like propositional variables and – as far as the minimal logic
is concerned – they do not give rise to any axioms or rules.
Deﬁnition 4.14 Let τ be a modal similarity type. Given a set of τ -formulas Γ ,
we deﬁne Kτ Γ, the normal modal logic axiomatized or generated by Γ , to be the
smallest normal modal τ -logic containing all formulas in Γ . Formulas in Γ are
called axioms of this logic, and Γ may be called an axiomatization of Kτ Γ. The
normal modal logic generated by the empty set is denoted by Kτ .
Exercises for Section 4.1
4.1.1 Show that if G is any class of general frames, then Λ G is a normal logic. (To prove
this, you will have to show that the modal proof rules preserve validity on any general
frame.)196
4 Completeness
4.1.2 First, show that the diamond-based deﬁnition of normal modal logics given in Re-
mark 4.7 is equivalent to the box-based deﬁnition. Then, for languages of arbitrary simi-
larity type, formulate a -based deﬁnition of normal modal logics, and prove it equivalent
to the -based one given in Deﬁnition 4.13.
4.1.3 Show that the set of all normal modal logics (in some ﬁxed language) ordered by set
theoretic inclusion forms a complete lattice. That is, prove that every family {Λ i | i ∈ I}
of logics has both an inﬁmum and a supremum. (An inﬁmum is a logic Λ such that Λ ⊆ Λ i
for all i ∈ I, and for any other logic Λ  that has this property, it holds that Λ  ⊆ Λ; the
concept of a supremum is deﬁned analogously, with ‘⊇’ replacing ‘⊆.’)
4.1.4 Show that the normal logic generated by 2(p ∧ 2p → q) ∨ 2(q ∧ 2q → p) is sound
with respect to the class of K4.3 frames (see Table 4.1). Further, show that the normal
modal logic generated by 2(2p → q) ∨ 2(2q → p) is not sound with respect to this class
of frames, but that it is sound with respect to the class of S4.3 frames.
4.2 Canonical Models
Completeness theorems are essentially model existence theorems – that is the con-
tent of Proposition 4.12. Given a normal logic Λ, we prove its strong completeness
with respect to some class of structures by showing that every Λ-consistent set of
formulas can be satisﬁed in some suitable model. Thus the fundamental question
we need to address is: how do we build (suitable) satisfying models?
This section introduces the single most important answer: build models out of
maximal consistent sets of formulas, and in particular, build canonical models. It
is difﬁcult to overstress the importance of this idea. In one form or another it
underlies almost every modal completeness result the reader is likely to encounter.
Moreover, as we will learn in Chapter 5, the idea has substantial algebraic content.
Deﬁnition 4.15 (Λ-MCSs) A set of formulas Γ is maximal Λ-consistent if Γ is Λ-
consistent, and any set of formulas properly containing Γ is Λ-inconsistent. If Γ is
a maximal Λ-consistent set of formulas then we say it is a Λ-MCS.
Why use MCSs in completeness proofs? To see this, ﬁrst note that every point
w in every model M for a logic Λ is associated with a set of formulas, namely
{φ | M, w  φ}. It is easy to check (and the reader should do so) that this
set of formulas is actually a Λ-MCS. That is: if φ is true in some model for Λ,
then φ belongs to a Λ-MCS. Second, if w is related to w in some model M,
then it is clear that the information embodied in the MCSs associated with w and
w is ‘coherently related’. Thus our second observation is: models give rise to
collections of coherently related MCSs.
The idea behind the canonical model construction is to try and turn these obser-
vations around: that is, to work backwards from collections of coherently related
MCSs to the desired model. The goal is to prove a Truth Lemma which tells us that4.2 Canonical Models
197
‘φ belongs to an MCS’ is actually equivalent to ‘φ is true in some model.’ How will
we do this? By building a special model – the canonical model – whose points are
all MCSs of the logic of interest. We will pin down what it means for the informa-
tion in MCSs to be ‘coherently related,’ and use this notion to deﬁne the required
accessibility relations. Crucially, we will be able to prove an Existence Lemma
which states that there are enough coherently related MCSs to ensure the success of
the construction, and this will enable us to prove the desired Truth Lemma.
To carry out this plan, we need to learn a little more about MCSs.
Proposition 4.16 (Properties of MCSs) If Λ is a logic and Γ is a Λ-MCS then:
(i) Γ is closed under modus ponens: if φ, φ → ψ ∈ Γ , then ψ ∈ Γ ;
(ii) Λ ⊆ Γ ;
(iii) for all formulas φ: φ ∈ Γ or ¬φ ∈ Γ ;
(iv) for all formulas φ, ψ: φ ∨ ψ ∈ Γ iff φ ∈ Γ or ψ ∈ Γ .
Proof. Exercise 4.2.1.
As MCSs are to be our building blocks, it is vital that we have enough of them. In
fact, any consistent set of formulas can be extended to a maximal consistent one.
Lemma 4.17 (Lindenbaum’s Lemma) If Σ is a Λ-consistent set of formulas then
there is a Λ-MCS Σ+ such that Σ ⊆ Σ+ .
Proof. Let φ0 , φ1 , φ2 , . . . be an enumeration of the formulas of our language. We
deﬁne the set Σ+ as the union of a chain of Λ-consistent sets as follows:
Σ0 = Σ,
Σn+1 =
Σ+ =
if this is Λ-consistent
Σn ∪ {φn },
Σn ∪ {¬φn }, otherwise
n≥0 Σn .
The proof of the following properties of Σ+ is left as Exercise 4.2.2: (i) Σn is
Λ-consistent, for all n; (ii) exactly one of φ and ¬φ is in Σ+ , for every formula φ;
(iii) if Σ + Λ φ, then φ ∈ Σ + ; and ﬁnally (iv) Σ+ is a Λ-MCS.
We are now ready to build models out of MCSs, and in particular, to build the
very special models known as canonical models. With the help of these structures
we will be able to prove the Canonical Model Theorem, a universal completeness
result for normal logics. We ﬁrst deﬁne canonical models and prove this result for
the basic modal language; at the end of the section we generalize our discussion to
languages of arbitrary similarity type.
Deﬁnition 4.18 The canonical model MΛ for a normal modal logic Λ (in the basic
language) is the triple (W Λ , RΛ , V Λ ) where:198
4 Completeness
(i) W Λ is the set of all Λ-MCSs;
(ii) RΛ is the binary relation on W Λ deﬁned by RΛ wu if for all formulas ψ,
ψ ∈ u implies 3ψ ∈ w. RΛ is called the canonical relation;
(iii) V Λ is the valuation deﬁned by V Λ (p) = {w ∈ W Λ | p ∈ w}. V Λ is called
the canonical (or natural) valuation.
The pair FΛ = (W Λ , RΛ ) is called the canonical frame for Λ.
All three clauses deserve comment. First, the canonical valuation equates the truth
of a propositional symbol at w with its membership in w. Our ultimate goal is to
prove a Truth Lemma which will lift this ‘truth = membership’ equation to arbitrary
formulas.
Second, note that the states of MΛ consist of all Λ-consistent MCSs. The signif-
icance of this is that, by Lindenbaum’s Lemma, any Λ-consistent set of formulas
is a subset of some point in MΛ – hence, by the Truth Lemma proved below, any
Λ-consistent set of formulas is true at some point in this model. In short, the sin-
gle structure MΛ is a ‘universal model’ for the logic Λ, which is why it is called
‘canonical.’
Finally, consider the canonical relation: a state w is related to a state u precisely
when for each formula ψ in u, w contains the information 3ψ. Intuitively, this
captures what we mean by MCSs being ‘coherently related.’ The reader should
compare the present discussion with the account of ultraﬁlter extensions in Chap-
ter 2 – in Chapter 5 we will discuss a unifying framework. In the meantime, the
following lemma shows that we are getting things right:
Lemma 4.19 For any normal logic Λ, RΛ wv iff for all formulas ψ, 2ψ ∈ w
implies ψ ∈ v.
Proof. For the left to right direction, suppose RΛ wv. Further suppose ψ ∈ v. As v
is an MCS, by Proposition 4.16 ¬ψ ∈ v. As RΛ wv, 3¬ψ ∈ w. As w is consistent,
¬3¬ψ ∈ w. That is, 2ψ ∈ w and we have established the contrapositive. We
leave the right to left direction to the reader.
In fact, the deﬁnition of RΛ is exactly what we require; all that remains to be
checked is that enough ‘coherently related’ MCSs exist for our purposes.
Lemma 4.20 (Existence Lemma) For any normal modal logic Λ and any state
w ∈ W Λ , if 3φ ∈ w then there is a state v ∈ W Λ such that RΛ wv and φ ∈ v.
Proof. Suppose 3φ ∈ w. We will construct a state v such that RΛ wv and φ ∈ v.
Let v− be {φ} ∪ {ψ | 2ψ ∈ w}. Then v− is consistent. For suppose not. Then
there are ψ1 , . . . , ψn such that Λ (ψ1 ∧ · · · ∧ ψn ) → ¬φ, and it follows by an
easy argument that Λ 2(ψ1 ∧ · · · ∧ ψn ) → 2¬φ. As the reader should check, the4.2 Canonical Models
199
formula (2ψ1 ∧ · · · ∧ 2ψn ) → 2(ψ1 ∧ · · · ∧ ψn ) is a theorem of every normal
modal logic, hence by propositional calculus, Λ (2ψ1 ∧· · ·∧2ψn ) → 2¬φ. Now,
2ψ1 ∧ · · · ∧ 2ψn ∈ w (for 2ψ1 , . . . , 2ψn ∈ w, and w is an MCS) thus it follows
that 2¬φ ∈ w. Using Dual, it follows that ¬3φ ∈ w. But this is impossible: w is
an MCS containing 3φ. We conclude that v− is consistent after all.
Let v be any MCS extending v− ; such extensions exist by Lindenbaum’s Lemma.
By construction φ ∈ v. Furthermore, for all formulas ψ, 2ψ ∈ w implies ψ ∈ v.
Hence by Lemma 4.19, RΛ wv.
With this established, the rest is easy. First we lift the ‘truth = membership’ equa-
tion to arbitrary formulas:
Lemma 4.21 (Truth Lemma) For any normal modal logic Λ and any formula φ,
MΛ , w  φ iff φ ∈ w.
Proof. By induction on the degree of φ. The base case follows from the deﬁnition
of V Λ . The boolean cases follow from Proposition 4.16. It remains to deal with the
modalities. The left to right direction is more or less immediate from the deﬁnition
of RΛ :
MΛ , w  3φ
iff
iff
only if
∃v (RΛ wv ∧ MΛ , v  φ)
∃v (RΛ wv ∧ φ ∈ v)
(Induction Hypothesis)
3φ ∈ w
(Deﬁnition RΛ ).
For the right to left direction, suppose 3φ ∈ w. By the equivalences above, it
sufﬁces to ﬁnd an MCS v such that RΛ wv and φ ∈ v – and this is precisely what
the Existence Lemma guarantees.
Theorem 4.22 (Canonical Model Theorem) Any normal modal logic is strongly
complete with respect to its canonical model.
Proof. Suppose Σ is a consistent set of the normal modal logic Λ. By Linden-
baum’s Lemma there is a Λ-MCS Σ+ extending Σ. By the previous lemma,
MΛ , Σ +  Σ.
At ﬁrst glance, the Canonical Model Theorem may seem rather abstract. It is a
completeness result with respect to a class of models, not frames, and a rather ab-
stract class at that. (That K4 is complete with respect to the class of transitive
frames is interesting; that it is complete with respect to the singleton class contain-
ing only its canonical model seems rather dull.) But appearances are misleading:
canonical models are by far the most important tool used in the present chapter.
For a start, the Canonical Model Theorem immediately yields the following result:
Theorem 4.23 K is strongly complete with respect to the class of all frames.200
4 Completeness
Proof. By Proposition 4.12, to prove this result it sufﬁces to ﬁnd, for any K-
consistent set of formulas Γ , a model M (based on any frame whatsoever) and a
state w in M such that M, w  Γ . This is easy: simply choose M to be (FK , V K ),
the canonical model for K, and let Γ + be any K-MCS extending Γ . By the previous
lemma, (FK , V K ), Γ +  Γ .
More importantly, it is often easy to get useful information about the structure of
canonical frames. For example, as we will learn in the next section, the canonical
frame for K4 is transitive – and this immediately yields the (more interesting) re-
sult that K4 is complete with respect to the class of transitive frames. Even when
a canonical model is not as cleanly structured as we would like, it still embod-
ies a vast amount of information about its associated logic; one of the important
themes pursued later in the chapter is how to make use of this information in-
directly. Furthermore, canonical models are mathematically natural. As we will
learn in Chapter 5, from an algebraic perspective canonical models are not abstract
oddities: indeed, they are precisely the structures one is lead to by considering the
ideas underlying the Stone Representation Theorem.
To conclude this section we sketch the generalizations required to extend the
results obtained so far to languages of arbitrary similarity types.
Deﬁnition 4.24 Let τ be a modal similarity type, and Λ a normal modal logic in
Λ, V Λ)
the language over τ . The canonical model MΛ = (W Λ , R
∈τ for Λ has
Λ
Λ
W and V as deﬁned in Deﬁnition 4.18, while for an n-ary operator  ∈ τ the
Λ ⊆ (W Λ )n+1 is deﬁned by RΛ wu . . . u if for all formulas ψ ∈ u ,
relation R
1
n
1
1

. . . , ψn ∈ un we have (ψ1 , . . . , ψn ) ∈ w.
There is an analog of Lemma 4.19.
Λ wu . . . u iff for all formulas
Lemma 4.25 For any normal modal logic Λ, R
1
n
ψ1 , . . . , ψn , (ψ1 , . . . , ψn ) ∈ w implies that for some i such that 1 ≤ i ≤ n,
ψi ∈ ui .
Proof. See Exercise 4.2.3.
Now for the crucial lemma – we must show that enough coherently related MCSs
exist. This requires a more delicate approach than was needed for Lemma 4.20.
Lemma 4.26 (Existence Lemma) Suppose (ψ1 , . . . , ψn ) ∈ w. Then there are
u1 , . . . , un such that ψ1 ∈ u1 , . . . , ψn ∈ un and RΛ wu1 . . . un .
Proof. The proof of Lemma 4.20 establishes the result for any unary operators in
the language, so it only remains to prove the (trickier) case for modalities of higher
arity. To keep matters simple, assume that  is binary; this illustrates the key new
idea needed.4.3 Applications
201
So, suppose (ψ1 , ψ2 ) ∈ w. Let φ0 , φ1 , . . . enumerate all formulas. We con-
struct two sequences of sets of formulas
{ψ1 } = Π0 ⊆ Π1 ⊆ · · · and {ψ2 } = Σ0 ⊆ Σ1 ⊆ · · ·
such that all Πi and Σi are ﬁnite and consistent, Πi+1 is either Πi ∪ {φi } or


Πi ∪{¬φi }, and similarly for Σi+1 . Moreover, putting πi := Πi and σi := Σi ,
we will have that (πi , σi ) ∈ w.
The key step in the inductive construction is
(πi , σi ) ∈ w ⇒  (πi ∧ (φi ∨ ¬φi ), σi ∧ (φi ∨ ¬φi )) ∈ w
⇒  ((πi ∧ φi ) ∨ (πi ∧ ¬φi ), (σi ∧ φi ) ∨ (σi ∧ ¬φi )) ∈ w
⇒ one of the formulas (πi ∧ [¬]φi , σi ∧ [¬]φi ) is in w.
If, for example, (πi ∧ φi , σi ∧ ¬φi ) ∈ w, we take Πi+1 := Πi ∪ {φi }, Σi+1 :=
Σi ∪ {¬φi }. Under this deﬁnition, all Πi and Σi have the required properties.
Finally, let u1 = i Πi and u2 = i Σi . It is easy to see that u1 , u2 are Λ-MCSs
Λ wu u , as required.
and R
1 2
With this lemma established, the real work has been done. The Truth Lemma
and the Canonical Model Theorem for general modal languages are now obvious
analogs of Lemma 4.21 and Theorem 4.22. The reader is asked to state and prove
them in Exercise 4.2.4.
Exercises for Section 4.2
4.2.1 Show that all MCSs have the properties stated in Proposition 4.16. In addition, show
that if Σ and Γ are distinct MCSs, then there is at least one formula φ such that φ ∈ Σ and
¬φ ∈ Γ .
4.2.2 Lindenbaum’s Lemma is not fully proved in the text. Give proofs of the four claims
made at the end of our proof sketch.
4.2.3 Prove Lemma 4.25. (This is a good way of getting to grips with the deﬁnition of
normality for modal languages of arbitrary similarity type.)
4.2.4 State and prove the Truth Lemma and the Canonical Model Theorem for languages
of arbitrary similarity type. Make sure you understand the special case for nullary modali-
ties (recall that we have no special axioms or rules of proof for these).
4.3 Applications
In this section we put canonical models to work. First we show how to prove
the frame completeness results noted in Example 4.11 using a simple and uniform
method of argument. This leads us to isolate one of most important concepts of
modal completeness theory: canonicity. We then switch to the basic temporal202
4 Completeness
language and use similar arguments to prove two important temporal completeness
results. We conclude with a statement of the Sahlqvist Completeness Theorem,
which we will prove in Chapter 5.
Suppose we suspect that a normal modal logic Λ is strongly complete with re-
spect to a class of frames F; how should we go about proving it? Actually, there is
no infallible strategy. (Indeed, as we will learn in the following section, many nor-
mal modal logics are not complete with respect to any class of frames whatsoever.)
Nonetheless, a very simple technique works in a large number of interesting cases:
simply show that the canonical frame for Λ belongs to F. We call such proofs
completeness-via-canonicity arguments, for reasons which will soon become clear.
Let us consider some examples.
Theorem 4.27 The logic K4 is strongly complete with respect to the class of tran-
sitive frames.
Proof. Given a K4-consistent set of formulas Γ , it sufﬁces to ﬁnd a model (F, V )
and a state w in this model such that (1) (F, V ), w  Γ , and (2) F is transitive.
Let (W K4 , RK4 , V K4 ) be the canonical model for K4 and let Γ + be any K4-
MCS extending Γ . By Lemma 4.21, (W K4 , RK4 , V K4 ), Γ +  Γ so step (1) is
established. It remains to show that (W K4 , RK4 ) is transitive. So suppose w, v
and u are points in this frame such that RK4 wv and RK4 vu. We wish to show that
RK4 wu. Suppose φ ∈ u. As RK4 vu, 3φ ∈ v, so as RK4 wv, 33φ ∈ w. But w is
a K4-MCS, hence it contains 33φ → 3φ, thus by modus ponens it contains 3φ.
Thus RK4 wu.
In spite of its simplicity, the preceding result is well worth reﬂecting on. Two
important observations should be made.
First, the proof actually establishes something more general than the theorem
claims: namely, that the canonical frame of any normal logic Λ containing 33p →
3p is transitive. The proof works because all MCSs in the canonical frame contain
the 4 axiom; it follows that the canonical frame of any extension of K4 is transitive,
for all such extensions contain the 4 axiom.
Second, the result suggests that there may be a connection between the structure
of canonical frames and the frame correspondences studied in Chapter 3. We know
from our previous work that 33p → 3p deﬁnes transitivity – and now we know
that it imposes this property on canonical frames as well.
Theorem 4.28 T, KB and KD are strongly complete with respect to the classes of
reﬂexive frames, of symmetric frames, and of right-unbounded frames, respectively.
Proof. For the ﬁrst claim, it sufﬁces to show that the canonical model for T is
reﬂexive. Let w be a point in this model, and suppose φ ∈ w. As w is a T-MCS,
φ → 3φ ∈ w, thus by modus ponens, 3φ ∈ w. Thus RT ww.4.3 Applications
203
For the second claim, it sufﬁces to show that the canonical model for KB is
symmetric. Let w and v be points in this model such that RKB wv, and suppose
that φ ∈ w. As w is a KB-MCS, φ → 23φ ∈ w, thus by modus ponens 23φ ∈ w.
Hence by Lemma 4.19, 3φ ∈ v. But this means that RKB vw, as required.
For the third claim, it sufﬁces to show that the canonical model for KD is right-
unbounded. (This is slightly less obvious than the previous claims since it requires
an existence proof.) Let w be any point in the canonical model for KD. We
must show that there exists a v in this model such that RKD wv. As w is a KD-
MCS it contains 2p → 3p, thus by closure under uniform substitution it contains
2 → 3. Moreover, as  belongs to all normal modal logics, by generalization
2 does too; so 2 belongs to KD, hence by modus ponens 3 ∈ w. Hence,
by the Existence Lemma, w has an RKD successor v.
Once again, these results hint at a link between deﬁnability and the structure of
canonical frames: after all, T deﬁnes reﬂexivity, B deﬁnes symmetry, and D right
unboundedness. And yet again, the proofs actually establish something more gen-
eral than the theorem states: the canonical frame of any normal logic containing
T is reﬂexive, the canonical frame of any normal logic containing B is symmetric,
and the canonical frame of any normal logic containing D is right unbounded. This
allows us to ‘add together’ our results. Here are two examples:
Theorem 4.29 S4 is strongly complete with respect to the class of reﬂexive, tran-
sitive frames. S5 is strongly complete with respect to the class of frames whose
relation is an equivalence relation.
Proof. The proof of Theorem 4.27 shows that the canonical frame of any normal
logic containing the 4 axiom is transitive, while the proof of the ﬁrst clause of
Theorem 4.28 shows that the canonical frame of any normal logic containing the
T axiom is reﬂexive. As S4 contains both axioms, its canonical frame has both
properties, thus the completeness result for S4 follows.
As S5 contains both the 4 and the T axioms, it also has a reﬂexive, transitive
canonical frame. As it also contains the B axiom (which by the proof of the second
clause of Theorem 4.28 means that its canonical frame is symmetric), its canonical
relation is an equivalence relation. The desired completeness result follows.
As these examples suggest, canonical models are an important tool for proving
frame completeness results. Moreover, their utility evidently hinges on some sort
of connection between the properties of canonical frames and the frame corre-
spondences studied earlier. Let us introduce some terminology to describe this
important phenomenon.
Deﬁnition 4.30 (Canonicity) A formula φ is canonical if, for any normal logic Λ,
φ ∈ Λ implies that φ is valid on the canonical frame for Λ. A normal logic Λ is204
4 Completeness
canonical if its canonical frame is a frame for Λ. (That is, Λ is canonical if for all
φ such that Λ φ, φ is valid on the canonical frame for Λ.)
Clearly 4, T, B and D axioms are all canonical formulas. For example, any normal
logic Λ containing the 4 axiom has a transitive canonical frame, and the 4 axiom is
valid on transitive frames. Similarly, any modal logic containing the B axiom has
a symmetric canonical frame, and the B axiom is valid on symmetric frames.
Moreover K4, T, KB, KD, S4 and S5 are all canonical logics. Our previous
work has established that all the axioms involved are valid on the relevant canonical
frames. But (see Exercise 4.1.1) modus ponens, uniform substitution, and general-
ization preserve frame validity. It follows that every formula in each of these logics
is valid on that logic’s canonical frame. In general, to show that KA1 . . . An is a
canonical logic it sufﬁces to show that A1 , . . . , An are canonical formulas.
Deﬁnition 4.31 (Canonicity for a Property) Let φ be a formula, and P be a prop-
erty. If the canonical frame for any normal logic Λ containing φ has property P ,
and φ is valid on any class of frames with property P , then φ is canonical for P .
For example, we say that the 4 axiom is canonical for transitivity, because the pres-
ence of 4 forces canonical frames to be transitive, and 4 is valid on all transitive
frames.
Let us sum up the discussion so far. Many important frame completeness results
can be proved straightforwardly using canonical models. The key idea in such
proofs is to show that the relevant canonical frame has the required properties.
Such proofs boil down to the following task: showing that the axioms of the logic
are canonical for the properties we want (which is why we call them completeness-
via-canonicity arguments).
Now for some rather different application of completeness-via-canonicity argu-
ments. The theorems just proved were syntactically driven: we began with syn-
tactically speciﬁed logics (for example K4 and T) and showed that they could be
semantically characterized as the logics of certain frame classes. Canonical models
are clearly useful for such proofs – but how do they fare when proving semantically
driven results? That is, suppose F is a class of frames we ﬁnd interesting, and we
have isolated a set of axioms which we hope generates ΛF . Can completeness-via-
canonicity arguments help establish their adequacy?
As such semantically driven questions are typical of temporal logic, let us switch
to the basic temporal language. Recall from Example 1.14 that this language has
two diamonds, F and P , whose respective duals are G and H. The F operator
looks forwards along the ﬂow of time, and P looks backwards. Furthermore, recall
from Example 1.25 that we are only interested in the frames for this language in
which the relations corresponding to F and P are mutually converse. That is, a4.3 Applications
205
bidirectional frame is a triple (W, {RP , RF }) such that
RP = {(y, x) | (x, y) ∈ RF }.
Recall that by convention we present bidirectional frames as unimodal frames
(T, R); in such presentations we understand that RF = R and RP = Rˇ. The
class of all bidirectional frames is denoted by Ft , and a bidirectional model is a
model whose underlying frame belongs to Ft .
So, what is a temporal logic? As a ﬁrst step towards answering this we deﬁne:
Deﬁnition 4.32 The minimal temporal logic ΛFt is {φ | Ft  φ}.
That is, the minimal temporal logic contains precisely the formulas valid on all
bidirectional frames. This is a semantic deﬁnition, and, given our interest in frames,
a sensible one. But can we axiomatize ΛFt ? That is, can we give ΛFt a simple syn-
tactic characterization? First, note that ΛFt is not identical to the minimal normal
logic in the basic temporal language. As we noted in Example 1.29(v), for any
frame F = (W, {RF , RP }) we have that
F  (q → HF q) ∧ (q → GP q) iff F ∈ Ft .
The two conjuncts deﬁne the ‘mutually converse’ property enjoyed by RF and
RP . Clearly, both conjuncts belong to ΛFt . Equally clearly, they do not belong to
the minimal normal logic in the basic temporal language. Nonetheless, although
ΛFt is stronger, it is not much stronger: the only axioms we need to add are these
converse-deﬁning conjuncts.
Deﬁnition 4.33 A normal temporal logic Λ is a normal modal logic (in the basic
temporal language) that contains p → GP p and p → HF p (the converse axioms).
The smallest normal temporal logic is called Kt . We usually call normal temporal
logics tense logics.
Note that in the basic temporal language the K axioms are G(p → q) → (Gp →
Gq) and H(p → q) → (Hp → Hq), and the Dual axioms are F p ↔ ¬G¬p and
P p ↔ ¬H¬p. Closure under generalization means that if Λ φ then Λ Gφ and
Λ Hφ.
We want to show that Kt generates exactly the formulas in ΛFt . Soundness is
immediate: clearly Kt ⊆ ΛFt . We show completeness using a canonicity argument.
So, what are canonical models for tense logics? Nothing new: simply the following
instance of Deﬁnition 4.24:
Deﬁnition 4.34 The canonical model for a tense logic Λ is the structure MΛ =
(T Λ , {RPΛ , RFΛ }, V Λ ) where:
(i) T Λ is the set of all Λ-MCSs.206
4 Completeness
(ii) RPΛ is the binary relation on T Λ deﬁned by RPΛ ts if for all formulas φ, φ ∈ s
implies P φ ∈ t.
(iii) RFΛ is the binary relation on T Λ deﬁned by RFΛ ts if for all formulas φ, φ ∈ s
implies F φ ∈ t.
(iv) V Λ is the valuation deﬁned by V Λ (p) = {t ∈ T Λ | p ∈ t}.
We immediately inherit a number of results from the previous section, such as an
Existence Lemma, a Truth Lemma, and a Canonical Model Theorem telling us that
each tense logic is complete with respect to its canonical model. This is very useful
– but it is not quite enough. We want to show that Kt generates all the temporal
validities. None of the results just mentioned allow us to conclude this, and for a
very obvious reason: we do not yet know whether canonical frames for tense logics
are bidirectional frames! In fact they are, and this is where the converse axioms
come into play. As the next lemma shows, these axioms are canonical; they force
RPΛ and RFΛ to be mutually converse.
Lemma 4.35 For any tense logic Λ, if RPΛ ts then RFΛ st, and if RFΛ ts then RPΛ st.
Proof. Rather like the proof that B is canonical for symmetry (see Theorem 4.28).
We leave it to the reader as Exercise 4.3.2.
Thus canonical frames of tense logics are bidirectional frames, so from now on we
present them as pairs (T Λ , RΛ ). Moreover, we now have the desired result:
Corollary 4.36 Kt is strongly complete with respect to the class of all bidirec-
tional frames, and Kt = ΛFt .
Proof. Kt is strongly complete with respect to its canonical model. As we have just
seen, this model is based on a bidirectional frame, so the strong frame complete-
ness result follows. Strong completeness implies weak completeness, so ΛFt ⊆ Kt .
The inclusion Kt ⊆ ΛFt has already been noted.
With this basic result established, we are ready to start a semantically driven ex-
ploration of tense logic. That is, we can now attempt to capture the logics of ‘time-
like’ classes of frames as axiomatic extensions of Kt . Here we limit ourselves to
the following question: how can the temporal logic of dense unbounded weak total
orders be axiomatized? From the point of view of tense logic, this is an interesting
problem: dense frames and totally ordered frames both play an important role in
modeling temporal phenomena. Moreover, as we will see, there is an instructive
problem that must be overcome if we build totally ordered models. This will give
us a gentle initiation to the fundamental difﬁculty faced by semantically driven
completeness results, a difﬁculty which we will explore in more detail later in the
chapter.4.3 Applications
207
Deﬁnition 4.37 A bidirectional frame (T, R) is dense if there is a point between
any two related points (∀xy (Rxy → ∃z (Rxz ∧ Rzy))). It is right-unbounded if
every point has a successor, left-unbounded if every point has a predecessor, and
unbounded if it is both right- and left-unbounded. It is trichotomous if any two
points are equal or are related one way or the other (∀xy (Rxy ∨ x = y ∨ Ryx)),
and a weak total order (or weakly linear) if it is both transitive and trichotomous.
We call a frame with all these properties a DUWTO-frame.
Note that weakly linear frames are allowed to contain both reﬂexive and irreﬂexive
points. Indeed, they are allowed to contain non-empty subsets S such that for all
s, s ∈ S, Rss . Thus they do not fully model the idea of linearity. Linearity is
better captured by the class of strict total orders, which are transitive, trichotomous
and irreﬂexive. Building strictly totally ordered models is harder than building
weakly totally ordered models; we examine the problem in detail later in the chap-
ter.
Our ﬁrst task is to select suitable axioms. Three of the choices are fairly obvious:
(4)
FFp → Fp
(Dr ) Gp → F p
(Dl ) Hp → P p
Note that F F p → F p is simply the 4 axiom in tense logical notation. We know
(by the proof of Theorem 4.27) that it is canonical for transitivity, hence choosing
it as an axiom ensures the transitive canonical frame we want. Next, Dr (a tense
logical analog of the D axiom) is (by the proof of the third claim of Theorem 4.28)
canonical for right-unboundedness. Similarly, its backwards-looking companion
Hp → P p is canonical for left-unboundedness, so we obtain an unbounded canon-
ical frame without difﬁculty.
What about density? Here we are in luck. The following formula is canonical
for density:
(den)
Fp → FFp
This is worth a lemma, since the proof is not trivial. (Note that density is a
universal-existential property, rather than a universal property like transitivity or
reﬂexivity. This means that proving canonicity requires establishing the existence
of certain MCSs.)
Lemma 4.38 F p → F F p is canonical for density.
Proof. Let Λ be any tense logic containing F p → F F p, let (TΛ , RΛ ) be its canon-
ical frame, and let t and t be points in this frame such that RΛ tt . We have to
show that there is a Λ-MCS s such that RΛ ts and RΛ st . If we could show that
{φ | Gφ ∈ t} ∪ {F ψ | ψ ∈ t } was consistent we would have the desired result208
4 Completeness
(for by the Lemmas 4.19 and 4.35, any MCS extending this set would be a suitable
choice for s).
So suppose for the sake of contradiction that this set is not consistent. Then, for
some ﬁnite set of formulas φ1 , . . . , φm , ψ1 , . . . , ψn from this set,
Λ (φ1 ∧ · · · ∧ φm ∧ F ψ1 ∧ · · · ∧ F ψn ) →⊥ .
Deﬁne φ to be φ1 ∧ · · · ∧ φm and ψ to be ψ1 ∧ · · · ∧ ψn . Note that ψ ∈ t .


Now, Λ F ψ → F ψ1 ∧· · ·∧F ψn , hence Λ φ∧F
ψ →⊥, hence Λ φ → ¬F ψ,
 Because Gφ1 , . . . , Gφm ∈ t, we have that Gφ ∈ t
and hence Λ Gφ → G¬F ψ.

too, hence G¬F ψ ∈ t, and hence ¬G¬F ψ ∈ t. That is, F F ψ ∈ t. But this
means that F ψ ∈ t, as (by uniform substitution in den) Fψ → F F ψ ∈ t. But
now we have a contradiction: as ψ ∈ t and RΛ tt , F ψ must be in t. We conclude
that {φ | Gφ ∈ t} ∪ {F ψ | ψ ∈ t } is consistent after all. (Note that this proof
makes no use of the converse axioms, thus we have also proved that 3p → 33p
is canonical for density.)
So it only remains to ensure trichotomy – but here we encounter an instructive
difﬁculty. Because modal (and temporal) validity is preserved under the formation
of disjoint unions (see Theorem 3.14) no formula of tense logic deﬁnes trichotomy.
Moreover, a little experimentation will convince the reader that canonical frames
may have disjoint point generated subframes; such canonical frames are clearly
not trichotomous. In short, to prove the desired completeness result we need to
build a model with a property for which no modal formula is canonical. This is
the problem we encounter time and time again when proving semantically driven
results.
In the present case, a little lateral thinking leads to a solution. First, let us get rid
of a possible preconception. Until now, we have always used the entire canonical
model – but we do not need to do this. A point generated submodel sufﬁces. More
precisely, if MΛ , w  Γ , then as modal satisfaction is preserved in generated
submodels (see Proposition 2.6) S, w  Γ , where S is the submodel of MΛ
generated by w.
The observation is trivial, but its consequences are not. By restricting our at-
tention to point-generated submodels, we increase the range of properties we can
impose. In particular, we can impose trichotomy on point-generated submodels.
We met the relevant axioms when working with the basic modal language. From
our discussion of S4.3 and K4.3 (in particular, Exercise 4.3.3) we know that
(.3r )
(F p ∧ F q) → F (p ∧ F q) ∨ F (p ∧ q) ∨ F (q ∧ F p)
is canonical for no-branching-to-the-right. Analogously
(.3l )
(P p ∧ P q) → P (p ∧ P q) ∨ P (p ∧ q) ∨ P (q ∧ P p).4.3 Applications
209
is canonical for no-branching-to-the-left. Call a frame with no branching to the left
or right a non-branching frame.
Proposition 4.39 Any trichotomous frame (T, R) is non-branching. Furthermore,
if R is transitive and non-branching and t ∈ T , then the subframe of (T, R) gen-
erated by t is trichotomous.
Proof. Trivial – though the reader should recall that when forming generated sub-
frames for the basic temporal language, we generate on both the relation corre-
sponding to F and that corresponding to P . That is, we generate both forwards
and backwards along R.
In short, although no formula is canonical for trichotomy, there is a good ‘ap-
proximation’ to it (namely, the non-branching property) for which we do have a
canonical formula (namely, the conjunction of .3l and .3r ). With this observed, the
desired result is within reach.
Deﬁnition 4.40 Let Kt Q be the smallest tense logic containing 4, Dl , Dr , den, .3l
and .3r .
Theorem 4.41 Kt Q is strongly complete with respect to the class of DUWTO-
frames.
Proof. If Γ is a Kt Q-consistent set of formulas, extend it to a Kt Q-MCS Γ + . Let
M be the canonical model for Kt Q, and let S be the submodel of M generated
by Γ + . As we just noted, S, Γ +  Γ . Moreover, the frame underlying S is
a DUWTO-frame as required. First, as Kt Q contains axioms that are canonical
for transitivity, unboundedness, and density, M has these properties; it is then not
difﬁcult to show that S has them too. Moreover, as the conjunction of .3l and .3r
is canonical for non-branching, M is non-branching and S trichotomous.
To conclude, two important remarks. First, the need to build models possessing
properties for which no formula is canonical is the fundamental difﬁculty facing
semantically driven results. In the present case, a simple idea enabled us to bypass
the problem – but we will not always be so lucky and in the second part of the
chapter we develop more sophisticated techniques for tackling the issue.
Second, the relationships between completeness, canonicity and correspondence
are absolutely fundamental to the study of normal modal logics. These relation-
ships are further discussed in the following section, and explored algebraically in
Chapter 5, but let us immediately mention one of the most elegant positive results
in the area: the Sahlqvist Completeness Theorem. In Chapter 3 we proved the
Sahlqvist Correspondence Theorem: every Sahlqvist formula deﬁnes a ﬁrst-order
class of frames. Here is its completeness theoretic twin, which we will prove in
Chapter 5:210
4 Completeness
Theorem 4.42 Every Sahlqvist formula is canonical for the ﬁrst-order property
it deﬁnes. Hence, given a set of Sahlqvist axioms Σ, the logic KΣ is strongly
complete with respect to the class of frames FΣ (that is, the ﬁrst-order class of
frames deﬁned by Σ).
This is an extremely useful result. Most commonly encountered axioms in the
basic modal language are Sahlqvist (the Löb and McKinsey formulas are the ob-
vious exceptions) thus it provides an immediate answer to a host of completeness
problems. Moreover, like the Sahlqvist Correspondence Theorem, the Sahlqvist
Completeness Theorem applies to modal languages of arbitrary similarity type.
Finally, the theorem generalizes to a number of extended modal logics, most no-
tably D-logic (which we introduce in Chapter 7). Note that Kracht’s Theorem (see
Chapter 3) can be viewed as providing a sort of ‘converse’ to Sahlqvist’s result, for
it gives us a way of computing formulas that are canonical for certain ﬁrst-order
classes of frames.
Exercises for Section 4.3
4.3.1 Let 1.1 be the axiom 3p → 2p. Show that K1.1 is sound and strongly complete
with respect to the class of all frames (W, R) such that R is a partial function.
4.3.2 Let Λ be a normal temporal logic containing the axioms p → GP p and p → HF p.
Show that if RPΛ ts then RFΛ st, and if RFΛ ts then RPΛ st.
4.3.3 Use canonical models to show that K4.3 is strongly complete with respect to the class
of frames that are transitive and have no branching to the right. Then, by proving suitable
completeness results (and making use of the soundness results proved in Exercise 4.1.4),
show that the normal logic axiomatized by 4 and 2(p ∧ 2p → q) ∨ 2(q ∧ 2q → p) is
K4.3. Try proving the equivalence of these logics syntactically.
Formulate and prove similar results for S4.3.
4.3.4 Prove directly that 32p → 23p is canonical for the Church-Rosser property.
4.3.5 Let W5 be the formula 32p → (p → 2p), and let S4W5 be the smallest normal
logic extending S4 that contains W5. Find a simple class of frames that characterizes this
logic.
4.3.6 Show that S5 is complete with respect to the the class of globally related frames,
that is, those frames (W, R) in which R connects any two points.
4.3.7 Consider a similarity type τ with one binary operator . For each of the following
Sahlqvist formulas, ﬁrst compute the (global) ﬁrst-order correspondent. Then, give a direct
proof that the modal formula is canonical for the corresponding ﬁrst-order property.
(a) pq → qp,
(b) (pq)r → p(qr),
(c) ((q¬(pq)) ∧ p) → ⊥.4.4 Limitative Results
211
4.4 Limitative Results
Although completeness-via-canonicity is a powerful method, it is not infallible.
For a start, not every normal modal logic is canonical. Moreover, not every normal
logic is the logic of some class of frames. In this section we prove both claims and
discuss their impact on modal completeness theory.
We ﬁrst demonstrate the existence of non-canonical logics. We will show that
KL, the normal modal logic generated by the Löb axiom 2(2p → p) → 2p,
is not canonical. We prove this by showing that KL is not sound and strongly
complete with respect to any class of frames. Now, every canonical logic is sound
and strongly complete with respect to some class of frames. (For suppose Λ is a
canonical logic and Γ is a Λ-consistent set of formulas. By the Truth Lemma, Γ is
satisﬁable on FΛ ; as Λ is canonical, FΛ is a frame for Λ.) Hence if KL is not sound
and strongly complete with respect to any class of frames, it cannot be canonical
either.
Theorem 4.43 KL is not sound and strongly complete with respect to any class of
frames, and hence it is not canonical.
Proof. Let Γ be {3q1 } ∪ {2(qi → 3qi+1 ) | 1 ≤ i ∈ ω}. We will show that Γ is
KL-consistent, and that no model based on a KL-frame can satisfy all formulas in
Γ at a single point. The theorem follows immediately.
To show that Γ is consistent, it sufﬁces to show that every ﬁnite subset Ψ of Γ is
consistent. Given any such Ψ , for some natural number n there is a ﬁnite set Φ of
the form {3q1 } ∪ {2(qi → 3qi+1 ) | 1 ≤ i < n} such that Ψ ⊆ Φ ⊂ Γ . We show
that Φ, and hence Ψ , is consistent.
 be the conjunction of all the formulas in Φ. To show that Φ
 is KL-
Let Φ
consistent, it sufﬁces to show that it can be satisﬁed in a model based on a frame for
 is not valid on all frames for KL, and hence is not one
KL, for this shows that ¬Φ
of its theorems. Let F be the frame consisting of {0, . . . , n} in their usual order; as
this is a transitive, converse well-founded frame, by Example 3.9 it is a frame for
KL. Let M be any model based on F such that for all 1 ≤ i ≤ n, V (qi ) = {i}.
 and Φ
 is KL consistent.
Then M, 0  Φ
Next, suppose for the sake of a contradiction that KL is sound and strongly com-
plete with respect to some class of frames F; note that as KL is not the inconsistent
logic, F must be non-empty. Thus any KL-consistent set of formulas can be satis-
ﬁed at some point in a model based on a frame in F. In particular, there is a model
M based on a frame in F and a point w in M such that M, w  Γ . But this is
impossible: because M, w  Γ , we can inductively deﬁne an inﬁnite path through
M starting at w; however as M is based on a frame for KL it cannot contain such
inﬁnite paths. Hence KL is not sound and strongly complete with respect to any
class of frames, and so cannot be canonical.212
4 Completeness
Remark 4.44 A normal logic Λ is said to be compact when any Λ-consistent set
Σ can be satisﬁed in a frame for Λ at a single point. So the above proof shows that
KL is not compact. Note that a non-compact logic cannot be canonical, and cannot
be sound and strongly complete with respect to any class of frames. We will see a
similar compactness failure when we examine PDL in Section 4.8.
What are we to make of this result? The reader should not jump to the conclusion
that it is impossible to characterize KL as the logic of some class of frames. Al-
though no strong frame completeness result is possible, as we noted in Table 4.1
there is an elegant weak frame completeness result for KL, namely:
Theorem 4.45 KL is weakly complete with respect to the class of all ﬁnite transi-
tive trees.
Proof. The proof uses the ﬁnitary methods studied later in the chapter. The reader
is asked to prove the theorem in Exercises 4.8.7 and 4.8.8.
Thus KL is the logic of all ﬁnite transitive trees – and there exist non-canonical
but (weakly) complete normal logics. We conclude that, powerful though it is, the
completeness-via-canonicity method cannot handle all interesting frame complete-
ness results.
Let us turn to the second conjecture: are all normal logics weakly complete with
respect to some class of frames? No: incomplete normal logics exist.
Deﬁnition 4.46 Let Λ be a normal modal logic. Λ is (frame) complete if there is a
class of frames F such that Λ = ΛF , and (frame) incomplete otherwise.
We now demonstrate the existence of incomplete logics in the basic temporal lan-
guage. The demonstration has three main steps. First, we introduce a tense logic
called Kt Tho and show that it is consistent. Second, we show that no frame
for Kt Tho can validate the McKinsey axiom (which in tense logical notation is
GF φ → F Gφ). It is tempting to conclude that Kt ThoM, the smallest tense logic
containing both Kt Tho and the McKinsey axiom, is the inconsistent logic. Sur-
prisingly, this is not the case. Kt ThoM is consistent – and hence is not the tense
logic of any class of frames at all. We prove this in the third step with the help of
general frames.
Kt Tho is the tense logic generated by the following axioms:
(.3r )
(Dr )
(Ll )
F p ∧ F q → F (p ∧ F q) ∨ F (p ∧ q) ∨ F (F p ∧ q)
Gp → F p
H(Hp → p) → Hp
As we have already seen, the ﬁrst two axioms are canonical for simple ﬁrst-order
conditions (no branching to the right, and right-unboundedness, respectively). The4.4 Limitative Results
213
third axiom is simply the Löb axiom written in terms of the backwards looking
operator H; it is valid on precisely those frames that are transitive and contain no
inﬁnite descending paths. (Note that such frames cannot contain reﬂexive points.)
Let Kt Tho be the tense logic generated by these three axioms. As all three axioms
are valid on the natural numbers, Kt Tho is consistent. If (T, R) is a frame for
Kt Tho and t ∈ T , then {u ∈ T | Rtu} is a right-unbounded strict total order.
Now for the second step. Let Kt ThoM be the smallest tense logic containing
Kt Tho and the McKinsey axiom GF p → F Gp. What are the frames for this
enriched logic? The answer is: none at all, or, to put it another way, Kt ThoM
deﬁnes the empty class of frames. To see this we need the concept of coﬁnality.
Deﬁnition 4.47 Let (U, <) be a strict total order and S ⊆ U . S is coﬁnal in U if
for every u ∈ U there is an s ∈ S such that u < s.
For example, both the even numbers and the odd numbers are coﬁnal in the natural
numbers. Indeed, they are precisely the kind of coﬁnal subsets we will use in the
work that follows: mutually complementary coﬁnal subsets.
Lemma 4.48 Let T be any frame for Kt Tho. Then T  GF p → F Gp.
Proof. Let t be any point in T, let U = {u ∈ T | Rtu}, and let < be the restriction
of R to U . As T validates all the Kt Tho axioms, (U, <) is a right-unbounded strict
total order. Suppose we could show that there is a non-empty proper subset S of
U such that both S and U \S are coﬁnal in U . Then the lemma would be proved,
for we would merely need to deﬁne a valuation V on T such that V (p) = S, and
(T, V ), t  GF p → F Gp.
Such subsets S of U exist by (3.18) in Example 3.57. For a more direct proof,
take a cardinal κ that is larger than the size of U . By ordinal induction, we will
deﬁne a sequence of pairs of sets (Rα , Sα )α≤κ such that Rκ ∩ Sκ = ∅ and both
Rκ and Sκ are coﬁnal. We can easily prove the lemma from this by taking S = Sκ .
The deﬁnition is as follows:
(i) For α = 0, take some points r0 and s0 in U such that r0 < s0 and deﬁne
R0 = {r0 } and S0 = {s0 }.
(ii) If α is a successor ordinal β + 1, then distinguish two cases:
(a) if Rβ or Sβ is coﬁnal, then deﬁne Rα = Rβ and Sα = Sβ ,
(b) if neither Rβ nor Sβ is coﬁnal, then take some upper bound rβ of
Sβ (that is, rβ > s for all s ∈ Sβ ), take some sβ bigger than rβ and
deﬁne Rα = Rβ ∪ {rβ } and Sα = Sβ ∪ {sβ }.
(iii) If α is a limit ordinal, then deﬁne Rα =
β<α Rβ and Sα =
β<α Sβ .
It is easy to prove that Rα ∩ Sα = ∅ for every ordinal α ≤ κ, so it remains to
be shown that both Rκ and Sκ are coﬁnal. The key to this proof is the observation214
4 Completeness
that if Rκ and Sκ were not coﬁnal, then the map f : κ → U given by f : α →
rα+1 would be injective (further proof details are left to the reader). This would
contradict the assumption that κ exceeds the size of U .
We are ready for the ﬁnal step. As Kt ThoM deﬁnes the empty class of frames, it is
tempting to conclude that it is also complete with respect to this class; that is, that
Kt ThoM is the inconsistent logic. However, this is not the case.
Theorem 4.49 Kt ThoM is consistent and incomplete.
Proof. Let (N, <) be the natural numbers in their usual order. Let A be the col-
lection of ﬁnite and co-ﬁnite subsets of N; we leave it to the reader to show that
A is closed under boolean combinations and modal operations. Thus (N, <, A) is
a general frame; we claim that it validates all the Kt ThoM axioms. Now, it cer-
tainly validates all the Kt Tho axioms, for these are already valid on the underlying
frame. But what about M? As we noted in Example 1.34, GF p → F Gp cannot be
falsiﬁed under assignments mapping p to either a ﬁnite or a co-ﬁnite set. Hence all
the axioms are valid and Kt ThoM must be consistent.
Now, by Lemma 4.48, Kt ThoM is not the logic of any non-empty class of
frames. But as Kt ThoM is consistent, it is not the logic of the empty class of
frames either. In short, it is not the logic of any class of frames whatsoever, and is
incomplete.
Frame incompleteness results are not some easily ﬁxed anomaly. As normal logics
are sets of formulas closed under three rules of proof, the reader may be tempted to
think that these rules are simply too weak. Perhaps there are yet-to-be-discovered
rules which would strengthen our deductive apparatus sufﬁciently to overcome in-
completeness? (Indeed, later in the chapter we introduce an additional proof rule,
and it will turn out to be very useful.)
Nonetheless, no such strengthening of our deductive apparatus can eliminate
frame incompleteness. Why is this? Ultimately it boils down to something we
learned in Chapter 3: frame consequence is essentially a second-order relation.
Moreover, as we discussed in the Notes to Chapter 3, it is a very strong relation
indeed: strong enough to simulate the standard second-order consequence relation.
Frame incompleteness results reﬂect the fact that (over frames) modal logic is sec-
ond order logic in disguise. Hence, it will come as no surprise that incompleteness
hits every modal similarity type: in Exercise 4.4.2 we meet an example in the basic
modal similarity type. However, examples (such as Kt ThoM) of consistent logics
with an empty frame class cannot be found for the basic modal similarity type, as
the reader is asked to prove in Exercise 4.4.3.
There are many incomplete logics. Indeed, if anything, incomplete logics are
the norm. An analogy may be helpful. When differential calculus is ﬁrst encoun-4.4 Limitative Results
215
tered, most students have rather naive ideas about functions and continuity; poly-
nomials, and other simple functions familiar from basic physics, are taken to be
typical of all real-valued functions. The awakening comes with the study of anal-
ysis. Here the student encounters such specimens as everywhere-continuous but
nowhere-differentiable functions – and comes to see that the familiar functions are
actually abnormally well-behaved. The situation is much the same in modal logic.
The logics of interest to philosophers – logics such as T, S4 and S5 – were the ﬁrst
to be semantically characterized using frames. It is tempting to believe that such
logics are typical, but they are actually fairly docile creatures; the lattice of normal
logics contains far wilder inhabitants.
The signiﬁcance of the incompleteness results depends on one’s goals. Logi-
cians interested in applications are likely to focus on certain intended classes of
models, and completeness results for these classes. Beyond providing a salutary
warning about the folly of jumping to hasty generalizations, incompleteness results
are usually of little direct signiﬁcance here. On the other hand, for those whose pri-
mary interest is syntactically driven completeness results, the results could hardly
be more signiﬁcant: they unambiguously show the inadequacy of frame-based clas-
siﬁcations. Unsurprisingly, this has had considerable impact on the study of modal
logic. For a start, it lead to a rebirth of interest in alternative tools – and, in partic-
ular, to the renaissance of algebraic semantics, which we will study in Chapter 5.
Moreover, it has lead modal logicians to study new types of questions. Let us
consider some of the research themes that have emerged.
One response has been to look for general syntactic constraints on axioms which
guarantee canonicity. The most elegant such result is the Sahlqvist Completeness
Theorem, which we have already discussed. A second response has been to investi-
gate the interplay between completeness, canonicity, and correspondence. Typical
of the questions that can be posed is the following: If A1 , . . . , An are axioms that
deﬁne an elementary class of frames, is KA1 . . . An frame complete? (In fact,
the answer here is no – as the reader is asked to show in Exercise 4.4.4.) The
most signiﬁcant positive result that has emerged from this line of enquiry is the
following:
Theorem 4.50 If F is a ﬁrst-order deﬁnable class of frames, then ΛF is canonical.
Again, we prove this in Chapter 5 using algebraic tools (see Theorem 5.56). Tanta-
lizingly, at the time of writing the status of the converse was unknown: If a normal
modal logic Λ is canonical, then there is a ﬁrst-order deﬁnable class of frames F
such that Λ = ΛF . This conjecture seems plausible, but neither proof nor coun-
terexample has been found.
A third response has been to examine particular classes of normal modal log-
ics more closely. The entire lattice may have undesirable properties – but many216
4 Completeness
sub-regions are far better behaved. We will examine a particularly well-behaved
sub-region (namely, the normal logics extending S4.3) in the ﬁnal section of this
chapter.
This concludes our survey of basic completeness theory. The next four sections
(all of which are on the basic track) explore the following issue: how are we to
prove completeness results when we need to build a model that has a property for
which no formula is canonical? Some readers may prefer to skip this for now and
go straight on to the following chapter. This discusses completeness, canonicity
and correspondence from an algebraic perspective.
Exercises for Section 4.4
4.4.1 Recall that any normal modal logic that has the ﬁnite model property also has the
ﬁnite frame property. What are the consequences of this for incomplete normal modal
logics?
4.4.2 The logic KvB consists of all formulas valid on the general frame J. The domain J
of J is N ∪ {ω, ω + 1} (the set of natural numbers together with two further points), and R
is deﬁned by Rxy iff x = ω + 1 and y < x or x = ω + 1 and y = ω. (The frame (J, R)
is shown in Figure 6.2 on page 351.) A, the collection of subsets of J admissible in J,
consists of all X ⊆ J such that either X is ﬁnite and ω ∈ X, or X is co-ﬁnite and ω ∈ X.
(a) Show that 23() → 2(2(2p → p) → p) is valid on J.
(b) Show that on any frame on which the previous formula is valid, 23() → 2(⊥)
is valid too.
(c) Show that 23() → 2(⊥) is not valid on J.
(d) Conclude that KvB is incomplete.
4.4.3 Prove that any consistent normal modal logic in the basic modal similarity type is
either valid on the frame consisting of a single reﬂexive point or valid on the frame con-
sisting of a single irreﬂexive point. (Hint: use the fact that either 2⊥ is Λ-consistent or
3 is a Λ-theorem.)
Conclude that no consistent normal modal logic in the basic similarity type deﬁnes the
empty frame class.
4.4.4 Consider the formulas (T) p → 3p, (M) 23p → 32p, (E) 3(3p ∧ 2q) → 2(3p ∨
2q) and (Q) (3p ∧ 2(p → 2p)) → p. Let Λ denote the normal modal logic axiomatized
by these formulas.
(a) Prove that E corresponds to the following ﬁrst-order formula: ∀xy 1 y2 ((Rxy1 ∧
Rxy2 ) → (∀z (Ry1 z → Ry2 z) ∨ ∀z (Ry2 z → Ry1 z))).
(b) Prove that within the class of frames validating both T and E, Q deﬁnes the frames
satisfying the condition Rˇ ⊆ R∗ (that is, if Rst then there is a ﬁnite path back
from t to s).
(c) Prove that the conjunction of the four axioms deﬁnes the class of frames with a
trivial accessibility relation – that is, T ∧ M ∧ E ∧ Q corresponds to ∀xy (Rxy ↔
x = y). (Hint: consider the effect of the McKinsey formula on the frames satisfying
the condition Rˇ ⊆ R∗ .)4.5 Transforming the Canonical Model
217
(d) Consider the so-called veiled recession frame (N, R, A), where N is the set of natu-
ral numbers, Rmn holds iff m ≤ n+1 and A is the collection of ﬁnite and co-ﬁnite
subsets of N. Show that all four axioms are valid on this general frame, but that the
formula p → 2p can be refuted.
(e) Conclude that Λ is incomplete, although it deﬁnes an elementary class of frames.
(f) Does this contradict Theorem 4.50?
4.4.5 Given a class K of frames, let Θ(K) = Λ K denote the set {φ | F  φ for all F in K }
and given a logic Λ, let Fr(Λ) denote the class of frames on which Λ is valid.
(a) Show that the operations Θ and Fr form a so-called Galois connection. That is,
prove that for all classes K and logics Λ:
Λ ⊆ Θ(K) iff K ⊆ Fr(Λ).
(b) What does it mean for a logic Λ if Λ = Θ(Fr(Λ))? (Give an example of a logic for
which it does not hold.)
(c) What does it mean for a frame class K if K = Fr(Θ(K))? (Give an example of a
frame class for which it does not hold.)
4.5 Transforming the Canonical Model
What is the modal logic of partial orders? And what is the tense logic of strict total
orders? Such questions bring us face to face with the fundamental problem con-
fronting semantically driven completeness results. Partial orders are antisymmet-
ric, and strict total orders are irreﬂexive. No modal formula deﬁnes either property,
and (as the reader probably suspects) no formula is canonical for them either. Thus,
to answer either question, we need to build a model for which we lack a canoni-
cal formula – and hence we will need to expand our repertoire of model building
techniques. This is the main goal of the present section and the three that follow.
In this section we explore a particularly natural strategy: transforming the canon-
ical model. Although a canonical model may lack some desired properties, it does
get a lot of things right. Perhaps it is possible to reshape it, transforming it into
a model with all the desired properties? We have done this once already, though
in a very simple way: in the completeness proof for Kt Q (see Theorem 4.41 and
surrounding discussion) we formed a point-generated submodel of the canonical
model to ensure trichotomy. Here we will study two more sophisticated transfor-
mations – unraveling and bulldozing – and use them to answer the questions with
which this section began.
It seems plausible that S4 is the modal logic of partial orders: Theorem 4.29 tells
us that S4 is complete with respect to the class of reﬂexive transitive frames (that
is, preorders) and there do not seem to be any modal formulas we could add to S4
to reﬂect antisymmetry. Furthermore, it seems reasonable to hope that we could
prove this using some sort of model transformation: as every S4-consistent set of
formulas can be satisﬁed on a preorder, and as we know that modal languages are
blind to antisymmetry (at least as far as frame deﬁnability is concerned) maybe we4 Completeness
218
t
t
@
R t 
t
t
@
Rt
@
Rt
@
Rt
@
Rt
..
.
Fig. 4.1. A model and its unraveling
can ﬁnd a way of transforming any satisfying preorder into a partial order without
affecting satisﬁability? (It is worth stressing that this informal line of argument is
not a proof; it is intended solely to motivate the work that follows.)
A transformation called unraveling will enable us do this. Indeed, unraveling
will let us prove the stronger result that S4 is complete with respect to the class of
reﬂexive and transitive trees. (This will be useful in Chapter 6 when we discuss
decidability). We brieﬂy discussed unraveling in Chapter 2, where we used it to
show that modal logic has the tree property (see Proposition 2.15). Informally,
given any model, unraveling builds a new model, whose points are paths of the
original model. That is, transition sequences in the original model are explicitly
represented as states in the unraveled model. More precisely:
Deﬁnition 4.51 (Unraveling) Let (W, R) be a frame generated by some point w ∈
 , R)
 where:
W . The unraveling of (W, R) around w is the frame (W
 is the set of all ﬁnite sequences (w, w1 , . . . , wn ) such that w1 , . . . , wn ∈
(i) W
W and Rww1 , . . . , Rwn−1 wn , and
 , then R
 s1s2 if there is some v ∈ W such that s1 + (v) = s2 ,
(ii) If s1 , s2 ∈ W
where + denotes sequence concatenation.
 , R)
 is the unraveling of (W, R) around w,
If M = (W, R, V ) is a model and (W
 on (W
 , R)
 as follows:
then we deﬁne the valuation V
 (p) = {(w, w1 , . . . , wn ) ∈ W
 | wn ∈ V (p)}
V
 = (W
 , R,
 V
 ) is called the unraveling of M around w.
The model M
A simple example is given in Figure 4.1. As this example suggests (and as the
reader should check) unraveling any frame around a generating point w yields an
irreﬂexive, intransitive, and asymmetric frame. Indeed, note that unraveled frames
 is just the familiar
are trees: the root node is the sequence (w), and the relation R
(immediate) successor (or daughter-of) relation on trees.
 = (W
 , R,
 V
 ) be the unraveling of M = (W, R, V ) around
Lemma 4.52 Let M4.5 Transforming the Canonical Model
219
 , R),
 and M is a bounded
w. Then (W, R) is a bounded morphic image of (W

morphic image of M.
 → W be deﬁned by f (w, w1 , . . . , wn ) = wn . It is easy to see
Proof. Let f : W
 , s
that f is surjective, has the back and forth properties, and that for any s ∈ W
and f (s) satisfy the same propositional variables.
A simple corollary is that any satisﬁable set of formulas is satisﬁable on a (irreﬂex-
ive, intransitive, and asymmetric) tree: for if a set of formulas is satisﬁable, it is
satisﬁable on a point-generated model (take the submodel generated by the satis-
fying point), hence by unraveling we have the result. It follows that K is (strongly)
complete with respect to this class of models.
But our real interest is S4. How do we use unraveling to make the partially or-
dered models we require for the completeness result? In the most obvious way
possible: we simply take the reﬂexive transitive closures of unraveled models.
More precisely, suppose we unravel M around some generating point w to obtain
 , R,
 V ). Now consider the model M∗ = (W
 , R∗ , V
 ) where R∗ is the reﬂexive
(W
 Trivially, M∗ is an S4 model. Moreover, as (W
 , R)
 is a
transitive closure of R.
∗
 , R ) is an antisymmetric frame. Indeed, it is a reﬂexive and transitive
tree, (W
tree, for R∗ is simply the familiar dominates (or ancestor-of) relation on trees. So
only one question remains: is M a bounded morphic image of M∗ ? In general, no.
But if the model M we started with was itself reﬂexive and transitive, yes:
Lemma 4.53 Let M = (W, R, V ) be a reﬂexive transitive model generated by
 , R,
 V
 ) be the unraveling of M around w. Let R∗ be the
some w ∈ W , and let (W
 and deﬁne M∗ to be (W
 , R∗ , V ). Then M is a
reﬂexive transitive closure of R,
∗
bounded morphic image of M .
Proof. It is easy to see that the function f deﬁned in Lemma 4.52 remains the
required bounded morphism; as far as surjectivity, the back property, and the dis-
tribution of proposition letters are concerned, nothing has changed. We only have
 does not harm the forth
to check that taking the reﬂexive transitive closure of R
property. But, as R is itself reﬂexive and transitive, the forth property survives.
Theorem 4.54 S4 is strongly complete with respect to the class of partially or-
dered reﬂexive and transitive trees.
Proof. If Σ is an S4-consistent set of formulas, and Σ+ is an S4-MCS extending
Σ, then MS4 , Σ +  Σ. Moreover, as the S4 axioms are canonical, MS4 is a
reﬂexive transitive model. We now transform this model into the required partial
order in two steps.
Step 1. Let MS be the submodel of MS4 generated by Σ+ . Clearly this is a
reﬂexive, transitive, point-generated model such that MS , Σ +  Σ.220
4 Completeness
 , R∗ , V ) be the reﬂexive transitive closure of the unraveling
Step 2. Let M∗ = (W
of MS around Σ+ .
By Lemma 4.53, MS is a bounded morphic image of M∗ under f , hence for all
sequences s ∈ f −1 [Σ], we have M∗ , s  Σ, and by the surjectivity of f there is at
least one such s. Hence we have satisﬁed Σ on a reﬂexive and transitive tree.
The previous proof could be summed up as follows: we found a way to use the
information in a canonical model indirectly. The canonical model for S4 did not
have the structure we wanted – nonetheless, we successfully tapped into the in-
formation it contained via a short sequence of bisimulations (M∗ had MS as a
bounded morphic image, and MS was a generated submodel of MS4 ).
Unraveling is an intrinsically global transformation that can change a model’s
geometry drastically. This is in sharp contrast to the transformation we will now
examine – bulldozing – which works locally, and (in spite of its name) rather more
gently. We will use bulldozing to answer the second of the questions posed above.
Recall that a strict total order (STO) is a relation that is transitive, trichotomous
and irreﬂexive. The class of strict total orders contains such important structures as
(N, <), (Z, <), (Q, <), and (R, <) (the natural numbers, the integers, the rationals
and the reals in their usual order) and is widely used to model various temporal
phenomena. What is its tense logic?
Once again, it is not hard to ﬁnd a plausible candidate: Kt 4.3, the tense logic
generated by 4, .3l and .3r , seems the only reasonable candidate. For a start, Kt 4.3
is strongly complete with respect to the class of weak total orders. (To see this,
observe that the axioms are canonical for transitivity and non-branching. Hence
any point generated submodel MS of the canonical model is transitive and tri-
chotomous, and the completeness result is immediate.) Moreover, there simply are
no other plausible axioms – in particular, irreﬂexivity is not deﬁnable. Has this
(somewhat dangerous) line of reasoning led to the right answer? Let us see.
If we could ﬁnd a way of transforming weakly linear models into strictly linear
models we would have the desired completeness result. Note that unraveling will
not help – it would turn the weak total order into a tree, thus destroying trichotomy.
If only we could ﬁnd a method which replaced the undesirable parts of the model
with some suitable STO, and left the good parts untouched: then trichotomy would
not be affected, and we would have assembled the required strict total order. Bull-
dozing is a way of doing this. The ﬁrst step is to pin down what the ‘undesirable’
parts of weak total orders are. The obvious response is ‘reﬂexive points’ – but
while this is not exactly wrong, it misses the crucial insight. The entities we really
need to think about are clusters, introduced in Chapter 2. We repeat the deﬁnition:
Deﬁnition 4.55 Let (T, R) be a transitive frame. A cluster on (T, R) is a subset
C of T that is a maximal equivalence relation under R. That is, the restriction of4.5 Transforming the Canonical Model
221
R to C is an equivalence relation, and this is not the case for any other subset D
of T such that C ⊂ D. A cluster is simple if it consists of a single reﬂexive point,
and proper if it contains more than one point. When we say that a model contains
clusters, we mean that its underlying frame does.
The point is this: we should not think in terms of removing isolated reﬂexive points;
rather, we should remove entire clusters at one stroke. (Intuitively, the information
in a cluster is information that ‘belongs together.’) Any transitive trichotomous
frame can be thought of as a strictly totally ordered collection of clusters (cf. Exer-
cise 1.1.1). If we could remove each cluster as a single chunk, and replace it with
something equivalent, we would have performed a local model transformation.
So the key question is: what should we replace clusters with? Clearly some sort
of STO – but how can we do this in a truth preserving way? Note that any cluster C,
even a simple one, introduces an inﬁnity of information recurrence in both the for-
wards and backwards directions: we can follow paths within C, moving forwards
and backwards, for as long as we please. Thus, when we replace a cluster C with a
STO, we must ensure that the STO duplicates all the information in C inﬁnitely of-
ten, in both directions. Bulldozing does precisely this in a straightforward way. We
simply impose a strict total order on the cluster (that is, we pick some path through
the cluster that visits each point once and only once) and then lay out inﬁnitely
many copies of this path in both the forwards and backwards direction. We then
replace the cluster by the inﬁnite repetition of the chosen path. We have squashed
the clusters down into inﬁnitely long STOs – hence the name ‘bulldozing’.
Theorem 4.56 Kt 4.3 is strongly complete with respect to the class of strict total
orders.
Proof. Let Σ be a Kt 4.3-consistent set of formulas; expand it to a Kt 4.3-MCS
Σ + . Let M = (T, R, V ) be the canonical model for Kt 4.3. By the canonicity
of the axioms, M is transitive and non-branching. Let MS = (S, RS , V S ) be the
submodel of M generated by Σ+ ; MS is a transitive and trichotomous model such
that MS , Σ +  Σ. But MS may contain clusters, which we will bulldoze away.
Step 1. Index the clusters in MS by some suitable set I.
Step 2. Deﬁne an arbitrary strict total order <i on each cluster Ci .
Step 3. Deﬁne Ci to be Ci × Z. (Z is the set of integers.)
Step 4. Deﬁne B, the set underlying the bulldozed model, to be
S− ∪
Ci ,
i∈I
where S − is the set (S \ i∈I Ci ) of points not belonging to any cluster.
Step 5. Deﬁne a mapping β : B → S by: β(b) = b, if b ∈ S− ; and β(b) = s, if
b = (s, z).222
4 Completeness
Step 6. Deﬁne an ordering <b on B by b <b b iff
either (b ∈ S − or b ∈ S − ) and β(b)RS β(b );
or b = (s, z) and b = (s , z  ) and
either s and s belong to distinct clusters and β(b)RS β(b );
or s and s belong to the same cluster and z <Z z  (where <Z is
the usual ordering on the integers);
or s and s belong to the same cluster Ci and z = z and s <i s .
Step 7. Deﬁne a valuation V b on (B, <b ) by b ∈ V (p) iff β(b) ∈ V S (p).
Step 8. Deﬁne MB , the bulldozed model, to be (B, <b , V b ).
We now make the following claims:
Claim 1. The mapping β is a surjective bounded morphism from (B, <b ) to
(S, RS ), and the model MS is a bounded morphic image of MB under β.
Claim 2. (B, <b ) is a strict total order.
Proving these claims is a matter of checking the deﬁnitions; we leave this to the
reader as Exercise 4.5.5. With this done, the theorem is immediate. By Claim 1,
for any b ∈ β−1 (Σ + ) we have MB , b  Σ, and since β is surjective, there is at
least one such b. Thus B is a model of Σ, and by Claim 2 it has the structure we
want.
Although it works more locally, like unraveling, bulldozing is a way of using the
information in canonical models indirectly. Indeed, like unraveling, it accesses
the information in the relevant canonical model via a sequence of bisimulations:
the ﬁnal model MB had MS as a bounded morphic image, and MS in turn was a
generated submodel of M.
Bulldozing is a ﬂexible method. For example, we are not forced to deﬁne Ci to
be Ci × Z; any unbounded STO would do. Moreover, if we used a reﬂexive total
order (for example (Z, ≤)) instead, we could prove analogous completeness results
for reﬂexive total orders; for example, the reader is asked to show in Exercise 4.5.6
that St 4.3 is the logic of this class of frames. Moreover, for modal languages,
we only need to ensure inﬁnite information repetition in the forward direction, so
structures such as (N, <) and (N, ≤) sufﬁce.
But there are more interesting variations. For example, instead of simply or-
dering the points in the cluster, one can embed the cluster in some suitable total
order, and work with its embedded image instead. By embedding the clusters in a
dense set, it is possible to build dense totally ordered models. And by combining
such ideas with other transformations (notably ﬁltrations) the method can be used
to prove many classic completeness results of modal and tense logics.
Model manipulation methods, and completeness proofs making use of them,4.6 Step by Step
223
abound. Further examples are mentioned in the Notes, but it is not remotely possi-
ble to be encyclopedic: such methods trade on speciﬁc insights into the geometry
of relational structures, and this gives rise to a wide variety of variants and combi-
nations. The reader should certainly be familiar with such methods – they are often
simple to adapt to speciﬁc problems – but it is just as important to appreciate the
general point that has emerged from our discussion: even if the canonical model
is not quite what we need, it can still be extremely useful. The following section
further explores this theme.
Exercises for Section 4.5
4.5.1 K is complete with respect to the class of irreﬂexive frames. Unraveling shows this,
but there is a much simpler transformation proof. (Hint: given a model M, tinker with the
disjoint union of M with itself.)
4.5.2 Formulate the unraveling method for modal languages containing two diamonds.
Then formulate the method in such a way that bidirectional frames unravel into bidirec-
tional frames.
4.5.3 Consider a similarity type τ with one binary operator . Call a τ -frame F = (W, T )
acyclic if the binary relation R = {(s, t) ∈ W 2 | T stu or T sut for some u ∈ W } is
acyclic (that is to say, R + is irreﬂexive). Prove that the basic modal logic K τ is strongly
sound and complete with respect to the class of acyclic frames.
4.5.4 Show that the canonical model for K t Q contains proper clusters.
4.5.5 Prove Claims 1 and 2 of Theorem 4.56.
4.5.6 Let K t QT be the smallest normal temporal logic containing both K t Q and p → F p.
Show, using a light bulldozing argument, that K t QT is strongly complete with respect to
the class of all dense unbounded reﬂexive total orders. (In this context of reﬂexive orders,
density refers to the property ∀x∀y ((Rxy ∧ x = y) → ∃z (Rxz ∧ x = z ∧ Rzy ∧ z = y)).)
4.6 Step by Step
Three main ideas underly the step-by-step method:
(i) Do not consider the entire canonical model to be the key ingredient of a
completeness proof. Rather, think of selections of MCSs from the canonical
model as the basic building blocks.
(ii) The standard way of proving completeness is by constructing a model for
a consistent set of formulas. Take the term ‘constructing’ as literally as
possible: break it down into a sequence of steps.
(iii) Putting the ﬁrst two observations together, think of the construction of a
model as the stepwise selection of the needed MCSs. More precisely, think
of the model construction process as approaching a limit via a sequence224
4 Completeness
of ever better approximations, using local conﬁgurations of the canonical
model to make improvements at each step of the construction.
The method gives us enormous control over the models we build, and even at this
stage it is easy to see why. First, we do not have to worry about unpleasant features
of the canonical model (such as clusters) since we only work with selections of
the information that canonical structures contain. Furthermore, as we select our
information one step at a time, we obtain an iron grip on what ends up in the
model.
To illustrate the method’s potential, we use it to prove that the logic Kt Q de-
ﬁned in Deﬁnition 4.40 is strongly complete with respect to (Q, <). In what fol-
lows, consistency means Kt Q-consistency, and Mc = (T c , Rc , V c ) is this logic’s
canonical model. Furthermore we ﬁx a maximal consistent set Σ; the goal of our
proof is to construct a model M = (T, <, V ) for Σ such that (T, <) is an ordering
which is isomorphic to (Q, <). At each step of the construction we will be dealing
with an approximation of M consisting of a strictly ordered ﬁnite set of points (that
will ultimately end up) in T and for each of these, the set of all formulas that we
want to be the point’s modal type (that is, the set of formulas holding at the point).
Deﬁnition 4.57 A network is a triple N = (N, <, ν) such that R is a binary re-
lation on the set N , and ν is a labeling function mapping each point in N to a
maximal consistent set.
We are not interested in networks that are blatantly faulty as approximations of our
desired model. For example, we want < to be a strict total ordering. Moreover,
whenever a formula ψ is in the label set of a point s, then F ψ should be in ν(t) for
any t with t < s. Such requirements lead to the following deﬁnition.
Deﬁnition 4.58 A network N = (N, <, ν) is coherent if it satisﬁes:
(C1) < is a strict total ordering,
(C2) ν(s)Rc ν(t) for all s, t ∈ N such that s < t.
A network for Σ is a network such that Σ is the label set of some node.
C1 and C2 are the minimal requirements for a network to be useful to us; note that
both requirements are universal. (C2 is equivalent to the requirement that if s < t
then F φ ∈ ν(s) for all φ ∈ ν(t) and P φ ∈ ν(t) for all φ ∈ ν(s).) But if a network
is to really resemble a model, it must also satisfy certain existential requirements.
Deﬁnition 4.59 A network N = (N, <, ν) is saturated if it satisﬁes:
(S1) < is unbounded to the left and to the right,
(S2) < is dense,4.6 Step by Step
225
(S3) N is modally saturated. That is, we demand that (F) if F ψ ∈ ν(s) for some
s ∈ N , then there is some t ∈ N such that s < t and ψ ∈ ν(t), and (P) if
P ψ ∈ ν(s) for some s ∈ N , then there is some t ∈ N such that t < s and
ψ ∈ ν(t).
A network is perfect if it is both coherent and saturated.
We want networks to give rise to models. Let us now check that we have imposed
sufﬁciently many criteria on networks to achieve this.
Deﬁnition 4.60 Let N = (N, <, ν) be a network. The frame FN = (N, <) is
called the underlying frame of N . The induced valuation VN on F is deﬁned by
VN (p) = {s ∈ N | p ∈ ν(s)}. The structure IN = (FN , VN ) is the induced
model.
The following lemma shows that our deﬁnition of perfection is the right one.
Lemma 4.61 (Truth Lemma) Let N be a countably inﬁnite perfect network. Then
for all formulas ψ, and all nodes s in N ,
IN , s  ψ iff ψ ∈ ν(s).
Moreover, FN is isomorphic to the ordering of the rational numbers.
Proof. The ﬁrst part of the proof is by induction on the degree of ψ. The base case
is clear from the deﬁnition of the induced valuation, and the steps for the booleans
are straightforward. As for the modal operators, the coherency of N drives the left
to right implication through, and saturation takes care of the other direction.
Finally, the underlying frame of a perfect network must be a dense, unbounded,
strict total ordering. Hence, if it is countably inﬁnite, it must be isomorphic to
(Q, <) by Cantor’s Theorem. (Readers unfamiliar with this theorem should try
to prove this classic result from ﬁrst principles. The standard proof builds up the
isomorphism using a step-by-step argument!)
It follows from Lemma 4.61 that we have reduced the task of ﬁnding a model for
our MCS Σ to the quest for a countable, perfect network for Σ. And now we arrive
at the heart of the step-by-step method: the crucial idea is that each witness to
the imperfection of a coherent network can be removed, one step at a time. Such
witnesses will be called defects. There are three kinds of defect: each corresponds
to a violation of a saturation condition.
Deﬁnition 4.62 Let N = (N, <, ν) be a network. An S1-defect of N consists of
a node s ∈ N that has no successor, or no predecessor; an S2-defect is a pair (s, t)
of nodes for which there is no intermediate point. An S3-defect consists of (F) a
node s and a formula F ψ ∈ ν(s) for which there is no t in N such that s < t and226
4 Completeness
ψ ∈ ν(t), or (P) a node s and a formula P ψ ∈ ν(s) for which there is no t in N
such that t < s and ψ ∈ ν(t).
Now we need to say more about what it means to repair a defect. To do so, we
need the notion of one network extending another.
Deﬁnition 4.63 Let N0 = (N0 , <0 , ν0 ) and N1 = (N1 , <1 , ν1 ) be two networks.
We say that N1 extends N0 (notation: N1  N0 ) if FN0 is a subframe of FN1 and
ν0 agrees with ν1 on N0 .
The key lemma of this (or for that matter, any) step-by-step proof states that any
defect of a ﬁnite coherent network can be repaired. More precisely:
Lemma 4.64 (Repair Lemma) For any defect of a ﬁnite, coherent network N
there is a ﬁnite, coherent N   N lacking this defect.
Proof. Let N = (N, <, ν) be a ﬁnite, coherent network and assume that N has
some defect. We prove the Lemma by showing that all three types of defect can be
removed.
S1-defects.
These are left as an exercise to the reader.
S2-defects.
Assume that there are nodes s and t in N for which there is no intermediate point.
How should we repair this defect? The basic idea is simple: just throw in a
new point between s and t, and ﬁnd an appropriate label for it. This can be done
easily, since it follows by coherence of N that ν(s)Rc ν(t), and by canonicity of
the density axiom that there is some MCS Γ such that ν(s)Rc Γ Rc ν(t). Hence,
take some new node u (new in the sense that u ∈ N ) and deﬁne N = (N  , < , ν  )
by
N  := N ∪ {u},
< := < ∪ {(x, u) | x ≤ s} ∪ {(u, x) | t ≤ x},
ν  := ν ∪ {(u, Γ )}.
It is clear that N  is a network that does not suffer from the old defect. But is N
coherent? Condition C1 is almost immediate by the deﬁnition, so we concentrate
on C2. Let x and y be two arbitrary nodes in N  such that x < y; we have to check
that ν  (x)Rc ν  (y). Now, as < is irreﬂexive, x and y are distinct. Moreover, there
can only be a problem if one of the nodes is the new point u; assume that y = u
(the other case is similar). If x = s then we have ν (x)Rc ν  (u) by our assumption
on Γ , so suppose that x = s. By deﬁnition of < and the fact that there are no
old nodes between s and t, this means that x < s, so by the coherency of N we4.6 Step by Step
227
have that ν(x)Rc ν(s). Hence, it follows by the transitivity of Rc that ν(x)Rc Γ ;
but then it is immediate by the deﬁnition of ν that ν  (x)Rc ν  (u).
S3-defects.
We only treat the P-defects; the case for F-defects follows by symmetry. Assume
that there is a node s in N and a formula P ψ in ν(s) for which there is no t in N
such that t < s and ψ ∈ ν(t).
Again, the basic strategy is simple: we insert a new point s into the network
(before s!) and choose an adequate label for it; this has to be a maximal consistent
set containing ψ and preceding ν(s) in the preorder Rc . But where should s be
inserted? If we are not careful we will destroy the coherency of N . The following
maneuver (which takes advantage of the fact that FN is a ﬁnite STO) overcomes
the difﬁculty.
Let m be the unique point in N such that (i) (m, P ψ) is an S3-defect in N , and
(ii) for all w < m, (w, P ψ) is not a defect. Such an m must exist (it is either s
itself, or one of the ﬁnitely many points preceding s) and, as we will see, we can
repair (m, P ψ) without problems by simply inserting the new point s immediately
before m. Repairing this minimal defect automatically repairs the defect (s, P ψ).
Choose some new point s (that is, s ∈ S) and let Ψ be an MCS containing ψ
such that Ψ Rc ν(m); such a Ψ exists by the Existence Lemma for normal logics.
Deﬁne N  = (N  , < , ν  ) as follows:
N  := N ∪ {s },
< := < ∪ {(x, s ) | x < m} ∪ {(s , x) | m ≤ x},
ν  := f ∪ {(s , Ψ )}.
Observe that FN  is a strict total order, and that N  does not contain the defect
(s, P ψ). It only remains to ensure that N  satisﬁes the second coherency condition.
Consider two nodes x, y ∈ N  such that x < y. Again, the only cases worth
checking are when either x or y is the new point s . If we have x = s we are in a
similar situation as in the case of S2-defects, so we do not go into details here.
Hence, assume that y = s . By construction ν(s ) = Ψ Rc ν(m), and by the co-
herency of N , ν(x)Rc ν(m). But Rc is the canonical relation for Kt Q – a relation
with no branching to the left – hence either Ψ Rc ν(x), Ψ = ν(x) or ν(x)Rc Ψ . We
claim that the ﬁrst two options are impossible. For, if Ψ Rc ν(x) then ψ ∈ Ψ would
imply that P ψ ∈ ν(x) and this contradicts the minimality of m; and if Ψ = ν(x),
then ψ ∈ ν(x) would mean that (s, P ψ) was not a defect in the ﬁrst place! We
conclude that ν(x)Rc Ψ , which establishes coherence.
With both the Truth Lemma for induced models and the Repair Lemma at our
disposal, we can prove the desired strong completeness result. The idea is straight-
forward. We start with a singleton network and extend it step by step to larger4 Completeness
228
(but ﬁnite) networks by repeated use of the Repair Lemma. We obtain the required
perfect network by taking the union of our sequence of networks.
Theorem 4.65 Kt Q is strongly complete with respect to (Q, <).
Proof. Choose some set S = {si | i ∈ ω} (we will use its elements to build the
required frame) and enumerate the set of potential defects (that is, the union of the
sets S, S × S and S × {F, P } × Form). Given a consistent set of formulas Σ,
expand it to an MCS Σ0 . Let N0 be the network ({s0 }, ∅, (s0 , Σ0 )). Trivially, N0
is a ﬁnite, coherent network for Σ0 .
Let n ≥ 0 and suppose Nn is a ﬁnite, coherent network. Let D be the defect of
Nn that is minimal in our enumeration. Such a D exists, since any ﬁnite network
must at least have S1- and S2-defects. Form Nn+1 by repairing the defect D as
described in the proof of the Repair Lemma. Observe that D will not be a defect
of any network extending Nn .
Let N = (N, <, ν) be given by
N=
Nn , < =
n∈ω
<n , and ν =
n∈ω
νn .
n∈ω
It is easy to see that FN is a strict total order. Moreover, as we chose the points in
N from a countably inﬁnite set, N is countable.
It should be intuitively clear that N is perfect, but the actual proof has to take
care of a subtlety. Suppose that N is not perfect; let D be the minimal (according
to our enumeration) defect of N , say D = Dk . By our construction, there must be
an approximation Ni of N of which D is also a defect. Note that D need not be
the minimal defect of Ni – this is the subtlety. Fortunately, there can be at most
k defects that are more urgent, so D will be repaired before stage k + i of the
construction.
Finally, by the perfection of N it follows from Lemma 4.61 that the induced
model IN satisﬁes Σ at s0 .
The step-by-step method is one of the most versatile tools at the modal logician’s
disposal: a wide variety of results in modal and tense logic have been using this
method, it is the tool of choice for many stronger modal systems such as arrow
logic and since/until logic, and we will make use of step-by-step arguments when
we discuss rules for the undeﬁnable in the following section. We urge the reader to
experiment with it. A good starting point is Exercise 4.6.1.
Exercises for Section 4.6
4.6.1 Consider a modal language with three diamonds 3 1 , 32 and 33 . Give a complete
axiomatization for the class of frames F = (W, R 1 , R2 , R3 ) satisfying R3 = R1 ∩ R2 .4.7 Rules for the Undeﬁnable
229
4.6.2 Consider, for a modal language with two diamonds 3 0 and 31 , the normal modal
logic (S5)2 axiomatized by S5 axioms for both diamonds, and the commutativity axiom
30 31 p ↔ 31 30 p. Prove that this logic is complete for the class of square frames. A
square frame for this language is of the form F = (W, R 0 , R1 ) where for some set U we
have
W
Ri st
=
iff
U 2,
s i = ti .
(Hint: take as approximations networks of the form (N, ν) where ν is a labeling mapping
pairs over N to maximal consistent sets.)
4.6.3 Consider a similarity type τ with one binary operator ◦, as in arrow logic. Call a
τ -frame F = (W, T ) a relativized square if W is some collection of pairs over a base set
U , and T ⊆ W 3 satisﬁes T stu iff s0 = t0 , t1 = u0 and s1 = u1 .
(a) Prove that the basic modal logic K τ is strongly sound and complete with respect to
the class of relativized squares.
(b) Try to axiomatize the logic of the class of frames (W, R) in which W is as above,
but T satisﬁes T stu iff s0 = t1 , t0 = u and u0 = s1 .
4.7 Rules for the Undeﬁnable
In the previous two sections we proved semantically driven completeness results
by using standard canonical models indirectly. The present section takes a rather
different approach: we enrich the deductive system with a special proof rule, and
consider a special (not necessarily generated) submodel of the canonical model for
this new logic. The submodel that we study contains only special distinguishing (or
witnessing) MCSs. The completeness proof shows that this new canonical model
has all the good properties of the original, and that, in addition, it is already in
the right shape. We will make use of ideas introduced in our discussion of the
step-by-step method in the previous section (in particular, the concept of a defect).
The running example in this section will (again) be the tense logic of dense un-
bounded strict total orderings. Recall that the difﬁculty when working with this
logic is that there is no axiom ensuring the irreﬂexivity of the canonical frame – we
have all the other required properties: point generated submodels of the candidate
logic Kt Q are transitive, trichotomous, dense, and unbounded. Now, in previous
sections we achieved irreﬂexivity indirectly: either we bulldozed away clusters,
or we used the canonical model for Kt Q to induce a model on a carefully con-
structed irreﬂexive frame. In this section we will construct a canonical frame that
is transitive, non-branching, dense and irreﬂexive right from the start. Indeed, if
we work with a countably inﬁnite language, every point generated subframe of this
canonical model will be countable, and hence (by Cantor’s Theorem) isomorphic
to (Q, <).
The starting point of the enterprise is that irreﬂexivity, although not deﬁnable in
basic modal languages, can be characterized in an alternative sense:230
4 Completeness
If a temporal formula ψ is satisﬁable on an irreﬂexive frame, then for any
proposition letter p not occurring in ψ, the conjunction (¬P p ∧ p ∧ ¬F p) ∧ ψ
is also satisﬁable on that frame.
For, if F, V, s  ψ, then F, V  , s  (¬P p ∧ p ∧ ¬F p) ∧ ψ, where V  is just like V
except that it assigns the singleton {s} to p. The condition that p does not occur in
ψ is crucial here: it ensures that changing the set assigned to p does not affect the
satisfaction of ψ.
Now, by taking the contrapositive of the above statement, we turn it into a proof
rule:
(IRR)
if  (¬P p ∧ p ∧ ¬F p) → φ then  φ, provided p does not occur in φ.
We have just seen that this rule is sound on the class of irreﬂexive frames. More-
over, note that on the class of strict total orders the formula (¬P φ ∧ φ ∧ ¬F φ) is
true at some state s iff s is the only state where φ holds (we need trichotomy and
transitivity to guarantee this). That is, the formula ¬P φ ∧ φ ∧ ¬F φ acts as a sort of
‘name’ for the satisfying point. Call this formula name(φ). Bearing these remarks
in mind, let us now see how adding this rule is of any help in proving the desired
completeness result.
Deﬁnition 4.66 The logic Kt Q+ is obtained by adding to Kt Q the irreﬂexivity
rule IRR. In what follows, consistency means Kt Q+ -consistency,  φ means that
φ is provable in Kt Q+ , and so on. The canonical model for Kt Q+ is denoted by
Mc , the canonical relation by Rc .
The remainder of this section is devoted to proving completeness of the proof sys-
tem Kt Q+ with respect to (Q, <). Of course the result is not surprising: we have
already seen that plain old Kt Q is strongly complete with respect to (Q, <). It
is the method that is important: rules such as IRR give us a way of forming more
cleanly structured canonical models.
Our goal is to construct an irreﬂexive version of the canonical model for Kt Q+ .
The basic idea is to work only with special witnessing MCSs:
Deﬁnition 4.67 A maximal consistent set is called witnessing if it contains a for-
mula of the form name(φ).
Why are these witnessing MCSs so interesting? Well, suppose that we are dealing
with a collection W of witnessing maximal consistent sets. This collection induces
a model in the obvious way: the relation is just the canonical accessibility relation
restricted to W and likewise for the valuation. Now suppose that we can prove a
Truth Lemma for this model; that is, suppose we can show that ‘truth and mem-
bership coincide’ for formulas and MCSs. It is then immediate that the underlying
relation of the model is irreﬂexive: name(φ) ∈ Γ implies φ ∈ Γ and F φ ∈ Γ .4.7 Rules for the Undeﬁnable
231
This is all very well, but it is obvious that we cannot just throw away non-
witnessing MCSs from the canonical model without paying a price. How can we
be sure that we did not throw away too many MCSs? An examination of the stan-
dard canonical completeness proof reveals that there are two spots where claims
are made concerning the existence of certain MCSs.
(i) There is the Existence Lemma, which is needed to prove the Truth Lemma.
In our case, whenever the formula F φ is an element of one of our witness-
ing MCSs (Γ , say) then there must be a witnessing Δ such that Γ Rc Δ and
φ ∈ Δ. But if Δ is witnessing, then there is some δ with name(δ) ∈ Δ;
it follows from the deﬁnition of the canonical accessibility relation that
F (φ ∧ name(δ)) ∈ Γ . This shows that it will not do to just take the
witnessing MCSs: the Existence Lemma requires stronger saturation condi-
tions on MCSs, namely that whenever F φ ∈ Γ , then there is some δ such
that F (φ ∧ name(δ)) ∈ Γ too.
(ii) If there are axioms in the logic that are canonical for some property with
existential import, how can we make sure that the trimmed down version
of the canonical model still validates these properties? Examples are the
formulas 32p → 23p, or, in the present case, the density axiom. The
point is that from the density of the standard canonical frame we may not
infer that its subframe formed by witnessing MCSs is dense as well: why
should there be a witnessing MCS between two witnessing MCSs?
These two kinds of problems will be taken care of in two different ways. We ﬁrst
deal with the Existence Lemma. To start with, let us see how sets of MCSs give
rise to models – the alternative versions of the canonical model that we already
mentioned.
Deﬁnition 4.68 Let W be a set of maximal consistent sets of formulas. Deﬁne
Mc |W to be the submodel of the canonical model induced by W ; that is, Mc |W =
(W, R, V ) where R is the relation Rc restricted to W , and V is the canonical
relation restricted to W .
Obviously, we are only interested in such models for which we can prove a Truth
Lemma. The following deﬁnition gives a sufﬁcient condition for that.
Deﬁnition 4.69 A set W of maximal consistent sets is called diamond saturated if
it satisﬁes the requirement that for each Σ ∈ W and each formula F ψ ∈ Σ there
is a set Ψ ∈ W such that ΣRc Ψ and ψ ∈ Ψ , and the analogous condition holds for
past formulas.232
4 Completeness
Lemma 4.70 (Truth Lemma) Let W be a diamond saturated set of maximal con-
sistent sets of formulas. Then for any Γ ∈ W and any formula φ:
Mc |W , Γ  φ iff φ ∈ Γ.
Proof. Straightforward by induction on φ.
Our goal is now to prove the existence of diamond saturated collections of witness-
ing MCSs.
Proposition 4.71 Let ξ be some consistent formula. Then there is a countable,
diamond saturated collection W of witnessing MCSs such that ξ ∈ Ξ for some
Ξ ∈ W.
Proof. The basic idea of the proof is to deﬁne W step by step, in a sort of parallel
Lindenbaum construction on graphs. During the construction we are dealing with
ﬁnite approximations of W . At each stage, one of the shortcomings of the current
approximation is taken care of; this can be done in such a way that the limit of the
construction has no shortcomings at all. A ﬁnite approximation of W will consist
of a ﬁnite graph together with a labeling which assigns a ﬁnite set of formulas to
each node of the graph. We associate a formula with each of these ﬁnite labeled
graphs, and require that this corresponding formula be consistent for each of the
approximations. The ﬁrst graph has no edges, and just one point whose label set
is the singleton {ξ}. The construction is such that the graph is growing in two
senses: edges may be added to the graph, and formulas may be added to the label
sets. (Some readers may ﬁnd it helpful to think of this process as a rather abstract
tableaux construction.) All this is done to ensure that in the limit we are dealing
with a (possibly inﬁnite) labeled graph meeting the requirements that (i) the label
set of each point is an MCS, (ii) each label set contains a witness and (iii) if a
formula of the form F φ (P φ) belongs to the label set of some node, then there is
an edge connecting this node to another one containing φ in its label set. Finally,
W is deﬁned as the range of this inﬁnite labeling function – note that the label
function will not be required to be injective.
Now for the technical details. Approximations to W will be called networks: a
network is a quadruple N = (N, E, d, Λ) such that (N, E) is a ﬁnite, undirected,
connected and acyclic graph; d is a direction function mapping each edge (s, t) of
the graph to either R or its converse Rˇ; and Λ is a label function mapping each
node of N to a ﬁnite set of formulas.
As in our earlier example of a step-by-step construction, we ﬁrst want to formu-
late coherence conditions on networks and deﬁne the notion of a defect of network
with respect to its ideal, W . We start with a formulation of the coherence of a
network. Since we are working in the basic temporal similarity type – that is, we
have diamonds both for looking along R and along Rˇ – there is an obvious way of4.7 Rules for the Undeﬁnable
233
describing the network, from each of its nodes. Let N = (N, E, d, Λ) be some net-
work, and let s and t be two adjacent nodes of N . We use the following notational
conventions:
F if d(s, t) = R,
st :=
P if d(t, s) = Rˇ.
Moreover, let E(s) denote the set of nodes adjacent to s. Finally, we let λ(s)

denote the conjunction Λ(s). Deﬁne

Δ(N , s) := λ(s) ∧ v∈E(s) svθ(N , v, s),

θ(N , t, s) := λ(t) ∧ s=v∈E(t) tvθ(N , v, t).
In words, Δ(N , s) starts with a local description λ(s) of s and then proceeds to its
neighbors. For each neighbor v, Δ(N , s) writes a future operator if d(s, v) = R
(and a past operator if d(s, v) = Rˇ) and then starts to describe the network after v
by calling θ. θ(N , v, s) ﬁrst gives a local description λ(v) of v, and then recursively
proceeds to the neighbors of v – except for s. The omission of s, together with the
ﬁniteness and acyclicity of the graph, ensures that we end up with a ﬁnite formula.
The following claim shows that it does not really matter from which perspective
we describe N .
Lemma 4.72 For any network N and any two nodes s, t in N , Δ(N , s) is consis-
tent iff Δ(N , t) is consistent.
Proof. By the connectedness of N it is sufﬁcient to prove the Lemma for adjacent
s and t; the general case can be proved by a simple induction on the length of the
path connecting the two nodes.
So suppose that s and t are adjacent; without loss of generality assume that
d(s, t) = R. Since N is ﬁxed it will not lead to confusion if we abbreviate Δ(N , x)
by Δ(x) and θ(N , x, y) by θ(x, y). Then by deﬁnition, Δ(s) is given by

Δ(s) = λ(s) ∧
suθ(u, s)
u∈E(s)
= λ(s) ∧ F θ(t, s) ∧

suθ(u, s)
t=u∈E(s)
= F θ(t, s) ∧ θ(s, t).
Likewise, we can show that
Δ(t) = θ(t, s) ∧ P θ(s, t).
But it is a general property of any logic extending Kt that for any two formulas
α and β, F α ∧ β is consistent iff α ∧ P β is consistent. From this, the Lemma is
immediate.234
4 Completeness
The upshot of Lemma 4.72 is a good deﬁnition of the coherence of a network: we
will call a network N coherent if Δ(N , s) is consistent for each of (equivalently:
some of) its nodes s. However, being ﬁnite, our networks will never be perfect.
What kinds of defects can they have?
A defect of a network is either (D1) a pair (s, φ) such that neither φ nor ¬φ
belongs to Λ(s); (D2) a pair (s, F φ) such that F φ ∈ Λ(s) while there is no witness
for this (in the sense that φ ∈ Λ(t) for some node t with Est and d(s, t) = R); (D3)
a similar pair (s, P φ); or (D4) a node s without a name; that is, name(φ) ∈ Λ(s)
for no formula φ.
We will show that each kind of defect of a network can be repaired. For this we
need some terminology. A network N  extends a network N (notation: N   N ),
if N ⊆ N  , while E = E  ∩ N × N , d = d |N and Λ(s) ⊆ Λ (s) for each node s
of N .
Lemma 4.73 For any defect of a ﬁnite, coherent network N there is a ﬁnite, co-
herent N   N lacking this defect.
Proof. Let N = (N, E, d, Λ) be a coherent network and assume that N has some
defect. We will prove the Lemma by showing how to remove the various types of
defect.
D1-defects.
Assume that there is a node s and a formula φ such that neither φ nor ¬φ belongs
to Λ. Since the formula Δ(N , s) is consistent, it follows that either Δ(N , s) ∧ φ
or Δ(N , s) ∧ ¬φ is consistent; let ±φ denote the formula such that Δ(N , s) ∧ ±φ
is consistent. Now deﬁne N  by N  := N , E  := E, d := d, while Λ is given by
Λ (t) = Λ(t) for t = s and
Λ(s) := Λ(s) ∪ {±φ}.
Clearly, N  is a ﬁnite network lacking the defect (s, φ). It is also obvious that
Δ(N  , s) is the formula Δ(N , s) ∧ ±φ, so Δ(N  , s) is consistent, and hence, N 
is coherent.
D2-defects.
Assume that there is a node s and a formula φ such that F φ ∈ Λ(s) while there is
no witness for this. Take a new node t (that is, t does not belong to N ) and deﬁne
N  as follows:
N  := N ∪ {t},
E  := E ∪ {(s, t)},
d := d ∪ {((s, t), R)},
Λ := Λ ∪ {(t, {φ})}.4.7 Rules for the Undeﬁnable
235
It is obvious that N  extends N and that the defect has been repaired. Finally,
it is clear by the deﬁnitions that Δ(N  , s) = Δ(N , s): the only information that
the new node adds to the description is a conjunct F φ and by assumption this was
already a member of Λ(s), and thus a conjunct of λ(s). Hence, the coherence of
N  is an immediate consequence of the coherence of N .
D3-defects.
Repaired analogously to D2-defects.
D4-defects.
These are repaired in the same way as D1-defects, using the fact that if Δ(N , s)
is consistent, then there is a propositional variable p that does not occur in any of
the label sets. And here – at last – we use the IRR-rule to show that the formula
Δ(N , s) ∧ name(p) is consistent. This completes the proof of Lemma 4.73.
Finally, we return to the proof of Proposition 4.71. Assume that ξ is a consistent
formula.
By a standard step-by-step construction we can deﬁne a sequence (Ni )i∈N of
networks such that
(i) N0 is a one-node network with label set {ξ},
(ii) Nj extends Ni whenever i < j, and
(iii) for every defect of any network Ni there is a network Nj with j > i lacking
this defect.
Let N be the set i∈N Ni ; and for s ∈ N , deﬁne Λ(s) = i∈N Λi (s). We claim
that for every s ∈ N , Λ(s) is a witnessing MCS. We ﬁrst show that for all formulas
φ, either φ or ¬φ belongs to Λ(s). Let i ∈ N be such that s is already in existence
in Ni ; if neither φ nor ¬φ belongs to Λi (s), this constitutes a defect of Ni . Hence,
by the construction there is some j > i such that either φ or ¬φ belongs to Λj (s).
But then the same formula belongs to Λ(s). In the same manner we can prove
that every set Λ(s) contains a name. Now assume that Λ(s) is not consistent; then
there are formulas φ1 , . . . , φn in Λ(s) such that φ1 ∧ · · · ∧ φn is inconsistent. By
construction, there must be a k ∈ N such that each φi belongs already to Λk (s).
But this contradicts the consistency of Δ(Nk , s) and hence, the coherency of Nk .
Finally, deﬁne W as the range of Λ. The preceding paragraphs show that W is
a collection of witnessing MCSs. By our deﬁnition of N0 , it follows that ξ belongs
to some MCS in W .
Now let F φ be some formula in Γ ∈ W . By deﬁnition, there is some s ∈ N such
that Γ = Λ(s), and thus, some i ∈ N such that F φ ∈ Λi (s). By our construction
there is some j ≥ i and some t ∈ Nj such that Ej st and φ ∈ Λj (t). It follows that
φ ∈ Λ(t), so it remains to prove that Λ(s)Rc Λ(t). In order to reach a contradiction,
suppose otherwise. Then there is a formula ψ ∈ Λ(t) such that F ψ ∈ Λ(s). Since236
4 Completeness
Λ(s) is an MCS, this implies that ¬F ψ ∈ Λ(s). Now let k ∈ N be large enough
that ψ ∈ Λk (t) and ¬F ψ ∈ Λk (s). From this it is immediate that Δ(Nk , s) is
inconsistent; this contradicts the coherency of Nk . This proves that W is diamond
saturated.
But then we have proved that W meets all requirements phrased in Proposi-
tion 4.71, and this completes its proof.
This shows that we have more or less solved the ﬁrst problem concerned with work-
ing in a trimmed down version of the canonical model: we have established that
every consistent formula ξ can be satisﬁed in an irreﬂexive canonical-like model.
Let us now think about the second kind of problem. Concretely, how can we prove
that we have not destroyed the nice properties of the canonical frame by moving
to a subframe? In particular, how can we ascertain density? We will see that here
we will make good use of the special naming property of the formulas name(φ),
namely that they can be used as identiﬁers of MCSs.
Lemma 4.74 Let W be a diamond saturated collection of witnessing maximal
consistent sets of formulas, and let < denote the canonical relation Rc restricted to
W . Then the frame (W, <) is a non-branching, unbounded, dense, strict ordering.
Proof. Let W and < be as in the statement of the lemma. Clearly, (W, <) is a
subframe of the canonical frame; hence, it inherits every universal property of T,
such as transitivity or non-branching. Irreﬂexivity follows from the fact that Γ Rc Γ
for no witnessing Γ . This shows that < is a non-branching, strict ordering of W .
Unboundedness is not a universal condition, but nevertheless follows rather eas-
ily: simply use the fact that the formulas F  and P  are theorems of the logic
and, hence, belong to every maximal consistent set. Unboundedness then follows
by the diamond saturation of W .
The case of density is more difﬁcult, and here is where names are genuinely
useful. Assume that Γ and Δ are two MCSs such that Γ < Δ. We have to ﬁnd an
MCS Θ in W that lies between Γ and Δ. Let δ be the formula such that name(δ) ∈
Δ. It follows from Γ < Δ that F name(δ) ∈ Γ , so using the density axiom, we
ﬁnd that F F name(δ) ∈ Γ . From this we may infer the existence of an MCS
Θ ∈ W with Γ < Θ and F name(δ) ∈ Θ.
But is Θ < Δ? Note that since < is non-branching to the right, we already know
that Θ < Δ or Θ = Δ or Δ < Θ. But it clearly cannot be the case that Θ = Δ,
since F δ ∈ Θ and ¬F δ ∈ Δ. Neither is it possible that Δ < Θ, for suppose
otherwise. It would follows from F δ ∈ Θ that F F δ ∈ Δ, so by the transitivity
axiom, F δ ∈ Δ; but this would contradict the fact that ¬F δ ∈ Δ.
We now have all the ingredients for the main theorem of this section:
Theorem 4.75 Kt Q+ is complete with respect to (Q, <).4.7 Rules for the Undeﬁnable
237
Proof. Given any consistent formula ξ, construct a countable, diamond saturated
set W of witnessing MCSs for ξ, as in the proof of Proposition 4.71. By the Truth
Lemma 4.70, ξ is satisﬁable at some MCS Ξ in the model Mc |W induced by W ;
and by Lemma 4.74, this model is based on a non-branching, unbounded, dense,
strict ordering. But then the subframe generated by Ξ is based on a countable,
dense, unbounded, strict total order and, hence, is isomorphic to the ordering of
the rationals.
How widely applicable are these ideas? Roughly speaking, the situation is as fol-
lows. The basic idea is widely applicable; various rules for the undeﬁnable have
been employed in many different modal languages, and for many different classes
of models (we will see further examples in Chapter 7). Moreover, the use of such
rules can be fruitfully combined with other techniques, notably the step-by-step
method (this combination sometimes succeeds when all else fails). Rules for the
undeﬁnable are fast becoming a standard item in the modal logicians’ toolkit.
Nonetheless the method has its limitations, at least in the kinds of modal lan-
guages we have been considering so far. These limitations are centered on the
problem of working with submodels of the original canonical model.
As we saw, the ﬁrst problem – retaining sufﬁciently many MCSs for proving the
Truth Lemma – has a fairly satisfactory solution. Two remarks are in order here.
(i) The method only works well when we are working in tense logic. In the
proof of the ‘multiple Lindenbaum Lemma’, we crucially needed operators
for looking in both directions in order to show that it does not matter from
which perspective we describe a graph. If we have no access to the infor-
mation of nodes lying ‘behind,’ we are forced to add a countably inﬁnite
family of more and more complex rules, instead of one single irreﬂexivity
rule.
But there are no problems in generalizing the proof of Proposition 4.71 to
similarity types with more than one tense diamond and/or versatile polyadic
operators. For example, in Exercise 4.7.3 the reader is asked to use the
method to prove completeness for the language of PDL with converse pro-
grams.
(ii) Observe that we only proved weak completeness for Kt Q+ . This is be-
cause our proof of Proposition 4.71 only works with ﬁnite networks. In the
presence of names, however, it is possible to prove a stronger version of
Proposition 4.71; the basic idea is that when an MCS Γ contains a name,
other MCSs may have complete access to the information in Γ through the
ﬁnite ‘channel’ of Γ ’s name. For details we refer to Exercise 4.7.2.
There is a second problem which seems to be more serious. Which properties of the
canonical frame can we guarantee to hold in a trimmed down version? In general,238
4 Completeness
very few. Obviously, universal properties of the canonical model hold in each of
its submodels, and ﬁrst-order properties that are the standard translation of closed
modal formulas (such as ∀x∃y Rxy) are valid in each subframe for which a Truth
Lemma holds, but that is about it.
This is the point where the names come in very handy. In fact, in order to prove
the inheritance of universal-existential properties like density, the names seem to
be really indispensable. If, on the other hand, we have names at our disposal,
we can prove completeness results for a wide range of logics. Roughly speaking,
in case the logic is a tense logic, we can show that every Sahlqvist formula is
‘distinguishing-canonical’. The crucial observation is that the witnessing submodel
of the canonical model is a named model.
Deﬁnition 4.76 Let τ be some modal similarity type. A τ -model M is called
named if for every state s in M there is a formula φ such that s is the only point in
M satisfying φ.
Theorem 4.77 Let τ be some modal similarity type, and suppose that M = (F, V )
is a named τ -model. Then for every very simple Sahlqvist formula σ:
M  σ iff F  σ.
(4.1)
In the particular case of the basic temporal similarity type, if M is in addition a
bidirectional model, then (4.1) holds for every Sahlqvist formula.
Proof. Let M be a named model. It was the aim of Exercise 1.4.7 to let the reader
show that the collection
A := {V (φ) | φ a formula }
is closed under the boolean and modal operations. Hence, the structure g = (F, A)
is a general frame. Since M is named, A contains all singletons. The result then
follows from Theorem 5.90 in Chapter 5 – for the second part of the theorem,
Exercise 5.6.1 is needed as well.
The use of rules for the undeﬁnable really comes into its own in some of the ex-
tended modal languages studied for Chapter 7. Two main paths have been explored,
and we will discuss both. In the ﬁrst, the difference operator is added to an ortho-
dox modal language. It is then easy to state a rule for the undeﬁnable (even if the
underlying modal language does not contain converse operators) and (by extending
the remarks just made) to prove a D-Sahlqvist theorem. In the second approach,
atomic formulas called nominals and operators called satisfaction operators are
added to an orthodox modal language. These additions make it straightforward to
deﬁne simple rules for the undeﬁnable (even if the underlying modal language does
not contain converse operators) and to prove a general completeness result without
making use of step-by-step arguments.4.8 Finitary Methods I
239
Exercises for Section 4.7
4.7.1 We are working in the basic modal similarity type. First, prove that a frame is intran-
sitive (∀xyz (Rxy ∧ Ryz → ¬Rxz)) iff we can falsify the formula 2p → 33p at every
state of the frame.
Second, let KB be the logic K, extended with the symmetry axiom p → 23p and the
rule
(ITR)
if  (2p ∧ 22¬p) → φ then  φ, provided p does not occur in φ.
Show that KB is sound and complete with respect to the class of symmetric, intransitive
frames.
4.7.2 Assume that we are working with the logic K t Q+ . Show that for each consistent
set Σ there is a diamond saturated set of MCSs W such that Σ ⊆ Ξ for some Ξ ∈ W .
(Hint: use a construction analogous to the one employed in the proof of Proposition 4.71.
Add an inﬁnite set of new variables to the language and ﬁrst prove that Σ ∪ {name(p)} is
consistent for any new variable p. A network is now allowed to have one special node with
an inﬁnite label set, which should contain Σ ∪ {name(p)}. A description of a network is
now an inﬁnite set of formulas.)
4.7.3 Assume that we extend the language of PDL with a reverse program constructor:
• if π is a program then so is π −1 .
The intended accessibility relation of π −1 is the converse relation of R π . Let PDLω be
the axiom system of PDL (see Section 4.8), modulo the following changes:
(i) Add the converse axiom schemas p → [π]π −1 p and p → [π −1 ]πp,
(ii) Replace the Segerberg induction axiom with the following inﬁnitary rule:
(ω–∗)
If  φ → [π n ]ψ for all n ∈ ω, then  φ → [π ∗ ]ψ.
Prove that this logic is sound and complete with respect to the standard models.
4.8 Finitary Methods I
In this section we introduce ﬁnite canonical models. We use such models to prove
weak completeness results for non-compact logics. We examine one of the best
known examples – propositional dynamic logic – in detail. More precisely, we
will axiomatize the validities of regular (test free) propositional dynamic logic.
Recall from Chapter 1 that this has a set of diamonds π indexed by a collection
of programs Π. Π consists of a collection of basic programs, and the programs
generated from them using the constructors ∪, ; and ∗. A frame for this language is
a transition system F = (W, Rπ )π∈Π , but we are only interested in regular frames,
that is, frames such that for all programs π, π1 and π2 :
Rπ1 ∪π2
= R π 1 ∪ Rπ 2 ,
Rπ1 ;π2 = Rπ1 ; Rπ2 ,
Rπ∗
= (Rπ )∗ .240
4 Completeness
We say that a formula φ is a PDL-validity (written  φ) if it is valid on all regular
frames.
The collection of PDL-validities is not compact: consider the set
Σ = {a∗ p, ¬p, ¬ap, ¬aap, ¬aaap, . . .}.
Any ﬁnite subset of Σ is satisﬁable on a regular frame at a single point, but Σ
itself is not. This compactness failure indicates that a strong completeness result
will be out of reach (recall Remark 4.44) so our goal (as with KL) should be to
prove a weak completeness result. It is not too hard to come up with a candidate
axiomatization. For a start, the ﬁrst two regularity conditions given above can be
axiomatized by Sahlqvist axioms. The last condition is more difﬁcult, but even
here we have something plausible: recall that in Example 3.10 we saw that this last
condition is deﬁned by the formula set
Δ = {(p ∧ [π ∗ ](p → [π]p)) → [π ∗ ]p, π ∗ p ↔ (p ∨ ππ ∗ p) | π ∈ Π}.
This suggests the following axiomatization.
Deﬁnition 4.78 A logic Λ in the language of propositional dynamic logic is a nor-
mal propositional dynamic logic if it contains every instance of the following ax-
iom schemas:
(i) [π](p → q) → ([π]p → [π]q),
(ii) πp ↔ ¬[π]¬p,
(iii) π1 ; π2 p ↔ π1 π2 p,
(iv) π1 ∪ π2 p ↔ π1 p ∨ π2 p,
(v) π∗ p ↔ (p ∨ ππ ∗ p),
(vi) [π∗ ](p → [π]p) → (p → [π ∗ ]p),
and is closed under modus ponens, generalization (Λ φ implies Λ [π]φ, for all
programs π) and uniform substitution. We call the smallest normal propositional
dynamic logic PDL. In this section,  φ means that φ is a theorem of PDL,
consistency means PDL-consistency, and so on.
As we have already remarked, axioms (iii) and (iv) are (conjunctions of) Sahlqvist
axioms; they are canonical for the ﬁrst two regularity conditions, respectively. Fur-
ther, observe that axiom (v) is a Sahlqvist formula as well; it is canonical for the
condition Rπ∗ = Id ∪Rπ ; Rπ∗ . Thus we have isolated the difﬁcult part: axiom (vi),
which we will call the induction axiom for obvious reasons, is the formula we need
to think about if we are to understand how to cope with the canonicity failure. It is
probably a good idea for the reader to attempt Exercise 4.8.1 right away.
Proving the soundness of PDL is straightforward (though the reader should
(re-)check that the induction axiom really is valid on all regular frames). We will4.8 Finitary Methods I
241
prove completeness with the help of ﬁnite canonical models. Our work falls into
two parts. First we develop the needed background material: ﬁnitary versions of
MCSs, Lindenbaum’s Lemma, canonical models, and so on. Following this, we
turn to the completeness proof proper.
Recall that a set of formulas Σ is closed under subformulas if for all φ ∈ Σ, if
ψ is a subformula of φ then ψ ∈ Σ.
Deﬁnition 4.79 (Fischer-Ladner Closure) Let X be a set of formulas. Then X is
Fischer-Ladner closed if it is closed under subformulas and satisﬁes the following
additional constraints:
(i) If π1 ; π2 φ ∈ X then π1 π2 φ ∈ X.
(ii) If π1 ∪ π2 φ ∈ X then π1 φ ∨ π2 φ ∈ X.
(iii) If π∗ φ ∈ X then ππ∗ φ ∈ X.
If Σ is any set of formulas then FL(Σ) (the Fischer-Ladner closure of Σ) is the
smallest set of formulas containing Σ that is Fischer-Ladner closed.
Given a formula φ, we deﬁne ∼φ as the following formula:
∼φ =
ψ
if φ is of the form ¬ψ,
¬φ otherwise.
A set of formulas X is closed under single negations if ∼φ belongs to X whenever
φ ∈ X.
We deﬁne ¬FL(Σ), the closure of Σ, as the smallest set containing Σ which is
Fischer-Ladner closed and closed under single negations.
It is convenient to talk as if ∼φ really is the negation of φ, and we often do so in
what follows. The motivation of closing a set under single negations is simply to
have a ‘connective’ that is just as good as negation, while keeping the set ﬁnite.
(If we naively closed under ordinary negation, then any set would have an inﬁnite
closure.)
It is crucial to note that if Σ is ﬁnite, then so is its closure. Some reﬂection on the
closure conditions will convince the reader of this fact, but it is not entirely trivial
to give a precise proof. We leave this little combinatorial puzzle to the reader as
Exercise 4.8.2.
We are now ready to deﬁne the generalization of the notion of a maximal con-
sistent set that we will use in this section.
Deﬁnition 4.80 (Atoms) Let Σ be a set of formulas. A set of formulas A is an
atom over Σ if it is a maximal consistent subset of ¬FL(Σ). That is, A is an atom
over Σ if A ⊆ ¬FL(Σ), if A is consistent, and if A ⊂ B ⊆ ¬FL(Σ) then B is
inconsistent. At(Σ) is the set of all atoms over Σ.4 Completeness
242
Lemma 4.81 Let Σ be any set of formulas, and A any element of At(Σ). Then:
(i) For all φ ∈ ¬FL(Σ): exactly one of φ and ∼φ is in A.
(ii) For all φ ∨ ψ ∈ ¬FL(Σ): φ ∨ ψ ∈ A iff φ ∈ A or ψ ∈ A.
(iii) For all π1 ; π2 φ ∈ ¬FL(Σ): π1 ; π2 φ ∈ A iff π1 π2 φ ∈ A.
(iv) For all π1 ∪π2 φ ∈ ¬FL(Σ): π1 ∪π2 φ ∈ A iff π1 φ ∈ A or π2 φ ∈ A.
(v) For all π∗ φ ∈ ¬FL(Σ): π ∗ φ ∈ A iff φ ∈ A or ππ∗ φ ∈ A.
Proof. With the possible exception of the last item, obvious.
Atoms are a straightforward generalization of MCSs. Note, for example, that if we
choose Σ to be the set of all formulas, then At(Σ) is just the set of all MCSs. More
generally, the following holds:
Lemma 4.82 Let M be the set of all MCSs, and Σ any set of formulas. Then
At(Σ) = {Γ ∩ ¬FL(Σ) | Γ ∈ M}.
Proof. Exercise 4.8.3.
Unsurprisingly, an analog of Lindenbaum’s Lemma holds:
Lemma 4.83 If φ ∈ ¬FL(Σ) and φ is consistent, then there is an A ∈ At(Σ)
such that φ ∈ A.
Proof. If Σ is inﬁnite, the result is exactly Lindenbaum’s Lemma, so let us turn to
the more interesting ﬁnite case. There are two ways to prove this. We could simply
apply Lindenbaum’s Lemma: as φ is consistent, there is an MCS Γ that contains φ.
Thus, by the previous lemma, Γ ∩ ¬FL(Σ) is an atom containing φ.
But this is heavy handed: let us look for a ﬁnitary proof instead. Note that the

information in an atom A can be represented by the single formula φ∈A φ. We
 Obviously A
 ∈ A.
will write such conjunctions of atoms as A.
Using this notation, we construct the desired atom as follows. Enumerate the
elements of ¬FL(Σ) as σ1 , . . . , σm . Let A0 be {φ}. Suppose that An has been
deﬁned, where n < m. We have that
n ↔ (A
n ∧ σn+1 ) ∨ (A
n ∧ ∼σn+1 ),
A
as this is a propositional tautology, thus either An ∪ {σn+1 } or An ∪ {∼σn+1 } is
consistent. Let An+1 be the consistent extension, and let A be Am . Then A is an
atom containing φ.
Note the technique: we forced a ﬁnite sequence of choices between σ and ∼σ.
Actually, we did much the same thing in the proof of Lemma 4.26, the Existence
Lemma for modal languages of arbitrary similarity type, and we will soon have
other occasions to use the idea.
Now that we have Lemma 4.83, it is time to deﬁne ﬁnite canonical models:4.8 Finitary Methods I
243
Deﬁnition 4.84 (Canonical Model over Σ) Let Σ be a ﬁnite set of formulas.
The canonical model over Σ is the triple (At(Σ), {SπΣ }π∈Π , V Σ ) where for all
propositional variables p, V Σ (p) = {A ∈ At(Σ) | p ∈ A}, and for all atoms
A, B ∈ At(Σ) and all programs π,
 ∧ πB
 is consistent.
ASπΣ B if A
V Σ is called the canonical valuation, and the Sπ are called the canonical relations.
We generally drop the Σ superscripts.
Although we have deﬁned it purely ﬁnitarily, the canonical model over Σ is ac-
tually something very familiar: a ﬁltration. Which ﬁltration? Exercise 4.8.4 asks
the reader to ﬁnd out. Further, note that although some of the above discussion is
speciﬁc to propositional dynamic logic (for example, the use of the Fischer-Ladner
closure) the basic ideas are applicable to any modal language. In Exercise 4.8.7 we
ask the reader to apply such techniques to the logic KL.
But of course, the big question is: does this ﬁnite canonical model work? Given
a consistent formula φ, we need to satisfy φ in a regular model. This gives two
natural requirements on the canonical model: ﬁrst, we need to prove some kind of
Truth Lemma, and second, we want the model to be regular. The good news is that
we can easily prove a Truth Lemma; the bad news is that we are unable to show
regularity. This means that we cannot use the canonical model itself; rather, we
will work with the canonical relations Sπ for the atomic relations only, and deﬁne
relations Rπ for the other programs in a way that forces the model to be regular.
Deﬁnition 4.85 (Regular PDL-model over Σ) Let Σ be a ﬁnite set of formulas.
For all basic programs a, deﬁne RaΣ to be SaΣ . For the complex programs, induc-
tively deﬁne the PDL-relations RπΣ in the usual way using unions, compositions,
and reﬂexive transitive closures. Finally, deﬁne R, the regular PDL-model over Σ,
to be (At(Σ), {RπΣ }π∈Π , V Σ ), where V Σ is the canonical valuation. Again, we
generally drop the Σ superscripts.
But of course, now the main question is, will we be able to prove a Truth Lemma?
Fortunately, we can prove the key element of this lemma, namely, an Existence
Lemma (cf. Lemma 4.89 below). First the easy part. As the canonical relations Sa
are identical to the PDL-relations Ra for all basic programs a, we have:
Lemma 4.86 (Existence Lemma for Basic Programs) Let A be an atom, and let
a be a basic program. Then for all formulas aψ in ¬FL(Σ), aψ ∈ A iff there
is a B ∈ At(Σ) such that ARa B and ψ ∈ B.
Proof. This can be proved by appealing to the standard Existence Lemma and then
taking intersections (as in Lemma 4.83) – but it is more interesting to prove it244
4 Completeness
ﬁnitarily. For the right to left direction, suppose there is a B ∈ At(Σ) such that
ARa B and ψ ∈ B. As Ra and Sa are identical for basic programs, we have that
 ∧ aB
 is consistent. As ψ is one of the conjuncts in B,
 A
 ∧ aψ is
ASa B, thus A
consistent. As aψ is in ¬FL(Σ) it must also be in A, for A is an atom and hence
maximal consistent in ¬FL(Σ).
For the left to right direction, suppose aψ ∈ A. We construct an appropriate
atom B by forcing choices. Enumerate the formulas in ¬FL(Σ) as σ1 , . . . , σm .
Deﬁne B0 to be {ψ}. Suppose as an inductive hypothesis that Bn is deﬁned such
 ∧ aB
!n is consistent (where 0 ≤ n < m). We have
that A
n ↔ a((B
n ∧ σn+1 ) ∨ (B
n ∧ ∼σn+1 ))
 aB
thus
n ↔ (a(B
n ∧ σn+1 ) ∨ a(B
n ∧ ∼σn+1 )).
 aB
Therefore either for B = Bn ∪ {σn+1 } or for B  = Bn ∪ {∼σn+1 } we have that
! is consistent. Choose Bn+1 to be this consistent expansion, and let B
 ∧ aB
A
be Bm . B is the atom we seek.
Now for the hard part. Axioms (v) and (vi) from Deﬁnition 4.78 cannot enforce
the desired identity between Sπ and Rπ . But good news is at hand. These axioms
are very strong and manage to ‘approximate’ the desired behavior fairly well. In
particular, they are strong enough to ensure that Sπ ⊆ Rπ for arbitrary programs
π. This inclusion will enable us to squeeze out a proof of the desired Existence
Lemma. The following lemma is the crucial one:
Lemma 4.87 For all programs π, Sπ∗ ⊆ (Sπ )∗ .
Proof. We need to show that for all programs π, if ASπ∗ B then there is a ﬁnite
sequence of atoms C0 , . . . , Cn such that A = C0 Sπ C1 , . . . , Cn−1 Sπ Cn = B. Let
D be the set of all atoms reachable from A by such a sequence. We will show that
B ∈ D.

 Note that δ ∧ π¬δ is inconsistent, for suppose other-
Deﬁne δ to be D∈D D.
 would be consistent for at least one atom E not in D, which
wise. Then δ ∧ πE

 was consistent for at least one D ∈ D. But then by
would mean that D ∧ πE
DSπ E, E could be reached from A in ﬁnitely many Sπ steps, which would imply
that E ∈ D – which it is not.
As δ ∧ π¬δ is inconsistent,  δ → [π]δ, hence by generalization  [π∗ ](δ →
 is one of the disjuncts
[π]δ). By axiom (vi),  δ → [π∗ ]δ. Now, as A(Sπ )∗ A, A
∗
 → δ and hence  A
 → [π ]δ. As our initial assumption was that
in δ, thus  A
∗


 ∧ π ∗ (B
 ∧ δ) is consistent too. But this
A ∧ π B is consistent, it follows that A
 of δ, B
∧D
 is consistent. As B and D are
means that for one of the disjuncts D
atoms, B = D and hence B ∈ D.4.8 Finitary Methods I
245
With the help of this lemma, it is straightforward to prove the desired inclusion:
Lemma 4.88 For all programs π, Sπ ⊆ Rπ .
Proof. Induction on the structure of π. The base case is immediate, for we deﬁned
 ∧ π1 ; π2 B

Ra to be Sa for all basic programs a. So suppose ASπ1 ;π2 B, that is, A


is consistent. By axiom (iii) of Deﬁnition 4.78, A ∧ π1 π2 B is consistent as
well. Using a ‘forcing choices’ argument we can construct an atom C such that




A∧π
1 C and C∧π2 B are both consistent. But then, by the inductive hypothesis,
ARπ1 C and CRπ2 B. It follows that ARπ1 ;π2 B, as required. A similar argument
using axiom (iv) from Deﬁnition 4.78 shows that Sπ1 ∪π2 ⊆ Rπ1 ∪π2 .
The case for reﬂexive transitive closures follows from the previous lemma and
the observation that Sπ ⊆ Rπ implies (Sπ )∗ ⊆ (Rπ )∗ .
We can now prove an Existence Lemma for arbitrary programs.
Lemma 4.89 (Existence Lemma) Let A be an atom and let πψ be a formula in
¬FL(Σ). Then πψ ∈ A iff there is a B such that ARπ B and ψ ∈ B.
Proof. The left to right direction puts the crucial inclusion to work. Suppose
πψ ∈ A. We can build an atom B such that ψ ∈ B and ASπ B by ‘forcing
choices’ in the now familiar manner. But we have just proved that Sπ ⊆ Rπ , thus
ARπ B as well.
For the right to left direction we proceed by induction on the structure of π.
The base case is just the Existence Lemma for basic programs, so suppose π has
the form π1 ; π2 , and further suppose that ARπ1 ;π2 B and ψ ∈ B. Thus there is
an atom C such that ARπ1 C and CRπ2 B and ψ ∈ B. By the Fischer-Ladner
closure conditions, π2 ψ belongs to ¬FL(Σ), hence by the inductive hypothesis,
π2 ψ ∈ C. Similarly, as π1 π2 ψ is in ¬FL(Σ), π1 π2 ψ ∈ A. Hence by
Lemma 4.81, π1 ; π2 ψ ∈ A, as required.
We leave the case π = π1 ∪ π2 to the reader and turn to the reﬂexive transitive
closure: suppose π is of the form ρ∗ . Assume that ARρ∗ B and ψ ∈ B. This
means there is a ﬁnite sequence of atoms C0 , . . . , Cn such that A = C0 Rρ C1 , . . . ,
Cn−1 Rρ Cn = B. By a subinduction on n we prove that ρ∗ ψ ∈ Ci for all i; the
required result for A = C0 is then immediate.
Base case: n = 0. This means A = B. From axiom (v) in Deﬁnition 4.78
we have that  ρ∗ ψ ↔ ψ ∨ ρρ∗ ψ, and hence that  ψ → ρ∗ ψ. Thus
ρ∗ ψ ∈ A.
Inductive step. Suppose the result holds for n ≤ k, and that
A = C0 Rρ C1 , . . . , Ck Rρ Ck+1 = B.
By the inductive hypothesis, ρ∗ ψ ∈ C1 . Hence ρρ∗ ψ ∈ A, for ρρ∗ ψ ∈
¬FL(Σ). But  ρ∗ ψ ↔ ψ ∨ ρρ∗ ψ. Hence ρ∗ ψ ∈ A.246
4 Completeness
This completes the subinduction, and establishes the required result for ρ∗ . It
also completes the main induction and thus the proof of the lemma.
Lemma 4.90 (Truth Lemma) Let R be the regular PDL-model over Σ. For all
atoms A and all ψ ∈ ¬FL(Σ), R, A  ψ iff ψ ∈ A.
Proof. Induction on the number of connectives. The base case follows from the
deﬁnition of the canonical valuation over Σ. The boolean case follows from
Lemma 4.81 on the properties of atoms. Finally, the Existence Lemma pushes
through the step for the modalities in the usual way.
The weak completeness result for propositional dynamic logic follows.
Theorem 4.91 PDL is weakly complete with respect to the class of all regular
frames.
Exercises for Section 4.8
4.8.1 Show that the induction axiom is not canonical.
4.8.2 Prove that for a ﬁnite set Σ, its closure set ¬FL(Σ) is ﬁnite as well.
4.8.3 Prove Lemma 4.82. That is, show that At(Σ) = {Γ ∩ ¬FL(Σ) | Γ ∈ M}, where
M is the set of all MCSs, and Σ is any set of formulas.
4.8.4 Show that the ﬁnite models deﬁned in the PDL completeness proofs are isomorphic
to certain ﬁltrations.
4.8.5 Show that for any collection of formulas Σ, 


A∈At(Σ) A.
4.8.6 Extend the completeness proof in the text to PDL with tests. Once you have found
an appropriate axiom governing tests, the main line of the argument follows that given in
the text. However, because tests build modalities from formulas you will need to think
carefully about how to state and prove analogs of the key lemmas (such as Lemmas 4.87
and 4.88).
4.8.7 Use ﬁnite canonical models to show that KL is weakly complete with respect to the
class of ﬁnite strict partial orders (that is, the class of ﬁnite irreﬂexive transitive frames).
(Hint: given a formula φ, let Φ be the set of all φ’s subformulas closed under single nega-
tions. Let the points in the ﬁnite canonical model be all the maximal KL-consistent subsets
of Φ. For the relation R, deﬁne Rww  iff (1) for all 2φ ∈ w, both 2φ and φ belong to w 
and (2) there is some 2φ ∈ w  such that 2φ ∈ w. Use the natural valuation. You will need
to make use of the fact that  KL 2φ → 22φ; bonus points if you can ﬁgure out how to
prove this yourself!)
4.8.8 Building on the previous result, show that KL is weakly complete for the class of
ﬁnite transitive trees. (Hint: unravel.)4.9 Finitary Methods II
247
4.9 Finitary Methods II
As we remarked at the end of Section 4.4, although the incompleteness results show
that frame-theoretic tools are incapable of analyzing the entire lattice of normal
modal logics, they are capable of yielding a lot of information about some of its
subregions. The normal logics extending S4.3 are particularly well-behaved, and
in this section we prove three results about them. First, we prove Bull’s Theorem:
all such logics have the ﬁnite frame property. Next, we show that they are all
ﬁnitely axiomatizable. Finally, we show that each of these logics has a negative
characterization in terms of ﬁnite sets of ﬁnite frames, which will be important
when we analyze their computational complexity in Chapter 6.
The logics extending S4.3 are logics of frames that are rooted, transitive, and
connected (∀xy (Rxy ∨Ryx))). To see this, recall that S4.3 has as axioms 4, T, and
.3. These formulas are canonical for transitivity, reﬂexivity, and no branching to the
right, respectively. Hence any point-generated submodel of the canonical model
for these logics inherits all three properties, and will in addition be rooted and
connected. Now, any connected model is reﬂexive. Thus rootedness, transitivity,
and connectedness are the fundamental properties, and we will call any frame that
has them an S4.3 frame. Note that any S4.3 frame can be viewed as a chain of
clusters (see Deﬁnition 2.43), a perspective which will frequently be useful in what
follows.
Bull’s Theorem
Our ﬁrst goal is to prove Bull’s Theorem: all extensions of S4.3 have the ﬁnite
frame property. In Deﬁnition 3.23 we deﬁned the ﬁnite frame property as follows:
Λ has the ﬁnite frame property with respect to a class of ﬁnite frames F if and
only if F  Λ, and for every formula φ such that φ ∈ Λ there is some F ∈ F
such that φ is falsiﬁable on F. Using the terminology introduced in this chapter,
we can reformulate this more concisely as follows: Λ has the ﬁnite frame property
if and only if there is a class of ﬁnite frames F such that Λ = ΛF . So, to prove
Bull’s Theorem, we need to show that if Λ extends S4.3, then any Λ-consistent
formula φ is satisﬁable in a ﬁnite model (W, R, V ) such that (W, R)  Λ. In
short, Bull’s Theorem is essentially a general weak completeness result covering
all logics extending S4.3.
But how are we to build the required models? By transforming the canonical
model. Suppose φ is Λ-consistent. Let w be any Λ-MCS containing φ, and let
Mw = (W w , Rw , V w ) be the submodel of MΛ generated by w. Then Mw , w  φ,
and (as just discussed) Mw is based on an S4.3 frame. We are going to transform
Mw into a ﬁnite model Ms that satisﬁes φ and is based on an S4.3 frame that
validates Λ.
Figure 4.2 shows what is involved. We are going to transform Mw in two distinct4 Completeness
248
MΛ
generated
submodel
- Mw
deﬁnable
variant
- M
bounded
morphism
ﬁltration
?
Mf
?
- Ms
elimination
Fig. 4.2. The models we will construct, and their relationships
ways. One involves taking a ﬁltration and eliminating certain points; this is the
technical heart of the proof. The other involves deﬁning a bounded morphism on
a deﬁnable variant M of Mw ; this part uses the results on deﬁnable variants and
distinguishing models proved in Section 3.4. These transformations offer us two
perspectives on the properties of Ms , and together yield enough information to
prove the result.
And so to work. We ﬁrst discuss the ﬁltration/elimination transformation. Let Φ
be the (ﬁnite) set consisting of all subformulas of 3φ, and let Mf = (W f , Rf , V f )
be the result of transitively ﬁltrating Mw through Φ. Recall that the relation Rf
used in transitive ﬁltrations is deﬁned by Rf |u||v| iff 3ψ ∈ v implies 3ψ ∈ u,
for all 3ψ ∈ Φ, and all u, v ∈ W w ; see Lemma 2.42. As Φ is ﬁnite, so is W f .
By the Filtration Theorem (Theorem 2.39), Mf , |u|  ψ iff Mw , u  ψ, for all
ψ ∈ Φ, and all u ∈ W w . Moreover, Rf is transitive, reﬂexive, and connected, and
|w| is a root of the ﬁltration, thus Mf is based on an S4.3 frame. Hence the frame
underlying Mf is a ﬁnite chain of ﬁnite clusters.
Now for the key elimination step. We want to build a ﬁnite model based on a
frame for Λ. Now, we do not know whether Mw is based on such a frame, but we
do know that Mw  Λ. If we could transfer the truth of Λ in Mw to a ﬁnite dis-
tinguishing model, then by item (iii) of Lemma 3.27 we would immediately have
Bull’s Theorem. Unfortunately, while Mf is ﬁnite, and also (being a ﬁltration) dis-
tinguishing, we have no guarantee that Mf  Λ. This reﬂects something discussed
in Section 2.3: the natural map associated with a ﬁltration need not be a bounded
morphism. It also brings us to the central idea of the proof: eliminate all points in
Mf which prevent the natural map from being a bounded morphism. Obviously,
any model built from Mf by eliminating points will be ﬁnite and distinguishing.
So the crucial questions facing us are: which points should be eliminated, and how
do we know that they can be thrown away without affecting the satisﬁability of
formulas in Φ?
Recall that the natural map associated with a ﬁltration sends each point u in
the original model to the equivalence class |u| in the ﬁltration. So if the natural4.9 Finitary Methods II
249
map from the frame underlying Mw to the frame underlying Mf is not a bounded
morphism, this means that for some β, α ∈ W f we have that Rf βα but
¬∀v ∈ β ∃z (Rw vz ∧ z ∈ α),
or equivalently, that Rf βα but
∃v ∈ β ∀z (z ∈ α → ¬Rw vz).
This motivates the following deﬁnition:
Deﬁnition 4.92 Suppose β, α ∈ W f . We say that α is subordinate to β (α sub β)
if there is a v ∈ β such that for all z ∈ α, it is not the case that Rw vz.
So: if Mf is not a bounded morphic image of Mw under the natural map, then
there is some α ∈ W f such that for some β ∈ W f , Rf βα and α sub β. We must
get rid of all such αs; we will call them eliminable points. But to show that we can
safely eliminate them, we need to understand the sub relation a little better.
Lemma 4.93
(i) If α sub β, then there is a v ∈ β such that for all z ∈ α,
Rw zv.
(ii) If α sub β then Rf αβ.
(iii) The sub relation is transitive and asymmetric.
(iv) Suppose α, β, γ ∈ W f such that α sub γ and not α sub β. Then β sub γ.
Proof. For item (i), note that by deﬁnition there is a v ∈ β such that for all z ∈ α,
it is not the case that Rw vz. But Rw is a connected relation, hence for every z ∈ α,
Rw zv.
For item (ii), suppose α sub β. By item (i), this means that there is some
element v of β, such that every element of α Rw -precedes v. Now if 3ψ ∈ β, then
Mw , v  3ψ. Hence (by the transitivity of Rw ) for all z ∈ α, Mw , z  3ψ too.
This means that 3ψ ∈ α, that is, Rf αβ. (It follows that if the natural map fails
to be bounded morphism because of its behavior on the points β and α, then the
eliminable point α belongs to the same cluster as β.)
Items (iii) and (iv) are left for the reader as Exercise 4.9.1.
We are now ready for the key result: we can safely get rid of all the eliminable
points; there are enough non-eliminable points left to prove an Existence Lemma:
Lemma 4.94 (Existence Lemma) Let u ∈ W w and suppose 3ψ ∈ u ∩ Φ. Then
there is a |v| ∈ W f such that Rf |u||v|, ψ ∈ |v|, and |v| is not eliminable.
Proof. Construct a maximal sequence α0 , α1 , . . . through W f with the following
properties:
(i) α0 = |u|.250
4 Completeness
(ii) If i > 0 and odd, then αi is some |v| such that ψ ∈ v, Rf αi−1 |v|, and not
|v| sub αi−1 .
(iii) If i > 0 and even, then αi is some |v| such that Rf |v|αi−1 and αi−1 sub |v|.
Here is the basic idea. Think of this sequence as a series of moves through the
model. We are given 3ψ, and our goal is to ﬁnd an Rf -related ψ-containing point
that is not eliminable. So, on our ﬁrst move (an odd move) we select an Rf -
related ψ-containing point (we are guaranteed to ﬁnd one, pretty much as in any
Existence Lemma). If the point is not-eliminable we have found what we need
and are ﬁnished. Unfortunately, the point may well be eliminable. If so, we make
a second move (an even move) to another point in the same cluster – namely a
point to which the ﬁrst point we found is subordinate. We iterate the process, and
eventually we will ﬁnd what we are looking for. We now make this (extremely
sketchy) outline precise.
Claim 1. For every item αi = |v| in the sequence, 3ψ ∈ v.
If i = 0, αi = |u| and by assumption 3ψ ∈ u. If i > 0 and odd, then ψ ∈ |v| by
construction, hence ψ ∈ v. As v is a Λ-MCS it contains ψ → 3ψ, thus 3ψ ∈ v
also. Finally, if i > 0 and even, then as we have just seen, 3ψ ∈ αi−1 . By
construction, Rf |v|αi−1 hence 3ψ ∈ |v| and hence 3ψ ∈ v. This proves Claim 1.
Claim 2. The sequence terminates.
Suppose i is even. By property (iii), αi+1 sub αi+2 and by property (ii), it is not the
case that αi+1 sub αi . Hence by item 3 of Lemma 4.93, αi sub αi+2 . By item (ii)
of Lemma 4.93, sub is a transitive and asymmetric relation, thus all αi with even i
are different. As there are only ﬁnitely many elements in Wf , the sequence must
terminate. This proves Claim 2.
Claim 3. The sequence does not terminate on even i.
Suppose i is even. We need to show that there is an αi+1 ∈ W f such that Rf αi αi+1
and not αi+1 sub αi . Let {β1 , . . . , βm } be {β ∈ W f | β sub αi }. Then for each
k (1 ≤ k ≤ m) there is a vk ∈ αi such that not Rw vk z, for all z ∈ βk . Let v be
one of these points vk such that for all k, Rw vk v, for 1 ≤ k ≤ m. (It is always
possible to choose such a v as Rw is connected.) As αi = |v|, by Claim 1 3ψ ∈ v.
By the Existence Lemma for normal logics (Lemma 4.20), there is an x ∈ W such
that ψ ∈ x and Rw vx. Moreover, not |x| sub |v|. For suppose for the sake of a
contradiction that |x| sub |v|. Then |x| = βk , for some 1 ≤ k ≤ m, and hence not
Rw vk x. But Rw vk v and Rw vx, hence (by transitivity) Rw vk x – contradiction. We
conclude that not |x| sub |v|, hence (recalling that |v| = αi ) we can always choose
αi+1 to be |x|. This proves Claim 3.
We can now prove the result. By Claims 2 and 3, the sequence terminates on
αm = |v|, for some odd number m. By construction, ψ ∈ v, hence ψ ∈ |v|.4.9 Finitary Methods II
251
Since αm+1 does not exist, αm is not eliminable. By construction, for all even i,
Rf αi αi+1 . By item (ii) of Lemma 4.93, for all odd i, Rf αi αi+1 . Hence by the
transitivity of Rf , Rf |u||v|, and we are through.
We now deﬁne the model Ms . Let W s be the set of non-eliminable points in
W f . (Note that by the previous lemma there must be at least one such point, for
3φ ∈ w ∩ Φ.) Then Ms = (W s , Rs , V s ) is Mf restricted to W s . Hence Ms is a
ﬁnite distinguishing model, and (W s , Rs ) is an S4.3 frame.
Lemma 4.95 Ms satisﬁes φ.
Proof. First, we show by induction on the structure of ψ that for all ψ ∈ Φ, and
all |u| ∈ W s , Ms , |u|  ψ iff ψ ∈ u. The only interesting case concerns the
modalities. So suppose 3ψ ∈ u. By the previous lemma, there is some |v| such
that Rf |u||v|, ψ ∈ |v|, and |v| is not eliminable. As ψ ∈ |v|, ψ ∈ v, hence by the
inductive hypothesis, Ms , |v|  ψ, hence Ms , |u|  3ψ as desired. The converse
is straightforward; we leave it to the reader.
It follows that φ is satisﬁed somewhere in Ms . For, as 3φ ∈ w ∩ Φ, by
Lemma 4.94 there is a non-eliminable |u| such that Rf |w||u| and φ ∈ |u|. Hence
φ ∈ u, and Ms , |u|  φ.
We are almost there. If we can show that Ms  Λ, then as Ms is a ﬁnite distin-
guishing model, its frame validates Λ and we are through. Showing that Ms  Λ,
will take us along the other path from Mw to Ms shown in Figure 4.2. That is, we
will show that Ms is a bounded morphic image of a deﬁnable variant M of Mw .
The required bounded morphism f is easy to describe: it agrees with the natural
map on all non-eliminable points, and where the natural map sent a point w to a
point that has been eliminated, f (w) will be a point ‘as close as possible’ to the
eliminated point. Let us make this precise. Enumerate the elements of Ws . Deﬁne
f : W w → W s by
⎧
s
⎪
⎨ |w|, if |w| ∈ W ,
f (w) =
the ﬁrst element in the enumeration which is an Rs -minimal
⎪
⎩
element of {α ∈ W s | Rs |w|α}, otherwise.
As W s is ﬁnite, the minimality requirement (which captures the ‘as close as possi-
ble’ idea) is well deﬁned.
As we will show, f is a bounded morphism from (W w , Rw ) into (W s , Rs ).
But we have no guarantee that f is a bounded morphism from the model Mw
to Ms , for while the underlying frame morphism is ﬁne, we need to ensure that
the valuations agree on propositional symbols. We ﬁx this as follows. For any
propositional symbol p, deﬁne V  (p) to be {u ∈ W w | f (u) ∈ V s (p)}, and let M
be (W w , Rw , V  ). That is, M is simply a variant of Mw that agrees with Ms under252
4 Completeness
the mapping f . But it is not just any variant: as we will now see, it is a deﬁnable
variant. It is time to pull all the threads together and prove the main result.
Theorem 4.96 (Bull’s Theorem) Every normal modal logic extending S4.3 has
the ﬁnite frame property.
Proof. First we will show that M is a deﬁnable variant of Mw . If β is any of the
equivalence classes that make up the ﬁltration Mf , then β ⊆ W w . Moreover, Mw
can deﬁne any such β: the deﬁning formula β̂ is simply a conjunction of all the
formulas in some subset of Φ, the set we ﬁltrated through. (Incidentally, we take
the conjunction of the empty set to be ⊥.) It follows that Mw can deﬁne V  (p)
for any propositional symbol p. To see this, note that V s (p) is either the empty set
or some ﬁnite collection of equivalence classes {β1 , . . . , βn }. In the former case,

deﬁne δp to be ⊥. In the latter case, deﬁne δp to be i∈n β̂i . Either way, δp deﬁnes
V  (p) in Mw , for V  (p) is {u ∈ W w | f (u) ∈ V s (p)}. Thus M is a deﬁnable
variant of Mw . (Note that this argument makes use of facts about all four models
constructed in the course of the proof.)
Next we claim that f is indeed a surjective bounded morphism from Ms onto
M ; we show here that it satisﬁes the back condition and leave the rest to the
reader. Suppose Rs f (u)f (v). As f (v) ∈ W s , it is not eliminable, hence not
f (v) sub f (u). But this means that every element in f (u) Rw -precedes an element
in f (v), as required.
But now Bull’s Theorem follows. If Λ is a normal modal logic extending S4.3
and φ is a Λ-consistent formula, build Ms as described above. By Lemma 4.95,
Ms satisﬁes φ. Moreover Ms  Λ. To see this, simply follow the upper left to
right path through Figure 4.2. MΛ  Λ, hence so does Mw , for it is a generated
submodel of MΛ . As M is a deﬁnable variant of Mw , by Lemma 3.25 item (iii),
M  Λ. Hence, as Ms is a bounded morphic image of M , it too validates Λ as
required. But Ms is a ﬁnite distinguishing model, hence, by Lemma 3.27 item (iii),
its frame validates Λ and we are through.
Finite axiomatizability
We now show that every normal logic extending S4.3 is ﬁnitely axiomatizable. (A
logic Λ is ﬁnitely axiomatizable if there is a ﬁnite set of formulas Γ such that Λ
is the logic generated by Γ .) The proof makes use of a special representation for
ﬁnite S4.3 frames.
Because every ﬁnite S4.3 frame is a ﬁnite chain of ﬁnite clusters, any such frame
can be represented as a list of positive integers: each positive integer in the list
records the cardinality of the corresponding cluster. For example, the list [3, 1, 2]
represents the following frame:'

t?
@

 @
I@
R

@

: t





-
t
9


&
4.9 Finitary Methods II
$
'

t?
=⇒$
&%
%
253
$
'


?
t
=⇒

- t?
&
%
Such representations will allow us to reduce the combinatorial heart of the follow-
ing proofs to a standard result about lists. The following deﬁnition pins down the
relationship between lists that will be important.
Deﬁnition 4.97 A list is a ﬁnite non-empty list of positive integers. A list t con-
tains a list s if t has a sublist of the same length as s, each item of which is greater
than or equal to the corresponding item of s. A list t covers a list s if t contains s
and the last item of t is greater than or equal to the last item of s.
For example, the list [9, 40, 1, 9, 3] contains the list [8, 2, 9], for it has [9, 40, 9] as a
sublist, but it does not cover this list. But [9, 40, 1, 9, 10] covers [8, 2, 9].
The modal relevance of list covering stems from the following lemma:
Lemma 4.98 Let F and G be ﬁnite S4.3 frames, and let f and g be their associated
lists. Then f covers g iff there is a bounded morphism from F onto G.
Proof. Exercise 4.9.2.
In view of this result, the following well-known result can be viewed as asserting
the existence of inﬁnite sequences of bounded morphisms:
Theorem 4.99 (Kruskal’s Theorem) Every countably inﬁnite sequence of lists t
contains an inﬁnite subsequence s such that for all lists si and sj in s, i > j implies
si covers sj .
Proof. Let us call a (ﬁnite or inﬁnite) subsequence (ti )i∈I of a sequence of lists
t = (ti )i∈ω a chain in t if for all i, j ∈ I, tj covers ti whenever j > i. We assume
familiarity with the notions of the head, the tail and the sum of a list. For instance,
the head of [8, 2, 9] is 8, its tail is [2, 9] and its sum is 19. Call s smaller than t if
the sum of s is smaller than that of t.
In order to prove the theorem, we will show the following holds:
every countably inﬁnite sequence of lists t contains a chain of length 2.
(4.2)
Assume that (4.2) does not hold; that is, there are countably inﬁnite sequences
without chains of length 2 as subsequences.
Without loss of generality we may assume that t does not contain inﬁnitely many254
4 Completeness
lists of length 1. For otherwise, consider its subsequence (ti )i∈I of these one-
item lists. This subsequence may be identiﬁed with a sequence of natural numbers
(ni )i∈ω . But
any sequence (ni )i∈ω of natural numbers contains a subsequence
(ni )i∈I such that for all i, j ∈ I, i < j implies ni ≤ nj ,
(4.3)
as can easily be proved. But if ni ≤ nj then clearly tj covers ti . But then we
may also assume that t does not contain one-item lists at all: simply consider the
sequence found by eliminating all one-item lists.
Let t be a minimal such sequence. That is, t is a sequence of more-item lists,
t has no 2-chains, and for all n, there are no more-item lists tn , tn+1 , . . . such
that tn is smaller than tn , while the sequence t0 , t1 , . . . , tn−1 , tn , tn+1 , . . . has no
2-chains.
Now we arrive at the heart of the argument. Deﬁne (ni )i∈ω and (ui )i∈ω as the
sequences of the heads and the tails of t; that is, for each i, ni is the head of ti and
ui is the tail of ti . By (4.3), there is a subsequence (ni )i∈I such that i < j implies
ni ≤ nj , whenever i, j ∈ I. Now consider the corresponding subsequence (ui )i∈I
of u. We need the following result:
any subsequence (vi )i∈ω of tails of t contains a 2-chain.
(4.4)
By the same argument as before, we may assume that v contains only more-item
lists. Let k be the natural number such that v0 is the tail of tk , and consider the
sequence t0 , t1 , . . . , tk−1 , v0 , v1 , . . . . Since v0 is the tail of tk and, hence, smaller
than tk , it follows by the minimality of tk that the mentioned sequence contains a
2-chain. But obviously this 2-chain can only occur in the v-part of the sequence.
This proves (4.4).
But if u contains a 2-chain, this means that there are two numbers i and j in
I with i < j and uj covers ui . Also, by deﬁnition of I, ni ≤ nj . But then
ti = [mi ] ∗ ui is covered by tj = [mj ] ∗ uj . This proves (4.2).
Finally, it remains to prove the theorem from (4.2). Let t be an arbitrary count-
ably inﬁnite sequence of lists. By successive applications of (4.2), it follows that t
contains inﬁnitely many chains. We claim that one of these chains is inﬁnite. For if
we suppose that there are only ﬁnite chains, we may consider the sequence z of last
items of right-maximal ﬁnite chains in t (a chain is right-maximal if it can not be
extended to the right). There must be inﬁnitely many such right-maximal chains,
so z is an inﬁnite sequence. Hence, by yet another application of (4.2), z contains
a chain of length 2. But then some chain was not right-maximal after all.
We now extract the consequences for logics extending S4.3:
Corollary 4.100 There is no inﬁnite sequence Λ0 , Λ1 , . . . of normal logics con-
taining S4.3 such that for all i, Λi ⊂ Λi+1 .4.9 Finitary Methods II
255
Proof. Suppose otherwise. Then for some inﬁnite sequence of logics Λ0 , Λ1 ,
. . . extending S4.3, and for all natural numbers i, there is a formula φi such that
φi ∈ Λi and φi ∈ Λi+1 . So, by Bull’s Theorem, for all natural numbers i there
is a ﬁnite S4.3 frame Fi that validates Λi and does not satisfy φi . Let t be the
inﬁnite sequence of lists ti associated with the frames Fi . By Kruskal’s Theorem,
there exist natural numbers k and l, such that k > l and tk covers tl . Hence by
Lemma 4.98 there is a bounded morphism from Fk onto Fl . It follows that Fl  φl
and we have a contradiction.
Theorem 4.101 Every normal modal logic extending S4.3 is ﬁnitely axiomatiz-
able.
Proof. To arrive at a contradiction, we will assume that there does exist an ex-
tension Λ of S4.3 that is not ﬁnitely axiomatizable. We will construct an inﬁnite
sequence Λ0 ⊂ Λ1 ⊂ · · · of extensions of S4.3, thus contradicting Corollary 4.100.
As Λ is not ﬁnitely axiomatizable, it must be a proper extension of S4.3. Let
φ0 be an arbitrary formula in Λ \ S4.3, and deﬁne Λ0 to be the logic generated by
S4.3 ∪ {φ0 }. Then S4.3 ⊂ Λ0 ⊂ Λ. The latter inclusion is strict because Λ is
not ﬁnitely axiomatizable. Hence, there exists φ1 ∈ Λ \ Λ0 . Let Λ1 be the logic
generated by Λ0 ∪ {φ1 }. Continuing in this fashion we ﬁnd the required inﬁnite
sequence Λ0 ⊂ Λ1 ⊂ · · · of extensions of S4.3.
A negative characterization
We turn to the ﬁnal task: showing that every normal logic extending S4.3 has a
negative characterization in terms of ﬁnite sets of ﬁnite frames. Once again, the
proof makes use of the representation of S4.3 frames as lists of positive integers.
First some terminology. A set of lists X is ﬂat if for every two distinct lists in X,
neither covers the other. In view of Lemma 4.98, the modal relevance of ﬂatness
is this: if two frames are associated with distinct lists belonging to a ﬂat set, then
neither frame is a bounded morphic image of the other.
Lemma 4.102 All ﬂat sets are ﬁnite. Furthermore, for any set of lists Y there is a
maximal set X such that X ⊆ Y and X is ﬂat.
Proof. Easy consequences of Kruskal’s Theorem.
If X is a ﬂat set of lists, then C(X) is the set of lists covered by some list in X.
Note that C(X) is ﬁnite and that X ⊆ C(X). If X is a set of lists, then B(X) is
the class of all ﬁnite S4.3 frames F such that there is a bounded morphism from F
onto some frame whose list is in X.
Theorem 4.103 For every normal modal logic Λ extending S4.3 there is a ﬁnite set4 Completeness
256
N of ﬁnite S4.3 frames with the following property: for any ﬁnite frame F, F  Λ
iff F is an S4.3 frame and there does not exist a bounded morphism from F onto
any frame in N.
Proof. Let Λ ⊇ S4.3, and let L be the set of lists associated with ﬁnite S4.3 frames
which do not validate Λ. Let L be a maximal ﬂat set such that L ⊆ L . Note that
C(L) ⊆ L .
We claim that for any ﬁnite S4.3 frame F, F  Λ iff F ∈ B(C(L)). The left to
right implication is clear, for as no frame whose list belongs to C(L) validates Λ,
there cannot be a bounded morphism from F onto any such frame. For the other
direction, we show the contrapositive. Suppose that F  Λ. Let F’s list be f. Then
f ∈ L . Now either f ∈ C(L) or f ∈ L \ C(L). If f ∈ C(L), then the identity
morphism on F guarantees that F ∈ B(C(L)) as required. So suppose instead that
f ∈ L \ C(L). This means that f ∈ L (as L ⊆ C(L)), hence as L is a maximal
ﬂat subset of L , f must cover some list g in L. Thus by Lemma 4.98, any S4.3
frame G whose list is g is a bounded morphic image of F, hence F ∈ B(C(L)) as
required. This completes the proof of the claim.
We can now deﬁne the desired ﬁnite set N: for each g ∈ C(L), choose a frame
whose list is g, and let N be the set of all our choices.
Exercises for Section 4.9
4.9.1 Show that the sub relation is transitive and asymmetric. Furthermore, show that if
α sub γ and not α sub β, then β sub γ.
4.9.2 Prove Lemma 4.98. That is, let F and G be ﬁnite S4.3 frames, and let f and g be their
associated lists. Then show that f covers g iff there is a bounded morphism from F onto
G. (First hint: look at how we deﬁned the bounded morphism used in the proof of Bull’s
Theorem. Second hint: look at the statement (but not the proof!) of Lemma 6.39.)
4.9.3 Give a complete characterization of all the normal logics extending S5. Your answer
should include axiomatizations for all such logics.
4.9.4 Let Kt 4.3 be the smallest tense logic containing 4, T , .3 l and .3r . Show that there
are tense logics extending K t 4.3 that do not have the ﬁnite frame property. (Hint: look
at the tense logic obtained by adding the Grzegorczyk axiom in the operator F . Is the
Grzegorczyk axiom in P satisﬁable in a model for this logic? Is the Grzegorczyk axiom in
P satisﬁable in a ﬁnite model for this logic?)
4.10 Summary of Chapter 4
 Completeness: A logic Λ is weakly complete with respect to a class of structures
S if every formula valid on S is a Λ-theorem. It is strongly complete with
respect to S if whenever a set of premises entails a conclusion over S, then the
conclusion is Λ-deducible from the premises.4.10 Summary of Chapter 4
257
 Canonical Models and Frames: Completeness theorems are essentially model
existence theorems. The most important model building technique is the canon-
ical model construction. The points of the underlying canonical frames are max-
imal consistent sets of formulas, and the relations and valuation are deﬁned in
terms of membership of formulas in such sets.
 Canonicity: Many formulas are canonical for a property P . That is, they are
valid on any frame with property P , and moreover, when used as axioms, they
guarantee that the canonical frame has property P . When working with such
formulas, it is possible to prove strong completeness results relatively straight-
forwardly.
 Sahlqvist’s Completeness Theorem: Sahlqvist formulas not only deﬁne ﬁrst-
order properties of frames, each Sahlqvist formula is also canonical for the ﬁrst-
order property it deﬁnes. As a consequence, strong completeness is automatic
for any logic that is axiomatized by axioms in Sahlqvist form.
 Limitative Results: The canonical model method is not universal: there are
weakly complete logics whose axioms are not valid on any canonical frame. In-
deed, no method is universal, for there are logics that are not sound and weakly
complete with respect to any class of frames at all.
 Unraveling and Bulldozing: Often we need to build models with properties for
which no modal formula is canonical. Sometimes this can be done by transform-
ing the logic’s canonical model so that it has the relevant properties. Unraveling
and bulldozing are two useful transformation methods.
 Step by Step: Instead of modifying canonical models directly, the step-by-step
method builds models by selecting MCSs. Because it builds these selections
inductively, it offers a great deal of control over the properties of the resulting
model.
 Rules for the Undeﬁnable: By enriching our deductive machinery with special
proof rules, it is sometimes possible to construct canonical models that have the
desired properties right from the start, thus avoiding the need to massage the
(standard) canonical model into some desired shape.
 Finitary Methods: The canonical model method establishes strong complete-
ness. Only weak completeness results are possible for non-compact logics such
as propositional dynamic logic, and ﬁnite canonical models (essentially ﬁltra-
tions of standard canonical models) are a natural tool for proving such results.
 Logics extending S4.3: Although the incompleteness results show that a frame
based analysis of all normal logics is impossible, many subregions of the lattice
of normal modal logics are better behaved. For example, the logics extend-
ing S4.3 all have the ﬁnite frame property, are ﬁnitely axiomatizable, and have
negative characterizations in terms of ﬁnite frames.258
4 Completeness
Notes
Modal completeness results can be proved using a variety of methods. Kripke’s
original modal proof systems (see [283, 284]) were tableaux systems, and com-
pleteness proofs for tableaux typically do not make use of MCSs (Fitting [137] is
a good introduction to modal tableaux methods). Completeness via normal form
arguments have also proved useful. For example, Fine [131] uses normal forms to
prove the completeness of the normal logic generated by the McKinsey axiom; this
logic is not canonical (see Goldblatt [187]).
Nonetheless, most modal completeness theory revolves, directly or indirectly,
around canonical models; pioneering papers include Makinson [307] (who uses
a method close to the step-by-step construction to pick out generated subframes
of canonical models) and Cresswell [99]. But the full power of canonical models
and completeness-via-canonicity arguments did not emerge clearly till the work
of Lemmon and Scott [296]. Their monograph stated and proved the Canoni-
cal Model Theorem and used completeness-via-canonicity arguments to establish
frame completeness results; these included a general canonicity result for axioms
of the form 3k 2j p → 2m 3n p, where k, j, m, n ≥ 0. While less general than
Sahlqvist’s [396] later result (Theorem 4.42), this covered most of the better-known
systems, and was testimony to the generality of the canonical model method.
That KL is weakly complete with respect to the class of ﬁnite transitive trees
is proved in Segerberg [404]. (Strictly speaking, Segerberg proved that KL4 is
complete with respect to the transitive trees, as it was not then known that 4 was
derivable in KL; derivations of 4 were independently found by de Jongh, Kripke,
and Sambin: see Boolos [69, page 11] and Hughes and Cresswell [235, page 150].)
Segerberg ﬁrst proves weak completeness with respect to the class of ﬁnite strict
partial orders (the result we asked the reader to prove in Exercise 4.8.7), however
he does so by ﬁltrating the canonical model for KL, whereas we asked the reader to
use a ﬁnite canonical model argument. Of course, the two arguments are intimately
related, but the ﬁnite canonical model argument (which we have taken from Hughes
and Cresswell [235, Theorem 8.4]) is rather more direct. Segerberg then proves
weak completeness with respect to ﬁnite trees by unraveling the resulting model
(just as we asked the reader to do in Exercise 4.8.8).
The incomplete tense logic Kt ThoM discussed in the text was the ﬁrst known
frame incomplete logic, and it is still one of the most elegant and natural exam-
ples. It can be found in Thomason [434], and the text follows Thomason’s original
incompleteness proof. Shortly afterward, both Fine [129] and Thomason [434]
exhibited (rather complex) examples of incomplete logics in the the basic modal
language. The (much simpler) incomplete logic KvB examined in Exercise 4.4.2
is due to van Benthem [39]; KvB is further examined in Cresswell [100]. In Exer-
cise 4.4.4 we listed three formulas which jointly deﬁne a ﬁrst-order class of frames,Notes to Chapter 4
259
but which when used as axioms give rise to an incomplete normal logic; this ex-
ample is due to van Benthem [37, 43]. The logic of the veiled recession frame was
ﬁrst axiomatized by Blok [64]. It was also Blok [65, 66] who showed that incom-
pleteness is the rule rather than the exception among modal logics. The result that
every consistent normal modal logic in the basic modal similarity type deﬁnes a
non-empty frame class is due to Makinson [309].
Although ﬁltration and unraveling had been used earlier to prove complete-
ness results, the systematic use of transformation methods stems from the work
of Segerberg [404]. Segerberg reﬁned the ﬁltration method, developed the bulldoz-
ing technique, and used them (together with other transformations) to prove many
important completeness results, including characterizations of the tense logics of
(N, <), (Z, <), (Q, <), (R, <) and their reﬂexive counterparts.
We do not know who ﬁrst developed the modal step-by-step method. Certainly
the idea of building models inductively is a natural one, and has long been used in
both algebraic logic (see [226]) and set-theory (see [417]). One inﬂuential source
for the method is the work of Burgess: for example, in [78] he uses it to prove
completeness results in since/until logic (see also Xu [466] for some instructive
step-by-step proofs for this language). Moreover, in [79], his survey article on
tense logic, Burgess proves a number of completeness results for the basic modal
language using the method. A set of lecture notes by de Jongh and Veltman [250] is
the source of the popularity among Amsterdam logicians. Recent work on Arrow
Logic uses the method (and the related mosaic method) heavily, often combined
with the use of rules for the undeﬁnable (see, for example, [320]). Step-by-step
arguments are now widely used in a variety of guises.
Gabbay [149] is one of the earliest papers on rules for the undeﬁnable, and one of
the most inﬂuential (an interesting precursor is Burgess [77], in which these rules
are used in the setting of branching time logic). Gabbay and Hodkinson [155] is an
important paper which shows that such rules can take a particularly simple form in
the basic temporal language. For rules in modal languages equipped with the D-
operator, see de Rijke [378] and Venema [444]. For rules in modal languages with
nominals, see Passy and Tinchev [358], Gargov and Goranko [164], Blackburn and
Tzakova [63], and Blackburn [56].
The axiomatization of PDL that we gave in the text is from [407], Segerberg’s
1977 abstract. But there was a gap in Segerberg’s completeness proof, and by the
time he had published a full corrected version (see [409]) very different proofs by
Parikh [353] and Kozen and Parikh [273], had appeared. It seems that several other
unpublished completeness proofs were also in circulation at this time: see Harel’s
survey of dynamic logic [209] for details. The proof in the text is based on lecture
notes by van Benthem and Meyer Viol [50].
Bull’s Theorem was the ﬁrst general result about the ﬁne structure of the lattice
of normal modal logics. Bull’s original proof (in [74]) was algebraic; the model-260
4 Completeness
theoretic proof given in the text is due to Fine [128]. A discussion of the relation-
ship between the two proofs may be found in Bull and Segerberg [75]. Moreover,
Goldblatt [177] presents Fine’s proof from a rather different perspective, empha-
sizing a concept he calls ‘clusters within clusters’; the reader will ﬁnd it instructive
to compare Goldblatt’s presentation with ours. Fine’s [128] also contains the ﬁnite
axiomatizability result for logics extending S4.3 (Theorem 4.101) and the (nega-
tive) characterization in terms of ﬁnite sets of ﬁnite frames (Theorem 4.103), and
the text follows Fine’s original proofs here too.
The work of Bull and Fine initiated a (still ﬂourishing) investigation into subre-
gions of the lattice of normal modal logics. For example, the position of logics in
the lattice characterized by a single structure is investigated in Maksimova [311],
Esakia and Meskhi [124] and (using algebraic methods) Blok [66]. In [130, 133],
Fine adapts his methods to analyze the logics extending K4.3 (the adaptation is
technically demanding as not all these logics have the f.f.p.). The Berlin school
has a long tradition in this area: see Rautenberg [372, 373, 374], Kracht [277, 278,
279], and Wolter [459]. More recently, the structure of the lattice of tense log-
ics has received attention: see, for example, Kracht [275] and Wolter [457]. And
Wolter [458] investigates the transfer of properties when the converse operator P is
added to a logic (in the basic modal language) that extends K4, obtaining various
axiomatizability and decidability results.
Work by Zakharyaschev has brought new ideas to bear. As we pointed out in the
Notes to Chapter 3, in the 1960s (the early years following the introduction of re-
lational semantics for modal logic) it was hoped that one could describe any modal
formula by imposing ﬁrst-order conditions on its frames. But the incompleteness
results, and the discovery of modal formulas that do not correspond to any ﬁrst-
order condition, destroyed this hope. In a series of papers Zakharyaschev [470,
471, 472, 473] has studied an alternative, purely frame-theoretic approach to the
classiﬁcation of modal formulas. Given a modal (or intuitionistic) formula φ, one
can effectively construct ﬁnite rooted frames F1 , . . . , Fn such that a general frame
g refutes φ iff there is a (not necessarily generated) subframe g of g which satisﬁes
certain natural conditions and which can be mapped to one of the Fi by a bounded
morphism. Conversely, with every ﬁnite rooted frame F Zakharyaschev associates
a canonical formula which can be refuted on a frame iff that frame contains a sub-
frame (satisfying certain natural conditions) that can be mapped to F by a bounded
morphism. Like the search for ﬁrst-order characterizations, the classiﬁcation ap-
proach in terms of canonical formulas is not universal either. But its limitations are
of a different kind: it only characterizes transitive general frames – but for every
modal (and intuitionistic) formula. Zakharyaschev [467] is a very accessible sur-
vey of canonical formulas, with plenty of motivations, examples and deﬁnitions;
technical details and discussions of the algebraic and logical background of canon-
ical formulas are provided by Chagrov and Zakharyaschev [88, Chapter 9].5
Algebras and General Frames
In this chapter we develop an algebraic semantics for modal logic. The basic idea
is to extend the algebraic treatment of classical propositional logic (which uses
boolean algebras) to modal logic. The algebras employed to do this are called
boolean algebras with operators (BAOs). The boolean part handles the underlying
propositional logic, the additional operators handle the modalities.
But why algebraize modal logic? There are two main reasons. First, the alge-
braic perspective allows us to bring powerful new techniques to bear on modal-
logical problems. Second, the algebraic semantics turns out to be better-behaved
than frame-based semantics: we will be able to prove an algebraic completeness
result for every normal modal logic. As our discussion of incompleteness in Sec-
tion 4.4 makes clear, no analogous result holds for frames.
This chapter has three main parts. The ﬁrst, consisting of the ﬁrst three sections,
introduces the algebraic approach: we survey the basic ideas in the setting of clas-
sical propositional logic, extend them to modal logic, and prove the Jónsson-Tarski
Theorem. The second part, which consists of the fourth section, introduces dual-
ity theory, the study of correspondences between the universe of algebras and the
universe of frames. The last part (the only part on the advanced track) is devoted
to general frames. These turn out to be set-theoretic representations of boolean
algebras with operators, and we examine their properties in detail, and use them to
prove the Sahlqvist Completeness Theorem. Background information on universal
algebra can be found in Appendix B.
Chapter guide
Section 5.1: Logic as Algebra (Basic track). What is algebraic logic? This sec-
tion provides some preliminary answers by examining the relationship be-
tween propositional logic and boolean algebras.
Section 5.2: Algebraizing Modal Logic (Basic track). To algebraize modal logic,
we introduce boolean algebras with operators (BAOs). We discuss BAOs
261262
5 Algebras and General Frames
from a semantic perspective (introducing an important class of BAOs called
complex algebras), and from a syntactic perspective (we use Lindenbaum-
Tarski algebras to obtain abstract BAOs from normal modal logics).
Section 5.3: The Jónsson-Tarski Theorem (Basic track). Here we prove the the-
orem underlying algebraic approaches to modal completeness theory. First
we learn how to construct a frame from an algebra by forming the ultra-
ﬁlter frame. By turning this frame back into a complex algebra, we ob-
tain the canonical embedding algebra. We then prove the Jónsson-Tarski
Theorem: every boolean algebra with operators can be embedded in its
canonical embedding algebra.
Section 5.4: Duality Theory (Basic track). Frames are inter-related by bounded
morphisms, generated subframes, and disjoint union. Boolean algebras
with operators are inter-related by homomorphisms, subalgebras, and di-
rect products. Modal duality theory studies the relationship between these
two mathematical universes. Two applications are given, one of which is
an algebraic proof of the Goldblatt-Thomason Theorem.
Section 5.5: General Frames (Advanced track). We (re)introduce general frames
and study them in detail, focusing on the relationship between general
frames, frames, and boolean algebras with operators. We conclude with a
brief discussion of some important topological aspects of general frames.
Section 5.6: Persistence (Advanced track). In this section we introduce a natural
generalization of the notion of canonicity encountered in Chapter 4: per-
sistence. We use it to prove the Sahlqvist Completeness Theorem.
5.1 Logic as Algebra
What do algebra and logic have in common? And why bring algebra into the study
of logic? This section provides some preliminary answers: we show that algebra
and logic share key ideas, and analyze classical propositional logic algebraically.
Along the way we will meet a number of important concepts (notably formula
algebras, the algebra of truth values, set algebras, abstract boolean algebras, and
Lindenbaum-Tarski algebras) and results (notably the Stone Representation Theo-
rem), but far more important is the overall picture. Algebraic logic offers a natural
way of re-thinking many basic logical issues, but it is important not to miss the
wood for the trees. The bird’s eye view offered here should help guide the reader
through the more detailed modal investigations that follow.
Algebra as logic
Most school children learn how to manipulate simple algebraic equations. Given
the expression (x + 3)(x + 1), they learn how to multiply these factors to form5.1 Logic as Algebra
263
x2 + 4x + 3, and (somewhat later) study methods for doing the reverse (that is, for
decomposing quadratics into factors).
Such algebraic manipulations are essentially logical. For a start, we have a well-
deﬁned syntax: we manipulate equations between terms. This syntax is rarely
explicitly stated, but most students (building on the analogy with basic arithmetic)
swiftly learn how to build legitimate terms using numerals, variables such as x, y
and z, and +, · and −. Moreover, they learn the rules which govern this symbol
manipulation process: replacing equals by equals, doing the same thing to both
sides of an equation, appealing to commutativity, associativity and distributivity to
simplify and rearrange expressions. High-school algebra is a form of proof theory.
But there is also a semantic perspective on basic algebra, though this usually
only becomes clear later. As students learn more about mathematics, they realize
that the familiar ‘laws’ do not hold for all mathematical objects: for example, ma-
trix multiplication is not commutative. Gradually the student grasps that variables
need not be viewed as standing for numbers: they can be viewed as standing for
other objects as well. Eventually the semantic perspective comes into focus: there
are various kinds of algebras (that is, sets equipped with collections of functions,
or operations, which satisfy certain properties), and terms denote elements in al-
gebras. Moreover, an equation such as x · y = y · x is not a sacrosanct law: it is
simply a property that holds for some algebras and not for others.
So algebra has a syntactic dimension (terms and equations) and a semantic di-
mension (sets equipped with a collection of operations). And in fact there is a
tight connection between the proof theory algebra offers and its semantics. In
Appendix B we give a standard derivation system for equational logic (that is, a
standard set of rules for manipulating equations) and state a fundamental result due
to Birkhoff: the system is strongly sound and complete with respect to the standard
algebraic semantics. Algebra really can be viewed as logic.
But logic can also be viewed as algebra. We will now illustrate this by examin-
ing classical propositional logic algebraically. Our discussion is based around three
main ideas: the algebraization of propositional semantics in the class of set alge-
bras; the algebraization of propositional axiomatics in the class of abstract boolean
algebras; and how the Stone Representation Theorem links these approaches.
Algebraizing propositional semantics
Consider any propositional formula, say (p ∨ q) ∧ (p ∨ r). The most striking thing
about propositional formulas (as opposed to ﬁrst-order formulas) is their syntactic
simplicity. In particular, there is no variable binding – all we have is a collection of
atomic symbols (p, q, r, and so on) that are combined into more complex expres-
sions using the symbols ⊥, , ¬, ∨ and ∧. Recall that we take ⊥, ¬ and ∨ as the
primitive symbols, treating the others as abbreviations.264
5 Algebras and General Frames
Now, as the terminology ‘proposition letters’ suggests, we think of p, q, and r
as symbols denoting entities called propositions, abstract bearers of information.
So what do ⊥, , ¬, ∨ and ∧ denote? Fairly obviously: ways of combining
propositions, or operations on propositions. More precisely, ∨ and ∧ must denote
binary operations on propositions (let us call these operations + and · respectively),
¬ must denote a unary operation on propositions (let us call it −), while ⊥ and 
denote special nullary operations on propositions (that is, they are the names of
two special propositions: let us call them 0 and 1 respectively). In short, we have
worked our way towards the idea that formulas can be seen as terms denoting
propositions.
But which kinds of algebras are relevant? Here is a ﬁrst step towards an answer.
Deﬁnition 5.1 Let Bool be the algebraic similarity type having one constant (or
nullary function symbol) ⊥, one unary function symbol ¬, and one binary function
symbol ∨. Given a set of propositional variables Φ, Form(Φ) is the set of Bool -
terms in Φ; this set is identical to the collection of propositional formulas in Φ.
Algebras of type Bool are usually presented as 4-tuples A = (A, +, −, 0). We
make heavy use of the standard abbreviations · and 1. That is, a · b is shorthand for
−(−a + −b), and 1 is shorthand for −0.
But this only takes us part of the way. There are many different algebras of this
similarity type – and we are only interested in algebras which can plausibly be
viewed as algebras of propositions. So let us design such an algebra. Propositional
logic is about truth and falsehood, so let us take the set 2 = {0, 1} as the set A
underlying the algebra; we think of ‘0’ as the truth value false, and ‘1’ as the value
true. But we also need to deﬁne suitable operations over these truth values, and we
want these operations to provide a natural interpretation for the logical connectives.
Which operations are appropriate?
Well, the terms we are working with are just propositional formulas. So how
would we go about evaluating a formula χ in the truth value algebra? Obviously
we would have to know whether the proposition letters in χ are true or false, but let
us suppose that this has been taken care of by a function θ : Φ → 2 mapping the set
Φ of proposition letters to the set 2 of truth values. Given such a θ (logicians will
call θ a valuation, algebraists will call it an assignment) it is clear what we have to
do: compute θ̃(φ) according to the following rules:
θ̃(p)
θ̃(⊥)
θ̃(¬φ)
θ̃(φ ∨ ψ)
=
=
=
=
θ(p), for all p ∈ Φ,
0,
1 − θ̃(φ),
max(θ̃(φ), θ̃(ψ)).
(5.1)
Clearly the operations used here are the relevant ones; they simply restate the fa-
miliar truth table deﬁnitions. This motivates the following deﬁnition:5.1 Logic as Algebra
265
Deﬁnition 5.2 The algebra of truth values is 2 = ({0, 1}, +, −, 0)), where − and
+ are deﬁned by −a = 1 − a and a + b = max(a, b), respectively.
Let us sum up our discussion so far. The crucial observations are that formulas can
be viewed as terms, that valuations can be identiﬁed with algebraic assignments
in the algebra 2, and that evaluating the truth of a formula under such a valua-
tion/assignment is exactly the same as determining the meaning of the term in the
algebra 2 under the assignment/valuation.
So let us move on. We have viewed meaning as a map θ̃ from the set Form(Φ)
to the set {0, 1} – but it is useful to consider this meaning function in more math-
ematical detail. Note the ‘shape’ of the conditions on θ̃ in (5.1): the resemblance
to the deﬁning condition of a homomorphism is too blatant to miss. But since ho-
momorphisms are the fundamental maps between algebras (see Appendix B) why
not try and impose algebraic structure on the domain of such meaning functions
(that is, on the set of formulas/terms) so that meaning functions really are homo-
morphisms? This is exactly what we are about to do. We ﬁrst deﬁne the needed
algebraic structure on the set of formulas.
Deﬁnition 5.3 Let Φ be a set of proposition letters. The propositional formula
algebra over Φ is the algebra
Form(Φ) = (Form(Φ), +, −, ⊥),
where Form(Φ) is the collection of propositional formulas over Φ, and − and +
are the operations deﬁned by −φ := ¬φ and φ + ψ := φ ∨ ψ, respectively.
In other words, the carrier of this algebra is the collection of propositional formulas
over the set of proposition letters Φ, and the operations − and + give us a simple
mathematical picture of the dynamics of formula construction.
Proposition 5.4 Let Φ be some set of proposition letters. Given any assignment
θ : Φ → 2, the function θ̃ : Form(Φ) → 2 assigning to each formula its meaning
under this valuation, is a homomorphism from Form(Φ) to 2.
Proof. A precise deﬁnition of homomorphism is given in Appendix B. Essentially,
homomorphisms between algebras map elements in the source algebra to elements
in the target algebra in an operation preserving way – and this is precisely what the
conditions on θ̃ in (5.1) express.
The idea of viewing formulas as terms, and meaning as a homomorphism, is fun-
damental to algebraic logic.
Another point is worth stressing. As the reader will have noticed, sometimes we
call a sequence of symbols like p ∨ q a formula, and sometimes we call it a term.
This is intentional. Any propositional formula can be viewed as – simply is – an266
5 Algebras and General Frames
algebraic term. The one-to-one correspondence involved is so obvious that it is not
worth talking about ‘translating’ formulas to terms or vice-versa; they are simply
two ways of looking at the same thing. We simply choose whichever terminology
seems most appropriate to the issue under discussion.
But let us move on. As is clear from high-school algebra, algebraic reasoning is
essentially equational. So a genuinely algebraic logic of propositions should give
us a way of determining when two propositions are equal. For example, such a
logic should be capable of determining that the formulas p ∨ (q ∧ p) and p denote
the same proposition. How does the algebraic approach to propositional semantics
handle this? As follows: an equation s ≈ t is valid in an algebra A if for every
assignment to the variables occurring in the terms, s and t have the same meaning
in A (see Appendix B for further details). Hence, an algebraic way of saying that
a formula φ is a classical tautology (notation: |=C φ) is to say that the equation
φ ≈  is valid in the algebra of truth values.
Now, an attractive feature of propositional logic (a feature which extends to
modal logic) is that not only terms, but equations correspond to formulas. There
is nothing mysterious about this: we can deﬁne the bi-implication connective ↔ in
classical propositional logic, and viewed as an operation on propositions, ↔ asserts
that both terms have the same meaning:
θ̃(φ ↔ ψ) =
1 if θ̃(φ) = θ̃(ψ),
0 otherwise.
So to speak, propositional logic is intrinsically equational.
Theorem 5.5 neatly summarizes our discussion so far: it shows how easily we
can move from a logical to an algebraic perspective and back again.
Theorem 5.5 (2 Algebraizes Classical Validity) Let φ and ψ be propositional
formulas/terms. Then
|=C φiff2 |= φ ≈ .(5.2)
2 |= φ ≈ ψiff|=C φ ↔ ψ.(5.3)
|=C φ ↔ (φ ↔ ).
(5.4)
Proof. Immediate from the deﬁnitions.
Remark 5.6 The reader may wonder about the presence of (5.3) and in particular,
of (5.4) in the Theorem. The point is that for a proper, ‘full’, algebraization of a
logic, one has to establish not only that the membership of some formula φ in the
logic can be rendered algebraically as the validity of some equation φ≈ in some
(class of) algebra(s). One also has to show that conversely, there is a translation
of equations to formulas such that the equation holds in the class of algebras if
and only if its translation belongs to the logic. And ﬁnally, one has to prove that5.1 Logic as Algebra
267
translating a formula φ to an equation φ≈ , and then translating this equation back
to a formula, one obtains a formula φ that is equivalent to the original formula φ.
The fact that our particular translations satisfy these requirements is stated by (5.3)
and (5.4), respectively.
Since we will not go far enough into the theory of algebraic logic to use these
‘full’ algebraizations, in the sequel we will only mention the ﬁrst kind of equiva-
lence when we algebraize a logic. Nevertheless, in all the cases that we consider,
the second and third requirements are met as well.
Set algebras
Propositional formulas/terms and equations may be interpreted in any algebra of
type Bool . Most algebras of this type are uninteresting as far as the semantics
of propositional logic is concerned – but other algebras besides 2 are relevant. A
particularly important example is the class of set algebras. As we will now see,
set algebras provide us with a second algebraic perspective on the semantics of
propositional logic. And as we will see in the following section, the perspective
they provide extends neatly to modal logic.
Deﬁnition 5.7 (Set Algebras) Let A be a set. As usual, we denote the power set
of A (the set of all subsets of A) by P(A). The power set algebra P(A) is the
structure
P(A) = (P(A), ∪, −, ∅),
where ∅ denotes the empty set, − is the operation of taking the complement of
a set relative to A, and ∪ that of taking the union of two sets. From these basic
operations we deﬁne in the standard way the operation ∩ of taking the intersection
of two sets, and the special element A, the top set of the algebra.
A set algebra or ﬁeld of sets is a subalgebra of a power set algebra. That is, a set
algebra (on A) is a collection of subsets of A that contains ∅ and is closed under
∪ and − (so any set algebra contains A and is closed under ∩ as well). The class
of all set algebras is called Set.
Set algebras provide us with a simple concrete picture of propositions and the way
they are combined – moreover, it is a picture that even at this stage contains a
number of traditional modal ideas. Think of A as a set of worlds (or situations,
or states) and think of a proposition as a subset of A. And think of a proposition
as a set of worlds – the worlds that make it true. So viewed, ∅ is a very special
proposition: it is the proposition that is false in every situation, which is clearly a
good way of thinking about the meaning of ⊥. Similarly, A is the proposition true
in all situations, which is a suitable meaning for . It should also be clear that ∪
is a way of combining propositions that mirrors the role of ∨. After all, in what268
5 Algebras and General Frames
worlds is p ∨ q true? In precisely those worlds that make p true or q true. Finally,
complementation mirrors negation, for ¬p is true in precisely those worlds where
p is not true.
As we will now show, set algebras and the algebra 2 make precisely the same
equations true. We will prove this algebraically by showing that the class of set
algebras coincides (modulo isomorphism) to the class of subalgebras of powers of
2. The crucial result needed is the following:
Proposition 5.8 Every power set algebra is isomorphic to a power of 2, and con-
versely.
Proof. Let A be an arbitrary set, and consider the following function χ mapping
elements of P(A) to 2-valued maps on A:
χ(X)(a) =
1 if a ∈ X,
0 otherwise.
In other words, χ(X) is the characteristic function of X. The reader should verify
that χ is an isomorphism between P(A) and 2A , where the latter algebra is as
deﬁned in Deﬁnition B.6.
Conversely, to show that every power of 2 is isomorphic to some power set
algebra, let 2I be some power of 2. Consider the map α : 2I → P(I) deﬁned by
α(f ) = {i ∈ I | f (i) = 1}.
Again, we leave it for the reader to verify that α is the required isomorphism be-
tween 2I and P(I).
Theorem 5.9 (Set Algebraizes Classical Validity) Let φ and ψ be propositional
formulas/terms. Then
|=C φ
iff
Set |= φ ≈ .
(5.5)
Proof. It is not difﬁcult to show from ﬁrst principles that the validity of equations is
preserved under taking direct products (and hence powers) and subalgebras. Thus,
with the aid of Theorem 5.5 and Proposition 5.8, the result follows.
Algebraizing propositional axiomatics
We now have two equational perspectives on the semantics of propositional logic:
one via the algebra 2, the other via set algebras. But what about the syntactic
aspects of propositional logic? It is time to see how the equational perspective
handles such notions as theoremhood and provable equivalence.
Assume we are working in some ﬁxed (sound and complete) proof system for
classical propositional logic. Let C φ mean that φ is a theorem of this system, and5.1 Logic as Algebra
269
call two propositional formulas φ and ψ provably equivalent (notation: φ ≡C ψ)
if the formula φ ↔ ψ is a theorem. Theorem 5.11 is a syntactic analog of Theo-
rem 5.9: it is the fundamental result concerning the algebraization of propositional
axiomatics. Its statement and proof makes use of boolean algebras, so let us deﬁne
these important entities right away.
Deﬁnition 5.10 (Boolean Algebras) Let A = (A, +, −, 0) be an algebra of the
boolean similarity type. Then A is called a boolean algebra iff it satisﬁes the
following identities (recall that x · y and 1 are shorthand for −(−x + −y) and −0,
respectively):
(B0)
(B1)
(B2)
(B3)
(B4)
x+y =y+x
x + (y + z) = (x + y) + z
x+0=x
x + (−x) = 1
x + (y · z) = (x + y) · (x + z)
x·y =y·x
x · (y · z) = (x · y) · z
x·1=x
x · (−x) = 0
x · (y + z) = (x · y) + (x · z)
The operations + and · are called join and meet, respectively, and the elements 1
and 0 are referred to as the top and bottom elements. We order the elements of a
boolean algebra by deﬁning a ≤ b if a + b = b (or equivalently, if a · b = a). Given
a boolean algebra A = (A, +, −, 0), the set A is called its carrier set. We call the
class of boolean algebras BA.
By a famous result of Birkhoff (discussed in Appendix B) a class of algebras de-
ﬁned by a collection of equations can be structurally characterized as a variety.
Thus in what follows we sometimes speak of the variety of boolean algebras, rather
than the class of boolean algebras.
If you have not encountered boolean algebras before, you should check that the
algebra 2 and the set algebras deﬁned earlier are both examples of boolean algebras
(that is, check that these algebras satisfy the listed identities). In fact, set algebras
are what are known as concrete boolean algebras. As we will see when we dis-
cuss the Stone Representation Theorem, the relationship between abstract boolean
algebras (that is, any algebraic structure satisfying the previous deﬁnition) and set
algebras lies at the heart of the algebraic perspective on propositional soundness
and completeness.
But this is jumping ahead: our immediate task is to state the syntactic analog of
Theorem 5.9 promised above.
Theorem 5.11 (BA Algebraizes Classical Theoremhood) Let φ and ψ be propo-
sitional formulas/terms. Then
C φ
iff
BA |= φ ≈ .
(5.6)270
5 Algebras and General Frames
Proof. Soundness (the direction from left to right in (5.6)) can be proved by a
straightforward inductive argument on the length of propositional proofs. Com-
pleteness will follow from the Propositions 5.14 and 5.15 below.
How are we to prove this completeness result? Obviously we have to show that ev-
ery non-theorem of classical propositional logic can be falsiﬁed on some boolean
algebra (falsiﬁed in the sense that there is some assignment under which the for-
mula does not evaluate to the top element of the algebra). So the key question is:
how do we build falsifying algebras? Our earlier work on relational completeness
suggests an answer. In Chapter 4 we made use of canonical models: that is, we
manufactured models out of syntactical ingredients (sets of formulas) taking care
to hardwire in all the crucial facts about the logic. So the obvious question is: can
we construct algebras from (sets of) formulas in a way that builds in all the proposi-
tional logic we require? Yes, we can. Such algebras are called Lindenbaum-Tarski
algebras. In essence, they are ‘canonical algebras.’
First, some preliminary work. The observation underpinning what follows is
that the relation of provable equivalence is a congruence on the formula algebra. A
congruence on an algebra is essentially an equivalence relation on the algebra that
respects the operations (a precise deﬁnition is given in Appendix B) and it is not
hard to see that provable equivalence is such a relation.
Proposition 5.12 The relation ≡C is a congruence on the propositional formula
algebra.
Proof. We have to prove that ≡C is an equivalence relation satisfying
φ ≡C ψ only if ¬φ ≡C ¬ψ(5.7)
φ0 ≡C ψ0 and φ1 ≡C ψ1 only if (φ0 ∨ φ1 ) ≡C (ψ0 ∨ ψ1 ).(5.8)
and
In order to prove that ≡C is reﬂexive, we have to show that for any formula φ, the
formula φ ↔ φ is a theorem of the proof system. The reader is invited to prove
this in his or her favorite proof system for proposition calculus. The properties of
symmetry and transitivity are also left to the reader.
But we want to prove that ≡C is not merely an equivalence relation but a congru-
ence. We deal with the case for negation, leaving (5.8) to the reader. Suppose that
φ ≡C ψ, that is, C φ ↔ ψ. Again, given that we are working with a sound and
complete proof system for propositional calculus, this implies that C ¬φ ↔ ¬ψ.
Given this, (5.7) is immediate.
The equivalence classes under ≡C are the building blocks for what follows. As any
such class is a maximal set of mutually equivalent formulas, we can think of such5.1 Logic as Algebra
271
classes as propositions. And as ≡C is a congruence, we can deﬁne a natural al-
gebraic structure on these propositions. Doing so gives rise to Lindenbaum-Tarski
algebras.
Deﬁnition 5.13 (Lindenbaum-Tarski Algebra) Given a set of proposition letters
Φ, let Form(Φ)/≡C be the set of equivalence classes that ≡C induces on the set
of formulas, and for any formula φ let [φ] denote the equivalence class containing
φ. Then the Lindenbaum-Tarski algebra (for this language) is the structure
LC (Φ) := (Form(Φ)/≡C , +, −, 0),
where +, − and 0 are deﬁned by: [φ] + [ψ] := [φ ∨ ψ], −[φ] := [¬φ] and 0 :=
[⊥]. Strictly speaking, we should write [φ]Φ instead of [φ], for φ’s congruence
class depends on the set Φ of proposition letters. But unless there is potential for
confusion, we usually will not bother to do so.
Lindenbaum-Tarski algebras are easy to work with. For instance, it is easy to see
that the meet operation in such an algebra is given by [φ] · [ψ] = [φ ∧ ψ], while
the top element 1 is []. As another example, we show that a + (−a) = 1 for
all elements a of LC (Φ). The ﬁrst observation is that a, just like any element of
LC (Φ), is of the form [φ] for some formula φ. But then we have
a + (−a) = [φ] + (−[φ]) = [φ] + [¬φ] = [φ ∨ (¬φ)] = [] = 1,
(5.9)
where the fourth equality holds because C (φ ∨ ¬φ) ↔ .
It is fairly obvious that the structure of a Lindenbaum-Tarski algebra only de-
pends on the cardinality of the set Φ of proposition letters; the reader is asked to
prove this in Exercise 5.1.4.
We need two results concerning Lindenbaum-Tarski algebras. First, we have to
show that they are indeed an ‘algebraic canonical model’ – that is, that they give us
a counterexample for every non-theorem of propositional logic. Second, we have
to show that they are counterexamples of the right kind: that is, we need to prove
that any Lindenbaum-Tarski algebra is a boolean algebra.
Proposition 5.14 Let φ be some propositional formula, and Φ a set of proposition
letters of size not smaller than the number of proposition letters occurring in φ.
Then
C φ iff LC (Φ) |= φ ≈ .
(5.10)
Proof. We may and will assume that Φ actually contains all variables occurring in
φ, cf. Exercise 5.1.4. We ﬁrst prove the easy direction from right to left. Assume
that φ is not a theorem of classical propositional logic. This implies that φ and
 are not provably equivalent, whence we have [φ] = []. We have to ﬁnd an
assignment on LC (Φ) that forms a counterexample to the validity of φ. There is272
5 Algebras and General Frames
one obvious candidate, namely the assignment ι given by ι(p) = [p]. It can easily
be veriﬁed (by a straightforward formula induction) that with this deﬁnition we
obtain ι̃(ψ) = [ψ] for all formulas ψ that use variables from the set Φ. But then by
our assumption on φ we ﬁnd that
ι̃(φ) = [φ] = [] = 1,
as required.
For the other direction we have to work a bit harder. If C φ then it is obvious
that ι̃(φ) = [φ] = [] = 1, but only looking at ι is not sufﬁcient now. We have to
show that θ̃(φ) = [] for all assignments θ.
So let θ be an arbitrary assignment. That is, θ assigns an equivalence class
(under ≡C ) to each proposition letter. For each variable p, take a representing
formula ρ(p) in the equivalence class θ(p); that is, we have θ(p) = [ρ(p)]. We
may view ρ as a function mapping proposition letters to formulas; in other words,
ρ is a substitution. Let ρ(ψ) denote the effect of performing this substitution on the
formula ψ. It can be proved by an easy formula induction that, for any formula ψ,
we have
θ̃(ψ) = [ρ(ψ)].
(5.11)
Now, the collection of propositional theorems is closed under uniform substitution
(depending on the formulation of your favorite sound and complete proof system,
this is either something that is hardwired in or can be shown to hold). This closure
property implies that the formula ρ(φ) is a theorem, and hence that ρ(φ) ≡C , or
equivalently, [ρ(φ)] = []. But then it follows from (5.11) that
θ̃(φ) = [],
which is precisely what we need to show that LC (Φ) |= φ.
Thus it only remains to check that LC (Φ) is the right kind of algebra.
Proposition 5.15 For any set Φ of proposition letters, LC (Φ) is a boolean algebra.
Proof. Fix a set Φ. The proof of this Proposition boils down to proving that all the
identities B0–4 hold in LC (Φ). In (5.9) we proved that the ﬁrst part of B3 holds;
we leave the reader to verify that the other identities hold as well.
Summarizing, we have seen that the axiomatics of propositional logic can be al-
gebraized in a class of algebras, namely the variety of boolean algebras. We have
also seen that Lindenbaum-Tarski algebras act as canonical representatives of the
class of boolean algebras. (For readers with some background in universal algebra,
we remark that Lindenbaum-Tarski algebras are in fact the free boolean algebras.)5.1 Logic as Algebra
273
Weak completeness via Stone
It is time to put our ﬁndings together, and to take one ﬁnal step. This step is more
important than any taken so far.
Theorem 5.9 captured tautologies as equations valid in set algebras:
|=C φ iff Set |= φ ≈ .
On the other hand, in Theorem 5.11 we found an algebraic semantics for the notion
of classical theoremhood:
C φ iff BA |= φ ≈ .
But there is a fundamental logical connection between |=C and C : the soundness
and completeness theorem for propositional logic tells us that they are identical.
Does this crucial connection show up algebraically? That is, is there an algebraic
analog of the soundness and completeness result for classical propositional logic?
There is: it is called the Stone Representation Theorem.
Theorem 5.16 (Stone Representation Theorem) Any boolean algebra is isomor-
phic to a set algebra.
Proof. We will make a more detailed statement of this result, and prove it, in Sec-
tion 5.3.
(Incidentally, this immediately tells us that any boolean algebra is isomorphic to a
subalgebra of a power of 2 – for Proposition 5.8 tells us that any power set algebra
is isomorphic to a power of 2.) But what really interests us here is the logical
content of Stone’s Theorem. In essence, it is the key to the weak completeness of
classical propositional logic.
Corollary 5.17 (Soundness and Weak Completeness) For any formula φ, φ is
valid iff it is a theorem.
Proof. Immediate from the equations above, since by the Stone Representation
Theorem, the equations valid in Set must coincide with those valid in BA.
The relation between Theorem 5.11 and Corollary 5.17 is the key to much of our
later work. Note that from a logical perspective, Corollary 5.17 is the interesting re-
sult: it establishes the soundness and completeness of classical propositional logic
with respect to the standard semantics. So why is Theorem 5.11 important? After
all, as it proves completeness with respect to an abstractly deﬁned class of boolean
algebras, it does not have the same independent logical interest. This is true, but
given that the abstract algebraic counterexamples it provides can be represented as
standard counterexamples – and this is precisely what Stone’s Theorem guarantees
– it enables us to prove the standard completeness result for propositional logic.274
5 Algebras and General Frames
To put it another way, the algebraic approach to completeness factors the algebra
building process into two steps. We ﬁrst prove completeness with respect to an
abstract algebraic semantics by building an abstract algebraic model. It is easy to
do this – we just use Lindenbaum-Tarski algebras. We then try and represent the
abstract algebras in the concrete form required by the standard semantics; that is,
in terms of set algebras or of the algebra 2.
In the next two sections we extend this approach to modal logic. Algebraizing
modal logic is more demanding than algebraizing propositional logic. For a start,
there is not just one logic to deal with – we want to be able to handle any normal
modal logic whatsoever. Moreover, the standard semantics for modal logic is given
in terms of frame-based models – so we are going to need a representation result
that tells us how to represent algebras as relational structures.
But all this can be done. In the following section we will generalize boolean
algebras to boolean algebras with operators; these are the abstract algebras we will
be dealing with throughout the chapter. We also generalize set algebras to com-
plex algebras; these are the concrete algebras which model the idea of set-based
algebras of propositions for modal languages. We then deﬁne the Lindenbaum-
Tarski algebras we need – and every normal modal logic will give rise to its own
Lindenbaum-Tarski algebra. This is all a fairly straightforward extension of ideas
we have just discussed. We then turn, in Section 5.3, to the crucial representation
result: the Jónsson-Tarski Theorem. This is an extension of Stone’s Representa-
tion Theorem that tells us how to represent a boolean algebra with operators as an
ordinary modal model. It is an elegant result in its own right, but for our purposes
its importance is the bridge it provides between completeness in the universe of
algebras and completeness in the universe of relational structures.
Exercises for Section 5.1
5.1.1 Let A and B be two sets, and f : A → B some map. Show that f −1 : P(B) →
P(A) given by f −1 (Y ) = {a ∈ A | f (a) ∈ Y } is a homomorphism from the power set
algebra of B to that of A.
5.1.2 Prove that every power set algebra is isomorphic to a power of the algebra 2, and
that conversely, every power of 2 is isomorphic to a power set algebra. That is, ﬁll in the
details of the proof of Theorem 5.8.
5.1.3 Here is a standard set of axioms for propositional calculus: p → (q → p), (p →
(q → r)) → ((p → q) → (p → r)), and (¬p → ¬q) → (q → p). Show that all three
axioms are valid on any set algebra. That is, show that whatever subset is used to interpret
the proposition letters, these formulas are true in all worlds. Furthermore, show that modus
ponens and uniform substitution preserve validity.
5.1.4 Let Φ and Ψ be two sets of proposition letters.
(a) Prove that Form(Φ) is a subalgebra of Form(Ψ ) iff Φ ⊆ Ψ .5.2 Algebraizing Modal Logic
275
(b) Prove that L C (Φ) can be embedded in L C (Ψ ) iff |Φ| ≤ |Ψ |.
(c) Prove that LC (Φ) and LC (Ψ ) are isomorphic iff |Φ| = |Ψ |.
(d) Does Φ ⊆ Ψ imply that L C (Φ) is a subalgebra of L C (Ψ )?
5.2 Algebraizing Modal Logic
Let us adapt the ideas introduced in the previous section to modal logic. The most
basic principle of algebraic logic is that formulas of a logical language can be
viewed as terms of an algebraic language, so let us ﬁrst get clear about the algebraic
languages we will use in the remainder of this chapter:
Deﬁnition 5.18 Let τ be a modal similarity type. The corresponding algebraic
similarity type Fτ contains as function symbols all modal operators, together with
the boolean symbols ∨ (binary), ¬ (unary), and ⊥ (constant). For a set Φ of vari-
ables, we let Ter τ (Φ) denote the collection of Fτ -terms over Φ.
The algebraic similarity type Fτ can be seen as the union of the modal similarity
type τ and the boolean type Bool . In practice we often identify τ and Fτ , speaking
of τ -terms instead of Fτ -terms. The previous deﬁnition takes the formulas-as-
terms paradigm quite literally: by our deﬁnitions
Form(τ, Φ) = Ter τ (Φ).
Just as boolean algebras were the key to the algebraization of classical proposi-
tional logic, in modal logic we are interested in boolean algebras with operators or
BAOs. Let us ﬁrst deﬁne BAOs abstractly; we will discuss concrete BAOs shortly.
Deﬁnition 5.19 (Boolean Algebras with Operators) Let τ = (O, ρ) be a modal
similarity type. A boolean algebra with τ -operators is an algebra
A = (A, +, −, 0, f )∈τ
such that (A, +, −, 0) is a boolean algebra and every f is an operator of arity
ρ(); that is, f is an operation satisfying
(normality) f(a1 , . . . , aρ() ) = 0 whenever ai = 0 for some i (0 < i ≤ ρ()).
(additivity) for all i (such that 0 < i ≤ ρ()),
f(a1 , . . . , ai + ai , . . . , aρ() ) =
f(a1 , . . . , ai , . . . , aρ() ) + f(a1 , . . . , ai , . . . , aρ() ).
If we abstract from the particular modal similarity type τ , or if τ is known from
context, we simply speak of boolean algebras with operators, or BAOs.5 Algebras and General Frames
276
Now, the boolean structure is obviously there to handle the propositional connec-
tives, but what is the meaning of the normality and additivity conditions on the f?
Consider a unary operator f . In this case these conditions boil down to:
f (0) = 0,
f (x + y) = f x + f y.
But these equations correspond to the following modal formulas:
3⊥ ↔ ⊥,
3(p ∨ q) ↔ 3p ∨ 3q,
both of which formulas are modal validities. Indeed (as we noted in Remark 4.7)
they can be even be used to axiomatize the minimal normal logic K. Thus, even
at this stage, it should be clear that our algebraic operators are well named: their
deﬁning properties are modally crucial.
Furthermore, note that all operators have the property of monotonicity. An oper-
ation g on a boolean algebra is monotonic if a ≤ b implies ga ≤ gb. (Here ≤ refers
to the ordering on boolean algebra given in Deﬁnition 5.10: a ≤ b iff a · b = a
iff a + b = b.) Operators are monotonic, because if a ≤ b, then a + b = b, so
f a + f b = f (a + b) = f b, and so f a ≤ f b. Once again there is an obvious
modal analog, namely the rule of proof mentioned in Remark 4.7: if Λ p → q
then Λ 3p → 3q.
Example 5.20 Consider the collection of binary relations over a given set U . This
collection forms a set algebra on which we can deﬁne the operations | (compo-
sition), (·)−1 (inverse) and Id (the identity relation); these are binary, unary and
nullary operations respectively. It is easy to verify that these operations are actu-
ally operators; to give a taste of the kind of argumentation required, we show that
composition is additive in its second argument:
(x, y) ∈ R | (S ∪ T )
iffthere is a z with (x, z) ∈ R and (z, y) ∈ S ∪ T
iffthere is a z with (x, z) ∈ R and (z, y) ∈ S or (z, y) ∈ T
iffthere is a z with (x, z) ∈ R and (z, y) ∈ S,
or there is a z with (x, z) ∈ R and (z, y) ∈ T
iff(x, y) ∈ R | S or (x, y) ∈ R | T
iff(x, y) ∈ R | S ∪ R | T.
The reader should check the remaining cases.5.2 Algebraizing Modal Logic
277
Algebraizing modal semantics
However it is the next type of BAO that is destined to play the leading role: complex
algebras. These structures make crucial use of the operations mR that we met in
Deﬁnition 1.30 and Deﬁnition 2.55.
Deﬁnition 5.21 (Complex Algebras) Let τ be a modal similarity type, and F =
(W, R)∈τ a τ -frame. The (full) complex algebra of F (notation: F+ ), is the
expansion of the power set algebra P(W ) with operations mR for every operator
 in τ . A complex algebra is a subalgebra of a full complex algebra. If K is a
class of frames, then we denote the class of full complex algebras of frames in K
by CmK.
It is important that you fully understand this deﬁnition. For a start, note that com-
plex algebras are set algebras (that is, concrete propositional algebras) to which
mR operations have been added. Recall that for a binary relation R, the unary
operation mR yields the set of all states which ‘see’ a state in a given subset X of
the universe:
mR (X) = {y ∈ W | there is an x ∈ X such that Ryx}.
For a relation of arity n + 1, the n-ary operation mR maps an n-tuple of subsets of
the universe to the set of all points which ‘see’ an n-tuple of states each of which
belongs to the corresponding subset. It easily follows that if we have some model
in mind and denote with Ṽ (φ) the set of states where φ is true, then
Ṽ ((φ1 , . . . , φn )) = mR (Ṽ (φ1 ), . . . , Ṽ (φn )).
Thus it should be clear that complex algebras are intrinsically modal. In the previ-
ous section we said that set algebras model propositions as sets of possible worlds.
By adding the mR operations, we have modeled the idea that one world may be
able to access the information in another. In short, we have deﬁned a class of con-
crete algebras which capture the modal notion of access between states in a natural
way.
How are complex algebras connected with abstract BAOs? One link is obvious:
Proposition 5.22 Let τ be a modal similarity type, and F = (W, R)∈τ a τ -
frame. Then F+ is a boolean algebra with τ -operators.
Proof. We have to show that operations of the form mR are normal and additive.
This rather easy proof is left to the reader; see Exercise 5.2.2.
The other link is deeper. As we will learn in the following section (Theo-
rem 5.43), complex algebras are to BAOs what set algebras are to boolean algebras:278
5 Algebras and General Frames
every abstract boolean algebra with operators has a concrete set theoretic repre-
sentation, for every boolean algebra with operators is isomorphic to a complex
algebra.
But we have a lot to do before we are ready to prove this – let us continue our
algebraization of the semantics of modal logic. We will now deﬁne the interpreta-
tion of τ -terms and equations in arbitrary boolean algebras with τ -operators. As
we saw for propositional logic, the basic idea is very simple: given an assignment
that tells us what the variables stand for, we can inductively deﬁne the meaning of
any term.
Deﬁnition 5.23 Assume that τ is a modal similarity type and that Φ is a set of
variables. Assume further that A = (A, +, −, 0, f )∈τ is a boolean algebra with
τ -operators. An assignment for Φ is a function θ : Φ → A. We can extend θ
uniquely to a meaning function θ̃: Ter τ (Φ) → A satisfying:
θ̃(p) = θ(p), for all p ∈ Φ,
θ̃(⊥) = 0,
θ̃(¬s) = −θ̃(s),
θ̃(s ∨ t) = θ̃(s) + θ̃(t),
θ̃((s1 , . . . , sn )) = f(θ̃(s1 ), . . . , θ̃(sn )).
Now let s ≈ t be a τ -equation. We say that s ≈ t is true in A (notation: A |= s ≈ t)
if for every assignment θ: θ̃(s) = θ̃(t).
But now consider what happens when A is a complex algebra F+ . Since elements
of F+ are subsets of the power set P(W ) of the universe W of F, assignments θ are
simply ordinary modal valuations! The ramiﬁcations of this observation are listed
in the following proposition:
Proposition 5.24 Let τ be a modal similarity type, φ a τ -formula, F a τ -frame, θ
an assignment (or valuation) and w a point in F. Then
(F, θ), w  φ
iffw ∈ θ̃(φ),(5.12)
FφiffF |= φ ≈ ,(5.13)
F+ |= φ ≈ ψiffF  φ ↔ ψ.(5.14)
+
Proof. We will only prove the ﬁrst part of the proposition (for the basic modal
similarity type); the second and third part follow immediately from this and the
deﬁnitions.
Let φ, F and θ be as in the statement of the theorem. We will prove (5.12) (for
all w) by induction on the complexity of φ. The only interesting part is the modal5.2 Algebraizing Modal Logic
279
case of the inductive step. Assume that φ is of the form 3ψ. The key observation
is that
θ̃(3ψ) = mR3 (θ̃(ψ)).
(5.15)
We now have:
(F, θ), w  3ψ
iff
iff
iff
iff
there is a v such that R3 wv and (F, θ), v  ψ
there is a v such that R3 wv and v ∈ θ̃(ψ)
w ∈ mR3 (θ̃(ψ))
w ∈ θ̃(3ψ).
Here the second equivalence is by the inductive hypothesis, and the last one by
(5.15). This proves (5.12).
The previous proposition is easily lifted to the level of classes of frames and com-
plex algebras. The resulting theorem is a fundamental one: it tells us that classes
of complex algebras algebraize modal semantics. It is the modal analog of Theo-
rem 5.9.
Theorem 5.25 Let τ be a modal similarity type, φ and ψ τ -formulas, and K a
class of τ -frames. Then
KφiffCmK |= φ ≈ ,(5.16)
CmK |= φ ≈ ψiffK  φ ↔ ψ.(5.17)
Proof. Immediate by Proposition 5.24.
This proposition allows us to identify the modal logic ΛK of a class of frames K
(that is, the set of formulas that are valid in each F ∈ K}) with the equational
theory of the class CmK of complex algebras of frames in K (that is, the set of
equations {s ≈ t | F+ |= s ≈ t, for all F ∈ K}).
Let us summarize what we have learned so far. We have developed an algebraic
approach to the semantics of modal logic in terms of complex algebras. These
complex algebras, concrete boolean algebras with operators, generalize to modal
languages the idea of algebras of propositions provided by set algebras. And most
important of all, we have learned that complex algebras embody all the information
about normal modal logics that frames do. Thus, mathematically speaking, we can
dispense with frames and instead work with complex algebras.
Algebraizing modal axiomatics
Turning to the algebraization of modal axiomatics, we encounter a situation similar
to that of the previous section. Once again, we will see that the algebraic counter-
part of a logic is an equational class of algebras. To give a precise formulation we
need the following deﬁnition.280
5 Algebras and General Frames
Deﬁnition 5.26 Given a formula φ, let φ≈ be the equation φ ≈ . Now let τ be a
modal similarity type. For a set Σ of τ -formulas, we deﬁne VΣ to be the class of
those boolean algebras with τ -operators in which the set Σ≈ = {σ ≈ | σ ∈ Σ} is
valid.
We now state the algebraic completeness theorem for modal logic. It is the obvious
analog of Theorem 5.11.
Theorem 5.27 (Algebraic Completeness) Let τ be a modal similarity type, and
Σ a set of τ -formulas. Then Kτ Σ (the normal modal τ -logic axiomatized by Σ) is
sound and complete with respect to VΣ . That is, for all formulas φ we have
Kτ Σ φ iff VΣ |= φ≈ .
Proof. We leave the soundness direction as an exercise to the reader. Completeness
is an immediate corollary of Theorems 5.32 and 5.33.
As a corollary to the soundness direction of Theorem 5.27, we have that VKτ Σ =
VΣ , for any set Σ of formulas. In the sequel this will allow us to forget about
axiom sets and work with logics instead.
To prove the completeness direction of Theorem 5.27, we need a modal version
of the basic tool used to prove algebraic completeness results: Lindenbaum-Tarski
algebras. As in the the case of propositional languages, we will build an algebra on
top of the set of formulas in such a way that the relation of provable equivalence
between two formulas is a congruence relation. The key difference is that we do
not have just one relation of provable equivalence, but many: we want to deﬁne the
notion of Lindenbaum-Tarski algebras for arbitrary normal modal logics.
Deﬁnition 5.28 Let τ be an algebraic similarity type, and Φ a set of proposition
letters. The formula algebra of τ over Φ is the algebra Form(τ, Φ) = (Form(τ, Φ),
+, −, ⊥, f)∈τ where +, − and ⊥ are given as in Deﬁnition 5.3, while for each
modal operator , the operation f is given by
f(t1 , . . . , tn ) = (t1 , . . . , tn ).
Notice the double role of  in this deﬁnition: on the right-hand side of the equation,
 is a ‘static’ part of the term (t1 , . . . , tn ), whereas in the-left hand side we have
a more ‘dynamic’ perspective on the interpretation f of the operation symbol .
Deﬁnition 5.29 Let τ be a modal similarity type, Φ a set of propositional variables,
and Λ a normal modal τ -logic. We deﬁne ≡Λ as a binary relation between τ -
formulas (in Φ) by
φ ≡Λ ψ iff Λ φ ↔ ψ.
If φ ≡Λ ψ, we say that φ and ψ are equivalent modulo Λ.5.2 Algebraizing Modal Logic
281
Proposition 5.30 Let τ be a modal similarity type, Φ a set of proposition letters
and Λ a normal modal τ -logic. Then ≡Λ is a congruence relation on Form(τ, Φ).
Proof. We conﬁne ourselves to proving the proposition for the basic modal simi-
larity type. First, we have to show that ≡Λ is an equivalence relation; this is easy,
and we leave the details to the reader. Next, we must show that ≡Λ is a congruence
relation on the formula algebra; that is, we have to demonstrate that ≡Λ has the
following properties:
φ0 ≡Λ ψ0 and φ1 ≡Λ ψ1 imply
φ0 ∨ φ1 ≡Λ φ0 ∨ ψ1 ,
φ ≡Λ ψ implies ¬φ ≡Λ ¬ψ,
φ ≡Λ ψ implies 3φ ≡Λ 3ψ.
(5.18)
The ﬁrst two properties are easy exercises in propositional logic. The third is an
immediate corollary of Lemma 4.6.
Proposition 5.30 tells us that the following are correct deﬁnitions of functions on
the set Form(τ, Φ)/≡Λ of equivalence classes under ≡Λ :
[φ] + [ψ] := [φ ∨ ψ],
−[φ] := [¬φ],
f([φ1 ], . . . , [φn ]) := [(φ1 , . . . , φn )].
(5.19)
For unary diamonds, the last clause boils down to: f3 [φ] := [3φ].
Given Proposition 5.30, the way is open to deﬁne the Lindenbaum-Tarski algebra
for any normal modal logic Λ: we simply deﬁne it to be the quotient algebra of the
formula algebra over the congruence relation ≡Λ .
Deﬁnition 5.31 (Lindenbaum-Tarski Algebras) Let τ be a modal similarity
type, Φ a set of proposition letters, and Λ a normal modal τ -logic in this language.
The Lindenbaum-Tarski algebra of Λ over the set of generators Φ is the structure
LΛ (Φ) := (Form(τ, Φ)/≡Λ , +, −, f),
where the operations +, − and f are deﬁned as in (5.19).
As with propositional logic, we need two results about Lindenbaum-Tarski alge-
bras. First, we must show that modal Lindenbaum-Tarski algebras are boolean
algebras with operators; indeed, we need to show that the Lindenbaum-Tarski al-
gebra of any normal modal logic Λ belongs to VΛ . Second, we need to prove that
Lindenbaum-Tarski algebras provide canonical counterexamples to the validity of
non-theorems of Λ in VΛ . The second point is easily dealt with:
Theorem 5.32 Let τ be a modal similarity type, and Λ a normal modal τ -logic.5 Algebras and General Frames
282
Let φ be some propositional formula, and Φ a set of proposition letters of size not
smaller than the number of proposition letters occurring in φ. Then
Λ φ iff LΛ (Φ) |= φ≈ .
(5.20)
Proof. This proof is completely analogous to that of Proposition 5.14 and is left to
the reader.
So let us verify that Lindenbaum-Tarski algebras are canonical algebraic models of
the right kind:
Theorem 5.33 Let τ be a modal similarity type, and Λ be a normal modal τ -logic.
Then for any set Φ of proposition letters, LΛ (Φ) belongs to VΛ .
Proof. Once we have shown that LΛ (Φ) is a boolean algebra with τ -operators, the
theorem immediately follows from Theorem 5.32. Now, that LΛ (Φ) is a boolean
algebra is clear, so the only thing that remains to be done is to show that the modal-
ities really give rise to τ -operators.
As an example, assume that τ contains a diamond 3; let us prove additivity of
f3 . We have to show that
f3 (a + b) = f3 a + f3 b,
for arbitrary elements a and b of LΛ (Φ). Let a and b be such elements; by deﬁnition
there are formulas φ and ψ such that a = [φ] and b = [ψ]. Then
f3 (a + b) = f3 ([φ] + [ψ]) = f3 ([φ ∨ ψ]) = [3(φ ∨ ψ)]
while
f3 a + f3 b = f3 ([φ]) + f3 ([ψ]) = [3φ] + [3ψ] = [3φ ∨ 3ψ].
It is easy to check that
Λ 3(φ ∨ ψ) ↔ (3φ ∨ 3ψ),
whence it follows that [3(φ ∨ ψ)] = [3φ ∨ 3ψ]. We leave it for the reader to ﬁll
in the remaining details of this proof as Exercise 5.2.4.
As an immediate corollary we have the following result: modal logics are always
complete with respect to the variety of boolean algebras with operators where their
axioms are valid. This is in sharp contrast to the situation in relational semantics,
where (as we saw in Chapter 4) modal logics need not be complete with respect to
the class of frames that they deﬁne.
This is an interesting result, but it is not what we really want, for it proves com-
pleteness with respect to abstract BAOs rather than complex algebras. Not only are
complex algebras concrete algebras of propositions, we also know (recall Proposi-
tion 5.24) that complex algebras embody all the information of relevance to frame5.3 The Jónsson-Tarski Theorem
283
validity – so we really should be aiming for completeness results with respect to
classes of complex algebras.
And that is why the long-promised Jónsson-Tarski Theorem, which we state
and prove in the following section, is so important. This tells us that every boolean
algebra with operators is isomorphic to a complex algebra, and thus guarantees that
we can represent the Lindenbaum-Tarski algebras of any normal modal logics Λ
as a complex algebra. In effect, it will convert Theorem 5.32 into a completeness
result with respect to complex algebras. Moreover, because of the link between
complex algebras and relational semantics, it will open the door to exploring frame
completeness algebraically.
Exercises for Section 5.2
5.2.1 Let A be a boolean algebra. Prove that · is an operator. How about +?
5.2.2 Show that every complex algebra is a boolean algebra with operators (that is, prove
Proposition 5.22).
5.2.3 Let A be the collection of ﬁnite and co-ﬁnite subsets of N. Deﬁne f : A → A by
f (X) =
{y ∈ N | y + 1 ∈ X} if X is ﬁnite,
N
if X is co-ﬁnite.
Prove that (A, ∪, −, ∅, f ) is a boolean algebra with operators.
5.2.4 Let Λ be a normal modal logic. Prove that the Lindenbaum-Tarski algebra L Λ is a
boolean algebra with τ -operators (that is, ﬁll in the missing proof details in Theorem 5.33).
5.2.5 Let Σ be a set of τ -formulas. Prove that for any formula φ,  Kτ Σ φ implies VΣ |=
φ≈ . That is, prove the soundness direction of Theorem 5.27.
5.2.6 Call a variety V of BAOs complete if it is generated by a class of full complex alge-
bras, i.e., if V = HSPCmK for some frame class K. Prove that a logic Λ is complete iff
the variety VΛ is complete.
5.2.7 Let A be a boolean algebra. In this exercise we assume familiarity with the notion
of an inﬁnite sum (supremum). An operation f : A → A is called completely additive if it
distributes over inﬁnite sums (in each of its arguments).
(a) Show that every operation of the form m R is completely additive.
(b) Give an example of an operation that is additive, but not completely additive. (Hint:
as the boolean algebra, take the set of ﬁnite and co-ﬁnite subsets of some frame.)
5.3 The Jónsson-Tarski Theorem
We already know how to construct a BAO from a frame: simply form the frame’s
complex algebra. We will now learn how to construct a frame from a BAO by form-
ing the ultraﬁlter frame of the algebra. As we will see, this operation generalizes284
5 Algebras and General Frames
two constructions that we have met before: taking the ultraﬁlter extension of a
model, and forming the canonical frame associated with a normal modal logic.
Our new construction will lead us to the desired representation theorem: by tak-
ing the complex algebra of the ultraﬁlter frame of a BAO, we obtain the canonical
embedding algebra of the original BAO. The fundamental result of this section
(and, indeed, of the entire chapter) is that every boolean algebra with operators
can be isomorphically embedded in its canonical embedding algebra. We will
prove this result and along the way discuss a number of other important issues,
such as the algebraic status of canonical models and ultraﬁlter extensions, and the
importance of canonical varieties of BAOs for modal completeness theory.
Let us consider the problem of (isomorphically) embedding an arbitrary BAO
A in a complex algebra. Obviously, the ﬁrst question to ask is: what should be
the underlying frame of the complex algebra? To keep our notation simple, let
us assume for the moment that we are working in a similarity type with just one
unary modality, and that A = (A, +, −, 0, f ) is a boolean algebra with one unary
operator f . Thus we have to ﬁnd a universe W and a binary relation R on W
such that A can be embedded in the complex algebra of the frame (W, R). Stone’s
Representation Theorem 5.16 gives us half the answer, for it tells us how to embed
the boolean part of A in the power set algebra of the set Uf A of ultraﬁlters of A.
Let us take a closer look at this fundamental result.
Stone’s Representation Theorem
We have already met ﬁlters and ultraﬁlters in Chapter 2, when we deﬁned the ul-
traﬁlter extension of a model. Now we generalize these notions to the context of
abstract boolean algebras.
Deﬁnition 5.34 A ﬁlter of a boolean algebra A = (A, +, −, 0) is a subset F ⊆ A
satisfying
(F1) 1 ∈ F ,
(F2) F is closed under taking meets; that is, if a, b ∈ F then a · b ∈ F ,
(F3) F is upward closed; that is, if a ∈ F and a ≤ b then b ∈ F .
A ﬁlter is proper if it does not contain the smallest element 0, or, equivalently, if
F = A. An ultraﬁlter is a proper ﬁlter satisfying
(F4) For every a ∈ A, either a or −a belongs to F .
The collection of ultraﬁlters of A is called Uf A.
Note the difference in terminology: an (ultra)ﬁlter over the set W is an (ultra)ﬁlter
of the power set algebra P(W ).5.3 The Jónsson-Tarski Theorem
285
Example 5.35 For any element a of a boolean algebra A, the set a↑ = {b ∈ A |
a ≤ b} is a ﬁlter. In the ﬁeld of ﬁnite and co-ﬁnite subsets of a countable set W ,
the collection of co-ﬁnite subsets of W forms an ultraﬁlter.
Example 5.36 Since the collection of ﬁlters of a boolean algebra is closed under
taking intersections, we may speak of the smallest ﬁlter FD containing a given set
D ⊆ A. This ﬁlter can also be deﬁned as the following set:
{a ∈ A | there are d0 , . . . , dn ∈ D such that d0 · . . . · dn ≤ a}
(5.21)
which explains why we will also refer to FD as the ﬁlter generated by D. This
ﬁlter is proper if D has the so-called ﬁnite meet property; that is, if there is no ﬁnite
subset {d0 , . . . , dn } of D such that d0 · . . . · dn = 0.
For future reference, we gather some properties of ultraﬁlters; the proof of the next
proposition is left to the reader.
Proposition 5.37 Let A = (A, +, −, 0) be a boolean algebra. Then
(i) For any ultraﬁlter u of A and for every pair of elements a, b ∈ A we have
that a + b ∈ u iff a ∈ u or b ∈ u.
(ii) Uf A coincides with the set of maximal proper ﬁlters on A (‘maximal’ is
understood with respect to set inclusion).
The main result that we need in the proof of Stone’s Theorem is the Ultraﬁlter
Theorem: this guarantees that there are enough ultraﬁlters for our purposes.
Proposition 5.38 (Ultraﬁlter Theorem) Let A be a boolean algebra, a an element
of A, and F a proper ﬁlter of A that does not contain a. Then there is an ultraﬁlter
extending F that does not contain a.
Proof. We ﬁrst prove that every proper ﬁlter can be extended to an ultraﬁlter. Let
G be a proper ﬁlter of A, and consider the set X of all proper ﬁlters H extending
G. Suppose that Y is a chain in X; that is, Y is a nonempty subset of X of which
the elements are pairwise ordered by set inclusion. We leave it to the reader to
verify that Y is a proper ﬁlter; obviously, Y extends G; so Y belongs to X
itself. This shows that X is closed under taking unions of chains, whence it follows
from Zorn’s Lemma that X contains a maximal element u. We claim that u is an
ultraﬁlter.
For suppose otherwise. Then there is a b ∈ A such that neither b nor −b belongs
to u. Consider the ﬁlters H and H generated by u∪{b} and u∪{−b}, respectively.
Since neither of these can belong to X, both must be improper; that is, 0 ∈ H and286
5 Algebras and General Frames
0 ∈ H  . But then by deﬁnition there are elements u1 , . . . , un , u1 , . . . , um in u such
that
u1 · . . . · un · b ≤ 0 and u1 · . . . · um · −b ≤ 0.
From this it easily follows that
u1 · . . . · un · u1 · ... · um = 0,
contradicting the fact that u is a proper ﬁlter.
Now suppose that a and F are as in the statement of the proposition. It is not
hard to show that F ∪ {−a} is a set with the ﬁnite meet property. In Example 5.36
we saw that there is a proper ﬁlter G extending F and containing −a. Now we use
the ﬁrst part of the proof to ﬁnd an ultraﬁlter u extending G. But if u extends G it
also extends F , and if it contains −a it cannot contain a.
It follows from Proposition 5.38 and the facts mentioned in Example 5.36 that any
subset of a boolean algebra can be extended to an ultraﬁlter provided that it has
the ﬁnite meet property. We now have all the necessary material to prove Stone’s
Theorem.
Theorem 5.16 (Stone Representation Theorem) Any boolean algebra is iso-
morphic to a ﬁeld of sets, and hence, to a subalgebra of a power of 2. As a
consequence, the variety of boolean algebras is generated by the algebra 2:
BA = V({2}).
Proof. Fix a boolean algebra A = (A, +, −, 0). We will embed A in the power set
of Uf A. Consider the map ρ : A → P(Uf A) deﬁned as follows:
ρ(a) = {u ∈ Uf A | a ∈ u}.
We ﬁrst show that ρ is a homomorphism. As an example we treat the join operation:
ρ(a + b) = {u ∈ Uf A | a + b ∈ u}
= {u ∈ Uf A | a ∈ u or b ∈ u}
= {u ∈ Uf A | a ∈ u} ∪ {u ∈ Uf A | b ∈ u}
= ρ(a) ∪ ρ(b).
Note that the crucial second equality follows from Proposition 5.37.
It remains to prove that ρ is injective. Suppose that a and b are distinct elements
of A. We may derive from this that either a ≤ b or b ≤ a. Without loss of
generality we may assume the second. But if b ≤ a then a does not belong to the
ﬁlter b↑ generated by {b}, so by Proposition 5.38 there is some ultraﬁlter u such
that b↑ ⊆ u and a ∈ u. Obviously, b↑ ⊆ u implies that b ∈ u. But then we have
that u ∈ ρ(b) and u ∈ ρ(a).5.3 The Jónsson-Tarski Theorem
287
This shows that A is isomorphic to a ﬁeld of sets; it then follows by Propo-
sition 5.8 that A is isomorphic to a subalgebra of a power of 2. From this it is
immediate that BA is the variety generated by the algebra 2.
Remark 5.39 That every boolean algebra is isomorphic to a subalgebra of a power
of the algebra 2 can be proved more directly by observing that there is a one-to-
one correspondence between ultraﬁlters of A and homomorphisms from A onto 2.
Given an ultraﬁlter u of A, deﬁne αu : A → 2 by
αu (a) =
1 if a ∈ u,
0 otherwise.
And conversely, given a homomorphism α : A → 2, deﬁne the ultraﬁlter uα by
uα = α−1 (1) (= {a ∈ A | α(a) = 1}).
We leave further details to the reader.
Ultraﬁlter frames
Now that we have a candidate for the universe of the ultraﬁlter frame of a given
BAO A, let us see how to deﬁne a relation R on ultraﬁlters such that we can embed
A in the algebra (Uf A, R)+ . To motivate the deﬁnition of R, we will view the
elements of the algebra as propositions, and imagine that r(a) (the representation
map r applied to proposition a) yields the set of states where a is true according
to some valuation. Hence, reading f a as 3a, it seems natural that a state u should
be in r(f a) if and only if there is a v with Ruv and v ∈ r(a). So, in order to
decide whether Ruv should hold for two arbitrary states (ultraﬁlters) u and v, we
should look at all the propositions a holding at v (that is, all elements a ∈ v) and
check whether f a holds at u (that is, whether f a ∈ u). Putting it more formally,
the natural, ‘canonical’ choice for R seems to be the relation Qf given by
Qf uv iff f a ∈ u for all a ∈ v.
The reader should compare this deﬁnition with the deﬁnition of the canonical re-
lation given in Deﬁnition 4.18. Although one is couched in terms of ultraﬁlters,
and the other in terms of maximal consistent sets (MCSs), both clearly trade on the
same idea. As we will shortly learn (and as the above identiﬁcation of ‘ultraﬁlters’
and ‘maximal sets of propositions’ already suggests), this is no accident.
In the general case, we use the following deﬁnition (an obvious analog of Deﬁ-
nition 4.24).
Deﬁnition 5.40 Given an n-ary operator f on a boolean algebra (A, +, −, 0), we
deﬁne the (n + 1)-ary relation Qf on the set of ultraﬁlters of the algebra by
Qf uu1 . . . un iff f (a1 , . . . , an ) ∈ u for all a1 ∈ u1 , . . . , an ∈ un .288
5 Algebras and General Frames
Let A = (A, +, −, 0, f )∈τ be a boolean algebra with operators. The ultraﬁlter
frame of A, notation: A+ , is the structure (Uf A, Qf )∈τ . The complex algebra
(A+ )+ is called the (canonical) embedding algebra of A (notation: EmA).
We leave it to the reader to verify that the ultraﬁlter extension ue F of a frame
F is nothing but the ultraﬁlter frame of the complex algebra of F, in symbols:
ue F = (F+ )+ .
For later reference, we state the following proposition (an obvious analog of
Lemma 4.25) which shows that we could have given an alternative but equivalent
deﬁnition of the relation Qf .
Proposition 5.41 Let f be an n-ary operator on the boolean algebra A, and u,
u1 , . . . , un an (n + 1)-tuple of ultraﬁlters of A. Then
Qf uu1 . . . un iff −f (−a1 , . . . , −an ) ∈ u implies that for some i, ai ∈ ui .
Proof. We only prove the direction from left to right. Suppose that Qf uu1 . . . un ,
and that −f (−a1 , . . . , −an ) ∈ u. To arrive at a contradiction, suppose that there is
no i such that ai ∈ ui . But as Qf uu1 . . . un , it follows that f (−a1 , . . . , −an ) ∈ u.
But this contradicts the fact that −f (−a1 , . . . , −an ) ∈ u.
As the above sequence of analogous deﬁnitions and results suggest, we have al-
ready encountered a kind of frame which is very much like an ultraﬁlter frame,
namely the canonical frame of a normal modal logic (see Deﬁnition 4.18). The
basic idea should be clear now: the states of the canonical frame are the MCSs
of the logic, and an ultraﬁlter is nothing but an abstract version of an MCS. But
this is no mere analogy: the canonical frame of a logic is actually isomorphic to
the ultraﬁlter frame of its Lindenbaum-Tarski algebra, and the mapping involved
is simple and intuitive. When making this connection, the reader should keep in
mind that when we deﬁned ‘the’ canonical frame in Chapter 4, we always had a
ﬁxed, countable set Φ of proposition letters in mind.
Theorem 5.42 Let τ be a modal similarity type, Λ a normal modal τ -logic, and Φ
the set of proposition letters used to deﬁne the canonical frame FΛ . Then
FΛ ∼
= (LΛ (Φ))+ .
Proof. We leave it to the reader to show that the function θ deﬁned by
θ(Γ ) = {[φ] | φ ∈ Γ },
mapping a maximal Λ-consistent set Γ to the set of equivalence classes of its mem-
bers, is the required isomorphism between FΛ and (LΛ (Φ))+ .5.3 The Jónsson-Tarski Theorem
289
The Jónsson-Tarski Theorem
We are ready to prove the Jónsson-Tarski Theorem: every boolean algebra with
operators is embeddable in the full complex algebra of its ultraﬁlter frame.
Theorem 5.43 (Jónsson-Tarski Theorem) Let τ be a modal similarity type, and
A = (A, +, −, 0, f)∈τ be a boolean algebra with τ -operators. Then the repre-
sentation function r : A → P(Uf A)) given by
r(a) = {u ∈ Uf A | a ∈ u}
is an embedding of A into EmA.
Proof. To simplify our notation a bit, we work in a similarity type with a single
n-ary modal operator, assuming that A = (A, +, −, 0, f ) is a boolean algebra with
a single n-ary operator f . By Stone’s Representation Theorem, the map r : A →
P(Uf A) given by
r(x) = {u ∈ Uf A | x ∈ u}
is a boolean embedding. So, it sufﬁces to show that r is also a modal homomor-
phism; that is, that
r(f (a1 , . . . , an )) = mQf (r(a1 ), . . . , r(an )).
(5.22)
We will ﬁrst prove (5.22) for unary f . In other words, we have to prove that
r(f a) = mQf (r(a)).
We start with the inclusion from right to left: assume u ∈ mQf (r(a)). Then by
deﬁnition of mQf , there is an ultraﬁlter u1 with u1 ∈ r(a) (that is, a ∈ u1 ) and
Qf uu1 . By deﬁnition of Qf this implies f a ∈ u, or u ∈ r(f a).
For the other inclusion, let u be an ultraﬁlter in r(f a), that is, f a ∈ u. To
prove that u ∈ mQf (r(a)), it sufﬁces to ﬁnd an ultraﬁlter u1 such that Qf uu1 and
u1 ∈ r(a), or a ∈ u1 . The basic idea of the proof is that we ﬁrst pick out those
elements of A (other than a) that we cannot avoid putting in u1 . These elements are
given by the condition Qf uu1 . By Proposition 5.41 we have that for every element
of the form −f (−y) in u, y has to be in u1 ; therefore, we deﬁne
F := {y ∈ A | −f (−y) ∈ u}.
We will now show that there is an ultraﬁlter u1 ⊇ F containing a. First, an easy
proof (using the additivity of f ), shows that F is closed under taking meets. Sec-
ond, we prove that
F  := {a · y | y ∈ F }
has the ﬁnite meet property. As F is closed under taking meets, it is sufﬁcient to
show that a · y = 0 whenever y ∈ F . To arrive at a contradiction, suppose that5 Algebras and General Frames
290
a · y = 0. Then a ≤ −y, so by the monotonicity of f , f a ≤ f (−y); therefore,
f (−y) ∈ u, contradicting y ∈ F .
By Proposition 5.38 there is an ultraﬁlter u1 ⊇ F  . Note that a ∈ u1 , as 1 ∈ F .
Finally, Qf uu1 holds by deﬁnition of F : if −f (−y) ∈ u then y ∈ F ⊆ u1 .
We now prove (5.22) for arbitrary n ≥ 1 by induction on the arity n of f . We
have just proved the base case. So, assume that the induction hypothesis holds for
n. We only treat the direction from left to right, since the other direction can be
proved as in the base case. Let f be a normal and additive function of rank n + 1,
and suppose that a1 , . . . , an+1 are elements of A such that f (a1 , . . . , an+1 ) ∈ u.
We have to ﬁnd ultraﬁlters u1 , . . . , un+1 of A such that (i) ai ∈ ui for all i with
1 ≤ i ≤ n + 1, and (ii) Qf uu1 . . . un+1 . Our strategy will be to let the induction
hypothesis take care of u1 , . . . , un and then to search for un+1 .
Let f  : An → A be the function given by
f  (x1 , . . . , xn ) = f (x1 , . . . , xn , an+1 ).
That is, for the time being we ﬁx an+1 . It is easy to see that f  is normal and
additive, so we may apply the induction hypothesis. Since f (a1 , . . . , an ) ∈ u, this
yields ultraﬁlters u1 , . . . , un such that ai ∈ ui for all i with 1 ≤ i ≤ n, and
f (x1 , . . . , xn , an+1 ) ∈ u, whenever xi ∈ ui (1 ≤ i ≤ n).
(5.23)
Now we will deﬁne an ultraﬁlter un+1 such that an+1 ∈ un+1 and Qf uu1 . . . un+1 .
This second condition can be rewritten as follows (we abbreviate ‘x1 ∈ u1 , . . . ,
xn ∈ un ’ by ‘x ∈ u’):
Qf uu1 . . . un+1
ifffor all x, y: if x ∈ u, then y ∈ un+1 implies f (x, y) ∈ u
ifffor all x, y: if x ∈ u, then f (x, y) ∈ u implies y ∈ un+1
ifffor all x, y: if x ∈ u, then −f (x, y) ∈ u implies −y ∈ un+1
ifffor all x, z: if x ∈ u, then −f (x, −z) ∈ u implies z ∈ un+1 .
This provides us with a minimal set of elements that un+1 should contain; put
F := {z ∈ A | ∃x ∈ u (−f (x, −z) ∈ u)}.
If −f (x, −z) ∈ u, we say that x drives z into F . We now take the ﬁrst condition
into account as well, deﬁning F  := {an+1 } ∪ F .
Our aim is to prove the existence of an ultraﬁlter un+1 containing F  . It will be
clear that this is sufﬁcient to prove the theorem (note that an+1 ∈ F  as 1 ∈ F ). To
be able to apply the Ultraﬁlter Theorem 5.38, we will show that F has the ﬁnite
meet property. We ﬁrst need the following fact:
F is closed under taking meets.
(5.24)5.3 The Jónsson-Tarski Theorem
291
Let z  , z  be in F ; assume that z and z are driven into F by x and x , respec-
tively. We will now see that x := (x1 · x1 , . . . , xn · xn ) drives z := z · z  into F ,
that is, that −f (x, −z) ∈ u.
Since f is monotonic, we have f (x, −z ) ≤ f (x , −z  ), and hence we ﬁnd that
−f (x , −z  ) ≤ −f (x, −z  ). As u is upward closed and −f (x , −z  ) ∈ u by
our ‘driving assumption’, this gives −f (x, −z ) ∈ u. In the same way we ﬁnd
−f (x, −z  ) ∈ u. Now
f (x, −z) = f (x, −(z  · z  )) = f (x, (−z  ) + (−z  )) = f (x, −z  ) + f (x, −z  ),
whence
−f (x, −z) = [−f (x, −z  )] · [−f (x, −z  )].
Therefore, −f (x, −z) ∈ u, since u is closed under taking meets. This proves
(5.24).
We can now ﬁnish the proof and show that indeed
F  has the ﬁnite meet property.
(5.25)
By (5.24) it sufﬁces to show that an+1 ·z = 0 for all z ∈ F . To prove this, we reason
by contraposition: suppose that z ∈ F and an+1 · z = 0. Let x ∈ u be a sequence
that drives z into F , that is, −f (x, −z) ∈ u. From an+1 · z = 0 it follows that
an+1 ≤ −z, so by monotonicity of f we get −f (x, −z) ≤ −f (x, an+1 ). But then
−f (x, an+1 ) ∈ u, which contradicts (5.23). This proves that indeed an+1 · z = 0
and hence we have shown (5.25) and thus, Theorem 5.43.
Canonicity: the algebraic perspective
To conclude this section, let us discuss the signiﬁcance of this result. Clearly the
Jónsson-Tarski Theorem guarantees that we can represent the Lindenbaum-Tarski
algebras of normal modal logics as complex algebras, so it immediately converts
Theorem 5.32 into a completeness result with respect to complex algebras.
But we want more: because of the link between complex algebras and relational
semantics, it seems to offer a plausible algebraic handle on frame completeness.
And in fact it does – but we need to be careful. As should be clear from our work in
Chapter 4, even with the Jónsson-Tarski Theorem at our disposal, one more hurdle
remains to be cleared. In Exercise 5.2.6 we deﬁned the notion of a complete variety
of BAOs: a variety V is complete if there is a frame class K that generates V in the
sense that V = HSPCmK. The exercise asked the reader to show that any logic
Λ is complete if and only if VΛ is a complete variety. Now does the Jónsson-Tarski
Theorem establish such a thing? Not really – it does show that every algebra A is
a complex algebra over some frame, thus proving that for any logic Λ we have that
VΛ ⊆ SCmK for some frame class K. So, this certainly gives VΛ ⊆ HSPCmK.292
5 Algebras and General Frames
However, in order to prove completeness, we have to establish an equality instead
of an inclusion. One way to prove this is to show that the complex algebras that we
have found form a subclass of VΛ . By Proposition 5.24 it would sufﬁce to show
that for any algebra A in the variety VΛ , the frame A+ is a frame for the logic Λ.
This requirement gives us an algebraic handle on the notion of canonicity.
Let us examine a concrete example. Recall that K4 is the normal logic gen-
erated by the 4 axiom, 33p → 3p. We know from Theorem 4.27 that K4 is
complete with respect to the class of transitive frames. How can we prove this
result algebraically?
A little thought reveals that the following is required: we have to show that
the Lindenbaum-Tarski algebras for K4 are embeddable in full complex algebras
of transitive frames. Recall from Section 3.1 that the 4 axiom characterizes the
transitive frames, thus in our proposed completeness proof, we would have to show
that 4 is valid in the ultraﬁlter frame (LK4 (Φ))+ of LK4 (Φ), or equivalently, that
((LK4 (Φ))+ )+ belongs to the variety V4 . Note that by Theorem 5.32 we already
know that LK4 (Φ) belongs to V4 .
As this example suggests, proving frame completeness results for extensions of
K algebraically leads directly to the following question: which varieties of BAOs
are closed under taking canonical embedding algebras? In fact, this is the required
algebraic handle on canonicity and motivates the following deﬁnition.
Deﬁnition 5.44 Let τ be a modal similarity type, and C a class of boolean algebras
with τ -operators. C is canonical if it is closed under taking canonical embedding
algebras; that is, if for all algebras A, EmA is in C whenever A is in C. Likewise,
an equation is canonical if its validity is preserved when moving from a BAO to its
canonical embedding algebra.
Thus we now have two notions of canonicity, namely the logical one of Deﬁni-
tion 4.30 and the algebraic one just deﬁned. Using Theorem 5.32, we show that
these two concepts are closely related.
Proposition 5.45 Let τ be a modal similarity type, and Σ a set of τ -formulas. If
VΣ is a canonical variety, then Σ is canonical.
Proof. Assume that the variety VΣ is canonical, and let Φ be the ﬁxed countable set
of proposition letters that we use to deﬁne canonical frames. By Theorem 5.32, the
Lindenbaum-Tarski algebra LKΣ (Φ) is in VΣ ; then, by assumption, its canonical
embedding algebra EmLKΣ is in VΣ . However, from Theorem 5.42 it follows that
this algebra is isomorphic to the complex algebra of the canonical frame of KΣ:
EmLKΣ (Φ) = ((LKΣ (Φ))+ )+ ∼
= (FKΣ )+ .5.3 The Jónsson-Tarski Theorem
293
Now the fact that (FKΣ )+ is in VΣ means that FKΣ  Σ by Proposition 5.24. But
this implies that Σ is canonical.
An obvious question is whether the converse of Proposition 5.45 holds as well;
that is, whether a variety VΣ is canonical if Σ is a canonical set of modal formu-
las. However, note that canonicity of Σ only implies that one particular boolean
algebra with operators has its embedding algebra in VΣ , namely the Lindenbaum-
Tarski algebra over a countably inﬁnite number of generators. This is because
throughout the completeness chapter we were working in a ﬁxed, countable set of
proposition letters. In fact, we are facing an open problem here:
Open Problem 1 Let τ be a modal similarity type, and Σ a canonical set of τ -
formulas. Is VΣ a canonical variety?
Equivalently, suppose that E is a set of equations such that for all countable
boolean algebras with τ -operators we have the following implication
if A |= E then EmA |= E.
(5.26)
Is VE a canonical variety? In other words, does (5.26) hold for all boolean alge-
bras with τ -operators?
This is an interesting problem. However, arguably the restriction of the notion of
canonicity to countable languages that we adopted in Chapter 4 was not mathe-
matically natural. Thus, let us redeﬁne the logical notion of canonicity so that it
refers to languages of arbitrary size. The deﬁnition of canonical frames and models
can easily be parametrized by a set of proposition letters: the maximal consistent
sets are supposed to be maximal within the induced set of formulas. We now sim-
ply deﬁne a logic Λ to be canonical if it is valid on each of its canonical frames.
With this deﬁnition we can indeed establish equivalence between the logical and
algebraic notions of canonicity. (An alternative, and mathematically quite interest-
ing alternative, would be to introduce, both logically and algebraically, a hierarchy
of canonicity notions, parametrized by cardinal numbers. Such an approach has
indeed been studied in the literature, but this option will not be pursued here.)
Regardless of our approach towards this issue, the algebraic notion of canonic-
ity can do a lot of work for us. The important point is that it offers a genuinely
new perspective on what canonicity is, a perspective that will allow us to use al-
gebraic arguments. This will be demonstrated in Section 5.6 when we introduce
persistence, a generalization of the notion of canonicity, and prove the Sahlqvist
Completeness Theorem.
Exercises for Section 5.3
5.3.1 Prove that for any frame F, ue F = (F + )+ .5 Algebras and General Frames
294
5.3.2 Let Λ be a normal modal logic. Give a detailed proof that the canonical frame F Λ is
isomorphic to the ultraﬁlter frame of L Λ (over a countable set of proposition letters).
5.3.3 Let A denote the collection of sets X of integers satisfying one of the following
four conditions: (i) X is ﬁnite, (ii) X is co-ﬁnite, (iii) X ⊕ E is ﬁnite, (iv) X ⊕ E is
co-ﬁnite. Here E denotes the set of all even integers, and ⊕ denotes symmetric difference:
X ⊕ E = (X \ E) ∪ (E \ X). Consider the following algebra A = (A, ∪, −, ∅, f ) where
the operation f is given by
f (X) =
{x − 1 | x ∈ X}
Z
if X is of type (i) or (iii),
if X is of type (ii) or (iv).
(a) Show that A is a boolean algebra with operators.
(b) Describe A+ .
5.3.4 Let W be the set Z ∪ {−∞, ∞} and let S be the successor relation on Z, that is,
S = {(z, z + 1) | z ∈ Z}.
(a) Give a BAO whose ultraﬁlter frame is isomorphic to the frame F = (W, R) with
R = S ∪ {(−∞, −∞), (∞, ∞)}.
(b) Give a BAO whose ultraﬁlter frame is isomorphic to the frame F = (W, R) with
R = S ∪ (W × {−∞, ∞}).
(c) Give a BAO whose ultraﬁlter frame is isomorphic to the frame F = (W, R) with
R = S ∪ {(−∞, −∞)} ∪ (W × {∞}).
5.3.5 An operation on a boolean algebra is called 2-additive if it satisﬁes
f (x + y + z) = f (x + y) + f (x + z) + f (y + z).
Prove an analog of the Jónsson-Tarski Theorem for boolean algebras augmented with 2-
additive operations.
5.4 Duality Theory
We now know how to build frames from algebras and algebras from frames in
ways that preserve crucial logical properties. But something is missing. Modal
logicians rarely study frames in isolation: rather, they are interested in how to con-
struct new frames from old using bounded morphisms, generated subframes, and
disjoint unions. And algebraists adopt an analogous perspective: they are inter-
ested in relating algebras via such constructions as homomorphisms, subalgebras,
and direct products. Thus modal logicians work in one mathematical universe, and
algebraists in another, and it is natural to ask whether these universes are system-
atically related. They are, and duality theory studies these links.
In this section we will do two things. First, we will introduce the basic dualities
that exist between the modal and algebraic universes. Second, we will demonstrate
that these dualities are useful by proving two major theorems of modal logic. We
assume that by this stage the reader has picked up the basic deﬁnitions and re-
sults concerning the algebraic universe (and in particular, what homomorphisms,
subalgebras, and direct products are). If not, check out Appendix B.5.4 Duality Theory
295
Basic duality results
Theorems 5.47 and 5.48 below give a concise formulation of the basic links be-
tween the algebraic and frame-theoretic universes. They are stated using the fol-
lowing notation.
Deﬁnition 5.46 Let τ be a modal similarity type, F and G two τ -frames, and A
and B two boolean algebras with τ -operators. We recall (deﬁne, respectively) the
following notation for relations between these structures:
• F  G for F is isomorphic to a generated subframe of G,
• F
G for G is a bounded morphic image of F,
• A  B for A is isomorphic to a subalgebra of B,
• A
B for B is a homomorphic image of A.
Theorem 5.47 Let τ be a modal similarity type, F and G two τ -frames, and A and
B two boolean algebras with τ -operators.
(i) If F  G, then G+
F+ .
(ii) If F
G, then G+  F+ .
(iii) If A  B, then B+
A+ .
(iv) If A
B, then B+  A+ .
Proof. This follows immediately from Propositions 5.51 and 5.52 below.
Theorem 5.48 Let τ be a modal similarity type, and Fi , i ∈ I, a family of τ -
frames. Then

+
&
'
∼
Fi
F+ .
=
i
i∈I
i∈I
Proof. We deﬁne a map η from the power set of the disjoint union i∈I Wi to the

carrier i∈I P(Wi ) of the product of the family of complex algebras (F+
i )i∈I .
Let X be a subset of i∈I Wi . Clearly, η(X) has to be an element of the set


i∈I P(Wi ). And elements of the set
i∈I P(Wi ) are sequences σ such that
σ(i) ∈ P(Wi ). So it sufﬁces to say what the i-th element of the sequence η(X) is:
η(X)(i) = X ∩ Wi .
We leave it as an exercise to show that η is an isomorphism; see Exercise 5.4.6.
Note that Theorem 5.48 (in contrast to Theorem 5.47) only states a connection in
the direction from frames to algebras. This is because in general


'
&
∼
Ai
(Ai )+ .
=
i∈I
+
i∈I296
5 Algebras and General Frames
The reader is asked to give an example to this effect in Exercise 5.4.1.
In order to prove Theorem 5.47, the reader is advised to recall the deﬁnitions
of the back and forth properties of bounded morphisms between frames (Deﬁni-
tion 3.13). We also need some terminology for morphisms between boolean alge-
bras with operators.
Deﬁnition 5.49 Let A and A be two BAOs of the same similarity type, and let
η : A → A be a function. We say that η is a boolean homomorphism if η is a
homomorphism from (A, +, −, 0) to (A , + , − , 0 ). We call η a modal homomor-
phism if η satisﬁes, for all modal operators :
η(f(a1 , . . . , aρ() )) = f (ηa1 , . . . , ηaρ() ).
(Here ηai means η(ai ); we will sometimes use this shorthand to keep the notation
uncluttered.) Finally, η is a (BAO-)homomorphism if it is both a boolean and a
modal homomorphism.
In the following deﬁnition, the construction of dual or lifted morphisms is given
(here the word ‘dual’ is not used in the sense of 3 being the dual of 2).
Deﬁnition 5.50 Suppose θ is a map from W to W  ; then its dual, θ+ : P(W  ) →
P(W ) is deﬁned as:
θ + (X  ) = {u ∈ W | θ(u) ∈ X  }.
In the other direction, let A and A be two BAOs, and η : A → A be a map from A
to A ; then its dual is given as the following map from ultraﬁlters of A to subsets
of A:
η+ (u ) = {a ∈ A | η(a) ∈ u }.
The following propositions assert that the duals of bounded morphisms are nothing
but BAO-homomorphisms:
Proposition 5.51 Let F, F be frames, and θ : W → W  a map.
(i) θ+ is a boolean homomorphism.
(ii) mR (θ + (Y1 ), . . . , θ + (Yn )) ⊆ θ + (mR (Y1 , . . . , Yn )), if θ has the forth prop-
erty.
(iii) mR (θ + (Y1 ), . . . , θ + (Yn )) ⊇ θ + (mR (Y1 , . . . , Yn )), if θ has the back prop-
erty.
(iv) θ+ is a BAO-homomorphism from F+ to F+ , if θ is a bounded morphism.
(v) θ+ is surjective, if θ is injective.
(vi) θ+ is injective, if θ is surjective.5.4 Duality Theory
297
Proof. For notational convenience, we assume that τ has only one modal operator,
so that we can write F = (W, R).
(i) (Note that this was Exercise 5.1.1.) As an example, we treat complementa-
tion:
x ∈ θ + (−X  ) iff θ(x) ∈ −X  iff θ(x) ∈
/ X  iff x ∈ θ+ (X  ).
From this it follows immediately that θ+ (−X  ) = −θ + (X  ).
(ii) Assume that θ has the forth property. Then we have
x ∈ mR (θ + (Y1 ), . . . , θ + (Yn ))
=⇒ ∃ y1 , . . . , yn such that θ(yi ) ∈ Yi and Rxy1 . . . yn
=⇒ ∃ y1 , . . . , yn such that θ(yi ) ∈ Yi and R θ(x)θ(y1 ) . . . θ(yn )
=⇒ θ(x) ∈ mR (Y1 , . . . , Yn )
=⇒ x ∈ θ + (mR (Y1 , . . . , Yn )).
(iii) Now suppose x ∈ θ+ (mR (Y1 , . . . , Yn )). Then θ(x) ∈ mR (Y1 , . . . , Yn ).
So there are y1 , . . . , yn in W  with yi ∈ Yi and R θ(x)y1 . . . yn . As θ has the back
property, there are y1 , . . . , yn ∈ W with θ(yi ) = yi for all i, and Rxy1 . . . yn . But
then yi ∈ θ + (Yi ) for every i, so x ∈ mR (θ + (Y1 ), . . . , θ + (Yn )).
(iv) This follows immediately from items (i), (ii) and (iii).
(v) Assume that θ is injective, and let X be a subset of W . We have to ﬁnd a
subset X  of W  such that θ+ (X  ) = X. Deﬁne
θ[X] := {θ(x) ∈ W  | x ∈ X}.
We claim that this set has the desired properties. Clearly X ⊆ θ+ (θ[X]). For the
other direction, let x be an element of θ+ (θ[X]). Then by deﬁnition, θ(x) ∈ θ[X],
so there is a y ∈ X such that θ(x) = θ(y). By the injectivity of θ, x = y. So
x ∈ X.
(vi) Assume that θ is surjective, and let X and Y  be distinct subsets of W  .
Without loss of generality we may assume that there is an x such that x ∈ X  and
x ∈ Y  . As θ is surjective, there is an x in W such that θ(x) = x . So x ∈ θ + (X  ),
but x ∈ θ+ (Y  ). So θ(X  ) = θ(Y  ), whence θ+ is injective.
Going in the opposite direction, that is, from algebras to relational structures, we
ﬁnd that the duals of BAO-homomorphisms are bounded morphisms:
Proposition 5.52 Let A, A be boolean algebras with operators, and η a map from
A to A .
(i) If η is a boolean homomorphism, then η+ maps ultraﬁlters to ultraﬁlters.
(ii) If f  (η(a1 ), . . . , η(an )) ≤ η(f (a1 , . . . , an )), then η+ has the forth prop-
erty.298
5 Algebras and General Frames
(iii) If f  (η(a1 ), . . . , η(an )) ≥ η(f (a1 , . . . , an )) and η is a boolean homomor-
phism, then η+ has the back property.
(iv) If η is a BAO-homomorphism, then η+ is a bounded morphism from A+ to
A+ .
(v) If η is an injective boolean homomorphism, then η+ : Uf A → Uf A is
surjective.
(vi) If η is a surjective boolean homomorphism, then η+ : Uf A → Uf A is
injective.
Proof. Again, without loss of generality we assume that τ has only one modal
operator, so that we can write A = (A, +, −, 0, f ).
(i) This item is left as Exercise 5.4.2.
(ii) Suppose that Qf  u u1 . . . un holds between some ultraﬁlters u , u1 , . . . , un
of A . To show that A+ |= Qf η+ u η+ u1 . . . η+ un , let a1 , . . . , an be arbitrary
elements of η+ u1 , . . . , η+ un respectively. Then, by deﬁnition of η+ , ηai ∈
ui , so Qf u u1 . . . un gives f  (ηa1 , . . . , ηan ) ∈ u . Now the assumption yields
ηf (a1 , . . . , an ) ∈ u , as ultraﬁlters are upward closed. But then f (a1 , . . . , an ) ∈
η+ u , which is what we wanted.
(iii) This item is left as Exercise 5.4.2.
(iv) This follows immediately from items (i), (ii) and (iii).
(v) Assume that η is injective, and let u be an ultraﬁlter of A. We want to follow
the same strategy as in Proposition 5.51(v), and deﬁne
η[u] := {η(a) | a ∈ u}.
The difference with the proof of Proposition 5.51(v) is that here, η+ (η[u]) may not
be deﬁned. The reason for this is that, in general, η[u] will not be upwards closed
and hence, not an (ultra)ﬁlter, while η+ is deﬁned only for ultraﬁlters. Therefore,
we deﬁne
F  := {a | η(a) ≤ a for some a ∈ u }.
Clearly, η[u] ⊆ F  . We will ﬁrst show that F  is a proper ﬁlter of A (note that
the clauses (F 1)–(F 3) which deﬁne ﬁlters are given in Deﬁnition 5.34). For (F 1),
observe that 1 ∈ u, so η(1) = 1 ∈ η[u] ⊆ F  . For (F 2), assume a , b ∈ F  . Then
there are a, b in u such that ηa ≤ a and ηb ≤ b . It follows that η(a · b) = ηa · ηb ≤
a · b ∈ η[u]; hence, a · b ∈ F  since a · b ∈ u. This shows that F  is closed under
taking meets. It is trivial to prove (F 3), that is, that F is upwards closed. Finally,
in order to show that F  is proper, suppose that 0 ∈ F  . Then 0 = ηa for some
a ∈ u; as 0 = η(0), injectivity of η gives that 0 = a, and hence, 0 ∈ u. But then
u is not an ultraﬁlter.
By the Ultraﬁlter Theorem 5.38, F  can be extended to an ultraﬁlter u . We claim
that u = η+ (u ). First let a be in u, then ηa ∈ η[u] ⊆ u , so a ∈ η+ (u ). This5.4 Duality Theory
299
shows that u ⊆ η+ (u ). For the other inclusion, it sufﬁces to show that a ∈ η+ (u )
if a ∈ u; we reason as follows:
a ∈ u
=⇒
=⇒
=⇒
=⇒
=⇒
−a ∈ u
−ηa = η(−a) ∈ η[u]
−η(a) ∈ u
ηa ∈ u
a ∈ η+ (u ).
(vi) Similar to Proposition 5.51, item (vi); see Exercise 5.4.2.
Readers familiar with category theory will have noticed that the operation (·)+ is a
functor from the category of τ -frames with bounded morphisms to the category of
boolean algebras with τ -operators, and vice versa for (·)+ . This categorial perspec-
tive is implicit in what follows, but seldom comes to the surface. In the remainder
of the section we will see how our algebraic perspective on modal logic that we
have developed can be applied.
Applications
In this subsection we tie a number of threads together and show how to use the
duality between frames and algebras to give very short proofs of some major theo-
rems of modal logic.
Our ﬁrst example shows that all the results given in Theorem 3.14 on the preser-
vation of modal validity under the fundamental frame operations fall out as simple
consequences of well-known preservation results of universal algebra, namely that
equational validity is preserved under the formation of subalgebras, homomorphic
images and products of algebras.
Proposition 5.53 Let τ be a modal similarity type, φ a τ -formula and F a τ -frame.
Then
(i) If G is a bounded morphic image of F, then G  φ if F  φ.
(ii) If G is a generated subframe of F, then G  φ if F  φ.
(iii) If F is the disjoint union of a family {Fi | i ∈ I}, then F  φ if for every
i ∈ I, Fi  φ.
(iv) If ue F  φ, then F  φ.
Proof. We only prove the ﬁrst part of the proposition, leaving the other parts as
exercises for the reader.
Assume that F
G, and F  φ. By Proposition 5.24, we have F+ |= φ ≈ ,
and by Theorem 5.47, G+ is a subalgebra of F+ . So by the fact that equational
validity is preserved under taking subalgebras, we obtain that φ ≈  holds in G+ .
But then Proposition 5.24 implies that G  φ.300
5 Algebras and General Frames
Our second example is a simple proof of the Goldblatt-Thomason Theorem, which
gives a precise structural characterization of the ﬁrst-order deﬁnable classes of
frames which are modally deﬁnable. We discussed this result in Chapter 3, and
gave a proof which drew on the tools of ﬁrst-order model theory (see Theorem 3.19
in Section 3.8). As we will now see, there is also an algebraic way of viewing the
theorem: it is a more or less immediate corollary of Birkhoff’s Theorem (see Ap-
pendix B) identifying equational classes and varieties. The version we prove here
is slightly stronger than Theorem 3.19, since it applies to any class of frames that
is closed under taking ultrapowers.
Theorem 5.54 (Goldblatt-Thomason Theorem) Let τ be a modal similarity type,
and let K be a class of τ -frames that is closed under taking ultrapowers. Then K
is modally deﬁnable if and only if it is closed under the formation of bounded
morphic images, generated subframes, and disjoint unions, and reﬂects ultraﬁlter
extensions.
Proof. The left to right direction is an immediate corollary of the previous propo-
sition. For the right to left direction, let K be any class of frames satisfying the
closure conditions given in the theorem. It sufﬁces to show that any frame F vali-
dating the modal theory of K is itself a member of K.
Let F be such a frame. It is not difﬁcult to show that Proposition 5.24 implies
that F+ is a model for the equational theory of the class CmK. It follows by
Birkhoff’s Theorem (identifying varieties and equational classes) that F+ is in the
variety generated by CmK, so F+ is in HSPCmK. In other words, there is a
family (Gi )i∈I of frames in K, and there are boolean algebras with operators A
and B such that

(i) B is the product i∈I G+
i of the complex algebras of the Gi ,
(ii) A is a subalgebra of B, and
(iii) F+ is a homomorphic image of A.
By Theorem 5.48, B is isomorphic to the complex algebra of the disjoint union G
of the family (Gi )i∈I :
+

&
+
∼G =
B=
Gi
.
i∈I
As K is closed under taking disjoint unions, G is in K.
Now we have the following picture: F+  A  G+ . By Theorem 5.47 it
follows that
(F+ )+  A+  (G+ )+ .
Since K is closed under ultrapowers, Theorem 3.17 implies that (G+ )+ = ue G is5.4 Duality Theory
301
in K. As K is closed under the formation of bounded morphic images and generated
subframes, it follows that A+ and ue F = (F+ )+ (in that order) are in K. But then
F itself is also a member of K, since K reﬂects ultraﬁlter extensions.
For our third example, we return to the concept of canonicity. We will prove an
important result and mention an intriguing open problem, both having to do with
the relation between canonical varieties and ﬁrst-order deﬁnable classes of frames.
Both the result and the open problem were mentioned in Chapter 4 (see Theo-
rem 4.50 and the surrounding discussion), albeit in a slightly weaker form. To link
the earlier statements with the versions discussed here, simply observe that any
elementary class of frames is closed under the formation of ultraproducts.
First we need the following deﬁnition.
Deﬁnition 5.55 Let τ be modal similarity type, and K be a class of τ -frames. The
variety generated by K (notation: VK ) is the class HSPCmK.
Theorem 5.56 Let τ be modal similarity type, and K be a class of τ -frames which
is closed under ultraproducts. Then the variety VK is canonical.
Proof. Assume that the class K of τ -frames is closed under taking ultraproducts.
We will ﬁrst prove that the class HSCmK is canonical. Let A be an element of
this class; that is, assume that there is a frame F in K and an algebra B such that
A  B  F+ .
It follows from Theorem 5.47 that
EmA  EmB  EmF+ = (ue F)+ .
(5.27)
From Theorem 3.17 we know that ue F is the bounded morphic image of some
ultrapower G of F. Note that G is in K, by assumption. Now Theorem 5.47 gives
(ue F)+  G+ .
(5.28)
Since G+ is in CmK, (5.27) and (5.28) together imply that EmA is in HSCmK.
Hence this class is canonical.
To prove that the variety generated by K is canonical, we need an additional fact.
Recall that according to Proposition 3.63, the ultrapower of a disjoint union can be
obtained as a bounded morphic image of a disjoint union of ultraproducts.
Now assume that A is in VK = HSPCmK. In other words, assume there is a
family {Fi | i ∈ I} of frames in K and an algebra B such that
'
AB
F+
i .
i∈I

To prove that EmA is in VK , it sufﬁces to show that Em( i∈I F+
i ) is in SPCmK302
5 Algebras and General Frames
– the remainder of the proof is as before. Let F be the frame

Theorem 5.48, F+ ∼
= i∈I F+
i . Hence, by Theorem 5.47:


'
+
∼
Em
F
= ((F+ )+ )+ = (ue F)+ .
i∈I Fi , then by
i
(5.29)
i∈I
By Theorem 3.17, there is an ultrapower G of F such that G
ue F. Now we
apply Proposition 3.63, yielding a frame H such that (i) H is a disjoint union of
ultraproducts of frames in K and (ii) H
G. Putting these observations together
we have ue F  G  H. Hence, by Theorem 5.47:
(ue F)+  G+  H+ .
(5.30)
Note that H is a disjoint union of frames in K, since K is closed under taking
ultraproducts. This implies that H+ is in PCmK. But then it follows from (5.29)

and (5.30) that Em( i∈I F+
i ) is in SPCmK, which is what we needed.
Example 5.57 Consider the modal similarity type {◦, ⊗, 1’} of arrow logic, where
◦ is binary, ⊗ is unary and 1’ is a constant. The standard interpretation of this
language is given in terms of the squares (cf. Example 1.24). Recall that the square
SU = (W, C, R, I) is deﬁned as follows:
W=U × U,
C((u, v), (w, x), (y, z))iffu = w and v = z and x = y,
R((u, v), (w, x))iffu = x and v = w,
I(u, v)iffu = v.
It may be shown that the class SQ of (isomorphic copies of) squares is ﬁrst-order
deﬁnable in the frame language with predicates C, R and I. Therefore, Theo-
rem 5.56 implies that the variety generated by SQ is canonical. This variety is well
known in the literature on algebraic logic as the variety RRA of Representable Re-
lation Algebras. See Exercise 5.4.5.
Rephrased in terminology from modal logic, Theorem 5.56 boils down to the fol-
lowing result.
Corollary 5.58 Let τ be a modal similarity type, and K be a class of τ -frames
which is closed under ultraproducts. Then the modal theory of K is a canonical
logic.
We conclude the section with the foremost open problem in this area: does the
converse of Theorem 5.56 holds as well?5.5 General Frames
303
Open Problem 2 Let τ be modal similarity type, and V a canonical variety of
boolean algebras with τ -operators. Is there a class K of τ -frames, closed under
taking ultraproducts, such that V is generated by K?
Exercises for Section 5.4
5.4.1 Consider a countably inﬁnite collection (A i )i∈I of ﬁnite algebras that are non-trivial,
that is, of size at least 2.

(a) Show that the product i∈I Ai has uncountably many ultraﬁlters.
(b) Show that the ultraﬁlter frame of a ﬁnite algebra is ﬁnite, and that hence, the disjoint
union i∈I (Ai)+ is countable.

∼
(c) Conclude that
i∈I Ai + =
i∈I (Ai )+ .
5.4.2 Prove Proposition 5.52(i), (iii) and (vi). Prove (iii) ﬁrst for unary operators; for the
general case, see the proof of the Jónsson-Tarski Theorem for inspiration.
5.4.3 Prove or disprove the following propositions:
(a) For any two boolean algebras with operators A and B: A + ∼
= B.
= B+ only if A ∼
(Hint: ﬁrst consider the question for plain boolean algebras, thinking of specimens
like the ones occurring in Exercise 5.2.3 and Exercise 5.3.3.)
(b) For any two frames F and G: F + ∼
= G.
= G+ only if F ∼
5.4.4 Consider the frames F = (X, R) and G = (Y, S) given by
X=N
R = {(x, y) ∈ X × X | x = y}
Y = N ∪ {∞}
S = {(x, y) ∈ Y × Y | x = y} ∪ {(∞, ∞)}.
(a) Show that F is not a bounded morphic image of G.
(b) Show that on the other hand, F + can be embedded in G + (that is, deﬁne an injective
homomorphism η: F +  G+ ).
5.4.5 Show that the class SQ of (isomorphic copies of) square arrow frames is ﬁrst-order
deﬁnable. See Example 5.57.
5.4.6 Show that the embedding η used in the proof of Theorem 5.48 is an isomorphism.
5.5 General Frames
Although the algebraic semantics for modal logic has the nice property that there
is a fundamental completeness result (Theorem 5.27), many modal logicians still
prefer frame-based semantics, either because they ﬁnd it more intuitive, or because
frames are the structures in which they take an (application-driven) interest. In
this (and the following) section we will discuss an intermediate semantics which
in a sense uniﬁes relational and algebraic semantics. As we will see below, a
general frame is an ordinary frame and a boolean algebra with operators rolled
into one. The nice thing about general frames is that we can prove a fundamental304
5 Algebras and General Frames
completeness theorem for modal logic and general frames – and modal semantics
based on general frames is almost as intuitive as the familiar relational semantics.
Although we have already met general frames (we brieﬂy introduced them in
Section 1.4, and used them when we studied frame incompleteness in Section 4.4),
we have not yet discussed them systematically. We will now put that right. We will
reintroduce them, discuss some important classes of general frames, pin down the
relationship between general frames, frames and boolean algebras with operators,
and brieﬂy discuss them from a topological perspective.
Here is how general frames are deﬁned for an arbitrary similarity type τ :
Deﬁnition 5.59 (General Frame) Let τ be a modal similarity type. A general
τ -frame is a pair g = (F, A) such that F = (W, R)∈τ is a τ -frame, and A is
(the carrier of) a complex algebra over F. That is, A is a non-empty collection of
subsets of W which is closed under the boolean operations and under the modal
operation mR (X1 , . . . , Xn ) for each  ∈ τ .
A valuation V on F is called admissible for g if for each proposition letter p,
V (p) is an admissible subset of W , that is, an element of A. A model based on
a general frame is a triple (F, A, V ) where (F, A) is a general frame and V is an
admissible valuation for (F, A). Truth in such a model is deﬁned in the obvious
way, that is, as if we were talking about the model (F, V ).
Convention 5.60 To avoid confusion, in this section we will use the term ‘Kripke
frame’ when talking about (ordinary) frames.
It is easy to verify that the closure conditions mentioned in Deﬁnition 5.59 en-
sure that if V is an admissible valuation on a general frame, then the set V (φ) is
admissible for every formula φ. Conversely, every model gives rise to a general
frame.
Example 5.61 Given a model M = (F, V ), it is obvious that the collection
AM = {V (φ) | φ a modal formula }
is closed under the boolean operations and under each mR . Hence the structure
(F, AM) is a general frame.
Note that we can apply this technique to the canonical model McΛ of any normal
modal logic Λ. It follows from the Truth Lemma (Lemma 4.21) that the resulting
structure (FcΛ , AMcΛ ) is isomorphic to the canonical general frame fcΛ which is
deﬁned as
fc = (Fc , {φ | φ a formula }),
(5.31)
Λ
Λ
where φ is the set of maximal consistent sets Γ such that φ ∈ Γ .uu
5.5 General Frames
..
.uv2
..
..
. >v
.
u1
*
vu
- vu0
*
ju
w
-u
w0
ju
..
..
1
. ~w
.
u
.. w2
.
305
ju
* x
Fig. 5.1.
The notions of validity and semantic consequence of classes of general frames are
deﬁned in the expected way:
Deﬁnition 5.62 Let g be a general frame. A formula φ is valid on g if φ holds in
every state of g under every admissible valuation V ; a similar deﬁnition holds for
sets of formulas and classes of general frames.
For a set of formulas, in particular for a normal modal logic Λ, a general frame
is called a Λ-frame if Λ is valid on the frame.
Now, let K be a class of general frames, Σ a set of formulas and φ a formula.
We say that φ is a semantic consequence of Σ over K if for every general frame
g in K, every admissible valuation V on g and every state s in g, we have that
(g, V ), s  Σ implies (g, V ), s  φ.
The following example shows that a formula may be valid on a general frame,
while it is not valid on the underlying Kripke frame:
Example 5.63 Consider the following Kripke frame C = (C, R). Its set C of
states is given as C = {u, v, w, x} ∪ {vn , wn | n ∈ ω}, while the accessibility
relation R is deﬁned as follows: Ruv, Ruw, Rvvn and Rwwn (for all n), Rvn x
and Rwn x (for all n), and Rxx; see Figure 5.1.
We leave it as an exercise to verify that the pair c = (C, F ) is a general frame,
where F is the collection of all ﬁnite and co-ﬁnite subsets of C. We claim that
c  32p → 23p, while C  32p → 23p. Let us ﬁrst prove the latter: consider
the valuation V given by V (p) = {vn | n ∈ N}. Now, from (C, V ), v  2p we
derive (C, V ), u  32p, but (C, V ), u  23p, as (C, V ), w  3p.
To prove that c  32p → 23p, it sufﬁces to look at u (why?). Suppose that for
some admissible valuation V , 32p holds at u. Without loss of generality we may
assume that (c, V ), v  2p, so p holds at all vi . Then V (p) is not ﬁnite and since306
5 Algebras and General Frames
V (p) must be admissible, it follows from the deﬁnition of F that V (p) is co-ﬁnite.
Hence there are (co-ﬁnitely many) wi with (c, V ), wi  p. But then 3p holds at w
and thus 23p at u.
And now for the promised general completeness result: general frames share with
boolean algebras with operators the property of providing an adequate semantics
for all normal modal logics.
Theorem 5.64 Let Λ be a normal modal logic. Then Λ is sound and strongly
complete with respect to the class of general Λ-frames.
Proof. As usual, the soundness proof is rather trivial and is left to the reader.
For completeness, consider the canonical frame fcΛ as deﬁned in (5.31) in Ex-
ample 5.61. It is easy to verify that fcΛ  Λ (see Exercise 5.5.4). Now assume
that Σ Λ φ. It follows that the set Σ ∪ {¬φ} is Λ-consistent. By deﬁnition
of the canonical frame and the Truth Lemma, there is a state s of fcΛ such that
(fcΛ , V c ), s  Σ ∪ {¬φ}. Since the canonical valuation V c is admissible, this
means that we have falsiﬁed the claim that φ is a semantical consequence of Σ on
the class of general Λ-frames.
Properties of general frames
The following deﬁnition singles out some important properties and classes of gen-
eral frames.
Deﬁnition 5.65 (Properties of General Frames) Let τ be a modal similarity
type, and assume that g = (F, A) is a general τ -frame, with F being the Kripke
τ -frame (W, R)∈τ . Then g is called
differentiated if for all s, t in W :
s = t iff ∀a ∈ A (s ∈ a ⇐⇒ t ∈ a),
tight if for all  ∈ τ (assume that ρ() = n) and for all s, s1 , . . . , sn in W :

Rss1 . . . sn iff ∀a1 , . . . , an ∈ A (( i si ∈ ai ) ⇒ s ∈ mR (a1 , . . . , an )),

compact if A0 = ∅ for every subset A0 of A which has the ﬁnite intersection
property,
reﬁned if g is differentiated and tight,
descriptive if g is reﬁned and compact,
full if every subset of W is admissible, that is, if A = P(W ), and
discrete if every singleton is admissible, that is, if {s} ∈ A for every s ∈ W .5.5 General Frames
307
Convention 5.66 When discussing general frames we will usually drop the ad-
jective ‘general’ when it is clear that we are talking about general frames and not
about Kripke frames. For instance, ‘a descriptive frame’ is short for: ‘a descriptive
general frame.’
Let us try to develop some intuitions concerning the notions deﬁned above by con-
sidering a number of examples.
The best way to understand the concept of differentiation is by observing that
a general frame is differentiated if and only if for every distinct pair of states s
and t there is an admissible set a witnessing this difference in the sense that s ∈
a, t ∈ a. Likewise (now we conﬁne ourselves to the basic similarity type), a
general frame is tight if and only if for every state s and every state t which is
not accessible from s, there is an admissible set a witnessing this in the sense that
t ∈ a, s ∈ mR3 (a). Thus both differentiation and tightness are an indication that
there are many admissible sets. On the other hand, compactness means that there
are a multitude of states, the basic intuition being as follows. Consider a collection
A0 of admissible sets; if A0 is not ﬁnitely contradictory (in the sense that there is a
state in the intersection of any ﬁnite subcollection of A0 ), then there is some state
belonging to every set in A0 . The other deﬁnitions speak for themselves.
The notions of differentiation and tightness are independent, as is shown in the
following example:
Example 5.67 Consider the structure h = (N, ≡2 , A), where N is the set of natural
numbers, m ≡2 n iff m − n is even, and A is the set {∅, N, E, O}, such that E and
O are the sets of even and odd numbers, respectively. We leave it to the reader to
check that this is indeed a general frame, and that h is tight but not differentiated;
see Exercise 5.5.6.
Conversely, let g be the structure (W, >, B) where W is the set N ∪ {ω} and B
is given by
B = {b ⊆ W | b is ﬁnite and ω ∈ b} ∪ {b ⊆ W | b is co-ﬁnite and ω ∈ b}.
It is easy to see that m> (b) is co-ﬁnite and ω ∈ m> (b) for every non-empty b ⊆ W .
From this observation it is easy to deduce that g is a general frame. It should also
be obvious that g is differentiated: for any two non-identical states s and t, at least
one, say s, belongs to N; but then the singleton {s} is admissible, and s ∈ {s}, but
t ∈ {s}.
Now suppose that g is tight. Consider an arbitrary co-ﬁnite set a such that ω ∈ a.
Then a = ∅, whence the set m> (a) is co-ﬁnite as well, and hence, ω ∈ m> (a).
But since a was arbitrary, by tightness we may infer that ω > ω, which is clearly
not the case. It follows that g is not tight.5 Algebras and General Frames
308
An example of a reﬁned frame is given by the structure c of Example 5.63. In fact,
its reﬁnedness follows from the fact that c is discrete.
Proposition 5.68 Discrete frames are reﬁned.
Proof. We only treat tightness and conﬁne ourselves to the basic similarity type.
Let g = (W, R, A) be a discrete frame. Assume that the state t is not a successor
of the state s. Then s ∈ mR ({t}), while obviously t ∈ {t}. By deﬁnition of
discreteness, {t} is admissible.
The converse of Proposition 5.68 does not hold. Examples of reﬁned frames that
are not discrete are provided by canonical general frames, cf. Proposition 5.69
below.
Of the classes mentioned in Deﬁnition 5.65, the class of descriptive frames is
the most important one. One reason for this is that in a certain (category-theoretic)
sense, descriptive general frames and boolean algebras with operators are the same
mathematical objects. For instance, below we will see that every boolean alge-
bra with operators can be represented as a descriptive general frame. Let us ﬁrst
consider a particular example of this.
Proposition 5.69 Let τ be a modal similarity type, and Λ a normal modal τ -logic.
Then fcΛ is a descriptive general frame.
Proof. To show that fcΛ is differentiated, assume that Γ and Δ are distinct maximal
Λ-consistent sets of formulas. In other words, there is a formula γ such that γ ∈ Γ ,
γ ∈ Δ. But then Γ ∈ γ
, while Δ ∈ γ
. It is almost as easy to prove tightness –
simply use the deﬁnition of the canonical accessibility relation.
For compactness, assume that S := {
σ | σ ∈ Σ} is a collection of admissible
sets and that it has the ﬁnite intersection property. It follows that Σ is consistent, for
suppose otherwise; then there are σ1 , . . . , σn ∈ Σ such that Λ (σ1 ∧ · · · ∧ σn ) →
⊥. This implies that there is no maximal Λ-consistent Γ such that σi ∈ Γ for all
i ≤ n. But then σ
1 ∩ · · · ∩ σ
n = ∅, which contradicts our assumption on S.
But if Σ is consistent, it can be extended to a maximal Λ-consistent set Σ+ . It

is almost immediate that Σ+ ∈ {
σ | σ ∈ Σ}; this obviously bears witness to the
fact that S has a non-empty intersection.
The following example shows that the condition of compactness really adds to the
deﬁnition of a descriptive frame.
Example 5.70 In this example we will exhibit a general frame h = (W, R, A) that
is reﬁned but not descriptive. To deﬁne W , let S and T denote the sets S = {sn |
n ∈ N} and T = {tn | n ∈ N}, respectively. Now, put
W
= {r, ∞} ∪ S ∪ T,5.5 General Frames
309
R = {(r, ∞)} ∪ {(r, sn ), (sn , sn ), (sn , tn ) | n ∈ N}.
The set A is deﬁned as follows: a subset a of W is admissible if either a ∩ T is
ﬁnite and ∞ ∈ a, or a ∩ T is co-ﬁnite and ∞ ∈ a.
We will not give a detailed proof that this h is indeed a general frame. We will
only observe here that for all a ∈ A, the set mR (a) satisﬁes mR (a) ∩ T = ∅ and
∞ ∈ mR (a), whence it is admissible as well.
To show that h is reﬁned, we ﬁrst consider differentiation. Let v and w be
different states of W . One of them, say v, must be different from ∞. But then
the set {v} is admissible, and w ∈ {v}. For tightness, assume that Rvw does not
hold, for some states v and w. We will deﬁne an admissible set a such that w ∈ a
while v ∈ mR (a). Now, if w = ∞, then the set a = {w} sufﬁces, so assume that
w = ∞. Then clearly, v = r. Again distinguish cases.
First assume that v ∈ {∞} ∪ T ; in this case, take a = {∞} ∪ T , then mR (a) =
{r} ∪ S, so indeed, v ∈ mR (a). The only case that is left is where w = ∞ and
v = sn for some natural number n. Now consider the set a = ({∞} ∪ T ) \ {tn }.
Since tn is the only successor of sn , this gives sn ∈ mR (a).
Finally, we have to show that h is not compact. But this is rather easy; consider
for instance the set of co-ﬁnite subsets of S. This set has the ﬁnite intersection
property, but there is no state in W that belongs to all co-ﬁnite subsets of S.
Operations on general frames
In this subsection we look at the relation between ordinary frames, general frames
and boolean algebras with operators. First, however, we adapt familiar notions
from the theory of Kripke frames to the setting of general frames.
Deﬁnition 5.71 Let g = (F, A) and g = (F , A ) be two general frames. Assume
 )

that F = (W, R)∈τ and F = (W  , R
∈τ . A map θ : W → W is a bounded
morphism between g and g (notation: θ : g → g ) if θ is a bounded morphism
between the frames F and F such that
θ −1 (a ) ∈ A for all a ∈ A .
(5.32)
Such a bounded morphism θ is called an embedding if it is injective and satisﬁes
for all a ∈ A there is an a ∈ A such that θ[a] = θ[W ] ∩ a .
(5.33)
Here θ[a] is deﬁned as the set {θ(s) | s ∈ a}. We write g  g to denote that g
can be embedded in g .
The general frame g is called a bounded morphic image of g (notation: g
g )

if there is a surjective bounded morphism from g to g . Two general frames g and
g are isomorphic if there is a surjective embedding θ : g → g .
Assume that for all i ∈ I, gi is the general frame (Fi , Ai ); we deﬁne the disjoint310
5 Algebras and General Frames
union i gi of this family (gi )i∈I as the general frame ( i Fi , A) where A consists
of those subsets a ⊆ i Wi that satisfy a ∩ Wi ∈ Ai for all i ∈ I.
As a special example of an embedding, consider two general frames g = (F, A)
and g = (F , A ) such that F is a generated subframe of F . Then the identity
inclusion ι : W → W  is a bounded morphism from F into F , but ι is only a
bounded morphism from g to g if a ∩ W ∈ A for all a ∈ A . For ι to be an
embedding, condition (5.33) requires that for all a ∈ A, there is an a ∈ A such
that a = W ∩ a ; in other words, every admissible set a ∈ A must be the ‘W -part’
of an admissible set a ∈ A . Finally, it is not difﬁcult to see that an isomorphism
between g = (F, A) and g = (F , A ) is just an isomorphism θ between F and F
such that θ−1 is an isomorphism between the complex algebras with carriers A and
A .
As with Kripke frames, the constructions deﬁned in Deﬁnition 5.71 are truth-
preserving. The proof of Proposition 5.72 below is straightforward and left to the
reader.
Proposition 5.72 Let τ be a modal similarity type, and φ a τ -formula.
(i) Let {gi | i ∈ I} be a family of general frames. Then
every i in I.
(ii) Assume that g  g. Then g  φ if g  φ.
(iii) Assume that g
g . Then g  φ if g  φ.
gi  φ if gi  φ for
Now we deﬁne a number of operations that enable the construction of general
frames out of Kripke frames or out of BAOs, and conversely. The reader is advised
to recall from earlier sections of this chapter the deﬁnition of the complex algebra
F+ of a frame F, and the ultraﬁlter frame A+ of an algebra A.
Deﬁnition 5.73 Let τ be a modal similarity type, and let g = (W, R, A)∈τ be
a general τ -frame. The underlying τ -frame of g is given by g = (W, R)∈τ . It
follows from the closure conditions on A that the structure
g∗ = (A, ∪, −, ∅, mR )∈τ
is a boolean algebra with τ -operators; this algebra is called the underlying boolean
algebra with τ -operators of g.
Conversely, the full τ -frame of a τ -frame F = (W, R)∈τ is given by
F = (F, P(W )).
And ﬁnally, the general ultraﬁlter frame of a BAO A = (A, +, −, 0, f)∈τ is
deﬁned as
a | a ∈ A}),
A∗ = (A+ , {5.5 General Frames
311
where 
a ⊆ Uf A is deﬁned as the set of ultraﬁlters u such that a ∈ u:

a = {u ∈ Uf A | a ∈ u}.
There are many obvious connections between the operations (·)+ , (·)+ , (·) , (·) ,
(·)∗ and (·)∗ . We list a few of these in the next proposition, and invite the reader to
ﬁnd more.
Proposition 5.74 Let τ be a modal similarity type, and let F, g and A be a Kripke
τ -frame, a general τ -frame and a boolean algebra with τ -operators, respectively.
Then
(i) (F ) = F,
(ii) (F )∗ = F+ ,
(iii) (A∗ ) = A+ ,
(iv) (g ) = g if and only if g is full.
Next we devote our attention to the relation between BAOs and general frames. The
following theorem is a counterpart of Proposition 5.24 for general frames.
Theorem 5.75 Let τ be a modal similarity type, and let g and A be a general
τ -frame and a boolean algebra with τ -operators, respectively. Then for every τ -
formula φ:
gφiffg∗ |= φ ≈ ,
A |= φ ≈ iffA∗  φ.
We omit the relatively easy proof of Theorem 5.75. Note however, that the theorem
actually states something stronger than Proposition 5.24, namely that truth is also
preserved when going from an algebra to its associated general frame. The point is
that we may infer from A |= φ ≈  that A∗  φ because on A∗ only admissible
valuations over the Kripke frame A+ are allowed. The implication ‘if A |= φ ≈ ,
then A+  φ’ only holds for canonical formulas φ (we will come back to this point
in the next section).
The following theorem substantiates our earlier claim that BAOs and descriptive
general frames are really the same mathematical objects.
Theorem 5.76 Let τ be a similarity type, and let g and A be a general τ -frame
and a boolean algebra with τ -operators, respectively. Then
(i) A∗ is a descriptive general frame,
(ii) (A∗ )∗ ∼
= A,
∗
∼
(iii) (g )∗ = g if and only if g is descriptive.5 Algebras and General Frames
312
Proof. For notational convenience, we assume that τ has only one modal operator
, say, of arity n.
(i) This part of the proof is more or less the same as the proof that every canonical
general frame is descriptive (see Proposition 5.69).
(ii) Let A = (A, +, −, f ) be a boolean algebra with operator. Then A∗ is a
general frame whose underlying Kripke frame is of the form (Uf A, Qf ), while the
admissible sets are of the form 
a, where a ∈ A. Hence, the carrier of the algebra
(A∗ )∗ consists of all elements 
a, and its operator is of the form mQf . (For the
deﬁnition of Q and m we refer to Deﬁnitions 5.40 and 5.21, respectively). Clearly,
it sufﬁces to show that the map r : A → P(Uf A) given by
r : a → 
a
is a BAO-isomorphism. But it follows from the proof of Theorem 5.43 that r is an
injective homomorphism, and surjectivity is immediate by the deﬁnitions.
(iii) The ‘only if’ direction follows immediately from item (i). For the other
direction, assume that g = (W, R, A) is a descriptive frame. For each state s in W ,
deﬁne Us to be the set of admissible sets a such that s ∈ a. We claim that these
sets constitute precisely the set of ultraﬁlters of g∗ , that is,
{Us | s ∈ W } = Uf g∗ .
(5.34)
The inclusion ‘⊆’ is obvious. For the other inclusion, let u be an arbitrary ultra-
ﬁlter of the BAO g∗ , or, to be more precise, of the boolean algebra (A, ∪, −, ∅).
Since ultraﬁlters are closed under intersection and never contain the empty set, it
follows that u has the ﬁnite intersection property. By compactness, there is a state

s such that s ∈ u. This implies u ⊆ Us ; but since Us is also an ultraﬁlter of
(A, ∪, −, ∅), we obtain that u = Us . This proves (5.34).
Now consider the general frame (g∗ )∗ . Since its states are the ultraﬁlters of g∗ ,
(5.34) implies that the map θ given by θ : s → Us is a map from the universe W
of g onto the universe Uf g∗ of (g∗ )∗ . Injectivity follows from differentiation of g.
Hence, the map θ : W → Uf g∗ is a bijection.
We will show that θ is an isomorphism between general frames. Let R denote
the accessibility relation of  in (g∗ )∗ . Unraveling the deﬁnition of R , we ﬁnd
that for ultraﬁlters u, u1 , . . . , un we have
(
)
R uu1 . . . un iff ∀a1 , . . . , an ∈ A
ai ∈ ui ⇒ mR (a1 , . . . , an ) ∈ u . (5.35)
Now let s, s1 , . . . , sn be arbitrary points of g. By tightness, we have
Rss1 . . . sn iff
∀a1 , . . . , an ∈ A
(
)
si ∈ ai ⇒ s ∈ mR (a1 , . . . , an ) .
(5.36)
But by deﬁnition of θ, we have t ∈ a iff a ∈ θ(t), for all t ∈ W . Hence, from5.5 General Frames
313
(5.36) it follows that
Rss1 . . . sn iff
∀a1 , . . . , an ∈ A
(
)
ai ∈ θ(si ) ⇒ mR (a1 , . . . , an ) ∈ θ(s) . (5.37)
But then we may infer from (5.35) and (5.37) that
Rss1 . . . sn iff R θ(s)θ(s1 ) . . . θ(sn ).
In other words, θ is an isomorphism between the underlying Kripke frames of g
and (g∗ )∗ .
Finally, consider an arbitrary admissible set a of g. We will show that θ(a) is
an admissible set of (g∗ )∗ . By deﬁnition of the operation (·)∗ , a is a member of
the carrier of g∗ ; hence by deﬁnition of the operation (·)∗ , the set 
a := {u ∈
Uf (g∗ ) | a ∈ u} is an admissible set of (g∗ )∗ . We leave it to the reader to verify
that 
a = θ(a) and hence, that a = θ−1 [
a].
As an immediate corollary of Theorems 5.75 and 5.76 we have that every general
frame has an equivalent descriptive general frame.
Theorem 5.77 Let g be a general τ -frame for some similarity type τ . Then (g∗ )∗
is a descriptive general frame equivalent to g; that is, for every τ -formula φ:
g  φ iff (g∗ )∗  φ.
Just as in the case of the basic duality between Kripke frames and BAOs, we can
extend the constructions of Deﬁnition 5.73 to morphisms between algebras or be-
tween general frames.
Deﬁnition 5.78 Let τ be a modal similarity type, and let g = (W , R, A)∈τ
 , A )
and g = (W  , R
∈τ be two general τ -frames. Given a bounded morphism

θ : W → W , its dual θ∗ : A → A is deﬁned by
θ ∗ (a ) = θ −1 [a ] (= {s ∈ W | θs ∈ a }).
Now let A = (A, +, −, 0, f )∈τ and A = (A , + , − , 0 , f )∈τ be two boolean
algebras with τ -operators, and η a map from A to A . Then we deﬁne the dual η∗
of η to be the following map from Uf A to P(A):
η∗ (u ) = η −1 [u ] (= {a ∈ A | ηa ∈ u }).
For the maps deﬁned in Deﬁnition 5.78 we can prove results analogous to Propo-
sitions 5.51 and 5.52.
Proposition 5.79 Let τ be a modal similarity type, and let g and h be two general
τ -frames, and θ a map from the universe of g to the universe of h. Then314
5 Algebras and General Frames
(i) If θ is a bounded morphism, then θ∗ is a BAO-homomorphism from h∗ to
g∗ .
(ii) If θ : g  h, then θ∗ : h∗
g∗ .
(iii) If θ : g
h, then θ∗ : h∗  g∗ .
Proposition 5.80 Let τ be a modal similarity type, and let A and B be two boolean
algebras with τ -operators, and η a map from A to B. Then
(i) If η is a BAO-homomorphism, then η∗ is a bounded morphism from B∗ to
A∗ .
(ii) If η : A  B, then η∗ : B∗
A∗ .
(iii) If η : A
B, then η∗ : B∗  A∗ .
The proofs of Propositions 5.79 and 5.80 are similar to the proofs of Proposi-
tions 5.51 and 5.52. We leave it as an exercise to check where conditions (5.32)
and (5.33) are needed in the proof of Proposition 5.79; see Exercise 5.5.8.
By combining Theorem 5.76 and Propositions 5.79 and 5.80 together, we add
further support to our claim that boolean algebras with operators and descriptive
general frames are really equivalent objects.
Theorem 5.81 Let τ be a modal similarity type, and let g and h be two descriptive
general frames, and A and B two boolean algebras with τ -operators. Then
(i) g  h iff h∗
g∗ ,
∗
(ii) g
h iff h  g∗ ,
(iii) A  B iff B∗
A∗ ,
(iv) A
B iff B∗  A∗ .
For disjoint unions we cannot obtain an equivalence with a simple algebraic oper-
ation in the spirit of Theorem 5.81. The reason for this is that the disjoint union
of an inﬁnite family of frames can never be descriptive itself. This does not cast
a shadow on the duality between descriptive general frames and BAOs, it simply
indicates that the disjoint union of descriptive frames as we deﬁned it in Deﬁni-
tion 5.71, is not the proper categorical notion of a sum. For that one has to take
the descriptive union (( i gi )∗ )∗ of a family (gi )i∈I of descriptive frames; see
Exercise 5.5.10.
Topology
The reader familiar with topology will have realized that we are drawing on a
number of topological concepts. Examples are the notions of compactness and
of differentiation (the latter being very similar to topological separation axioms).
Furthermore, given a general frame g = (W, R, A) for the basic similarity type,5.5 General Frames
315
one can consider A as a base for a topology TA . The general frame g is descriptive
iff (W, TA ) is a boolean space with A as the set of clopens, and R is a point-closed
relation; that is, R[s] (deﬁned as {t ∈ W | Rst}) is closed for every s in W .
Indeed the whole theory of (descriptive) general frames is permeated with topo-
logical concepts, and an entire chapter could be devoted to the topic. We will
restrict ourselves to a brief discussion of closed sets.
Deﬁnition 5.82 Let g = (F, A) be a general frame. A subset c of the universe is
called closed if it is the intersection of a (possibly inﬁnite) collection of admissible
sets, or equivalently, if

c = {a ∈ A | c ⊆ a}.
By way of example, consider the canonical general frame fcΛ of any normal modal
logic Λ. Here, an admissible set a is of the form φ for some formula φ. We could
also say that a represents the formula φ, since by the Truth Lemma, a consists of
those states s such that φ is true at s. Likewise, a closed set c, being the intersection
of a family {
σ | σ ∈ Σ}, represents the set of formulas Σ in fcΛ . For, we have that
(every formula from) Σ holds at a state s iff s ∈ c.
Proposition 5.83 Let g be a descriptive general frame. Then
(i) Every singleton is closed.
(ii) The collection of closed sets is closed under ﬁnite unions and arbitrary
intersections.
(iii) If c is a closed set, then so is the set R3 [c] (deﬁned as R3 [c] = {t | ∃s ∈
c R3 st}), for every diamond 3.
(iv) For every state s and every sequence β of diamonds, the set Rβ [s] is closed.
(v) Let C be a family of closed sets with the ﬁnite intersection property. Then
C has a non-empty intersection.
Proof. Assume that g = (F, A) is a descriptive frame, and that F is the frame
(W, R)∈τ .
(i) We claim that for every point s ∈ W :

{s} = {a ∈ A | s ∈ a}.
In fact, this claim is nothing but a reformulation of the differentiation condition.

(ii) We only sketch the proof for ﬁnite unions. Suppose that ci = {a ∈ A |
ci ⊆ a}, i ∈ {0, 1}. We leave it to the reader to verify that

c0 ∪ c1 = {a0 ∪ a1 | c0 ⊆ a0 and c1 ⊆ a1 }.

(iii) Assume that c is a closed set, that is, that c = {a ∈ A | c ⊆ a}. Let 3 be
a diamond of τ ; we abbreviate R3 by R. We will prove that5 Algebras and General Frames
316
R[c] =

{b ∈ A | c ⊆ lR (b)}.
(5.38)
The left to right inclusion in (5.38) is trivial. For the other inclusion, assume that
t ∈ R[c] while t ∈ b whenever c ⊆ lR (b). We will derive a contradiction from this.
Deﬁne
A0 = {a ∈ A | c ⊆ a} ∪ {mR (b) | t ∈ b and b ∈ A}.
We ﬁrst prove that
A0 has the ﬁnite intersection property.
(5.39)
For, suppose that there is a ﬁnite subcollection of A0 with an empty intersection.
This means that there are a1 , . . . , am and b1 , . . . , bm in A such that c ⊆ ai for all
i ≤ m, t ∈ bj for all j ≤ n and
a1 ∩ · · · ∩ am ∩ mR (b1 ) ∩ · · · ∩ mR (bn ) = ∅.
Deﬁne a = a1 ∩ · · · ∩ am and b = b1 ∩ · · · ∩ bn , then we have a, b ∈ A, c ⊆ a,
t ∈ b and
a ∩ mR (b) = ∅
(5.40)
since mR (b) ⊆ mR (b1 ) ∩ · · · ∩ mR (bn ). But (5.40) implies that a ⊆ lR (−b),
whence c ⊆ lR (−b). It follows from the assumption that t ∈ −b. But t ∈ −b
contradicts t ∈ b. This proves (5.39).
Now since g is a compact frame, (5.39) implies that A0 has a non-empty inter-
section, so there is an s in W with

s ∈ {a | c ⊆ a}
(5.41)
and
s∈

{mR (b) | t ∈ b}.
(5.42)
It follows immediately from (5.41) that s ∈ c. But also, it follows from (5.42) that
Rst. For suppose otherwise: by tightness of g, there would be a b ∈ A witnessing
¬Rst; that is, t ∈ b while s ∈ mR (b). But this clearly contradicts (5.42).
(iv) The reader is asked to supply this proof in Exercise 5.5.11.
(v) Let {ci | i ∈ I} be a collection of closed sets with the ﬁnite intersection
property. By deﬁnition of closedness, for every i ∈ I there is a collection {aij |

j ∈ Ji } such that ci = j∈Ji aij . It is rather easy to see that the collection
{aij | i ∈ I, j ∈ Ji } has the ﬁnite intersection property. Hence, by compactness,

aij = ∅.
i∈I,j∈Ji
But then5.5 General Frames

ci =
i∈I
 
aij =
i∈I j∈Ji

317
aij = ∅.
i∈I,j∈Ji
The main result in the next section is the Sahlqvist Completeness Theorem, and
closed sets will play a key role in our proof of it. Phrased in terms of general
frames, canonicity is the following question. Given a descriptive general frame
and a formula φ that is valid on it, can we infer that φ is valid on the underlying
Kripke frame as well? That is, if we know that any admissible valuation makes φ
true everywhere in the frame, does the same hold for an arbitrary valuation? The
role of closed sets in the answer to this question is that we will need to consider
closed valuations (that is, valuations that map variables to closed sets); the cru-
cial observation then will be that such closed valuations behave almost as well as
admissible ones.
Exercises for Section 5.5
5.5.1 Which properties of general frames (for example: reﬁnedness, fullness,. . . ) are pre-
served under taking generated subframes, bounded morphic images or disjoint unions?
5.5.2 Let f = (F, A) be a reﬁned general frame. Prove that the following are equivalent:
(a) f is compact,
(b) every ultraﬁlter of A is of the form {a ∈ A | s ∈ a} for some state s.
5.5.3 Prove that a full frame is descriptive if and only if it is ﬁnite.
5.5.4 Let fcΛ be the canonical general frame for the normal modal logic Λ. Prove that
fcΛ  Λ.
5.5.5 Consider the structure c = (C, F ) of Example 5.63.
(a) Prove that c is a general frame if we view C as a frame for the basic modal similarity
type.
(b) What happens if we view C as a standard frame for the basic tense similarity type?
5.5.6 Consider the structure h deﬁned in Example 5.67.
(a) Show that h is a general frame.
(b) Show that h is tight but not differentiated.
5.5.7 Let τ be a similarity type, and let F, f and g be a τ Kripke frame and two general
τ -frames, respectively. Prove or disprove the following:
(a) (F ) = F,
(b) g  (g ) ,
(c) g∗ ∼
= f.
= f∗ only if g ∼
5.5.8 Prove Propositions 5.79 and 5.80.318
5 Algebras and General Frames
5.5.9 Given a frame F, let F ◦ denote the subalgebra of F + that is generated by the atoms
of F+ (that is, by the singleton subsets of the frame). Prove the following:
(a) If φ is a canonical formula (as deﬁned after Open Problem 1), then F  φ only if
(F◦ )+  φ.
(b) Show that the converse does not always hold.
5.5.10 Show that the disjoint union of an inﬁnite family of general frames can never be
descriptive, even if those frames are descriptive. Develop and describe the notion of a
descriptive union (( i gi )∗ )∗ of a family (gi )i∈I of descriptive frames.
5.5.11 Let g be a descriptive general frame. Prove that for every state s and every sequence
β of diamonds, the set R β [s] is closed. That is, prove item (iv) of Proposition 5.83.
5.6 Persistence
This section is devoted to the notion of persistence, a generalization of the concept
of canonicity. With the help of this notion we will show that all Sahlqvist formulas
are canonical.
Deﬁnition 5.84 Let τ be a similarity type. Let φ be a τ -formula, and let X denote
a property (or class) of general frames (as deﬁned in Deﬁnition 5.65). Then φ
is called X-persistent (or persistent with respect to X), if, for every general τ -
frame g in X, g  φ only if g  φ. Persistence with respect to the classes of
reﬁned, descriptive and discrete frames is called r-persistence, d-persistence and
di-persistence, respectively.
The best way to understand persistence is as follows. Let g = (W, R, A) be a
general frame, and φ a modal formula (in the basic similarity type). First, note
that the implication ‘g  φ ⇒ g  φ’ is immediate: if V (φ) = W for ev-
ery valuation, then certainly V (φ) = W for every admissible one. The converse
implication, which will obviously not hold in general, indicates that in order to de-
termine whether φ holds in the underlying Kripke frame g = (W, R), it sufﬁces
to look at admissible valuations only. If this is always the case when we take the
general frame from a given class X of general frames, then we call φ X-persistent.
There is also an algebraic interpretation of the notion of X-persistence. This
stems from the observation that given a general frame g, its associated algebra g∗
is a subalgebra of the full complex algebra (g )+ of the underlying Kripke frame
g of g. Preservation of validity under taking subalgebras means that (g )+ |= s ≈
t ⇒ g∗ |= s ≈ t for every equation s ≈ t; again, the preservation of validity in the
other direction will not always hold. The concept of persistence gives us a way of
describing the special situation (in the sense that g∗ is a special kind of subalgebra
of (g )+ ) where this ‘upward preservation’ does hold.5.6 Persistence
319
From the discussion of descriptive frames in Section 5.5 it is easy to see that
d-persistence and canonicity are really the same notion (provided that we have a
logical notion of canonicity as deﬁned after Open Problem 1).
Proposition 5.85 Let φ be a modal formula in a similarity type τ . Then φ is canon-
ical if and only if φ is d-persistent.
Example 5.86 As a ﬁrst example, we will prove that 2p → p is r-persistent. Let
g = (W, R, A) be a reﬁned frame such that g  2p → p. We have to show that
g  2p → p. By Sahlqvist correspondence, this is equivalent to showing that
g |= ∀x Rxx.
Suppose, in order to arrive at a contradiction, that there is an irreﬂexive state s
in g. It follows from tightness that there must exist a set a ∈ A such that s ∈ a,
but s ∈ mR (a). Now consider the valuation V given by V (p) = −a. Clearly V
is admissible, and since s ∈ lR (−a) and s ∈ −a, we ﬁnd that g, V, s  2p → p.
Hence, we have contradicted the assumption that g  2p → p.
Example 5.87 The formula 3p → 33p is di-persistent, but not r-persistent. For
di-persistence, let g = (W, R, A) be a discrete frame such that g  3p → 33p.
Denote the underlying Kripke frame of g by F – we have to prove that 3p → 33p
is valid in F. Again we use Sahlqvist correspondence, by which we may conﬁne
ourselves to proving that F |= ∀xx1 (Rxx1 → ∃z (Rxz ∧ Rzx1 )). Let s and s1 be
such that Rss1. Following Example 3.7, we deﬁne the minimal valuation Vm by
Vm (p) = {s1 }.
Our ﬁrst observation is that Vm is admissible, since g is discrete. This means that
we can proceed as in Example 3.7. Our second observation is that
(F, Vm ), s  33p iff F |= ∃z (Rxz ∧ Rzs1 )[s].
But (F, Vm ), s  33p is immediate by the validity of 3p → 33p in g.
To show that the formula 3p → 33p is not r-persistent, we consider the reﬁned
frame h of Example 5.70. It is rather easy to see that h  3p → 33p; take
for instance the valuation V given by V (p) = {∞}. Then r  3p, but r has no
successors where 3p is true. Hence, r  33p.
On the other hand, we will now show that h  3p → 33p. Consider a valuation
V and a state x of h such that (h, V ), x  3p. We have to show that x  33p.
From x  3p it follows that there is a y with Rxy and y  p. The only tricky
case is where x = r and y = ∞ – all the other cases are easily solved by using
the reﬂexivity of the states in S. But if ∞ ∈ V (p) and V (p) is admissible, then
V (p) ∩ T is a co-ﬁnite set. Hence, there is a state tn such that tn  p. But then
sn  3p and r  33p.320
5 Algebras and General Frames
Convention 5.88 Fix a modal similarity type τ and a set of propositional variables
Φ. In Section 2.4 we saw that models for this language can also be seen as struc-
tures for the corresponding ﬁrst-order language L1τ (Φ). In this and the following
section we will make good use of this fact; in fact, it will be very convenient to
have a sort of ‘hybrid’ notation, something between modal and ﬁrst-order logic.
Let F be a τ -frame, V a valuation on F and s a ﬁnite sequence of states in F.
Further, consider a ﬁrst-order formula ρ(x) in L1τ (Φ). We will write (F, V ), s  ρ
to denote (F, V ) |= ρ[s]. Here we assume that [s] is an assignment sending x0 to
s0 , x1 to s1 , and so on.
Example 5.89 Although the formula 31 22 p → 23 34 p is d-persistent, it is not
di-persistent. A counterexample to di-persistence is provided by a simple modiﬁ-
cation of the discrete frame c of Example 5.63.
For d-persistence, let g = (W, R, A) be a descriptive frame; deﬁne F = (W, R).
Assume that the formula holds on g; we will prove that it is also valid on F. By
Sahlqvist correspondence it sufﬁces to show that
F |= ∀xx1 (R1 xx1 → ∀z0 (R3 xz0 → ∃z1 (R2 x1 z1 ∧ R4 z0 z1 ))).
(5.43)
Let s and s1 be states in W such that R1 ss1 . Deﬁne the minimal valuation Vm by
Vm (p) = {u ∈ W | R2 s1 u}.
Now assume that Vm is admissible. Then it follows from (F, Vm ), s  31 22 p that
(F, Vm ), s  23 34 p. Hence, every R3 -successor t0 of s has its R4 -successor z1
such that (F, Vm ), t1  p. But by deﬁnition of Vm , t1  p iff R2 s1 t1 . This would
prove (5.43).
However, the problem is that Vm need not be admissible. Nevertheless, a close
inspection of the ‘proof’ in the preceding paragraph reveals that we only need that
in (F, Vm ) at the pair s, s1 the following formula holds:
(R1 xx1 ∧ ∀y (R2 x1 y → P y)) → ∀z0 (R3 xz0 → ∃z1 (R4 z0 z1 ∧ P z1 )). (5.44)
We will not prove (5.44) here; it follows from a far more general claim in the proof
of Theorem 5.91. The two important observations in the proof are that Vm (p) is
a closed set, and that the right-hand side of the formula in (5.44) is the standard
translation of a positive formula.
We will give three theorems concerning persistence. The most important result is
Theorem 5.91 stating that all Sahlqvist formulas are d-persistent and hence, canon-
ical. As a warming-up exercise for its proof, we show that every very simple Sahl-
qvist formula is di-persistent (Theorem 5.90). Finally, Theorem 5.92 states that
every r-persistent formula is elementary; that is, it has a ﬁrst-order frame corre-
spondent.5.6 Persistence
321
Theorem 5.90 Every very simple Sahlqvist formula is di-persistent.
Proof. Recall from Deﬁnition 3.41 that a very simple Sahlqvist formula is of the
form φ → ψ, where
• φ is built up from atoms, using conjunctions and (existential) modal operators,
and
• ψ is positive.
Now let χ ≡ φ → ψ be such a very simple Sahlqvist formula, and let g = (F, A)
be a discrete general frame such that g  χ. We want to prove that F  χ. From
the discussion in the proof of Theorem 3.42 we know that this is equivalent to the
following, cf. (3.10):
F |= ∀P1 . . . ∀Pn ∀x∀x1 . . . ∀xm (REL ∧ AT → POS),
where
REL is a conjunction of ﬁrst-order statements of the form Rx0 . . . xn , corre-
sponding to occurrences of (existential) modal operators in φ,
AT is a conjunction of translations of atomic formulas (these correspond to the
proposition letters and constants in φ), and
POS is the standard translation of the formula ψ.
Let s be a ﬁxed but arbitrary sequence of states in F, and deﬁne valuation Vm by
Vm (p) = {si | P xi is a conjunct of AT }.
It is easy to see that Vm is the minimal valuation U such that (F, U ), s  AT;
in other words, (F, U ), s  AT only if U is an extension of Vm . (Vm is in fact
the semantical version of the minimal substitution that we used in the proof of the
correspondence theoretic part of Sahlqvist’s Theorem in Chapter 3.)
The key observations to the proof of this theorem are (5.45) and (5.46) below:
Vm is admissible
(5.45)
and
(F, Vm ), s  (REL ∧ AT) → POS iff
(F, V ), s  (REL ∧ AT) → POS for every valuation V .
(5.46)
The assumption that χ is true in every admissible model over F means we must
have that (F, U ), s  (REL ∧ AT) → POS for every admissible valuation U .
Hence, the theorem follows immediately from (5.45) and (5.46).
The proof of (5.45) is rather easy: for every p, Vm (p) is a ﬁnite union of ﬁnitely
many singletons, and, since A contains all singletons and is closed under unions,
each Vm (p) is in A.5 Algebras and General Frames
322
Concerning (5.46), the direction from right to left is of course trivial; for the
other direction, assume that (F, Vm ), s  (REL∧AT) → POS, and that (F, V ), s 
REL ∧ AT. From (F, V ), s  AT it follows that V is an extension of Vm . From
(F, V ), s  REL it follows that, regardless of the valuation U , (F, U ), s  REL. In
particular, we have (F, Vm ), s  REL. But then (F, Vm ), s  REL∧ AT and hence,
(F, Vm ), s  POS. Since V is an extension of Vm , the monotonicity of positive
formulas implies that (F, V ), s  POS.
Theorem 5.91 Every Sahlqvist formula is d-persistent and hence, canonical.
Proof. We will prove the theorem for simple Sahlqvist formulas in a modal sim-
ilarity type containing diamonds only. Recall that such formulas are of the form
φ → ψ where
• φ is built up from constants and boxed atoms (cf. Deﬁnition 3.45), using con-
junctions and (existential) modal operators only, and
• ψ is positive.
Let χ ≡ φ → ψ be such a formula, and let g = (F, A) be a descriptive gen-
eral frame such that g  χ. We have to show that χ is valid on the underlying
Kripke frame F of g. Again, by Sahlqvist correspondence this is equivalent to the
following, cf. (3.10):
F |= ∀P1 . . . ∀Pn ∀x∀x1 . . . ∀xm (REL ∧ BOX-AT → POS),
(5.47)
where
REL is a conjunction of ﬁrst-order statements of the form R3 xi xj (corresponding
to occurrences of diamonds in φ),
BOX-AT is a conjunction of formulas of the form ∀y (Rβ xi y → P y), correspond-
ing to the occurrences 2β p of boxed atoms in φ (see Deﬁnition 3.45), and
POS is the standard translation of the formula ψ.
As in the proof of the previous theorem, statement (5.47) itself is equivalent to the
following:
for every s in F: for every valuation V , (F, V ), s  (REL ∧ BOX-AT → POS).
We ﬁx a sequence s of states in F, and deﬁne a valuation Vm by
Vm (p) =
{Rβ [si ] | the formula ∀y (Rβ xi y → P y) occurs in BOX-AT }.
Again, Vm is the minimal valuation U such that (F, U ), s  BOX-AT, and with
equal ease as in the proof of Theorem 5.90 we can show that
(F, Vm ), s  (REL ∧ BOX-AT) → POS iff
(F, V ), s  (REL ∧ BOX-AT) → POS for every valuation V ,
(5.48)5.6 Persistence
323
but – and this is different from the previous case – Vm need not be admissible now.
Nevertheless, it does hold that
(F, Vm ), s  (REL ∧ BOX-AT) → POS,
(5.49)
but we have to work much harder to prove it. The remainder of the proof is devoted
to establishing (5.49) – note that the theorem follows immediately from (5.48) and
(5.49).
We ﬁrst deﬁne the following concepts. For valuations U and V , let U  V
mean that V is an admissible extension of U . (We say that V is an extension of
U if U (p) ⊆ V (p) for every proposition letter p.) It is easy to see that the set of
valuations on a given frame is closed under taking argument-wise intersections and
unions.
Recall that a set c ⊆ W is closed if it is the intersection of a (possibly inﬁnite)
set of admissible sets. Now we call a valuation V closed if V (p) is a closed set for
every proposition letter p. It is then not very difﬁcult to prove that a valuation U is

closed iff U = U V V .
Now (5.49) follows from (5.50) and (5.51) below:
Vm is closed,(5.50)
if U is a closed valuation and γ a positive formula,

then U (γ) = U V V (γ).(5.51)
and
For, suppose that we have proved (5.50) and (5.51), and assume that
(F, Vm ), s  REL ∧ BOX-AT.
Let V be an arbitrary admissible valuation such that Vm  V . Then (F, V ), s 
REL ∧ BOX-AT, so by the assumption, (F, V ), s  POS. If we look up again what
formula POS is, we see that this means s ∈ V (ψ), where ψ was the consequent of

the Sahlqvist formula. Since V was arbitrary, this gives s ∈ Vm V V (ψ). But
then (5.50) and (5.51) imply that s ∈ Vm (ψ). Hence, (F, Vm ), s  POS. This
proves (5.49).
It remains to prove (5.50) and (5.51). The ﬁrst statement follows from Proposi-
tion 5.83, item (iv), and the fact that ﬁnite unions of closed sets are closed.
For (5.51), we assume (without loss of generality) that γ is built up from atomic
formulas using ∧, ∨, 3 and 2. This allows us to give the following inductive proof:
Atomic case. If γ is a variable p, then it follows immediately (by the closedness

of U ) that U (p) = U V V (p). If γ is a constant, then U (γ) = V (γ) for every

valuation V (admissible or not), and hence U (γ) = U V V (γ).5 Algebras and General Frames
324
Conjunction. Assume γ is of the form γ1 ∧ γ2 . Then U (γ) = U (γ1 ) ∩ U (γ2 ) =




V (γ1 ) ∩
V (γ2 ) =
(V (γ1 ) ∩ V (γ2 )) =
V (γ).
U V
U V
U V
U V
Disjunction. Assume γ is of the form γ1 ∨ γ2 . It is easy to see that U (γ) ⊆

U V V (γ). Then U (γ) = U (γ1 ) ∪ U (γ2 ) =




V (γ1 ) ∪
V (γ2 ) ⊆
(V (γ1 ) ∪ V (γ2 )) =
V (γ).
U V
U V
U V
U V
For the other direction, assume that u ∈ U (γ). It follows immediately that u ∈
U (γ1 ) and u ∈ U (γ2 ). By the inductive hypothesis, this implies the existence of
admissible valuations V1 and V2 such that U  Vi and u ∈ Vi (γi ) (i ∈ {1, 2}). Now
let V12 be the intersection of the valuations V1 and V2 , that is,
V12 (p) = V1 (p) ∩ V2 (p)
for every p. It is easy to see that V12 is admissible and that U  V12 . However,
since γ1 and γ2 are positive and hence monotone, we also have V12 (γ1 ) ⊆ V1 (γ1 )
and V12 (γ2 ) ⊆ V2 (γ2 ). So we ﬁnd that u ∈ V12 (γ1 ) and u ∈ V12 (γ2 ), whence

u ∈ V12 (γ1 ∨ γ2 ) = V12 (γ). But then U  V12 implies u ∈ U V V (γ).
Box. Assume that γ is of the form 2γ . Then (writing R for R3 ):



U (γ) = lR (U (γ  )) = lR (
V (γ  )) =
lR (V (γ  )) =
V (γ).
U V
U V
U V
Diamond. Finally, assume that γ is of the form 3γ . Again, the inclusion U (γ) ⊆

U V V (γ) is rather easy:



U (γ) = mR (U (γ  )) = mR (
V (γ  )) ⊆
mR (V (γ  )) =
V (γ).
U V
U V
U V

The other direction is the hard part of the proof. Assume that u ∈ U V V (γ).
Thus for every admissible extension V of U , there is a tV such that RutV and
tV ∈ V (γ  ).
We want to prove that there is a t such that Rut and t ∈ U (γ ). By the inductive
hypothesis, this is equivalent to showing that there is a single t such that Rut and
t ∈ V (γ  ) for every admissible V with U  V . In other words, it is sufﬁcient to
prove that

R[u] ∩
V (γ  ) = ∅.
(5.52)
U V
We will ﬁrst prove that the set
X = {R[u]} ∪ {V (γ  ) | U  V } has the ﬁnite intersection property.5.6 Persistence
325
Consider an arbitrary ﬁnite subcollection of X ; without loss of generality, R[u]
is part of it, hence we may assume that we have taken the sets R[u], V1 (γ  ), . . . ,
Vn (γ  ). Let V0 be the valuation given by
V0 (p) = V1 (p) ∩ · · · ∩ Vn (p)
for every p. Then obviously we have U  V0 , and so by assumption there is a
state t0 in F such that Rut0 and t0 ∈ V0 (γ  ). But since γ  is positive and Vi is
an extension of V0 for all i, it follows that V0 (γ  ) ⊆ Vi (γ  ) for all i. So t0 ∈
R[u] ∩ V1 (γ  ) ∩ · · · ∩ Vn (γ  ). This shows that X has the ﬁnite intersection property.
It follows from Proposition 5.83(iv) that R[u] is closed; hence, item (v) of the
same proposition implies (5.52).
This completes the proof of (5.51), and hence, of Theorem 5.91.
Theorem 5.92 Every r-persistent formula is elementary.
The reader is asked to supply the proof of Theorem 5.92 in Exercise 5.6.4.
Exercises for Section 5.6
5.6.1 Show that if we are working in the basic temporal similarity type, and we conﬁne
ourselves to bidirectional general frames (that is, those in which the accessibility relations
of the diamonds are each other’s converse), then every Sahlqvist formula is di-persistent.
5.6.2 Show that the formula 2M ∧ 4 (see Examples 3.11 and 3.57) is not equivalent to a
Sahlqvist formula. (Hint: use the previous exercise.)
5.6.3 In this exercise we deﬁne the notion of an ultraproduct of a general frame. Let
{gi | i ∈ I} be a family of general frames, whereeach g i is given asthe triple (Wi , Ri , Ai ).
Let U be an ultraﬁlter over I; for elements s ∈ i∈I Wi and a ∈  i∈I Ai , deﬁne [[s ∈ a]]
to be the set {i ∈ I | si ∈ ai }. Now deﬁne, for an arbitrary a U ∈ U Ai :
(aU )◦ := {sU | [[s ∈ a]] ∈ U }.
(a) Prove
that this is 
a correct deﬁnition, that is, show that for arbitrary elements s, t ∈

W
,
a,
b
∈
i
i∈I
i∈I Ai :
(i) if s ∼U t, then [[s ∈ a]] ∈ U iff [[t ∈ a]] ∈ U ,
(ii) if a ∼U b, then [[s ∈ a]] ∈ U iff [[s ∈ b]] ∈ U .


The ultraproduct U gi is deﬁned as the structure ( U (Wi , Ri ), AU ), where AU is given
as the set
'
AU := {(aU )◦ | a ∈
Ai }.
i∈I

(b) Prove that U gi is a general frame.
(c) Prove that for every modal formula φ:
'
gi  φ iff {i ∈ I | gi  φ} ∈ U.
U326
5 Algebras and General Frames
(d) Prove that the ultraproduct of a family of reﬁned general frames is again a reﬁned
general frame. How about the other properties of general frames?
5.6.4 In this exercise the reader is asked to supply the proof of Theorem 5.92.
Let φ be an r-persistent formula.
(a) Let {Fi | i ∈ I} be a family of 
frames such that F i  φ, for all i ∈ I, and let U be
an ultraﬁlter over I. Prove that U Fi  φ. (Hint: use Exercise 5.6.3.)
(b) Why is this sufﬁcient to prove Theorem 5.92? (Hint: use Exercise 3.8.3.)
5.7 Summary of Chapter 5
 The Algebra of Propositional Logic: Both the algebra 2 of truth values and the
class Set of set algebras algebraize classical validity. The class BA of boolean
algebras algebraizes classical theoremhood.
 Stone’s Representation Theorem: This classical result states that every boolean
algebra can be embedded in the power set algebra of the collection of its ultra-
ﬁlters. It is the key to the algebraic proof of the soundness and completeness
theorem for classical propositional logic.
 Modal Formulas as Terms: Modal similarity types, extended with the boolean
connectives, can be seen as algebraic similarity types. Modal formulas can be
identiﬁed with algebraic terms.
 Boolean Algebras with Operators (BAOs): BAOs are boolean algebras aug-
mented with a normal additive operator for each modal operator. They are the
abstract algebras used to interpret modal logic.
 The Semantic Approach to Algebraization: Complex algebras are boolean alge-
bras with operators based on the power set algebra of a frame. Complex algebras
are the concrete BAOs that algebraize relational semantics.
 The Axiomatic Approach to Algebraization: Provable equivalence of two formu-
las in a normal modal logic Λ is a congruence relation on the formula algebra
of the modal language. The Lindenbaum-Tarski Algebra of Λ is the induced
quotient structure. Such algebras act as algebraic canonical models.
 Completeness and Representation: Modal completeness theorems correspond
to algebraic representation theorems.
 Ultraﬁlter Frames: The ultraﬁlter frame of a boolean algebra with operators is
a relational structure based on the collection of ultraﬁlters of the algebra.
 Canonical Embedding Algebras: The complex algebra of the ultraﬁlter frame
of an algebra A is called the canonical embedding algebra of A.
 The Jónsson-Tarski Theorem: This is the fundamental theorem underlying the
algebraization of modal logic. It states that every boolean algebra with operators
can be embedded in the complex algebra of its ultraﬁlter frame.Notes to Chapter 5
327
 Algebraic Canonicity: A class of algebras is canonical if it is closed under taking
canonical embedding algebras; this concept is closely connected to the logical
notion of canonicity.
 Basic Duality: Bounded morphisms between frames correspond to homomor-
phisms between their complex algebras, and homomorphisms between algebras
give rise to bounded morphisms between their ultraﬁlter frames. This links
generated subframes to homomorphic images, bounded morphic images to sub-
algebras and disjoint unions to direct products.
 Goldblatt-Thomason Theorem: This can be derived from Birkhoff’s identiﬁca-
tion of varieties with equational classes using basic duality arguments.
 Ultraproducts and Canonicity: If K is a class of frames which is closed under
ultraproducts, then the variety VK is canonical.
 General Frames: A general frame combines a frame and a boolean algebra with
operators in one structure. Like boolean algebras with operators, general frames
provide an adequate semantics for normal modal logics. Important properties
of general frames include reﬁnedness, discreteness and descriptiveness.
 Descriptive Frames and BAOs: There is a full categorical duality between the
categories of descriptive τ -frames with bounded morphisms and boolean alge-
bras with τ -operators with homomorphic images.
 Persistence: A generalization of the notion of canonicity.
 Sahlqvist’s Completeness Theorem. All Sahlqvist formulas are d-persistent, and
hence canonical.
Notes
The main aim of algebraic logic is to gain a better understanding of logic by treat-
ing it in universal algebraic terms – in fact, the theory of universal algebra was
developed in tandem with that of algebraic logic. Given a logic, algebraic logi-
cians try to ﬁnd a class of algebras that algebraizes it in a natural way. When a
logic is algebraizable, natural properties of a logic will correspond to natural prop-
erties of the associated class of algebras, and the apparatus of universal algebra can
be applied to solve logical problems. For instance, we have seen that represen-
tation theorems are the algebraic counterpart of completeness theorems in modal
logic. The algebraic approach has had a profound inﬂuence on the development of
logic, especially non-classical logic; readers interested in the general methodology
of algebraic logic should consult Blok and Pigozzi’s [67] or Andréka et al. [5].
The ﬁeld has a long and strong tradition dating back to the nineteenth century.
In fact, nineteenth century mathematical logic was algebraic logic: to use the ter-
minology of Section 5.1, propositions were represented as algebraic terms, not
logical formulas. Boole is generally taken as the founding father of both proposi-
tional logic and modern algebra – the latter because, in his work, terms for the ﬁrst328
5 Algebras and General Frames
time refer to objects other than numbers, and operations very different from the
arithmetical ones are considered. The work of Boole was taken up by de Morgan,
Peirce, Schröder and others; their contributions to the theory of binary relations
formed the basis of Tarski’s development of relational algebra. In the Historical
Overview in Chapter 1 we mentioned MacColl, the ﬁrst logician in this tradition to
treat modal logic. A discussion of the nineteenth century roots of algebraic logic is
given by Anellis and Houser in [10].
However, when the quantiﬁcational approach to logic became ﬁrmly established
in the early twentieth century, interest in algebraic logic waned, and it was only
the inﬂuence of a relatively small number of researchers such as Birkhoff, Stone,
Tarski, and Rasiowa and Sikorski [370, 371], that ensured that the tradition was
passed on to the present day. The method of basing an algebra on a collection
of formulas (or equivalence classes of formulas), due to Lindenbaum and Tarski,
proved to be an essential research tool. This period also saw the distinction between
logical languages and their semantics being sharpened; an algebraic semantics for
non-classical logics was provided by Tarski’s matrix algebras. But the great suc-
cess story of algebraic logic was its treatment of classical propositional logic in
the framework of boolean algebras, which we sketched in Section 5.1. Here, the
work of Stone [425] was a milestone: not only did he prove the representation the-
orem for boolean algebras (our Theorem 5.16), he also recognized the importance
of topological notions for the area (something we did not discuss in the text). This
enabled him to prove a duality theorem permitting boolean algebras to be viewed
as essentially the same objects as certain topologies (now called Stone spaces).
Stone’s work has inﬂuenced many ﬁelds of mathematics, as is witnessed by John-
stone [248].
McKinsey and Tarski [324] drew on Stone’s work in order to prove a representa-
tion theorem for so-called closure algebras (that is, S4-algebras); this result signif-
icantly extended McKinsey’s [322] which dealt with ﬁnite closure algebras. How-
ever, when it comes to the algebraization of modal logics, the reader is now in a
position to appreciate the full signiﬁcance of the work of Jónsson and Tarski [255].
Although modal logic is not mentioned in their paper, the authors simultaneously
invented relational semantics, and showed (via their representation theorem) how
this new relational world related to the algebraic one. Both Theorem 5.43 from
the present chapter and important results on canonicity, overlapping with our The-
orem 5.91, are proved here. It is also obvious from their terminology (for instance,
the use of the words ‘closed’ and ‘open’ for certain elements of the canonical em-
bedding algebra) that hidden beneath the surface of the paper lies a duality theory
that extends Stone’s result to cover operators on boolean algebras.
For many years after the publication of the Jónsson-Tarski paper, research in
modal logic and in BAO theory pretty much took place in parallel universes. In
algebraic circles, the work of Jónsson and Tarski was certainly not neglected. TheNotes to Chapter 5
329
paper ﬁtted well with a line of work on relation algebras. These were introduced
by Tarski [427] to be to binary relations what boolean algebras are to unary ones;
the concrete, so-called representable relation algebras have, besides the boolean
repertoire, operations for taking the converse of a relation and the composition
of two relations, and as a distinguished element, the identity relation. (From the
perspective of our book, the class RRA of representable relation algebras is nothing
but the variety generated by the complex algebras of the two-dimensional arrow
frames; see Example 5.57. In fact, one of the motivations behind the introduction of
arrow logic was to give a modal account of the theory of relation algebras.) Much
attention was devoted to ﬁnding an analog of Stone’s result for boolean algebras:
that is, a nice equational characterization of the representable relation algebras.
But this nut turned out to be hard to crack. Lyndon [304] showed that the axioms
that Tarski had proposed did not sufﬁce, and Monk [334] proved that the variety
does not even have a ﬁnite ﬁrst-order axiomatization. Later work showed that
equational axiomatizations will be very complex (Andréka [6]) and not in Sahlqvist
form (Hodkinson [230] and Venema [446]), although Tarski proved that RRA is
a canonical variety. As a positive result, a nice game-theoretical characterization
was given by Hirsch and Hodkinson [225]. But these Notes can only provide a lop-
sided account of one aspect of the theory of relation algebras; for more, the reader
is referred to Jónsson [251, 252], Maddux [306] or Hirsch and Hodkinson [226].
One last remark on relation algebras: it is a very powerful theory. In fact, as Tarski
and Givant show in [428], one can formalize all of set theory in it.
Tarski and his students developed other branches of algebraic logic as well: for
example, the theory of cylindric algebras. The standard reference here is Henkin,
Monk and Tarski [218]. Cylindric algebras (and also the polyadic algebras of Hal-
mos [202]), are boolean algebras with operators that were studied as algebraic
counterparts of ﬁrst-order logic. For an introductory survey of these and other al-
gebras of relations we refer the reader to Németi [341]; modal logic versions of
these algebras are discussed in Section 7.5.
But in modal circles, the status of algebraic methods was very different. Indeed,
with the advent of relational semantics for modal logic in the 1960s, it seemed that
algebraic methods were to be swept away: model theoretic tools seemed to be the
route to a brave new modal world. (Bull’s work was probably the most impor-
tant exception to this trend. For example, his theorem that all normal extensions
of S4.3 are characterized by classes of ﬁnite models was proved using algebraic
arguments.) Indicative of the spirit of the times is the following remark made by
Lemmon in his two part paper on algebraic semantics for modal logic. After thank-
ing Dana Scott for ideas and stimulus, he remarks:
. . . I alone am responsible for the ugly algebraic form into which I have cast
some of his elegant semantics. [295, page 191]330
5 Algebras and General Frames
Such attitudes only seemed reasonable because Jónsson and Tarski’s work had been
overlooked by the leading modal logicians, and neither Jónsson nor Tarski had
drawn attention to its modal signiﬁcance. Only when the frame incompleteness
results (which began to appear around 1972) showed that not all normal modal
logics could be characterized in terms of frames were modal logicians forced to
reappraise the utility of algebraic methods.
The work of Thomason and Goldblatt forms the next major milestone in the
story: Thomason [433] not only contains the ﬁrst incompleteness results and uses
BAOs, it also introduced general frames (though similar, language dependent, struc-
tures had been used in earlier work by Makinson [308] and Fine [127]). Thomason
showed that general frames can be regarded as simple set theoretic representations
of BAOs, and notes the connection between general frames and Henkin models for
second-order logic (we brieﬂy noted this link in Chapter 3.2). In [435], Thomason
developed a duality between the categories of frames with bounded morphisms and
that of complete and atomic modal algebras with homomorphisms that preserve in-
ﬁnite meets. It was Goldblatt, however, who did the most inﬂuential work: in [184]
the full duality between the categories of modal algebras with homomorphisms and
descriptive general frames with bounded morphisms is proved, a result extending
Stone’s. Independently, Esakia [123] came up with such a duality for closure al-
gebras. Goldblatt generalized his duality to arbitrary similarity types in [186]; a
more explicitly topological version can be found in Sambin and Vaccaro [398].
Ever since their introduction in the seventies, general frames, a nice compromise
between algebraic and the relational semantics, have occupied a central place in
the theory of modal logic. Kracht [276, 279] developed an interesting calculus of
internal descriptions which connects the algebraic and ﬁrst-order side of general
frames. Zakharyaschev gave an extensive analysis of transitive general frames in
his work on canonical formulas – see the Notes to Chapter 4 for further informa-
tion.
The ﬁrst proof of the canonicity of Sahlqvist formulas, for the basic modal sim-
ilarity type, was given by Sahlqvist [396], although many particular examples and
less general classes of Sahlqvist axioms were known to be canonical. In particu-
lar, Jónsson and Tarski proved canonicity, not only for certain equations, but also
for various boolean combinations of suitable equations. This result overlaps with
Sahlqvist’s in the sense that canonicity for simple Sahlqvist formulas follows from
it, but on the other hand, Sahlqvist formulas allowing properly boxed atoms in
the antecedent do not seem to fall under the scope of the results in Jónsson and
Tarski [255]. Incidentally, Sahlqvist’s original proof is well worth consulting: it is
non-algebraic, and very different from the one given in the text. Our proof of the
Sahlqvist Completeness Theorem is partly based on the one given in Sambin and
Vaccaro [399].
Recent years have seen a revived interest in the notion of canonicity. De RijkeNotes to Chapter 5
331
and Venema [387] deﬁned the notion of a Sahlqvist equation and generalized the
theory to arbitrary similarity types. Jónsson became active in the ﬁeld again;
in [254] he gave a proof of the canonicity of Sahlqvist equations by purely algebraic
means, building on the techniques of his original paper with Tarski. Subsequent
work of Gehrke, Jónsson and Harding (see for instance [169, 168]) generalized
the notion even further by weakening the boolean base of the algebra to that of a
(distributive) lattice. Ghilardi and Meloni [171] proved canonicity of a wide class
of formulas using a different representation of the canonical extension of algebras
with operators. Whereas the latter lines of research tend to separate the canonicity
of formulas from correspondence theoretic issues, a reverse trend is visible in the
work of Kracht (already mentioned) and Venema [449]. The latter work shows that
for some non-Sahlqvist formulas there is still an algorithm generating a ﬁrst-order
formula which is now not equivalent to the modal one, but does deﬁne a property
for which the modal formula is canonical.
The applications of universal algebraic techniques in modal logic go much fur-
ther than we could indicate in this chapter. Various properties of modal logics have
been successfully studied from an algebraic perspective; of the many examples we
only mention the work of Maksimova [310] connecting interpolation with amalga-
mation properties. Also, most work by Blok, Kracht, Wolter and Zakharyaschev on
mapping the lattice of modal logics makes essential use of algebraic concepts such
as splitting algebras; a good starting point for information on this line of research
would be Kracht [279].
Most of the results that we present in Sections 5.4 and 5.5 are simpliﬁed ver-
sions of results in Goldblatt [184]. The proof of the Goldblatt-Thomason theorem
given in this chapter (as opposed to the model-theoretic one given in Section 3.8)
treats it as a corollary of Birkhoff’s Theorem [53] identifying varieties with equa-
tional classes; our proof is essentially the original proof of Goldblatt and Thoma-
son [188]. The proof of Theorem 5.56 is a generalization and algebraization by
Goldblatt [186] of results due to Fine [132] and van Benthem [41]. The Open
Problems 1 and 2 seem to have been formulated ﬁrst in Fine [132]; readers who
would like to try and solve the second one should deﬁnitely consult Goldblatt [180].
The now standard terminology concerning properties of general frames – reﬁned,
descriptive, and so on – is due to Thomason [433], Goldblatt [184] and Fine [130].
An exception, as far as we know, is the notion of discreteness, which did not play
a role until Venema [444], where our Theorem 5.90 was proved. The generaliza-
tion of canonicity to the notion of persistence stems from Goldblatt [185], and the
proof that r-persistent formulas are elementary (Theorem 5.92) was ﬁrst given by
Lachlan [291].6
Computability and Complexity
In this chapter we investigate the computability and complexity of normal modal
logics. In particular, we examine the computability of satisﬁability problems (given
a modal formula φ and a class of models M, is it computable whether φ is M-
satisﬁable?) and validity problems (given a modal formula φ and a class of models
M, is it computable whether φ is valid on M?). When the answer is ‘yes’, we
probe further: how complex is the problem – in particular, what resources of time
(that is, computation steps) or space (that is, memory) are needed to carry out the
required computations? When the answer is ‘no’, we pose a similar question: how
uncomputable is the problem? There are vast differences in the complexities of
modal satisﬁability problems: some are no worse than the satisﬁability problem
for propositional calculus, while others are highly undecidable.
This chapter has two main parts. The ﬁrst, consisting of the ﬁve sections on the
basic track, introduces the basic ideas and discusses modal (un-)decidability. Three
techniques for proving decidability are discussed (ﬁnite models, interpretations in
monadic second-order theories of trees, and quasi-models and mosaics) and unde-
cidability is approached via tiling problems. In the second part, consisting of the
last three sections of the chapter, we examine the complexity of some key modal
satisﬁability problems. These sections are on the advanced track, but the initial
part of each of them should be accessible to all readers.
Basic ideas about computability and complexity are reviewed in the ﬁrst section,
and further background information can be found in Appendix C. Throughout the
chapter we assume we are working with countable languages.
Chapter guide
Section 6.1: Computing Satisﬁability (Basic track). We discuss the key concepts
assumed throughout the chapter: satisﬁability and validity problems, and
how to compute them on Turing machines.
Section 6.2: Decidability via Finite Models (Basic track). We discuss the use of
3326.1 Computing Satisﬁability
333
ﬁnite models for proving decidability results. Three basic theorems are
proved, and many of the logics discussed in Chapter 4 are shown to be
decidable.
Section 6.3: Decidability via Interpretations (Basic track). Another way of prov-
ing modal decidability results is via interpretations in powerful decidable
theories such as monadic second-order theories of trees. This technique
is useful for showing the decidability of logics without the ﬁnite model
property.
Section 6.4: Decidability via Quasi-models and Mosaics (Basic track). For log-
ics lacking the ﬁnite model property it may also be possible to prove de-
cidability results by computing with more abstract kinds of ﬁnite structure;
quasi-models and mosaics are important examples of such structures.
Section 6.5: Undecidability via Tiling (Basic track). In this section we show just
how easily undecidable – and even highly undecidable – modal logics can
arise. We do so by introducing an important proof method: tiling argu-
ments.
Section 6.6: NP (Advanced track). This section introduces the concept of NP al-
gorithms, illustrates the modal content of this idea using some simple ex-
amples, and then proves Hemaspaandra’s Theorem: every normal logic
extending S4.3 is NP-complete.
Section 6.7: PSPACE (Advanced track). The key complexity class for the basic
modal language is PSPACE, the class of problems solvable in polynomial
space. We give a PSPACE algorithm for the satisﬁability problem for K,
and prove Ladner’s Theorem: every normal logic between K and S4 is
PSPACE-hard.
Section 6.8: EXPTIME (Advanced track). We show that the satisﬁability prob-
lem for PDL is EXPTIME-complete. EXPTIME-hardness is shown by
reduction from a tiling problem, and the EXPTIME algorithm introduces
an important technique called elimination of Hintikka sets.
6.1 Computing Satisﬁability
The work of this chapter revolves around satisﬁability and validity problems. Here
is an abstract formulation.
Deﬁnition 6.1 (Satisﬁability and Validity Problems) Let τ be a modal similarity
type, φ be a τ -formula and M a class of τ -models. The M-satisﬁability problem is
to determine whether or not φ is satisﬁable in some model in M. The M-validity
problem is to determine whether or not φ is true in all models in M; that is, whether
or not M  φ. (We call this the validity problem because we are mostly interested334
6 Computability and Complexity
in cases where M is the class of all models over some class of frames.) The M-
validity and M-satisﬁability problem are each other’s duals.
In fact, as far as discussions of computability (or non-computability) are concerned,
we are free to talk in terms of either satisﬁability or validity problems.
Lemma 6.2 Let τ be a modal similarity type, and suppose that M is a class of
τ -models. Then there is an algorithm for solving the M-satisﬁability problem iff
there is an algorithm for solving the M-validity problem.
Proof. As ¬φ is not satisﬁable in M iff M  φ, given an algorithm for M-satis-
ﬁability, we can test for the validity of φ by giving it the input ¬φ. In a similar
fashion, an algorithm for M-validity can be used to test for M-satisﬁability.
This argument does not give us any interesting information about the relative com-
plexity of dual satisﬁability and validity problems; and indeed, they may well be
different.
How do the themes of this chapter relate to the normal modal logics introduced
in Section 1.6 and discussed in Chapters 4 and 5? Clearly we should investigate
the following two problems.
Deﬁnition 6.3 Let τ be a modal similarity type, Λ be a normal modal logic in a
language for τ , and φ a τ -formula. The problem of determining whether or not φ is
Λ-consistent is called the Λ-consistency problem, and the problem of determining
whether or not Λ  φ is called the Λ-provability problem.
Note that Λ-consistency and Λ-provability problems are satisﬁability and validity
problems in disguise. In particular, if Λ is a normal modal logic, and M is any
class of models such that Λ = ΛM , then the Λ-consistency problem is the M-
satisﬁability problem, and the Λ-provability problem is the M-validity problem. As
every normal modal logic is determined by at least one class of models (namely, the
singleton class containing its canonical model; see Theorem 4.22), we are free to
think of consistency and provability problems in terms of satisﬁability and validity
problems. We do so in this chapter, and to emphasize this we usually call the Λ-
consistency problem the Λ-satisﬁability problem, and the Λ-provability problem
the Λ-validity problem.
Our discussion so far has given an abstract account of the problems we will ex-
plore, and most of our results will be stated, proved, and discussed at this level. But
what does it mean to have an algorithm for solving (say) a validity problem? And
what does it mean to talk about the complexity of (say) a satisﬁability problem?
After all, computation is the ﬁnitary manipulation of ﬁnite structures – but both
formulas and models are abstract set-theoretical objects. To show that our abstract6.1 Computing Satisﬁability
335
account really makes sense, we need to choose a well-understood method of com-
putation and show that formulas and models can be represented in a way that is
suited to our method.
We have chosen Turing machines (Appendix C) as our fundamental model of
computation. The most relevant fact about Turing machines for our purposes is
that they compute by manipulating ﬁnite strings of symbols; hence we need to
represent models and formulas as symbol strings. As far as mere computability is
concerned, the key demand is that these symbol string representations be ﬁnite. For
complexity analyses more is required: representations must also be efﬁcient. Let
us discuss these requirements.
Clearly modal formulas can be represented as ﬁnite strings over a ﬁnite set of
symbols: proposition letters can be represented by a single symbol (say, p) fol-
lowed by (the representation of) a number. Thus, instead of working with an inﬁ-
nite collection of primitive symbols we could work with (say) p1, p10, p11, p100
and so on, where the numeric tail is represented in binary. Fine – but what about
models? Models are set-theoretic entities of the form (W, R, V ), and each com-
ponent may be inﬁnite. However, the difﬁculty is more apparent than real. For a
start, when evaluating a formula φ in some model, the only relevant information in
the valuation is the assignments made to proposition letters actually occurring in
φ (see Exercise 1.3.1). Thus, instead of working with V , we can work with the ﬁ-
nite valuation V  which is deﬁned on the (ﬁnite) language consisting of exactly the
proposition letters in φ, and which agrees with V on these letters. Secondly, much
of our work will revolve around models based on ﬁnite frames (or more generally,
the frames of ﬁnite character deﬁned below).
We already know quite a lot about ﬁnite models and their logics. For a start,
in Section 2.3 we introduced two techniques for building ﬁnite models (selection
and ﬁltration) and deﬁned the ﬁnite model property for the basic modal language.
In Section 3.4 we introduced the ﬁnite frame property (again, for the basic modal
language) and proved Theorem 3.28: a normal modal logic has the ﬁnite frame
property iff it has the ﬁnite model property. Since then we have learned what a
normal modal logic in a language of arbitrary similarity type is (Deﬁnition 4.13),
so let us now deﬁne the ﬁnite frame property and the ﬁnite model property for
modal languages of arbitrary similarity type, and generalize Theorem 3.28.
Deﬁnition 6.4 Let τ be a modal similarity type. A frame of type τ has ﬁnite char-
acter if it contains ﬁnitely many states, and ﬁnitely many non-empty relations. If
Λ is a normal modal logic in a language for τ , and F is a class of τ -frames of ﬁnite
character, and Λ = ΛF , then Λ is said to have the ﬁnite frame property (f.f.p.) with
respect to F. If Λ = ΛF for some class of τ -frames F of ﬁnite character, then Λ has
the ﬁnite frame property.
A class of τ -models M is ﬁnitely based if every model in M is based on a τ -336
6 Computability and Complexity
frame of ﬁnite character. If Λ is a normal modal logic in a language for τ , and
M is a class of ﬁnitely based τ -models, and Λ = ΛM , then Λ has the ﬁnite model
property (f.m.p.) with respect to M. If Λ = ΛM for some class of of ﬁnitely based
τ -models M, then Λ has the ﬁnite model property.
A few remarks may be helpful. First, the concept of ﬁnite character is a natural way
of coping with similarity types containing inﬁnitely many relations. Second, note
that the way the ﬁnite frame property is deﬁned here (where we simply insist that
Λ = ΛF ) is somewhat simpler than that used in Deﬁnition 3.23 (where we insisted
that F  Λ, and for every formula φ such that φ ∈ Λ there is some F ∈ F such that
φ is falsiﬁable on F). It is easy to see that these deﬁnitions are equivalent. Finally,
a class of frames of ﬁnite character (or indeed, a class of ﬁnite frames) may well be
a proper class. Nonetheless, up to isomorphism, there are only denumerably many
frames in any such class; hence, if Λ has the ﬁnite frame property, it has the ﬁnite
frame property with respect to a denumerably inﬁnite set of frames, and we take
this for granted without further comment throughout the chapter.
Given this deﬁnition, it is straightforward to generalize Theorem 3.28.
Theorem 6.5 Let τ be a modal similarity type. Any normal modal logic in a lan-
guage for τ has the ﬁnite model property iff it has the ﬁnite frame property.
Proof. This is a matter of verifying that the proof of Theorem 3.28 extends to
arbitrary similarity types; see Exercise 6.1.1.
There are many ways to represent a frame of ﬁnite character, together with a val-
uation V  deﬁned on ﬁnitely many proposition letters, as a ﬁnite symbol string.
While any such ﬁnitization is sufﬁcient for discussions of computability, we need
to exercise more care when it comes to complexity. Complexity theory measures
the difﬁculty of problems in terms of the resources required to solve them – and
these are measured as a function of the size of the input. A highly inefﬁcient rep-
resentation of the input can render such resource measures vacuous, so we must be
careful not to smuggle in sources of inefﬁciency. For the complexity classes we
will be dealing with, this is pretty much a matter of common sense, but the follow-
ing point should be made explicit: we must not represent the numeric subscripts
on propositional variables and states in unary notation.
The point is this. Even binary representations (which are longer than the more
familiar decimal representations) are exponentially more compact than unary ones.
For example, the representation of the number 64 in unary is a string of 64 con-
secutive ones, whereas its representation in binary is 1000000. If we represent our
subscripts in unary, we are using a highly inefﬁcient representation of the problem.
For this reason we will regard modal formulas (for the basic modal language)
as strings over the alphabet {p, 0, 1, (, ), ∧, ¬, 3}, and proposition letters will6.1 Computing Satisﬁability
337
be represented by strings consisting of p followed by the binary representation of
a number (without leading zeroes). Similarly, we will regard models as strings
over the alphabet {w, p, 0, 1, ;, , }. A state in a model will be represented by
w followed by the binary representation of a number (without leading zeroes), and
the representation of proposition letters (which we need to encode the valuation)
will be as just described. A string representing a model will have the following
form:
*
w1 ; . . . ; wn ;
wi ; wj ; . . . ; wk ; wl ;
+
px ; wr ; . . . ; ws ; . . . ; py ; wt ; . . . ; wu  ,
where 1 ≤ i, j, k, l, r, s, t, u ≤ n. Such triples represent models in the obvious
way: the ﬁrst component gives the states, the second the relation, and the third the
valuation. The subscripted ws and ps are metavariables over our representations of
states and proposition letters, respectively. We assume that our representations of
models contain no repetitions in any of the three components, and that they satisfy
obvious well-formedness conditions (in particular, the third component represents
a function, thus we cannot have the same representation py appearing as the ﬁrst
item in different tuples). Here is a simple example (though to keep things readable
we have represented the numbers in decimal):
p
t
t q

I
@
@
t
p
A model
*
w1 ; w2 ; w3 ;
w1 ; w2 ; w1 ; w3 ;
+
p1 ; w1 ; w2 ; p2 ; w3  .
Its representation
Such representations open the door to all the standard concepts of computability
theory and computational complexity. For a start, it now makes sense to describe
sets of formulas (including normal modal logics), sets of models, and sets of frames
as being recursively enumerable (r.e.), or as being recursive. Saying that a set is
r.e. means that it is possible to write a Turing machine that will successively output
all and only its elements. Saying that a set is recursive means that it is possible to
write a Turing machine which, when given any input, will perform a ﬁnite number
of computation steps, halt, and then correctly tell us whether the input represents
a member of the set or not. (In short, recursive sets are those for which we can
decide membership using a terminating computation.)
Furthermore, it is clearly possible to program a Turing machine so that when it
is presented with (the representations of) a formula, a model, and a point, it will
evaluate (the representation of) the formula in (the representation of) the model at
(the representation of) the point. Admittedly it would be rather painful to write out338
6 Computability and Complexity
such a Turing machine in detail – but it is straightforward to write a program to
carry out this task in most high-level programming languages; hence, by Church’s
Thesis (see Appendix C), it is possible to write a Turing machine to do the job as
well. Thus it makes perfectly good sense to talk about writing Turing machines
which test for the satisﬁability or validity of a formula on a class of ﬁnitely based
models and to inquire about the complexity of such problems.
Apart from asking the reader to generalize the above representation schema to
cover modal languages of arbitrary similarity type (see Exercise 6.1.2) we will not
discuss the issue of representation further. In most of what follows we talk as if the
abstract deﬁnition of satisﬁability and validity problems given earlier was the focus
of our computational investigations. For example, we will often call |φ| the size
of the input formula; strictly speaking, it is the size of its representation. Nor do
we mention Turing machines very often. The results of this chapter rest on the fact
that there is an efﬁcient representation which enables us to compute satisﬁability
and validity problems; for many purposes we can ignore the details.
Exercises for Section 6.1
6.1.1 Prove Theorem 6.5. That is, show that for any modal similarity type τ , any normal
modal logic in a language for τ has the ﬁnite model property if and only if it has the ﬁnite
frame property. This is simply a matter of verifying that the proof of Theorem 3.28 extends
to arbitrary similarity types – but note that there will be a gap in your proof if you have not
yet proved the Filtration Theorem for modal languages of arbitrary similarity type.
6.1.2 Modify the representation schema for models given above so that it can represent
any ﬁnitely based model of any modal similarity type.
6.1.3 Show that if Λ is the normal modal logic generated by an r.e. set of formulas, then Λ
itself is an r.e. set. (The reader unfamiliar with this type of proof may ﬁnd it useful to look
at the proof of Lemma 6.12 below.)
6.2 Decidability via Finite Models
Call a normal modal logic Λ decidable if the Λ-satisﬁability (or equivalently: Λ-
validity) problem is decidable, and undecidable if it is not. How should we estab-
lish decidability results? A lot depends on our ‘access’ to the logic. For example,
we may know Λ purely semantically: it is given as the logic of some class of
frames of interest. However, we may also have a syntactic handle on Λ; in partic-
ular, we may know that it is the logic generated by some set of axioms. Whether
Λ is semantically or syntactically speciﬁed, establishing that it has the ﬁnite model
property is a useful ﬁrst step towards proving decidability, for if we can prove this,
two plausible strategies for establishing decidability suggest themselves, as we will
now explain.6.2 Decidability via Finite Models
339
• Decidability for semantically speciﬁed logics: informal argument. Suppose
we only have a semantic speciﬁcation of Λ, but that we have been able to prove
that Λ possesses a strong form of the ﬁnite model property: not only does Λ
have the f.m.p. with respect to some set of models, but for any formula φ there
is a computable function f such that f (|φ|) is an upper bound on the size of
these models needed to satisfy φ. Write a Turing machine that takes φ as input,
generates all the ﬁnite models belonging to this set up to size f (|φ|), and tests for
the satisﬁability of φ on these models. Because φ is Λ-satisﬁable iff it is satisﬁed
in a Λ-model of size at most f (|φ|), and because the machine systematically
examines all these models, our machine decides Λ-satisﬁability.
• Decidability for syntactically speciﬁed logics: informal argument. Suppose Λ
is given axiomatically, and we have been able to show that Λ has the f.m.p. with
respect to some set of models M. First, construct a Turing machine that makes
use of the axiomatization to recursively enumerate the Λ-validities. Second, con-
struct a Turing machine that recursively enumerates all the ﬁnite models in M.
Given two such machines we can effectively test the Λ-validity of any formula
φ: if φ is valid it will eventually be generated by the ﬁrst machine; if it is not,
we will eventually be able to falsify it on a model generated by the second. One
of the machines must eventually settle φ’s fate, and thus decide Λ-validity.
Such arguments underly most applications of the ﬁnite model property to decidabil-
ity. We have deliberately phrased both arguments rather loosely; the fundamental
goal of this section is to explore the underlying ideas more carefully, and formulate
them rigorously. Our investigation will yield three main theorems. The ﬁrst is a
precise formulation of the argument for semantically speciﬁed logics. The second
and third are distinct reformulations of the argument for syntactically speciﬁed log-
ics. We will consider a number of applications of these theorems, and will put both
of the methods introduced in Section 2.3 for constructing ﬁnite models (namely
ﬁltration and selection) to work.
Let us begin by scrutinizing the ﬁrst of the above arguments. This revolves
around a strong form of the ﬁnite model property.
Deﬁnition 6.6 (Strong Finite Model Property) Let Λ be a normal modal logic,
M a set of ﬁnitely based models such that Λ = ΛM , and f a function mapping nat-
ural numbers to natural numbers. Λ has the f (n)-size model property with respect
to M if every Λ-consistent formula φ is satisﬁable in a model in M containing at
most f (|φ|) states.
Λ has the strong ﬁnite model property with respect to M if there is a computable
function f such that Λ has the f (n)-size model property with respect to M. Λ has
the polysize model property with respect to M if there is a polynomial p such that
Λ has the p(n)-size model property with respect to M.340
6 Computability and Complexity
Λ has the f (n)-size model property (respectively, strong ﬁnite model property,
polysize model property) if there is a set of ﬁnitely based models M such that
Λ = ΛM and Λ has the f (n)-size model property (respectively, strong ﬁnite model
property, polysize model property) with respect to M.
If a logic Λ has the polysize model property, any Λ-satisﬁable formula is satisﬁable
not just on a ﬁnite model, but a genuinely small model. Even this very strong form
of the f.m.p does not guarantee decidability: as the reader is asked to prove in
Exercise 6.2.4, there are uncountably many normal modal logics which possess the
polysize model property but have undecidable satisﬁability problems.
In view of this result, the ﬁrst informal argument sketch is clearly inadequate –
but where does its deﬁciency lie? It makes the following (false) assumption: that
for any set of models, and any natural number n, it is possible to generate all and
only the models in M of size at most n. This assumption is warranted only if M
is a recursive set (that is, only if a Turing machine can decide exactly which ﬁnite
models belong to M). But this is the only shortcoming of the informal argument.
Theorem 6.7 If Λ is a normal modal logic that has the strong ﬁnite model property
with respect to a recursive set of models M, then Λ is decidable.
Proof. First, observe that for any natural number n it is possible to generate all
distinct (representations of) models in M that have size at most n: we simply need
to write a machine that generates all distinct (representations of) models that have
size at most n, tests each model (representation) as it is generated to see whether
it belongs to M (this is the key point: we can effectively test for membership in
M precisely because M is a recursive set) and then outputs exactly those models
(representations) which do belong to M. (From now on we drop all mention of
representations, and will speak simply of ‘generating all models’ or ‘generating all
models up to size n’, and so on.)
So, given φ, we use this machine to generate all models of the appropriate set up
to size f (|φ|), and test whether φ is satisﬁable on any of the models it produces.
If φ is satisﬁable on at least one of them, it is Λ-satisﬁable; if not, it is not Λ-
satisﬁable, for Λ has the strong f.m.p. with respect to M.
Theorem 6.7 is an important result. If we are to apply it, how do we establish that a
logic has the strong ﬁnite model property? Unfortunately, no fully general answer
to this question is known – nonetheless, both ﬁltration and selection can be useful.
We start by illustrating the utility of ﬁltrations.
Corollary 6.8 K, T, KB, K4, S4, S5, Kt , Kt 4.3 and Kt Q are decidable.
Proof. First, all these logics have the f.m.p. with respect to the expected sets of
models; for example, K4 has the f.m.p. with respect to the set of ﬁnite transitive6.2 Decidability via Finite Models
341
models, and Kt Q has the f.m.p with respect to the ﬁnite dense unbounded weak
total orders (that is, the ﬁnite DUWTO frames; see Theorem 4.41). The easiest
way to prove this is to use ﬁltrations. In Section 2.3 we deﬁned ﬁltrations for
both the basic modal language and the basic temporal language. Given a model M
that satisﬁes a formula φ at some state, by ﬁltrating M through the set of all φ’s
subformulas we obtain a ﬁnite model Mf that satisﬁes φ. Of course, we need to be
careful that Mf has all the right properties; for example, if M was a K4-model, we
want Mf to be a K4-model as well. By and large this is straightforward, though the
reader will need to think a little about how to handle density; see Exercise 6.2.1.
Such ﬁltration arguments actually establish the strong f.m.p. for these logics. If
we form Mf by ﬁltrating M through the subformulas of φ, then Mf has at most
2|φ| nodes, thus we have a computable (though, unfortunately, exponential) upper
bound on the size of satisfying models for all these logics; see Section 2.3.
It remains to check that the relevant sets of ﬁnite models are recursive. Checking
for membership in these sets boils down to checking that the models possess (vari-
ous combinations of) such properties as reﬂexivity, transitivity, trichotomy, and so
on. It is clearly possible to devise algorithms to test for the relevant properties,
hence (by Church’s thesis) we can program a Turing machine to do so. Thus The-
orem 6.7 applies, and all these logics are decidable.
Filtration is a widely used technique for showing that logics have the strong ﬁnite
model property, but it has limitations. Suppose we are working with a modal lan-
guage containing n unary modal operators (n > 0) and no others. Let Fn1 be the set
of frames for this language such that for each F ∈ Fn1 , the relation corresponding
to each modality is a partial function, let Mn1 be the set of models built over Fn1 ,
and let Kn Alt1 be its logic. Now, Kn Alt1 has the strong ﬁnite model property, but
there is no obvious way of using ﬁltrations to show this; see Exercise 6.2.3.
However – at least in the present case – it is straightforward to use selection, the
other method of building ﬁnite models discussed in Section 2.3, to establish the
strong ﬁnite model property.
Corollary 6.9 Kn Alt1 is decidable.
Proof. We argue as follows. Suppose M is in Mn1 and M, w  φ. Let M be the
model that is identical to M save possibly that any relations in M not correspond-
ing to modal operators in φ are empty. Clearly M is also in Mn1 and M , w  φ.
Let m be the degree of φ (that is, the maximal depth of nested modalities; see Deﬁ-
nition 2.28). Let M be the submodel of M formed by selecting all and only those
nodes reachable from w in m or fewer steps. Clearly M is in Mn1 and M , w  φ.
Moreover, because each relation is a partial function, M has only ﬁnitely many
nodes: indeed, it can contain at most tm + 1 nodes, where t is the number of dis-342
6 Computability and Complexity
tinct types of modality that occur in φ. Hence Kn Alt1 has the strong ﬁnite model
property with respect to Mn1 .
It is clear that the set of ﬁnitely based Mn1 models is recursive, for testing whether
a ﬁnite model M belongs to it essentially boils down to checking that each of M’s
(ﬁnitely many non-empty) transition relations is a partial function. Decidability
follows by Theorem 6.7.
Selection is not as general a method as ﬁltration – but it can be useful, especially
when working with non-transitive models. As we will see when we discuss NP-
completeness, selection is a natural way of turning a ﬁnite model (perhaps pro-
duced via a ﬁltration) into a truly small (that is, polysize) model.
Theorem 6.7, together with such methods as ﬁltration and selection, can be a
useful tool for establishing modal decidability results, for it does not require us to
have an axiomatization. Very often we do have an axiomatization at our disposal,
and it is natural to ask whether (and how) we can make use of it to help establish
decidability. This is what the second informal argument attempts to do. The key
idea it embodies is the following: if a logic is both axiomatizable and has the ﬁnite
model property with respect to some (recursively enumerable) set of models M,
then we should be able to prove decidability. This is an important idea that can be
developed in two different ways, depending on the kind of axiomatization we have,
and what we know about the computational properties of M.
When we discussed completeness in Chapter 4, we viewed axiomatizations very
abstractly: we simply said that if Λ was a normal modal logic, Σ a set of modal
formulas, and KΣ (the smallest normal logic generated by Σ) equaled Λ, then Σ
was an axiomatization of Λ. To give computational content to the phrase ‘gener-
ated by’ we need to impose restrictions on Σ, for under the deﬁnition just given
every normal logic Λ generates itself. This is too abstract to be useful here, so we
will introduce various notions of axiomatizability that offer more computational
leverage.
Deﬁnition 6.10 A logic Λ is ﬁnitely axiomatizable if it has a ﬁnite axiomatization
Σ; it is recursively axiomatizable if it has a recursive axiomatization Σ; and it is
axiomatizable if it has a recursively enumerable axiomatization Σ.
Although it will not play a major role in what follows, there is a neat result called
Craig’s Lemma that readers should know: every axiomatizable logic is recursively
axiomatizable. So the following lemma is essentially Craig’s Lemma for modal
logic:
Lemma 6.11 If Λ is axiomatizable, then Λ is recursively axiomatizable.
So, given a computationally reasonable notion of axiomatizability, the idea of using
axiomatizations to generate validities is correct. But how do we use this fact to turn6.2 Decidability via Finite Models
343
the informal argument into a theorem? Here is the most obvious way: demand that
M be an r.e. set. As the following lemma shows, this ensures that we can recursively
enumerate the formulas that are not valid on M.
Lemma 6.12 If M is a recursively enumerable set of ﬁnite models, then the set of
formulas falsiﬁable in M is recursively enumerable.
Proof. As M is an r.e. set, we can construct a machine M1 to generate all its ele-
ments, and clearly we can construct a machine M2 that generates all the formulas.
So, construct a machine M3 that operates as follows: it calls on M1 to generate a
model, and on M2 to generate a formula, and then stores both the model and the
formula. It then tests all stored formulas on all stored models (M3 is not going to
win any prizes for efﬁciency) and outputs any of the stored formulas it can falsify
on some stored model. At any stage there are only ﬁnitely many stored formulas
and models, hence this testing process terminates. When the testing process is ﬁn-
ished, M3 calls on M1 and M2 once more to generate another model and formula,
stores them, performs another round of testing, and so on ad inﬁnitum.
Suppose φ is falsiﬁable on some model M in M. At some ﬁnite stage both φ
and M will be stored by M3, hence φ will eventually be tested on M, falsiﬁed,
and returned as output. This means that the set of formulas falsiﬁable on M is
recursively enumerable.
Theorem 6.13 If Λ is an axiomatizable normal modal logic that has the ﬁnite
model property with respect to an r.e. set of models M, then Λ is decidable.
Proof. It is not difﬁcult to see that Λ, being axiomatizable, is recursively enumer-
able. But the set of formulas not in Λ is also r.e. for Λ = ΛM and the set of formulas
that are not M-valid is r.e. by the previous lemma. Any formula φ must eventually
turn up on one of these enumerations, hence Λ is decidable.
As an application, we will show that the minimal propositional dynamic logic is
decidable.
Corollary 6.14 PDL is decidable.
Proof. By Theorem 4.91, PDL is complete with respect to the set of all regular
PDL-models. The axioms of PDL clearly form a recursive set, so trivially they
form a recursively enumerable set, thus to be able to apply the Theorem 6.13 it
only remains to show that PDL has the ﬁnite model property with respect to an r.e.
set of models.
This follows easily from our completeness proof for PDL. Recall that we proved
completeness by constructing, for any consistent formula φ, a ﬁnite model P that
satisﬁed φ. This gives us what we want, modulo the following glitch: although344
6 Computability and Complexity
P contains only ﬁnitely many nodes, it may contain inﬁnitely many non-empty
relations, thus it may not be of ﬁnite character and thus (strictly speaking) our
completeness proof does not establish that PDL has the ﬁnite model property. This
is a triviality: for any formula φ, only ﬁnitely many of the relations on P are
relevant to the satisﬁability of φ, namely those that actually occur in φ. Let Rφ be
the smallest set that contains all the relations in P corresponding to modalities in
φ and is downward closed under the usual relation constructors (that is, if Rπ;π ∈
Rφ then so are Rπ and Rπ , and analogously for relations deﬁned by union and
transitive closure). Note that Rφ is ﬁnite. Let P be the model that is identical
to P save that all the relations not in Rφ are empty; we call P a reduced model.
Clearly P is a ﬁnitely based model that satisﬁes φ. This shows that PDL has the
ﬁnite model property.
The set of reduced models is a recursive set, since checking that a ﬁnite model is
a reduced model boils down to showing that the relations corresponding to non-
basic modalities really are generated out of simpler relations via composition,
union, or transitive closure, and this is obviously something we can write a program
to do. Hence, the relevant models are recursively enumerable, thus the conditions
of Theorem 6.13 are satisﬁed, and PDL is decidable.
We can also show that PDL is decidable by appealing to Theorem 6.7. As we have
just seen, our completeness proof for PDL gives us the ﬁnite model property for
PDL – but in fact it even gives us the strong ﬁnite model property. To see this,
recall that for any consistent φ, we constructed P out of atoms, that is, maximal
consistent subsets of the Fischer-Ladner closure of {φ}. As there are at most 2c|φ|
such atoms for some constant c, we have a computable upper bound on the size of
the models needed to satisfy φ. We noted in the proof of Corollary 6.14 that the
relevant ﬁnite models (the reduced models) form a recursive set, hence we have
established everything we need to apply Theorem 6.7.
Theorem 6.13 is a fundamental one and is useful in practice. It does not make
use of axiomatizations in a particularly interesting way: it uses them merely to
enumerate validities. To apply the theorem we need to know that the set of relevant
ﬁnite models is recursively enumerable. We often have much stronger syntactic
information at our disposal: we may know that a logic is ﬁnitely axiomatizable.
Our next theorem is based on the following observation: if a logic with the f.m.p.
is ﬁnitely axiomatizable, we can use the axiomatization not only to recursively
enumerate the validities, but to help us enumerate the non-validities as well.
Theorem 6.15 If Λ is a ﬁnitely axiomatizable normal modal logic with the ﬁnite
model property, then Λ is decidable.
Proof. As in the proof of Theorem 6.13, we can use the axiomatization to recur-6.2 Decidability via Finite Models
345
sively enumerate Λ, so if we can show that the set of formulas not in Λ is also r.e.
we will have proved the theorem.
By Theorem 6.5, if Λ has the ﬁnite model property it also has the ﬁnite frame
property, thus there is some set of ﬁnite frames F such that Λ = ΛF . Hence,
if φ ∈ Λ, φ is falsiﬁable in some model based on a frame in F. Obviously all
such frames must validate every axiom of Λ, hence if φ ∈ Λ, φ is falsiﬁable in
some model based on a frame that validates the Λ axioms. Now for the crucial
observation: we can write a machine M which decides whether or not a ﬁnite
frame validates the Λ axioms, for as Λ has only ﬁnitely many axioms, each frame
can be checked in ﬁnitely many steps. With the help of M , we can recursively
enumerate the formulas falsiﬁable in some F-based model, but these are just the
formulas which do not belong to Λ. It follows that Λ is decidable.
Can Theorem 6.15 be strengthened by replacing its demand for a ﬁnite axiomati-
zation with a demand for a recursive axiomatization? No – in Exercise 6.2.5 we
give an example of an undecidable recursively axiomatizable logic KUX with the
ﬁnite model property; the result hinges on Craig’s Lemma.
Theorem 6.15 has many applications, for many common modal and tense logics
have the f.m.p. and are ﬁnitely axiomatizable. For example, Theorem 6.15 yields
another proof that K, T, KB, K4, S4, S5, Kt , Kt 4.3, and Kt Q are decidable, for
all these logics were shown to be ﬁnitely axiomatizable in Chapter 4, and we saw
above that they all have the (strong) ﬁnite model property. However, a more inter-
esting application follows from our work on logics extending S4.3 in Section 4.9.
Corollary 6.16 Every normal logic extending S4.3 is decidable.
Proof. By Bull’s Theorem (Theorem 4.96) every normal logic extending S4.3 has
the ﬁnite model property, and by Theorem 4.101 every normal logic extending
S4.3 is ﬁnitely axiomatizable. Hence the result is an immediate corollary of Theo-
rem 6.15.
Corollary 6.16 completes the main discussion of the section. To summarize what
we have learned so far, in Theorems 6.7, 6.13, and 6.15 we have results that pin
down three important situations in which the ﬁnite model property implies decid-
ability – and indeed, most modal decidability results make use of one of these three
theorems.
Exercises for Section 6.2
6.2.1 Provide full proof details for Corollary 6.8. Pay particular attention to showing that
Kt Q has the f.m.p. with respect to the ﬁnite DUWTO-frames (see Theorem 4.41). Filtra-
tions generally do not preserve density, so how do we know that this ﬁltration is dense?
(Hint: trichotomy.)346
6 Computability and Complexity
6.2.2 Show that if Λ is a ﬁnitely axiomatizable normal modal logic with the ﬁnite model
property, then Λ has the ﬁnite frame property with respect to a recursive set of frames.
6.2.3 In this exercise we ask you to show that there is no method of ﬁltrating a partial
function that guarantees that the resulting relation is again a partial function.
Consider the model M = (N, S, V ) where S is the successor relation on the set N of
natural numbers, and V makes the proposition letter p true at precisely the even numbers.
Let Σ be the set {3¬p, 3p, ¬p, p}. Prove that no ﬁltration of M through Σ is based on a
frame in which S f is a partial function.
6.2.4 In this exercise we ask the reader to prove that there are uncountably many undecid-
able normal modal logics with the polysize model property.
Let Fsuc be the set of all ﬁnite frames (W, R) such that W = {0, . . . , k} (for some
k ∈ ω) and for all distinct m and n in W , Rnm iff m = n + 1. (Note that this deﬁnition
permits reﬂexive points. Indeed, any frame in this set is uniquely determined by its size and
which points, if any, are reﬂexive.) Then, for each j ∈ ω deﬁne F j to be the set containing:
(1) all the irreﬂexive frames in F suc ; (2) all the frames in F suc whose last point is reﬂexive;
and (3) the (unique) F suc frame containing j + 1 nodes such that 0 is the only reﬂexive
point; call this frame F j . Now deﬁne, for any non-empty I ⊆ ω, F I as the set i∈I Fi ; let
ΛI be its logic.
Deﬁne φj to be the formula p ∧ 3p ∧ 3(¬p ∧ 3 j−1 2 ⊥).
(a) Prove that φj is satisﬁable in Fi iff i = j.
(b) Prove that if φ is F i -satisﬁable, then it is satisﬁable on a frame in F i that contains
at most m + 2 points, where m is the number of modalities in φ.
(c) Prove that if I and J are distinct (non-empty) subsets of ω then there is a formula
that is satisﬁable in FI but not in FJ .
(d) Prove that each Λ I has the polysize model property.
(e) Prove that there can only be countably many decidable logics. (This step is actually
the easiest one: after all, how many distinct Turing machines can there be?)
(f) Conclude that there are uncountably many undecidable normal modal logics with
the polysize model property.
6.2.5 Let X be an r.e. subset of the natural numbers that is not recursive; assume that
0 ∈ X but 1 ∈ X. Then KU X is the smallest normal modal logic containing the following
formulas:
(U1)
(U2)
(U3)
(U4)k
3(3p ∧ 3q) → 33(p ∧ q),
3(p ∧ 2 ⊥) ∧ 3(q ∧ 2 ⊥) → 3(p ∧ q),
3(p ∧ 3) ∧ 3(q ∧ 3) → 3(p ∧ q),
(32 ⊥ ∧33) → 2k 3, where k ∈ X.
Note that by Craig’s Lemma KU X has a recursive axiomatization.
(a) Use Sahlqvist’s Correspondence and Completeness Theorems to ﬁnd a ﬁrst order
deﬁnable class U of frames for which KU X is sound and complete.
(b) Prove that KUX has the ﬁnite model property.
(c) Show that KUX is undecidable.
(Hint: prove that any formula U4 j with j not in X, is not satisﬁable in U.)6.3 Decidability via Interpretations
347
6.3 Decidability via Interpretations
For all its usefulness, decidability via ﬁnite models has a number of limitations.
One is absolute: as we will shortly see, there are decidable logics that lack the
ﬁnite model property. Another is practical: it may be difﬁcult to establish the ﬁnite
model property, for although ﬁltration or selection work in many cases, no univer-
sal approach is known. Thus we need to become familiar with other techniques
for establishing decidability, and in this section we introduce an important one:
decidability via interpretations, and in particular, interpretations in SnS.
A general strategy for proving a problem decidable is to effectively reduce it to
a problem already known to be decidable. But there are many decidable problems;
which of them can help us prove modal decidability results? We would like to ﬁnd
a decidable problem, or class of problems, to which modal satisﬁability problems
can be reduced in a natural manner. Moreover, we would like the approach to be as
general as possible: not only should a large number of modal satisﬁability problems
be so reducible, but the required reductions should be reasonably uniform.
A suitable group of problems is the satisﬁability problem for SnS (where n ∈ ω
or n = ω), the monadic second-order theory of trees of inﬁnite depth, where each
node has n successors. Because these problems are themselves satisﬁability prob-
lems – and indeed, satisﬁability problems for monadic second-order languages, the
kinds of language used in correspondence theory – it can be relatively straight-
forward to reduce modal satisﬁability to SnS satisﬁability. Moreover, the various
reductions share certain core ideas; for example, analogs of the standard translation
play a useful role. The method can also be used for strong modal languages, such
as languages containing the until operator U ; see Exercise 2.2.4.
In this section we introduce the reader to such reductions (or better, for reasons
which will become clear, interpretations). We ﬁrst introduce the theories SnS,
note some examples of their expressivity, and state the crucial decidability results
on which subsequent work depends. We then illustrate the method of interpreta-
tions with two examples. First, we prove that KvB, a logic lacking the ﬁnite model
property, is decidable. As KvB is characterized by a single structure (namely, a
certain general frame) this example gives us a relatively straightforward introduc-
tion to the method. We then show how the decidability of S4 can be proved via
interpretation. The result itself is rather unexciting – we already know that S4 has
the ﬁnite model property and is decidable (see Corollary 6.8) – but the proof is im-
portant and instructive. S4 is most naturally characterized as the logic of transitive
and reﬂexive frames, but this is a characterization in terms of an uncountable class
of structures. How can this characterization be ‘interpreted’ in SnS? In fact, it can
be done rather naturally, and the ideas involved open the doors to a wide range of
further decidability results.
Let us set about deﬁning SnS. If A is some ﬁxed set (our alphabet), then A∗ is348
6 Computability and Complexity
the set of all ﬁnite sequences of elements of A, including the null-sequence λ. We
introduce the following apparatus:
(i) Deﬁne an ordering ≤ on A∗ by x ≤ y if y = xz for some z ∈ A∗ . Clearly
this ‘initial-segment-of’ relation is a partial order. If x ≤ y and x = y we
write x < y.
(ii) Suppose A is totally ordered by a relation <A . Then we deﬁne * to be the
lexicographic ordering of A∗ induced by <A . That is, x * y if and only if
x ≤ y, or x = zau and y = zbv where a, b ∈ A and a <A b. Note that *
totally orders A∗ .
(iii) For any a ∈ A we deﬁne ra : A∗ → A∗ , the a-th successor function, by
ra (x) = xa.
Deﬁnition 6.17 (SnS) For any n such that n is a natural number, or n = ω, let
Tn be {i ∈ ω | i < n}∗ . The structure Nn is (Tn , ri , ≤, *)i<n , where * is the
lexicographic ordering induced by <ω , the usual ordering of the natural numbers.
Nn is called the structure of n successor functions. (Note that all these structures
are countably inﬁnite.)
The monadic second-order theory of n successor functions is the monadic sec-
ond-order theory of Nn in the monadic second-order language of appropriate signa-
ture (we spell out the details of this language below); this theory is usually referred
to as SnS.
Let us spell out the intuitions underlying this machinery. First, note that each
structure Nn really is an inﬁnite tree where each node has n immediate succes-
sors (or daughters, in standard tree terminology). For example, consider N1 ; that
is ({0}∗ , r0 , ≤, *). This is the inﬁnite tree in which each node has exactly one
daughter; that is, it is simply an isomorphic copy of the natural numbers in their
usual order. Next, consider N2 , that is ({0, 1}∗ , r0 , r1 , ≤, *). This is the full bi-
nary tree (that is, the inﬁnite tree in which every node has exactly two daughters).
An initial segment of N2 is shown in Figure 6.1. Note that λ is the root node of
the tree depicted in Figure 6.1, and that r0 and r1 are the ﬁrst daughter and second
daughter relations, respectively. Further, note that ≤ has a natural tree-geometric
interpretation: it is simply the dominates relation. That is, x ≤ y iff it is possible
to reach x by moving upwards in the tree from y. Similarly, * is the dominates-or-
to-the-left-of relation. The tree-like nature of these models plays an important role
in the work that follows, and must be properly understood. In particular, the reader
should check that Nω really is an inﬁnite tree in which every node has ω daughters.
So much for the structures – what about the theories? Each of the theories
SnS is a monadic second-order theory in the appropriate language. For exam-
ple, the monadic second-order language appropriate for talking about N2 contains
two function symbols for talking about r0 and r1 (we will be economical with our6.3 Decidability via Interpretations
349
λ
@
0
 A

A

A
00
01
..
..
.
.
@
@
@
1
 A

A

A
10
11
..
..
.
.
Fig. 6.1. An initial segment of N 2
notation and use r0 and r1 for these symbols) and two binary predicate symbols
for talking about ≤ and * (we use ≤ and * for this purpose). In addition, the
language contains a denumerably inﬁnite set of individual variables x, y, z, . . . , a
denumerably inﬁnite set of predicate (or set) variables P , Q, S, . . . , that range over
subsets of the domain, and the usual quantiﬁers and boolean operators. The syntax
and semantics of the language is standard; see Appendix A for further discussion
of monadic second-order logic.
Using these languages, we can say many useful things about Nn . First, note that
although we did not include a primitive equality predicate, an equality predicate is
deﬁnable over Nn :
x = y iff x * y ∧ y * x.
Next, note that we can deﬁne a unary predicate symbol ROOT that is true only of
the root node λ:
ROOT(x) iff ¬∃y (y < x).
(6.1)
We can deﬁne the unary higher-order predicate ‘P is a ﬁnite set.’ Recall that a
total ordering R on a set S is a well-ordering if every non-empty subset of S has
an R-least element; it is a standard observation that S is well-ordered by R iff S
contains no inﬁnitely descending R-chains. It follows that a subset P of Tn is ﬁnite
iff it is well-ordered by both * and its converse, for such a set contains no inﬁnitely
descending *-chains and no inﬁnitely ascending *-chains.
F INITE (P ) iff
(6.2)
∀Q ((∃x Qx ∧ ∀y (Qy → P y)) → ∃u (Qu ∧ ∀w (Qw → u * w))
∧ ∃v (Qv ∧ ∀w (Qw → w * v))).
(That is, P is ﬁnite if every non-empty subset of P has a *-ﬁrst and a *-last350
6 Computability and Complexity
element.) In short, monadic second-order logic is an extremely powerful language
for talking about trees – which makes the following result all the more remarkable.
Theorem 6.18 (Rabin) For any natural number n, or n = ω, SnS is decidable.
That is, for any n, it is possible to write a Turing machine which, when given
a monadic second-order formula (in the language of appropriate signature), cor-
rectly decides whether or not the formula is satisﬁable in Nn . The proof of this
beautiful result is beyond the scope of this book; we refer the reader to the Notes
for discussion and references.
Given a modal logic Λ, how can we use the fact of SnS-decidability to estab-
lish Λ-decidability? Suppose Λ = ΛM for some class of countable models M.
The essence of the interpretation method is to attempt to construct, for any modal
formula φ, a monadic second-order formula Sat-Λ(φ) that does three things.
• It must encode the information in φ; this is usually achieved by using some
variant of the standard translation.
• It must deﬁne a set of substructures of Nn (for some choice of n) which are
isomorphic copies of the models in M.
• It must bring the two previous steps together. That is, Sat-Λ(φ) must be con-
structed so that it is satisﬁable in Nn iff (the translation of) φ is satisﬁable in (a
deﬁnable substructure of Nn that is isomorphic to) a model in M – that is, iff φ
is Λ-satisﬁable.
If such a formula Sat-Λ(φ) can be constructed, the ramiﬁcations for modal decid-
ability are clear: as SnS is decidable, we can decide whether or not Sat-Λ(φ) is
satisﬁable on Nn . As this is equivalent to deciding the Λ-satisﬁability of φ, we will
have established that Λ is decidable.
As our ﬁrst example of the method in action, we will prove the decidability of
KvB. We met this logic brieﬂy in Exercise 4.4.2; it is the logic of a certain general
frame J. The domain J of J consists of N ∪ {ω, ω + 1} (that is, the set of natural
numbers together with two further points), and the relation R is deﬁned by Rxy iff
x = ω + 1 and y < x or x = ω + 1 and y = ω. The frame (J, R) is shown in
Figure 6.2. A, the collection of subsets of J admissible in J, consists of all X ⊆ J
such that either X is ﬁnite and ω ∈ X, or X is co-ﬁnite and ω ∈ X.
As the reader was asked to show in Exercise 4.4.2, KvB is incomplete; that is, there
is no class of frames F such that KvB = ΛF . By Theorem 6.5 it follows that KvB
lacks the ﬁnite model property. Even though it lacks the ﬁnite model property, KvB
is decidable, and we will demonstrate this via an interpretation in S2S.
Theorem 6.19 KvB is decidable.6.3 Decidability via Interpretations
vv
01
351
vω + 1


 

a



a
a
 a
a
a


)


=

?

v. . .
v
ω
2
Fig. 6.2. The frame underlying J. Note that ω + 1 is related only to ω
Proof. Let us make two initial assumptions; we will shortly show that both as-
sumptions are correct. First, let us suppose that J = (J, R, A) can be isomorphi-
cally embedded in N2 . We will refer to this isomorphic copy as J; no confusion
should arise because of this double usage. Furthermore, let us suppose that this
isomorphic image is deﬁnable in the monadic second-order language for N2 . That

 y) and A(P
 ) (containing 1 free indi-
is, suppose that there are formulas J(x),
R(x,
vidual variable x, 2 free individual variables x and y, and 1 free predicate variable
P , respectively) such that
J

= {t ∈ T2 | N2 |= J(x)[t]},
 y)[t, t ]},
R = {(t, t ) ∈ T2 × T2 | N2 |= R(x,
 )[U ]}.
A = {U ⊆ T2 | N2 |= A(P
Given these assumptions, it is easy to reduce the satisﬁability problem for the gen-
eral frame to the satisﬁability problem for S2S. First, with the help of the formula
 we can deﬁne a translation T from the modal language into the second-order
R,
language:
Tx (p) = P x,
Tx (¬φ) = ¬Tx (φ),
Tx (φ ∧ ψ) = Tx (φ) ∧ Tx (ψ),
 ∧ Ty (φ)).
Tx (3φ) = ∃y (Rxy
 replacing the use
Note that Tx is just the standard translation with the formula R
of a ﬁxed relation symbol. We leave it as an exercise to show that for any modal
formula φ (built out of proposition letters p1 , . . . , pn ):
((J, R, A), V ), w  φ iff N2 |= Tx (φ)[w, V (p1 ), . . . , V (pn )].
(6.3)
(See Exercise 6.3.1; the notation [w, V (p1 ), . . . , V (pn )] means assign the state w
to the free variable x, and assign the subset V (pi ) to the predicate variable Pi .)
For any modal formula φ, let Sat-KvB(φ) be the following monadic second-order
sentence:
 1 ) ∧ · · · ∧ A(P
 n ) ∧ J(x)
 ∧ Tx (φ)).
∃P1 . . . ∃Pn ∃x (A(P6 Computability and Complexity
352
It follows that φ is satisﬁable in (J, R, A) iff N2 |= Sat-KvB(φ). Thus – given our
two initial assumptions – we have effectively reduced the satisﬁability problem
for KvB to the S2S-satisﬁability problem, for φ is satisﬁable on J iff Sat-KvB(φ)
belongs to S2S, and by Rabin’s result it is possible to decide the latter.
Hence, to complete the proof that KvB is decidable, it only remains to show that
our assumptions were justiﬁed; that is, to show that J really does have a deﬁnable
isomorphic image in N2 . Given the expressive power at our disposal, this is actu-
ally rather easy to do. We will make use of the general predicates =, ROOT, and
F INITE deﬁned in (6.1) and (6.2). In addition, we will use
x <1 y iff r1 (x) ≤ y ∧ ¬∃z(x ≤ z ∧ r0 (z) ≤ y).
Note that x <1 y means that x is a proper initial subsequence of y such that y
extends x by a ﬁnite sequence of 1s – or, in terms of tree geometry, it is possible to
move down from x to y by using only the ‘second daughter’ relation.
We will now deﬁne an isomorphic image of J in N2 . First, we can deﬁne the
numeric part of the underlying frame as follows:
N (x) iff ROOT (x) ∨ ∃y (ROOT (y) ∧ y <1 x).
The isomorphism involved should be clear: the natural number zero is taken to be
the empty sequence, and the positive integer n is taken to be the sequence of n 1s.
Next, we will represent ω by 0, and ω + 1 by 00. Deﬁning these choices is easy:
O MEGA (x) iff ∃y (ROOT (y) ∧ x = r0 (y)),
O MEGA +1(x) iff ∃y (ROOT (y) ∧ x = r0 (r0 (y))).
 as follows:
Putting it all together, we deﬁne the required predicates J and R
J(x) = N x ∨ O MEGA (x) ∨ O MEGA +1(x),
 y) = (N y ∧ (y <1 x ∨ O MEGA (x))) ∨ (O MEGA (y) ∧ O MEGA +1(x)).
R(x,
Clearly these two formulas deﬁne a subset of the tree domain isomorphic to (J, R).
Thus it merely remains to deﬁne A, the class of allowable valuations. With the help
of the F INITE predicate, this is straightforward.
 ) iff
A(P

∀x (P x → J(x))
∧ ((F INITE (P ) ∧ ∀z (O MEGA (z) → ¬P z)) ∨
 ∧ ¬P x) → (F INITE (Q) ∧ ∀z (O MEGA (z) → ¬Qz)))).
∀Q∀x (Qx ↔ (Jx
In short, a deﬁnable isomorphic image of J really does live inside N2 . We conclude
that KvB is decidable.
While the above result is a nice introduction to decidability via interpretation, in
one respect it is rather misleading. KvB is characterized by a single structure (and6.3 Decidability via Interpretations
353
a rather simple one at that) thus we only had to deﬁne a single isomorphic image,
and were able to do this fairly straightforwardly using S2S. However, as we saw
in Chapter 4, it is usual to characterize logics in terms of a class of structures;
for example, S4 is usually characterized as the logic of the class of reﬂexive and
transitive models. Do class-based characterizations mesh well with the idea of
decidability via interpretations? Classes of models may contain uncountable struc-
tures – and only countable structures can be isomorphically embedded in Nn . And
why should we expect to be able to isomorphically embed even countable models
in inﬁnite trees?
Two simple observations clear the way. First, in many important cases, only
the countable structures in characterizing classes are required. Second, there is
a standard method for converting a model into a tree-based model, namely the
unraveling method studied in Chapters 2 and 4. Taken together, these observations
enable us to view the classes of structures characterizing many important logics
as a collection of deﬁnable substructures of Nω . We will illustrate the key ideas
involved by proving the decidability of S4 via interpretation in SωS.
As a ﬁrst step, we claim that S4 is sound and strongly complete with respect to
the class of countable reﬂexive and transitive models. We could prove this directly
(for example, using the step-by-step method discussed in Section 4.6) but it also
follows from the following general observation. (Recall that for the duration of this
chapter, we are only working with countable languages.)
Theorem 6.20 If Λ is a normal logic that is sound and strongly complete with re-
spect to a ﬁrst-order deﬁnable class of models M, then Λ is also sound and strongly
complete with respect to the class of all countable models in M.
Proof. Left as Exercise 6.3.3.
Lemma 6.21 S4 is sound and strongly complete with respect to the class of count-
able (reﬂexive and transitive) trees.
Proof. By Theorems 4.29 and 6.20, S4 is sound and strongly complete with respect
to the class of countable reﬂexive, transitive models; that is, every S4-consistent
set of sentences Σ is satisﬁable on such a model M = (W, R, V ) at some point w.
 = (W
 , R,
 V
 ) be the unraveling of M
Now, (as in the proof of Theorem 4.54) let M
∗
∗
∗


around w, and let M be (W , R , V ), where R is the reﬂexive transitive closure
 this model is a reﬂexive transitive tree that veriﬁes Σ at its root. Moreover,
of R;
it is a countable model, for its nodes are all the ﬁnite sequences of states in M that
start at w, and as M is countable, there are only countably many such sequences.
The result follows.
Corollary 6.22 S4 is decidable, and its decidability can be proved via interpreta-
tions.354
6 Computability and Complexity
Proof. Let us call a subset of Nω an initial subtree if it contains λ and is closed
under the inverse of ≤ (that is, if y belongs to the subset, and x ≤ y, then x
belongs to the subset). If S is such a subtree, then ≤S denotes the restriction of
 , R)
 be the unraveling of some
≤ to S. Now for the key observation. Let (W
countable S4-frame (W, R) around a point w, and let R∗ be the reﬂexive transitive
 Then (W
 , R∗ ) is isomorphic to a pair (S, ≤S ) for some initial subtree
closure of R.
S. To see this, note that we can inductively construct an isomorphism f from
 , R∗ ) to some initial subtree as follows. First, we stipulate that f maps the root
(W
 , R∗ ) to λ. Next, suppose that for some u ∈ W
 , f (u) has been deﬁned to be
of (W



m. Now, {s ∈ W | uRs} is a countable set as W is countable, so we can enumerate
its elements. Then, if s is the i-th element in this enumeration, we stipulate that
f (s) = ri (m). (That is, the successor of u that is i-th in our enumeration is mapped
to the i-th successor of m.) In short, Nω is ‘wide enough’ to accommodate a copy
of every branch through a tree-like S4 model in a very obvious way. In fact, it is
precisely because the required isomorphisms are so simple that we have elected to
work with Nω .
With this observed, the interpretation is easy to deﬁne. First, we deﬁne a predi-
cate I SUBTREE (S), which picks out the initial subtrees of Nω :
I SUBTREE (S) iff ∃y (ROOT (y) ∧ Sy) ∧ ∀z∀u ((Sz ∧ u ≤ z) → Su).
Second, we deﬁne a predicate ≤S that deﬁnes the restriction of ≤ to a subset S of
Nω by
x ≤S y iff Sx ∧ Sy ∧ x ≤ y.
Third, we deﬁne a translation T ω from the basic modal language to the monadic
second-order language for Nω . Like the translation T we used when proving the
decidability of KvB this translation is a simple variant of the standard translation.
In fact, it is identical to T save in the clause for modalities, which is given by:
ω
ω
Tx,S
(3φ) = ∃y (x ≤S y ∧ Ty,S
(φ)).
Note that as well as containing the free individual variable x, the translation of 3φ
contains a free set variable S; when written in full the above expression becomes:
ω
ω
Tx,S
(3φ) = ∃y (Sx ∧ Sy ∧ x ≤ y ∧ Ty,S
(φ)).
We need the free variable here because we are not working with one ﬁxed isomor-
phic image (as we were when proving the decidability of KvB). Rather, we have
a separate relation for each initial subtree, and the presence of the free variable
allows all our deﬁnitions to be relativized in the appropriate way.
It simply remains to put it all together. Suppose φ is a modal formula constructed
out of the proposition letters p1 , . . . , pn . Deﬁne Sat-S4(φ) to be the following6.3 Decidability via Interpretations
sentence:
355

∃S∃P1 . . . ∃Pn ∃x I SUBTREE (S) ∧
ω
∀z (P1 z → Sz) ∧ · · · ∧ ∀z (Pn z → Sz) ∧ Sx ∧ Tx,S
(φ) .
Recall that T ω (φ) contains free occurrences of S and x; these become bound in this
sentence. Bearing this in mind, it is clear that this sentence asserts the existence of
an initial subtree S of Nω , a collection of n subsets Pi of this subtree, and a state
x in the subtree, that satisfy the translation of φ. That is, it asserts the existence
of a tree-like S4 model for the (translation of) φ, and we have reduced the S4-
satisﬁability problem to the SωS-satisﬁability problem.
This completes our discussion of interpretations in SnS – though we should imme-
diately admit that we have barely scratched the surface of the method’s potential:
Rabin’s theorem is very strong, the ideas underlying it make contact with many
branches of mathematics, and it has become a fundamental tool in many branches
of logic and theoretical computer science. Nonetheless, our discussion has un-
earthed themes relevant to modal logic: the importance of establishing complete-
ness results with respect to classes of countable structures, the use of unraveling
to produce tree-like models, and the particular utility of Nω in allowing reasonably
straightforward isomorphic embeddings. These three ideas enable a wide range of
modal decidability results to be proved via interpretations.
One ﬁnal remark: while SnS is important, it is certainly not the only logical sys-
tem in which modal logics can be interpreted. Many fragments of classical logic,
or theories in classical logics, are known to be decidable, and offer opportunities
for proving modal decidability results. Indeed we have already met a (very simple)
example. We pointed out in Section 2.4 that the basic modal language translates
into the 2 variable fragment of classical logic, (see Proposition 2.49), from which it
immediately follows that K (and some simple extensions such as T) are decidable.
Moreover, on occasions it can be useful to interpret a modal logic in another modal
logic already known to be decidable. See the Notes for further discussion.
Exercises for Section 6.3
6.3.1 We claimed that the general frame for KvB is isomorphically embedded in the tree
 deﬁnes the accessibility relation of this isomorphic image. Check this
domain, and that R
claim, and show that
((W, R, A), V ), w  φ iff N2 |= Tx (φ)[w, V (p1 ), . . . , V (pn )],
for any modal formula φ (see (6.3)).
6.3.2 Show by interpretation in S2S that both the tense logic of the natural numbers, and
the tense logic of the integers, are decidable. Now add the until operator U to your language
(this operator was deﬁned in Chapter 2 in Exercise 2.2.4). Are the logics of the natural
numbers and the integers in this richer language still decidable?6 Computability and Complexity
356
6.3.3 Prove Theorem 6.20. That is, show that if Λ is a normal logic that is sound and
strongly complete with respect to a ﬁrst-order deﬁnable class of models M, then Λ is also
sound and strongly complete with respect to the class of all countable models in M. (Hint:
use the standard translation and the Downward Löwenheim-Skolem Theorem.)
6.4 Decidability via Quasi-models and Mosaics
In this section we will show that such familiar techniques as ﬁltration can be em-
ployed to prove decidability, even for logics lacking the ﬁnite model property. The
key move is simply to think more abstractly: instead of trying to work with ﬁnite
models themselves, we will work with ﬁnite structures which encode information
about models.
Quasi-models for KvB
For our ﬁrst example we will re-examine the logic KvB, which we proved de-
cidable in the previous section via interpretation in S2S. Recall that KvB is the
logic of a single general frame J whose universe J is N ∪ {ω, ω + 1}, and whose
accessibility relation is R. Also recall that KvB is an incomplete logic, which im-
plies that it does not have the ﬁnite model property. Nonetheless, we can establish
the decidability of KvB using a ﬁltration argument. We cannot use ﬁltration to
build a ﬁnite KvB model (no such model exists), but we can use it to build a ﬁnite
quasi-model.
Consider a model M = (J, R, V ), where V is an admissible valuation for J.
What kind of ﬁltration seems natural for this structure? If it were not for the point
ω + 1, it is obvious that we would go for the transitive ﬁltration. Very well then
– let us adopt the following procedure: ﬁrst delete the point ω + 1, then take the
transitive ﬁltration of the remainder of the frame, and ﬁnally glue a copy of the
point ω + 1 back on to the resulting ﬁnite structure. Of course, we know that this
will not result in a ﬁnite KvB model; but hopefully it will yield something from
which we can construct a KvB model.
First we need the notion of a closure of a set of sentences. We will not ﬁltrate
through arbitrary subformula-closed sets of sentences; rather, we will insist on
working with sets of sentences that are closed under single negations as well.
Deﬁnition 6.23 (Closed Sets and Closures) A set of formulas Σ is said to be
closed if it is closed under subformulas and single negations. That is, if σ ∈ Σ and
θ is a subformula of σ, then θ ∈ Σ; and moreover if σ ∈ Σ, and σ is not of the
form ¬θ, then ¬σ ∈ Σ.
If Γ is a set of formulas, then Cl(Γ ), the closure of Γ , is the smallest closed set
of formulas containing Γ . Note that if Γ is ﬁnite then so is Cl(Γ ). If Γ = {φ},6.4 Decidability via Quasi-models and Mosaics
357
where φ is any modal formula, then we usually write Cl(φ) for Cl({φ}) and call
this set the closure of φ.
Advanced track readers should note that they have already met a more elaborate
version of this idea when we proved the completeness of PDL: any Fischer-Ladner
closed set (see Deﬁnition 4.79) is closed in the sense of the previous deﬁnition.
Now for quasi-models. Let φ be some basic modal formula. A KvB quasi-
model for φ is a pair Q = (F, λ) where:
(i) F = (Q, S) is a ﬁnite frame, containing two distinct distinguished points
called c and ∞, that satisﬁes conditions F1–F5 below; and
(ii) λ is a function mapping states of F to subsets of Cl(φ) that satisﬁes the
conditions L0–L3 below. We call λ a labeling.
Let us ﬁrst consider the conditions F1–F5. These are very simple, and should be
checked against Figure 6.2. If you read c as ‘co-ﬁnite’ and view this element as the
quasi-model’s analog of ω, and view ∞ as the analog of ω + 1, the resemblance
between ﬁnite frames fulﬁlling these conditions and the frame (J, R) should be
clear.
(F1) On Q \ {∞}, S is trichotomous and transitive,
(F2) Scw iff w = ∞,
(F3) Swc iff w = c or w = ∞,
(F4) S∞w iff w = c, and
(F5) Sw∞ for no w in Q.
Note that c is reﬂexive. Intuitively, the ﬁltration process described above squashes
ω down into a cluster.
There are also conditions on the labeling. One of these conditions is that every
label should be a Hintikka set. This is an important concept, and one we will use
again later in this chapter.
Deﬁnition 6.24 (Hintikka Sets) Let Σ be a subformula closed set of formulas.
A Hintikka set H over Σ is a maximal subset of Σ that satisﬁes the following
conditions:
(i) ⊥ ∈ H.
(ii) If ¬φ ∈ Σ, then ¬φ ∈ H iff φ ∈ H.
(iii) If φ ∧ ψ ∈ Σ, then φ ∧ ψ ∈ H iff φ ∈ H and ψ ∈ H.
It is important to realize that Hintikka sets also satisfy conditions such as the fol-
lowing: if φ ∨ ψ ∈ Σ, then φ ∨ ψ ∈ H iff φ ∈ H or ψ ∈ H. This is because in
this book we deﬁne ∨ (and also →, ↔, and ) in terms of ⊥, ¬, and ∧ (see Deﬁ-
nition 1.12). Hintikka sets need not be satisﬁable (the reader is asked to construct358
6 Computability and Complexity
a non-satisﬁable Hintikka set in Exercise 6.4.2) but items (i) and (ii) above guar-
antee that they contain no blatant propositional contradictions. If a Hintikka set
is satisﬁable we call it an atom. Note that both the MCSs used to build canonical
models, and the special atoms used to prove the completeness of PDL are examples
of (consistent) Hintikka sets.
We are now ready for the quasi-model labeling conditions:
(L0) φ ∈ λ(w) for some w ∈ Q,
(L1) λ(w) is a Hintikka set, for each w ∈ Q,
(L2) for all 3ψ ∈ Cl(φ), 3ψ ∈ λ(w) iff ψ ∈ λ(v) for some v with Swv,
(L3) if 3ψ ∈ λ(w), then ψ ∈ λ(v) for some v with Swv and not Svw.
We take the size of a quasi-model (Q, S, λ) to be the size of its universe Q.
Lemma 6.25 Let φ be a formula in the basic modal language. Then φ is satisﬁable
in J if and only if there is a quasi-model for φ, of size at most 2|φ| .
Proof. We leave it to the reader to prove the left to right direction; this is simply a
matter ﬁlling in the details of the ‘delete ω + 1, ﬁltrate, glue ω + 1 back on’ strategy
sketched above (the ﬁltration must be made through Cl(φ)) and the upper bound
on the size of the quasi-model follows as in any ﬁltration argument. So let us look
at the right to left direction.
Let Q = (Q, S, λ) be a quasi-model for φ, let c and ∞ be the distinguished
points of the quasi-model, and let Q0 denote the set Q \ {∞}. We now deﬁne an
equivalence relation ∼0 on Q0 by
w ∼0 v iff w = v or (Swv and Svw).
This really is an equivalence relation, and a more-or-less familiar one at that: the
equivalence class w̄ containing a reﬂexive point w is simply the cluster that w be-
longs to (see Deﬁnition 4.55), while the equivalence class w̄ containing an irreﬂex-
ive point w is simply {w}. The equivalence classes on Q0 are naturally ordered by
the relation + deﬁned as follows:
w̄ + v̄ iff Swv and not Svw.
It follows from F1 that + is a strict total ordering. Now consider an enumeration
q0 , q1 , . . . , qN of the elements of Q0 , such that q ﬁrst enumerates all elements of
the leftmost equivalence class, then all elements of its rightmost neighbor, and so
on. We may extend this enumeration to a map f : J → Q by putting
⎧
⎨ qw if w ≤ N ,
f (w) =
c
if w > N or w = ω,
⎩
∞ if w = ω + 1.
It is straightforward to check that for all w, v in J, Rwv implies Sf (w)f (v).6.4 Decidability via Quasi-models and Mosaics
359
Consider, for instance, the case where w = ω; Rwv implies that v = n for some
natural number n. But then f (w) = c and f (v) ∈ Q0 , so Sf (w)f (v) follows from
F2. The other cases are left to the reader. What we have shown is that
f is a homomorphism mapping (J, R) onto (Q, S).
(6.4)
Now consider the following valuation V on (J, R):
V (p) = {w ∈ J | p ∈ λ(f (w))}.
It is easy to see that V is admissible in the general frame J: if ω ∈ V (p) then by
deﬁnition of V , n ∈ V (p) for all n > N , so V (p) is co-ﬁnite.
Hence, in order to prove the lemma, it is sufﬁcient to show that φ holds some-
where in the model (J, V ); but this follows from L0 and the following claim:
for all ψ ∈ Cl(φ), and all w ∈ J: J, V, w  ψ iff ψ ∈ λ(f (w)).
(6.5)
We will prove this claim by induction on the complexity of ψ. The base case, where
ψ is a propositional variable, holds by deﬁnition of V , and the induction step for
the boolean connectives is trivial since λ labels with Hintikka sets only. Hence,
the only interesting case is where ψ is of the form 3χ. Note that the inductive
hypothesis applies to χ and that χ ∈ Cl(φ) since the set is closed under taking
subformulas.
First assume that J, V, w  3χ. There is a state v with Rwv and v  χ.
By the fact that f is a homomorphism it is immediate that Sf (w)f (v), while the
inductive hypothesis implies that χ ∈ λ(f (v)). From this and L2 it follows that
3χ ∈ λ(f (w)).
Now suppose, in order to prove the other direction of (6.5), that 3χ ∈ λ(f (w)).
We have to show that J, V, w  3χ. Distinguish the following cases:
(i) w = ω + 1. From this it follows that f (w) = ∞, so from L2 and the fact
(F4) that c is the only successor of ∞, it follows that χ ∈ λ(c). Hence from
c = f (ω) and the inductive hypothesis it follows that ω  χ. But then it is
immediate that ω + 1  3χ.
(ii) w = ω + 1. By L3 we may assume the existence of an element q ∈ Q
satisfying Sf (w)q, not Sqf (w) and χ ∈ λ(q). It is obvious from Sf (w)q
and F 5 that q = ∞. Let v be a pre-image of q; from q = ∞ it follows
that v = ω + 1. Since R is trichotomous on J \ {ω + 1}, we have Rvw
or w = v or Rwv. The ﬁrst two options are impossible: Rvw would imply
Sf (v)f (w), while w = v is incompatible with the fact that Sf (v)f (w) but
not Sf (w)f (v). Hence, we ﬁnd that Rwv; but the induction hypothesis
gives v  χ, so indeed we have w  3χ.
This ﬁnishes the proof of (6.5) and hence, of the lemma.360
6 Computability and Complexity
Theorem 6.26 The logic KvB is decidable.
Proof. By Lemma 6.25 it sufﬁces to show that it is decidable whether there is a
quasi-model for φ of size not exceeding 2|φ| . But this is easy to see: we ﬁrst
make a ﬁnite list of all triples (Q, S, λ) such that |Q| ≤ 2|φ| , S ⊆ Q × Q and
λ : Q → P(Cl(φ)); we then check for each member of this list whether it is a
quasi-model for φ. And clearly it is possible to write a terminating program which
does this.
The important lesson is that in order to prove decidability of a logic, not only ﬁnite
models are useful: rather, any ﬁnite structure that encodes a model is potentially
valuable. Now, the ﬁnite structure employed in the previous example was still very
much like a model – as our name ‘quasi-model’ indicates – but in the general case
one can push the idea much further. The satisﬁability of φ does not need to be
witnessed by a ﬁnite model for φ, or indeed by anything that looks very much like
a model; all we need is a ﬁnite toolkit which contains the instructions needed to
construct a model for φ. The concept of a mosaic develops this line of thought.
Mosaics for the tense logic of the naturals
Consider the frame N = (N, <) with < the standard ordering of the natural num-
bers, and let Kt N be its tense logic. Kt N does not have the ﬁnite model property
(see Exercise 6.4.1), but it is decidable, as we will now show using mosaics.
We use the following terminology and notation. For a given formula φ in the
basic temporal similarity type, let Cl(φ) denote the smallest set containing φ, P 
and F  which is closed under taking subformulas and single negations (cf. 4.79).
Deﬁnition 6.27 (Bricks) A brick is a pair b = (Φ, Λ) such that Φ and Λ are
Hintikka sets satisfying
(B0) if F ψ or ψ belongs to Λ, then F ψ ∈ Φ,
(B1) if P ψ or ψ belongs to Φ, then P ψ ∈ Λ.
(B2) F  ∈ Λ.
A brick is called small if it satisﬁes, in addition:
(B3) if F ψ ∈ Φ, then either ψ or F ψ is in Λ,
(B4) if P ψ ∈ Λ, then either ψ or P ψ is in Φ.
What we are really interested in are sets of bricks satisfying certain saturation con-
ditions. A brick set B is a saturated set of bricks for φ (in short: a φ-SSB) if it
satisﬁes
(S0) for some (Φ, Λ) ∈ B, ¬P  ∈ Φ and φ ∈ Λ ∪ Φ,
(S1) for all (Φ, Λ) ∈ B, if F ψ ∈ Λ then there is a (Λ, Γ ) ∈ B with ψ ∈ Γ ,6.4 Decidability via Quasi-models and Mosaics
361
(S2) for all (Φ, Λ) ∈ B there is a path of small bricks leading from Φ to Λ.
Here we say that a path of (small) bricks from Φ to Λ is a sequence (Φ0 , Λ0 ), . . . ,
(Φn , Λn ) (n ≥ 0) of (small) bricks such that Φ = Φ0 , Λ = Λn and Λi = Φi+1
for all i < n. Finally, we simply deﬁne the size of an SSB B to be the number of
bricks in B.
The best way of grasping the intuitive meaning of these notions is by reading the
proof of the next lemma.
Lemma 6.28 If φ is satisﬁable in N, then there is a φ-SSB of size at most 22|φ| .
Proof. Assume that we have a valuation V on N such that φ is satisﬁed in the
model (N, V ). For any number n, let Γn denote the truth set of n:
Γn = {ψ ∈ Cl(φ) | N, V, n  ψ}.
Deﬁne B as the set
B = {(Γn , Γm ) | n < m},
and call a brick sequential if it is of the form (Γn , Γn+1 ) for some number n. We
claim that B is a saturated set of bricks for φ.
We ﬁrst show that all elements of B are indeed bricks. Let (Γn , Γm ) with n < m
be an arbitrary element of B. For B0, assume that F ψ or ψ belongs to Γm for some
m > n; we have to prove that F ψ ∈ Γn . But from the assumption it easily follows
that N, V, k  ψ for some k ≥ m, and transitivity of the ordering gives k > n. So
it holds that N, V, n  ψ, immediately yielding, as required, that F ψ ∈ Γn . B1 is
proved in a similar way, and B2 is trivial to show.
It is likewise straightforward to prove the saturation conditions. For example,
in order to prove S0, let k be the point where φ is true, and consider the brick
(Γ0 , Γn0 ) if n0 > 0, or the brick (Γ0 , Γ1 ) in case n0 = 0. It is immediate from
the deﬁnitions and assumptions that ¬P  ∈ Γ0 and φ ∈ Γ0 ∪ Γ1 . Proving S2
is straightforward from the observation that sequential bricks are small, and to see
why that is the case, take an arbitrary sequential brick (Γn , Γn+1 ). We only discuss
B3: assume that F ψ ∈ Γn . By deﬁnition, N, V, n  F ψ, so there must be some
m > n with m  ψ. Note that either m = n + 1 or m > n + 1; in the ﬁrst case,
we obtain ψ ∈ Γn+1 , in the second, F ψ ∈ Γn+1 . In either case we have B3.
Finally, the collection {Γn | n ∈ N} is a subset of the power set of Cl(φ),
whence its cardinality does not exceed 2|φ| ; but then the size of B can be at most
(2|φ| )2 = 22|φ| .
We now show that we have recorded enough information in the deﬁnition of a
saturated set of bricks for φ to construct an N-based model for φ.
Lemma 6.29 If there is a φ-SSB, then φ is satisﬁable in N.362
6 Computability and Complexity
Proof. Assume that B is a saturated set of bricks for φ. We will use these bricks to
build, step by step, the required model for φ. As usual, in each ﬁnite stage of the
construction we are dealing with a ﬁnite approximation of this model: a history is a
pair (L, λ) such that L is a natural number and λ is a function on the set {0, . . . , L}
to the set of Hintikka sets. Such a history (L, λ) is supposed to satisfy the following
constraints:
(H0) ¬P  ∈ λ(0),
(H1) for all m with m < L, (λ(m), λ(m + 1)) is a small brick.
We leave it to the reader to verify that any history (L, λ) has the following proper-
ties:
(H2) if F ψ ∈ λ(n) for some n < L, then there is some m with n < m ≤ L and
ψ ∈ λ(m), or otherwise F ψ ∈ λ(L),
(H3) if P ψ ∈ λ(n) for some n ≤ L, then there is some m with m < n and
ψ ∈ λ(m).
The importance of the properties H2 and H3 is that they show that the only essential
shortcomings of a history (regarded as a ﬁnite approximation of a model) are of the
form ‘F ψ ∈ λ(L), and there is no witness for this fact; that is, no m > L such that
ψ ∈ λ(m).’
Of course, we are not going to use histories in isolation; we say that one history
(L , λ ) is an extension of another history (L, λ), notation: (L, λ)  (L , λ ), if
L < L , while λ and λ agree on the domain of λ. The crucial extension lemma of
the step-by-step construction is given in the following claim:
Every history (L, λ) with F ψ ∈ λ(L)
has an extension (L , λ ) such that ψ ∈ λ (L ).
(6.6)
To prove (6.6), let (L, λ) be a history and ψ a formula such that F ψ ∈ λ(L). It
follows from H1 that (λ(L − 1), λ(L)) is a brick, so by S1 there is a brick (Φ, Λ)
in B such that Φ = λ(L) and ψ ∈ Λ. We now use S2 to ﬁnd a path of small bricks
(Σ0 , Σ1 ), (Σ1 , Σ2 ), . . . , (Σk−1 , Σk ), such that Σ0 = Φ and Σk = Λ. Obviously
we are going to ‘glue’ this path to the old history, thus creating a new history
(L , λ ). To be precise, L is deﬁned as L = L + k, while λ is given by
λ (n) =
λ(n) if n ≤ L,
Σi
if n = L + i.
With this deﬁnition (L , λ ) satisﬁes the condition of (6.6).
Using (6.6), by a standard step-by-step construction one can deﬁne a sequence
(L0 , λ0 )  (L1 , λ1 )  . . . of histories such that ¬P  ∈ λ0 (0) and φ ∈ λ0 (0) ∪
λ(L0 ), while for each i and each formula F ψ ∈ λi (Li ) there is a j > i and a
number Li < m ≤ Lj such that ψ ∈ λj (m). This sequence of nested histories will6.4 Decidability via Quasi-models and Mosaics
363
be our guideline for the deﬁnition of a valuation on N. Note that for all formulas
ψ and all i and n, we have that
if n ≤ Li , then ψ ∈ λi (n) iff ψ ∈ λj (n) for all j ≥ i.
In other words, the histories always agree where they are deﬁned; this fact will be
used below without explicit comment.
Now consider the following valuation V on N:
V (p) = {n ∈ N | p ∈ λi (n) for some i}.
We are now ready to prove the crucial claim of this lemma.
For all ψ ∈ Cl(φ) and all n: N, V, n  ψ iff ψ ∈ λi (n) for some i.
(6.7)
Obviously, (6.7) will be proved by induction on ψ. The base step and the boolean
cases of the induction step are straightforward and we leave them to the reader; we
concentrate on the modal cases.
First assume that ψ is of the form F χ. For the direction from left to right,
assume that N, V, n  F χ. There must be a number m > n with m  χ; so by the
inductive hypothesis, there is an i with χ ∈ λi (m). It is easy to show (by backward
induction and H1) that this implies F χ ∈ λi (k) for all k with n ≤ k < m.
For the other direction, assume that F χ ∈ λi (n) for some i. It follows from H2
that there is either a number m with n < m ≤ Li and χ ∈ λi (m), or otherwise
F χ ∈ λi (Li ). In the ﬁrst case we use the inductive hypothesis to establish that
m  χ and hence, n  F χ. Hence, assume that we are in the other case: F χ ∈
λi (Li ). Now our sequence of histories is such that this implies the existence of a
history (Lj , λj ) with j > i and such that χ ∈ λj (m) for some m with Li , m ≤ Lj .
It follows from the inductive hypothesis that m  χ; thus the truth deﬁnition gives
us that n  F χ.
Now assume that ψ is of the form P χ. The direction from left to right is as in
the previous case. For the other direction, assume that P χ ∈ λi (n) for some i; it
follows by H3 that there is an m < n with χ ∈ λi (m). The inductive hypothesis
yields that M, V, m  χ, so by the truth deﬁnition we get n  F χ.
Theorem 6.30 Kt N is decidable.
Proof. Immediate by Lemmas 6.28 and 6.29, and the obvious fact that it is decid-
able whether there is a φ-SSB of size at most 22|φ| .
A wide range of modal satisﬁability problems can be studied in using quasi-models
and mosaics. Indeed, such methods are not only useful for establishing decidability
results, they can be used to obtain complexity results as well; see the Notes for
further references.6 Computability and Complexity
364
Exercises for Section 6.4
6.4.1 Prove that K t N does not have the ﬁnite model property.
6.4.2 Give an example of an unsatisﬁable Hintikka set. (Hint: work with the closure of
{2(p ∧ q), ¬2p, ¬2q}.)
6.4.3 Extend our proof of the decidability of the tense logic of the natural numbers to a
similarity type including the next time operator X. The semantics of this operator is given
by
(N, V ), n  Xφ iff (N, V ), n + 1  φ.
6.4.4 Let F2 be the class of frames for the basic modal similarity type in which every point
has exactly two successors. Use a mosaic argument to prove that this class has a decidable
satisﬁability problem.
6.4.5 In this exercise we consider a version of deterministic PDL in which every program
is interpreted as a partial function – at least, in the intended semantics. The syntax of this
language is given by
φ
π
::= p | ⊥ | ¬φ | φ1 ∧ φ2 | πφ (p a proposition letter),
::= a | π1 ; π2 | if(φ, π1 , π2 ) | repeat(π, φ) (a an atomic program).
In a regular model M for this language, each relation R a is a partial function, and the com-
posed programs obtain the obvious interpretation. That is, R π1 ;π2 is the relational compo-
sition of Rπ1 and Rπ1 ; Rif (φ,π1 ,π2 ) st holds if either M, s  φ and R π1 st or else M, s  φ
and Rπ2 st. Finally, we have R repeat(π,φ) st if there is a path sRπ t1 Rπ t2 . . . Rπ tn = t of
length n ≥ 1 from s to t such that t = t n is the ﬁrst ti where φ holds.
(a) Prove that in a regular model, each program π is interpreted as a partial function.
(b) Prove that the class of regular models has a decidable theory over this language.
(Hint: use bricks of the form (Φ, Λ, Π) where Φ and Λ are Hintikka sets and Π is
a set of programs closed under some natural conditions associating a unique ‘ﬁrst’
atomic program with the brick. Also, make sure that any formula πφ ∈ Φ induces
a unique formula of the form aφ  ∈ Φ.)
6.5 Undecidability via Tiling
There are lots of undecidable modal logics; indeed, even uncountably many with
the polysize model property (see Exercise 6.2.4). Moreover, there are undecid-
able modal logics which in many other ways are rather well-behaved (we saw an
example in Exercise 6.2.5). Nice as they are, these examples do not really make
clear just how easily undecidable modal logics can arise, nor how serious the un-
decidability can be. This is especially relevant if we are working with the richer
modal languages (such as PDL) typically used in computer science and other appli-
cations, and the ﬁrst goal of this section is to show that natural (and on the face of it,
straightforward) ideas can transform simple decidable logics into undecidable (or
even highly undecidable) systems. While the examples are interesting in their own
right, this section has a second goal: to introduce the concept of tiling problems.6.5 Undecidability via Tiling
365
Given a modal satisﬁability problem S, to prove that S is undecidable we must
reduce some known undecidable problem U to S. But which problems are the
interesting candidates for reduction? Unsurprisingly, there is no single best answer
to this question. As with decidability proofs, proving undecidability is something
of an art: it can be very difﬁcult, and there is no substitute for genuine insight
into the satisﬁability problem. Certain problems lend themselves rather naturally
to modal logic, and tiling problems are a particularly nice example.
What is a tiling problem? In essence, a jigsaw puzzle. A tile T is simply a 1 × 1
square, ﬁxed in orientation, each side of which has a color. We refer to these four
colors as right(T ), left(T ), up(T ), and down(T ). Figure 6.3 depicts an example.
(We have used different types of shading to represent the different colors.)
@
@
@
@
ssss
ssss
@ ssssss @
@ ssssss @
@
@
@s
@
@
ss
sss@
@
@
@
@
s
@
@ s s s@
@
@
@
Fig. 6.3. Six distinct tile types
Six tiles are shown in Figure 6.3. Note that if we rotated the third tile 180
degrees clockwise, it would look just like the fourth tile, and that if we rotated the
ﬁrst tile 180 degrees clockwise it would look just like the sixth tile. We ignore
such similarities. (This is what we meant when we said that tiles are ‘ﬁxed in
orientation.’) That is, the diagram shows six distinct types of tile.
Now for a simple tiling problem:
Is it possible to arrange tiles of the type just shown on a 2 × 4 grid in such a
way that adjacent tiles have the same color on the common side?
A little experimentation shows that this is possible. A solution is given in Fig-
ure 6.4.
ssss
@ ssssss @
@
@
@
@s
@
@
ss
ssss@
@
@
@
s
s
s
@
@
@
@
sssssss
@
@ sss
@
@
@s
@
@
@
s ss
@
@
@
ssss@
s@
s
@
@
@
Fig. 6.4. A 2 × 4 tiling
This simple idea of pattern-matching underlying tiling problems gives rise to a
family of problems which can be used to analyze computational complexity and
demonstrate undecidability. This is the general form that tiling problems take:366
6 Computability and Complexity
Given a ﬁnite set of tile types T , can we cover a certain part of Z × Z in such
a way that adjacent tiles have the same color on the common edge? (Below,
covering a grid with tiles so that adjacent colors match will be called ‘tiling.’)
Some tiling problems impose additional constraints on what counts as a successful
tiling (we will shortly see an example) and some are formulated as games to be
played between two players (we will see an example at the end of this chapter).
To spell this out somewhat, we might describe our previous example as an in-
stance of the 2 × 4 tiling problem. That is, we were given a ﬁnite set of tile types
(six, to be precise), asked to tile a 2 × 4 grid, and no further constraints were im-
posed. In the remainder of this section, we are going to make use of two much
harder tiling problems. The ﬁrst is the:
N × N tiling problem. Given a ﬁnite set of tile types T , can T tile N × N?
Here is a simple instance of this problem: can we tile N × N using the six tile types
shown? Of course! We need simply ‘slot-together’ copies of our solution to the
2 × 4 problem.
In general, however, the N × N tiling problem is hard, and in fact it is known to
be undecidable. Indeed, this problem is Π10 -complete; that is, it is a paradigmatic
example of ‘ordinary undecidability.’ (See Appendix C for further discussion of
degrees of undecidability.) We will not prove this result here – see the Notes for
references – but it is really quite straightforward: think of each row of tiles as
encoding Turing machine tapes and states, and the matching process as governing
the state transitions.
The second problem we will use is the:
N × N recurrent tiling problem. Given a ﬁnite set of tile types T , which
includes some distinguished tile type T1 , can T tile N × N in such a way that
T1 occurs inﬁnitely often in the ﬁrst row?
As an easy example, note that our previous six tile types recurrently tile N × N
when either the ﬁrst, the third, the fourth, or the sixth tile type is distinguished.
Now our new problem is just the N × N tiling problem with an additional con-
straint imposed – but what a difference this constraint makes! Not only is this
problem undecidable, it is Σ11 -complete (again, see Appendix C).
We will prove two modal undecidability results with the aid of these problems.
Both examples are based around a natural variant of Deterministic Propositional
Dynamic Logic, with intersection replacing choice and iteration as program con-
structors; we call this variant KR. We obtain our undecidability results as follows.
First we enrich KR with the global modality. As we will show, the combination of
the intersection construct with the global modality is a powerful one: it is possible
to give an extremely straightforward reduction of the N × N tiling problem. We6.5 Undecidability via Tiling
367
then enrich KR with a modality called the master modality. This is also a natural
operator – indeed, perhaps more natural than the global modality. As a very easy
reduction from the N × N recurrent tiling problem reveals, the resulting system is
highly undecidable.
Intersection and the global modality
Our ﬁrst example vividly illustrates how easily undecidability can arise. We are
going to mix two simple ingredients together, both of which are decidable, and
show that the result has an undecidable satisﬁability problem.
The ﬁrst ingredient is a variant of DPDL, with intersection replacing choice and
iteration as program constructors. Recall from Example 1.15 that DPDL is simply
PDL interpreted over deterministic PDL structures (that is, PDL structures in which
the relations Ra corresponding to atomic programs a are partial functions). Further,
recall from Example 1.26 that modalities built with the intersection constructor
(that is, modalities of the form π1 ∩ π2 ) are interpreted by the relation Rπ1 ∩ Rπ2 ,
where Rπ1 is the relation corresponding to π1  and Rπ2 the relation corresponding
to π2 .
In what follows we will not use the entire language; instead we will work with a
fragment (called KR) which consists of all formulas without occurrences of ∗ and
∪. That is, KR contains precisely the following formulas φ:
φ ::= p | ⊥ | ¬φ | φ1 ∧ φ2 | πφ
π ::= a | π1 ; π2 | π1 ∩ π2
(p a proposition letter),
(a an atomic program).
The KR language is rather simple: essentially it allows us to state whether or not
different sequences of (deterministic) programs terminate in the same state when
executed in parallel. Note that (over deterministic PDL structures) a selection argu-
ment immediately shows that KR has a decidable satisﬁability problem. Over deter-
ministic structures, every modal operator in KR is interpreted by a partial function.
(This is because all atomic programs are modeled by partial functions, and the only
program constructors we have at our disposal are composition and intersection.) It
follows that if a sentence φ from KR is satisﬁable in a deterministic model, then it
is satisﬁable in a ﬁnite deterministic model; the proof is essentially the same as that
of Corollary 6.9.
The second ingredient is even simpler. We are going to add the global modality
A to our fragment. This is an interesting operator that we are going to discuss
in detail in Section 7.1; for present purposes we only need to know two things
about it. First, it is interpreted as follows: M, w  Aφ if for all v in M we have
M, v  φ. Thus, as its name suggests, the global modality is a modal operator
which allows us to express global facts. Second, A has a decidable satisﬁability368
6 Computability and Complexity
problem. (To see this, simply observe that A is an S5 operator, and we know that
S5 is decidable.) Thus, on its own, A is pretty harmless.
But what happens when we add A to KR? The resulting language called KRA can
talk about computations in a very natural (and very powerful) way. For example,
A(a → ψ)
expresses that in every state of a computation, ψ is a precondition for the program
a to have a terminating execution. As we will now show, KRA has crossed the
border into undecidability.
Theorem 6.31 Assume that the language has at least two atomic programs. Then
the satisﬁability problem for KRA is undecidable. To be precise, it is Π10 -hard.
Proof. We show this by reducing the N × N tiling problem to the KRA satisﬁability
problem; the undecidability (and Π10 -hardness) of the satisﬁability problem will
follow from the known undecidability (Π10 -hardness) of the N × N tiling problem.
Recall that the N×N tiling problem asks: given a ﬁnite set of tile types T , can T
tile N × N? Putting this more formally: does there exist a function t : N × N → T
such that
right (t(n, m)) = left(t(n + 1, m)),
up(t(n, m)) = down(t(n, m + 1))?
We will reduce N × N tiling to the satisﬁability problem as follows. Let T =
{T1 , . . . , Tk } be the given set of tile types. We will construct a formula φT such
that
T tiles N × N iff φT is satisﬁable.
(6.8)
If we succeed in constructing such a formula it follows that the KRA-satisﬁability
problem is undecidable. (For suppose it was decidable. Then we could solve the
N × N tiling problem as follows: given T , form φT , and use the putative KRA-
satisﬁability algorithm to check for satisﬁability. By (6.8) this would solve the
tiling problem – which is impossible.)
The construction of φT proceeds in three steps. First, we show how to use KRA
to demand ‘gridlike’ models. Second, we show how to use KRA to demand that a
tiling exists on this ‘grid.’ Finally we prove (6.8).
Step 1. Forcing the grid. The basic idea is to let the nodes in M mimic the nodes
in N × N, and to use two relations Rr and Ru to mimic the ‘to-the-right’ and the
‘up’ functions of N × N. To get the gridlike model we want, we simply demand
that Rr and Ru commute:
φgrid := A(r ; u) ∩ (u ; r).6.5 Undecidability via Tiling
369
This says that everywhere in the model it is possible to make a ‘to-the-right transi-
tion followed by an up transition’ and an ‘up transition followed by a to-the-right
transition,’ and both these transition sequences lead to the same point. (Note that
this is all we need to say, since by assumption Rr and Ru are partial functions.)
Step 2. Tiling the model. We will ‘tile the model’ by making use of proposition
letters t1 , . . . , tk which correspond to the tile types in T . The basic idea is simple:
we want ti to be true at a node w iff a tile of type Ti is placed on w. Of course, not
any placement of tiles will do: we want a genuine tiling. But the following three
demands ensure this:
(i) Exactly one tile is placed at each node:
⎛
⎞
k

φ1 := A ⎝ ti ∧
¬(ti ∧ tj )⎠ .
i=1
1≤i<j≤k
(ii) Colors match going right:
⎛⎞
φ2 := A ⎝(ti ∧ rtj )⎠ .
right (Ti )=left (Tj )
(iii) Colors match going up:
⎛⎞
φ3 := A ⎝(ti ∧ utj )⎠ .
up(Ti )=down (Tj )
Putting this together, we deﬁne φT := φgrid ∧ φ1 ∧ φ2 ∧ φ3 .
Step 3. Proving the equivalence. We now show that (6.8) holds. Assume ﬁrst
that t : N × N → T is a tiling of N × N. Construct a satisfying model for φT as
follows:
W
= {wn,m | n, m ∈ N},
Rr = {(wn,m , wn+1,m ) | n, m ∈ N},
Ru = {(wn,m , wn,m+1 ) | n, m ∈ N},
V (ti ) = {wn,m | n, m ∈ N and t(n, m) = Ti }.
Clearly, φT holds at any state w of M.
For the converse, let M be a model such that M, w0  φT . It follows from
M, w0  φgrid that there exists a function f : N × N → W such that f (0, 0) = w0 ,
Rr f (n, m)f (n + 1, m) and Ru f (n, m)f (n, m + 1). Deﬁne the tiling t : N × N →
T by
t(n, m) = Ti iff M, f (n, m)  ti .
By φ1 , t is well-deﬁned and total. Moreover, if t(n, m) = Ti and t(n+1, m) = Tj ,370
6 Computability and Complexity
then Rr f (n, m)f (n + 1, m), and both M, f (n, m)  ti and M, f (n + 1, m) 
tj . Given that w0 satisﬁes φ2 , we conclude that right(Ti ) = left(Tj ). Similarly,
because of φ3 , if t(n, m) = Ti and t(n, m + 1) = Tj , then up(Ti ) = down(Tj ).
Thus, T tiles N × N.
The above proof clearly depends on having two deterministic atomic programs at
our disposal. But what happens if we only have one? It should be clear that then
∩ cannot do any interesting work for us, and in fact the language has a decidable
satisﬁability problem; see Exercise 6.5.1.
We now know that KRA-satisﬁability is undecidable (given more than one atomic
program) but how undecidable is it? In particular can we also prove a Π10 upper
bound to match the Π10 -hardness result? (That is, can we show that we are dealing
with a case of ‘ordinary undecidability’?) To prove this, it sufﬁces to show that the
validities of KRA form an r.e. set. Now we could do this by devising a recursive
axiomatization of the KRA-validities, but by making use of a general lemma from
correspondence theory we can establish the result more straightforwardly.
Lemma 6.32 If K is a class of frames deﬁned by a ﬁrst-order formula, then its
modal logic is recursively enumerable.
Proof. Assume that the ﬁrst-order formula α deﬁnes K, where α is built using only
relation symbols of arity 2 or higher, and identity. Then, a modal formula φ is valid
on K iff it is valid on all frames in K iff
α |= ∀x∀P1 . . . ∀Pn ST x (φ),
(6.9)
where P1 , . . . , Pn are unary predicate symbols corresponding to the proposition
letters in φ. As the predicate variables P1 , . . . , Pn do not occur in α, (6.9) is
equivalent to α |= ∀x ST x (φ). But this is an ordinary ﬁrst-order implication,
which is an r.e. notion. Hence, modal validity on K is an r.e. notion as well.
Theorem 6.33 Assume that our language has at least two, but at most ﬁnitely
many atomic programs. Then the satisﬁability problem for KRA is Π10 -complete.
Proof. The Π10 lower bound is given by the encoding of the N × N tiling problem
in the proof of Theorem 6.31. For the Π10 upper bound we show that the validity
problem for KRA is r.e. The standard translations for the constructors ; and ∩ are
given in Section 2.4; both are ﬁrst-order. (Recall that the ∗ constructor is the only
part of PDL that takes us out of ﬁrst-order logic.) The standard translation for A is
obvious (and clearly ﬁrst-order):
ST x (Aφ) = ∀y ST y (φ).
Thus – assuming we are working with a language of KRA that contains at most6.5 Undecidability via Tiling
371
ﬁnitely many atomic programs – the required class of frames is deﬁned by

∀xyz (Rα xy ∧ Rα xz → y = z).
α atomic
Hence, by Lemma 6.32, the modal logic of the class of frames for KRA is r.e. as
required.
Intersection and the master modality
Our next example illustrates how easily high undecidability can arise. Once again,
we will enrich the KR language, but this time with the master modality. As we will
see, the resulting language KR[∗] has a Σ11 -complete satisﬁability problem.
Like the global modality, the master modality [∗] is a tool for expressing general
constraints in the object language, but it works rather differently. A formula of
the form [∗]φ is true at a node w iff φ is true at all nodes reachable by any ﬁnite
sequence of atomic transitions from w. Formally,

∗
w  [∗]φ iff v  φ for all v such that (w, v) ∈
Ra
.
a atomic
That is, [∗] explores the reﬂexive transitive closure of the union of all the relations
used to interpret the atomic programs. If we only have ﬁnitely many atomic pro-
grams a1 , . . . , an , the master modality is simply shorthand for the PDL modality
[(a1 ∪· · ·∪an )∗ ]. From a computational perspective, this modality is arguably even
more natural than the global modality: it is a way of looking at what must happen
throughout the space of possible computations. (It has other natural interpretations
as well. For example, if we interpret our basic modalities as in multi-agent epis-
temic logic – that is, [a]φ means ‘agent a knows that φ’ – then [∗] is the ‘common
knowledge’ operator.)
But, for all its naturalness, the master modality can be extremely dangerous.
Let us see what happens when we add it to KR. First, observe that KR[∗] must
be undecidable. (There is nothing new to prove here; simply observe that if we
systematically replace every occurrence of A in the proof of Theorem 6.31 by
[∗], the argument still goes through.) But can we prove a matching Π10 upper
bound? We certainly cannot appeal to Lemma 6.32; while the global modality
was essentially ﬁrst-order, the master modality is not. (As with the ∗ constructor
of PDL, its natural correspondence language is inﬁnitary; see Section 2.4.) And
indeed, any attempt to recursively enumerate the validities of KR[∗] is bound to
fail.
Theorem 6.34 The satisﬁability problem for KR[∗] is highly undecidable. To be
precise, it is Σ11 -hard.372
6 Computability and Complexity
Proof. We show this by reducing the recurrent tiling problem to the KR[∗]-satisﬁa-
bility problem; the Σ11 -hardness of the satisﬁability problem will follow from the
known Σ11 -hardness of the recurrent tiling problem.
Recall that the recurrent tiling problem asks: given a ﬁnite set of tile types T ,
which includes some distinguished tile type T1 , can T tile N × N in such a way that
T1 occurs inﬁnitely often in the ﬁrst row? Putting this more formally: does there
exist a function t : N × N → T such that
right(t(n, m)) = left(t(n + 1, m)),
up(t(n, m)) = down(t(n, m + 1)),
{n | t(n, 0) = T1 }
is inﬁnite?
We reduce N × N recurrent tiling to KR[∗]-satisﬁability as follows. Let T =
{T1 , . . . , Tk } be the set of tile types. We will deﬁne a formula φT ,T1 such that
T and T1 recurrently tile N × N iff φT ,T1 is satisﬁable.
(6.10)
Most of the real work was done in the proof of Theorem 6.31. Let us simply
take the earlier encoding φT and replace every occurrence of A with [∗]. Call the
result φ∗T . This formula reduces the N × N tiling problem to the KR[∗]-satisﬁability
problem.
To reduce the recurrent tiling problem, it remains to ensure that our distin-
guished tile T1 occurs inﬁnitely often on the ﬁrst row. As t1 is the proposition
letter corresponding to T1 , this means we want to force t1 to be true at nodes of the
form t(n, 0) for inﬁnitely many n. To do this, we will introduce a new proposition
letter ﬁrst-row and then deﬁne:
φrec := ﬁrst-row ∧ [∗][u]¬ﬁrst-row ∧ [∗](ﬁrst-row → r∗(ﬁrst-row ∧ t1 )).
Suppose that φrec is satisﬁed at some point w0 of a grid-like model. It follows that
ﬁrst-row is satisﬁed at w0 ; that ﬁrst-row can only be satisﬁed at points reachable
by a ﬁnite number of Rr transitions from w0 ; and that for inﬁnitely many distinct
natural numbers n, w0  rn (ﬁrst-row ∧ t1 ).
So, let φT ,T1 be the conjunction of φ∗T and φrec . Then (6.10) holds.
To conclude this section, two general remarks. First, the examples in this section
were clearly chosen to make the undecidability proofs run as smoothly as possible.
In particular, our examples hinged on the use of ∩ to force the existence of the
grid. What happens if we are working in languages without this constructor? That
is, how widely applicable is this method for proving undecidability?
Suppose we are working with an arbitrary modal language, and we want to es-
tablish the undecidability of its satisﬁability problem. If we abstract from the proof
of Theorem 6.31, we see that there is one ingredient that will always be needed
to make similar arguments go through: sufﬁcient ‘global’ expressive power. This6.6 NP
373
power may arise directly through the presence of additional operators, or it may
arise indirectly through special features of the class of models under consideration,
but one way or another we will need it. On the other hand, we do not need the ∩
constructor; Exercise 6.5.2 is a nice example.
Second, we have discussed tiling problems as if they were useful only for estab-
lishing different grades of undecidability. In fact, they can also be used to analyze
the complexity of decidable problems: for example, there are NP-hard, PSPACE-
hard, and EXPTIME-hard tiling problems (see the Notes for further references).
At the end of this chapter we will use a 2-player tiling problem to show that the
satisﬁability problem for PDL is EXPTIME-hard.
Exercises for Section 6.5
6.5.1 Show that KRA-satisﬁability is decidable if we have only one atomic program at our
disposal. (This result can be proved via a ﬁnite model property argument.)
6.5.2
(i) Show that the satisﬁability problem of the following ‘tiling’ logic Tile 1 is
undecidable. Tile 1 is a normal modal logic with three diamonds u, r and 3,
deﬁned by the following (Sahlqvist) axioms:
up → [u]p and rp → [r]p,
rup → [u]rp,
33p → 3p,
up → 3p and rp → 3p.
(6.11)
(ii) Now use this logic plus the standard translation to conclude that the three variable
fragment of ﬁrst-order logic (without function symbols, but possibly with equality)
is undecidable.
(iii) Let Tile2 be obtained from Tile 1 by omitting axiom (6.11). Show that Tile 2
is still undecidable. (Hint: Reduce the satisﬁability problem of Tile 1 to that of
Tile2 .)
(iv) Conclude that ﬁrst-order logic with three variables, but without equality is unde-
cidable.
(v) Use a similar tiling logic to show that ﬁrst-order logic with one variable, two unary
function symbols, and only unary predicate symbols is undecidable. (Hint: adjust
the standard translation so that it exploits the unary function symbols directly.)
6.6 NP
The interpretation method (and in particular, interpretations in SnS) is a powerful
and widely applicable way of proving decidability. Nevertheless, it has disadvan-
tages. Reducing the satisﬁability problems of what are often rather simple modal
logics to SnS is using a sledgehammer to crack a nut. The decision problem for
SnS is non-elementary. This means that the time required to decide whether an374
6 Computability and Complexity
arbitrary formula φ is decidable cannot be bounded by any ﬁnite tower of expo-
nentials of the form
. . 2|φ|
2.
2
.
The use of ﬁltrations to establish decidability is open to similar objections. A
ﬁltration is typically 2|φ| in the size of the input formula. But it is not feasible to
enumerate all the models up to this size even for quite small values of |φ|. And
even a nondeterministic Turing machine, which could ‘guess’ a ﬁltration in one
move (see Appendix C and the discussion below), would still be faced with the
immensely costly task of checking that φ was true on this huge structure (to use
the terminology discussed in Appendix C, ﬁltrations typically offer us NEXPTIME
algorithms). Indeed, of the three decidability techniques discussed so far, only
the mosaic method (which ‘deconstructs’ models locally) respects what is special
about modal logic; and as we will learn in Section 7.4, the mosaic method can be
used to give essentially optimal satisfaction algorithms.
But this is jumping ahead. In this section and the three that follow, we will
use concepts drawn from computational complexity theory to present a more ﬁne-
grained analysis of modal satisﬁability. This analysis is interesting for two reasons.
First, by making use of only three central complexity classes (NP, PSPACE and
EXPTIME), we will be able to present a classiﬁcation of modal satisﬁability that
covers many important logics. Secondly, in many cases the techniques involved
have a distinctly modal ﬂavor: essentially, the work boils down to a reﬁned analysis
of the ﬁnite model property.
We begin our analysis with the class NP, the class of problems solvable using
nondeterministic polynomial time algorithms. We ﬁrst review the central ideas
underlying this complexity class and their import for modal satisﬁability problems.
Then, using examples from multi-modal and tense logic, we show how simple
selection arguments can be used to prove NP-completeness results. Finally, we
apply the same method to prove a more general result: every normal modal logic
extending S4.3 has an NP-complete satisﬁability problem.
When a problem P is said to be complete with respect to a complexity class C,
two things are being claimed. The ﬁrst is that P belongs to C; that is, there is an
algorithm using only the resources permitted by C that solves P. For example, if
C = NP this means that there exists a non-deterministic polynomial time algorithm
for solving P. The second claim is that P is C-hard; that is, any other problem in
C is polynomial time reducible to P.
Now, as far as the satisﬁability problem for normal modal logics is concerned,
NP-hardness is a triviality: all (consistent) normal modal logics have NP-hard sat-
isﬁability problems. The point is this. The classic NP-hard problem is the satis-
ﬁability problem for propositional logic. But as every normal modal logic is an6.6 NP
375
extension of propositional logic, every (consistent) normal modal logic has a satis-
ﬁability problem at least as hard as that for propositional logic. Thus – for the class
NP – our work is somewhat simpliﬁed: we are simply looking for normal modal
logics whose satisﬁability problem belongs to NP.
What sort of problems belong to NP? Many problems decompose naturally into
the following two steps: a search for a solution followed by a veriﬁcation of
the solution. In general, search is expensive, but by thinking in terms of non-
deterministic algorithms we can abstract away from this expense: if a solution
exists, such an algorithm will ﬁnd it in one non-deterministic step. (If necessary,
consult Appendix C for further discussion.) This abstraction leaves us free to con-
centrate on the veriﬁcation step, and leads us to isolate the class NP: a problem be-
longs to NP iff it has the above general proﬁle (that is, a non-deterministic choice of
a solution followed by a veriﬁcation) and moreover the veriﬁcation step is tractable
(that is, solvable in polynomial time).
How do such ideas bear on modal satisﬁability? The key idea we need is em-
bodied in the following lemma.
Lemma 6.35 Let τ be a ﬁnite similarity type. Let Λ be a consistent normal modal
logic over τ with the polysize model property with respect to some class of models
M. If the problem of deciding whether M ∈ M is computable in time polynomial
in |M|, then Λ has an NP-complete satisﬁability problem.
Proof. As noted above, the NP-hardness of the problem is immediate, so it remains
to prove the existence of an algorithm in NP that solves Λ-satisﬁability. Given φ,
non-deterministically choose a model M whose size is polynomial in the size of φ.
Because M is polysize in |φ|, we can check in time polynomial in |φ| whether M
veriﬁes φ. For the special case of the basic modal language, this may be seen as
follows.
Let ||M|| denote the sum of the number of states in M and the number of pairs
in M’s binary relation RM. Let ψ1 , . . . , ψk be an enumeration of the subformulas
of φ, in increasing length. So ψk = φ and if ψi is a subformula of ψj , then i < j.
Notice that k ≤ |φ|. One can show by induction on m that we can mark each state
w in M with ψj or ¬ψj , for j = 1, . . . , m, depending on whether or not ψj is
true at w in time O(m · ||M||). The only non-trivial case is if ψm+1 = 3ψj , for
some j < m + 1. But in that case we mark w with 3ψj if some v with Rwv is
marked with ψj . By our induction hypothesis, every state is already marked with
ψj or ¬ψj , this step can be carried out in time O(||M||). Since M is polysize in
|φ|, so is ||M||. Hence, checking whether M satisﬁes φ can indeed be done in time
polynomial in |φ|.
Finally, then, because membership in M is decidable in time polynomial in |M|,376
6 Computability and Complexity
and |M| is polynomial in |φ|, we can check in time polynomial in |φ| that M is in
M.
Where did we use the assumption that τ is a ﬁnite similarity type in the proof
of Lemma 6.35? Essentially, it allows us to check whether M veriﬁes φ in time
polynomial in |φ| and in |M|. The key point is this: when working with a ﬁxed
ﬁnite similarity type, we are actually working within a ﬁnite-variable fragment,
say with l variables. This allows us to restrict our attention to only ﬁnitely many
relations of arity at most l in M. While the total number of tuples in all relations in
M may be huge, it is nonetheless independent of φ; see Exercise 6.6.2 for further
elaborations.
Note that the second demand – that M-membership be polynomial time decid-
able – is vital. As the reader was asked to show in Exercise 6.2.4, the polysize
model property alone is insufﬁcient to ensure decidability, let alone the existence
of a solution in NP. However, for many important logics this property can be estab-
lished by appealing to the following standard result.
Lemma 6.36 If F is a class of frames deﬁnable by a ﬁrst-order sentence, then the
problem of deciding whether F belongs to F is decidable in time polynomial in the
size of F.
Proof. Left as Exercise 6.6.1.
We will show that many normal modal logics are NP-complete. The proofs revolve
around one central idea: the construction of polysize models by the selection of
polynomially many points from some given satisfying model.
For our ﬁrst example, we return to the multi-modal language containing n unary
modal operators discussed earlier (see Corollary 6.9). Recall that Fn1 is the class of
frames for this language in which each relation is a partial function, Mn1 is the class
of models built over Fn1 , and Kn Alt1 is its logic.
Theorem 6.37 Kn Alt1 has an NP-complete satisﬁability problem.
Proof. We already showed that this logic has the strong f.m.p., but the selection
argument we used generated models exponential in size of the input formula. A
simple reﬁnement of the method shows that Kn Alt1 actually has the polysize model
property.
Given a formula φ of this language and a model M = (W, R, V ) we deﬁne a
selection function s as follows:
s(p, w) = {w},
s(¬φ, w) = s(φ, w),
s(φ ∧ ψ, w) = s(φ, w) ∪ s(ψ, w),6.6 NP
377
s(ψ, w ).
s(aψ, w) = {w} ∪
{w  |Ra ww  }
Intuitively, s(φ, w) selects the nodes actually needed when evaluating φ in M at w
– and indeed, it follows by induction on the structure of φ that for all nodes w of
M, and all formulas φ
M, w  φ iff M s(φ, w), w  φ.
It is clear that M s(φ, w) ∈ Mn1 . So let us look at the size of the new model. If
M ∈ Mn1 , we claim that |s(φ, w)| ≤ |φ|+ 1. To see this, note that only occurrences
of modalities in φ cause new nodes to be adjoined to s(φ, w). This adjunction of
points is carried out in the fourth clause of the inductive deﬁnition for s, which tells
us to adjoin every state w such that Ra ww . Because M ∈ Mn1 , every relation Ra
is a partial function; hence if such a w exists, it is unique. In short, Kn Alt1 has
the polysize model property: simply counting the number of occurrences of modal
operators in φ and adding one gives us an upper bound on the size of the domain
of the required satisfying model.
By Lemma 6.36, membership in Kn Alt1 is decidable in polynomial time, for this
is a class of frames deﬁnable by a ﬁrst-order sentence – namely the conjunction of
sentences that say that each of the n relations is a partial function.
The result follows by Lemma 6.35.
The argument for Kn Alt1 shows the selection method in its simplest form: given
any model for φ we build a new polysize model for φ by making a suitable selection
of polynomially many points. This simple form of argumentation is applicable to a
number of logics, a particularly noteworthy example being S5. Given any S5 model
for φ, it is possible to select m + 1 points from this model (where m is the number
of modality occurrences in φ) which sufﬁce to construct a new S5 model for φ,
and the NP-completeness of S5 follows straightforwardly. We leave the details as
Exercise 6.6.4 and turn our attention to a modiﬁcation of the point selection method
frequently needed in practice: a detour via ﬁnite models.
Both Kn Alt1 and S5 are very simple logics; in neither case is it difﬁcult to deter-
mine which points should be selected. In other cases, we may not be so fortunate.
Suppose we are trying to show that a logic Λ has the polysize model property, and
we already know that Λ has the f.m.p. Then, instead of trying to select points from
an arbitrary model, we are free to select points from a ﬁnite model, or even a point-
generated submodel of a ﬁnite model. This often gives us an easy way of zooming
in on the crucial points. In particular, when we are working with models based
on ﬁnite orderings it makes sense to talk of choosing points that are maximal (or
minimal) in the frame ordering that satisfy some subformula; such extremal points
are often the vital ones. As an example of such an argument, let us consider Kt 4.3,
the temporal logic of linear frames (in the basic temporal language).378
6 Computability and Complexity
Theorem 6.38 Kt 4.3 has an NP-complete satisﬁability problem.
Proof. We will ﬁrst show that Kt 4.3 has the polysize model property. Let φ be
a formula of the basic temporal language that is satisﬁable on a Kt 4.3 model.
As Kt 4.3 has the f.m.p. with respect to the class of weak total orders (see Def-
inition 4.37 and Corollary 6.8), there is a ﬁnite weakly totally ordered model
M = (T, ≤, V ) containing a node t such that M, t  φ. We now build a poly-
size model for φ by selecting points from M.
Let F ψ1 , . . . , F ψk and P θ1 , . . . , P θl be all subformulas of φ of the form F ψ
and P θ, respectively, that are satisﬁed in M. For each formula F ψi choose a point
ui such that M, ui  ψi and ui is a maximal point in the ≤-ordering with this
property. Similarly, for each formula P θj choose a point vj satisfying θj that is
minimal in the ≤-ordering with respect to this property. Let M (= (T  , ≤ , V  ))
be M {t, u1 , . . . , uk , v1 , . . . , vl }. As ≤ is a weak total ordering of T , ≤ is
a weak total ordering of T  . Furthermore, the number of nodes in M does not
exceed m + 1, where m is the number of modalities in φ, thus M is a polysize
model in the correct class. It remains to show that M , t  φ, but this follows
straightforwardly by induction on the structure of φ.
As the class of weak total orders is deﬁnable using a ﬁrst-order sentence, the NP-
completeness of Kt 4.3 follows from Lemma 6.36 and the polysize model property
that we have just established.
We are ready to prove a general complexity result for the basic modal language: all
normal logics extending S4.3 have an NP-complete satisﬁability problem. Recall
from our discussion of Bull’s Theorem in Section 4.9 that an S4.3 frame is a frame
that is rooted, transitive, and connected (∀xy (Rxy ∨ Ryx)); note that all such
frames are reﬂexive. Bull’s Theorem tells us that all normal modal logics extending
S4.3 have the ﬁnite frame property with respect to a class of S4.3 frames. By
making a suitable selection from models based on such frames, we can prove that
every such logic has the polysize model property. Then, by using the fact that every
normal logic extending S4.3 has a negative characterization in terms of ﬁnite sets of
ﬁnite frames (Theorem 4.103), we will be able to prove that all these satisﬁability
problems are NP-complete.
First we need the following lemma; it is really just Lemma 4.98, which linked
bounded morphisms and covering lists, stated in purely modal terms.
Lemma 6.39 Let F and G be two ﬁnite S4.3 frames. Then the following two state-
ments are equivalent:
(i) There exists a surjective bounded morphism from F to G.
(ii) G is isomorphic to a subframe of F that contains a maximal point of F.
Proof. First suppose that f is a surjective bounded morphism from F to G. Let6.6 NP
379
! consist of wmax together with exactly
wmax be a maximal point in F, and let W
−1
one maximal world in f [v] for every point v of G such that v = f (wmax ). Then
=F W
! is the subframe we want.
F
! is a subset of the points in F, such that W
! contains
Conversely, suppose that W
! is isomorphic to G. We claim that the following
a maximal point wmax , and F W
! : f (w) = w, for w ∈ W
! ; and if
deﬁnes a bounded morphism from F onto F W
! , then f (w) is a minimal world w
! such that Rww
w ∈ W
 ∈W
 (that is, for any



w , if Rww then Rww
 ). Note that such a minimal world must always exist, since
! , thus f is well-deﬁned. (In short, f maps ‘missing points’ to succes-
wmax ∈ W
sors that are as close as possible. We used the same idea to deﬁne the bounded
morphism in the proof of Bull’s Theorem.) Clearly f is surjective. So suppose
Rww . Since Rw f (w ) and R is transitive, we have Rwf (w ). By deﬁnition,
! such that Rwf (w), thus Rf (w)f (w ) and f sat-
f (w) is a minimal element in W
isﬁes the forth condition on bounded morphisms. Finally, suppose Rf (w)f (w ).
As Rwf (w), by the transitivity of R we have Rwf (w ). Since f (f (w )) = f (w ),
the back condition for bounded morphisms is also satisﬁed and we have shown that
! is a bounded morphic image of F. As F W
! is isomorphic to G, G is a
F W
bounded morphic image of F as well.
We now show that any normal modal logic extending S4.3 has the polysize model
property.
Lemma 6.40 Let Λ be a normal modal logic such that S4.3 ⊆ Λ. Any formula φ
that is satisﬁable on a frame for Λ is satisﬁable on a frame for Λ that contains at
most m + 2 states, where m is the number of occurrences of modal operators in φ.
Proof. Suppose φ is satisﬁable on a frame for Λ. By Bull’s Theorem, Λ has the
ﬁnite frame property, thus there is a ﬁnite model based on a Λ-frame that satisﬁes
φ at some point w0 . Let M be the submodel of this model that is generated by
w0 . Clearly M, w0  φ, and as formation of generated submodels preserves modal
validity, M is based on a frame for Λ.
Now we select points. Let 3ψ1 , . . . , 3ψk be all the 3-subformulas of φ that are
satisﬁed at w0 . For each 1 ≤ i ≤ k, select a point wi that is maximal with respect
to the property of satisfying ψi . These are the points needed to ensure that φ is
satisﬁed in the polysize model at w0 , but if we select only w0 and these points, we
have no guarantee that we have constructed a Λ-frame. However, as we will now
see, we can guarantee this if we glue on a maximal point. So, let wk+1 be such a
point and deﬁne
! := M {w0 , w1 , . . . , wk , wk+1 }.
M
! contains at most m + 2 points, where m is the number of modal operators in φ.
M
!
Moreover, it is based on a Λ-frame. To see this, note that the frame underlying M380
6 Computability and Complexity
is a subframe of the frame underlying M that satisﬁes the requirements of item (ii)
! Such
of Lemma 6.39; hence there is a surjective bounded morphism from M to M.
!
morphisms preserve modal validity, thus as M is a Λ-model, so is M.
! w0  φ. We prove by induction for all subformulas
It remains to ensure that M,
ψ of φ, and all i such that 0 ≤ i ≤ k, that
! wi  ψ.
M, wi  ψ iff M,
The only interesting step is for formulas of the form 3ψ. Suppose that M, wi 
3ψ (thus ψ = ψj for some 1 ≤ j ≤ k). Since M is point-generated by w0
and transitive, it follows that Rw0 wi , hence M, w0  3ψ. We chose wj to be a
world maximal with respect to the property of satisfying ψj , hence Rwi wj . By the
! wj  ψj . Hence M,
! wi  3ψ. The converse implication
induction hypothesis, M,
is left to the reader.
Theorem 6.41 (Hemaspaandra’s Theorem) Every normal modal logic extending
S4.3 has an NP-complete satisﬁability problem.
Proof. Lemma 6.40 established the polysize model property for Λ, so it remains to
check that membership for Λ-frames can be decided in polynomial time. How can
we show this? Recall Theorem 4.103:
For every normal modal logic Λ extending S4.3 there is a ﬁnite set N of ﬁnite
S4.3 frames with the following property: for any ﬁnite frame F, F  Λ iff F
is an S4.3 frame and there does not exist a bounded morphism from F onto
any frame in N.
This gives us a possible strategy: given any frame F, check whether it is an S4.3
frame, and whether there is a surjective bounded morphism onto any frame in N.
Now, as S4.3 frames are ﬁrst-order deﬁnable, by Lemma 6.36 the ﬁrst part can be
performed in polynomial time. But what about the second? First, note that because
N is a ﬁxed ﬁnite set, we need only ensure that the task of checking whether there
is a bounded morphism from F to a ﬁxed frame G can be performed in polynomial
time. But the naive strategy of examining all the functions from F to G is com-
pletely unsuitable: the number of such functions is |G||F| , which is exponential in
the size of F. However, applying Lemma 6.39, we see that the task can be sim-
! of worlds in F such that
pliﬁed: we only need to check whether there is a set W
! is isomorphic to G and W
! contains a maximal world. Thus we need to
F W
|G|
check less than |F| embeddings. But this number is polynomial in the size of F,
for G is ﬁxed. By Lemma 6.35, NP-completeness follows.
The results of this section tell us something about the complexity of validity prob-
lems. The complement of NP is called co-NP. As a formula φ is not Λ-satisﬁable
iff ¬φ is Λ-valid, it follows that an NP-completeness result for Λ-satisﬁability tells6.7 PSPACE
381
us that Λ-validity is co-NP complete (see Appendix C for further discussion). It is
standardly conjectured that NP = co-NP, thus the validity and satisﬁability prob-
lems for these logics probably have different complexities.
Exercises for Section 6.6
6.6.1 Prove Lemma 6.36. That is, show that if F is a class of frames deﬁnable by a ﬁrst-
order sentence, then the problem of deciding whether F belongs to F is decidable in time
polynomial in the size of F.
6.6.2 Explain why the argument given in the proof of Lemma 6.35 may break down when
we lift the restriction to ﬁnite similarity types. In particular, examine the situation when
the similarity type contains modal operators of arbitrarily high arities.
6.6.3 Extend the proof of Theorem 6.38 to show that K t Q has the polysize model prop-
erty, and is NP-complete.
6.6.4 Use a selection of points argument to show that S5 has the polysize model property,
and is NP-complete.
6.6.5 Show that if we restrict attention to a ﬁxed ﬁnite set of proposition letters Φ, then the
satisﬁability problem for S5 is decidable in linear time. (Hint: if Φ is ﬁnite, the number of
models we have to check to determine whether a given formula φ is satisﬁed in them, is
independent of φ.)
6.7 PSPACE
PSPACE, the class of problems solvable by a deterministic Turing machine us-
ing only polynomial space, is the complexity class of most relevance to the basic
modal language. As we will see, some important modal satisﬁability problems
belong to PSPACE, and many modal logics have PSPACE-hard satisﬁability prob-
lems. This suggests that modal satisﬁability problems are typically tougher than
the satisﬁability problem for propositional calculus, for it is standardly conjectured
that PSPACE-hard problems are not solvable in NP.
The work of this section revolves around trees. We ﬁrst show that K lacks the
polysize model property by forcing the existence of binary-tree-based models using
short formulas. We then take a closer look at K-satisﬁability and show that it is in
PSPACE. The proof also shows that every K-satisﬁable formula is satisﬁable on a
tree-based model of polynomial depth. We then put all this work together to prove
Ladner’s Theorem: every normal logic between K and S4 has a PSPACE-hard
satisﬁability problem.6 Computability and Complexity
382
Forcing binary trees
The NP-completeness results of the previous section were proved using polysize
model property arguments. So, before going any further, we will show that K does
not have the polysize model property. We do so by showing that K can force the
existence of binary trees. Many of the ideas introduced here will be reused in the
proof of Ladner’s Theorem.
For any natural number m, we are going to devise a satisﬁable formula φB (m)
with the following properties:
(i) the size of φB (m) is polynomial (indeed, quadratic) in m, but
(ii) when φB is satisﬁed in any model M at a node w0 , then the submodel of
M generated by w0 contains an isomorphic copy of the binary tree of depth
m.
As the binary branching tree of depth m contains 2m nodes, the size of the smallest
satisfying model of φB (m) is exponential in |φB (m)|. Thus we will have shown
that small formulas can force the existence of large models.
We will deﬁne these formulas by mimicking truth tables. For any natural number
m, φB (m) will be constructed out of the following variables: q1 , . . . , qm , and p1 ,
. . . , pm . The qi s play a supporting role. They will be used to mark the level (or
depth) in the model; that is, they will mark the number of upward steps that need to
be taken to reach the satisfying node. But any satisfying model for φB (m) will give
rise to a full truth table for p1 , . . . , pm : every possible combination of truth values
for p1 , . . . , pm will be realized at some node, and hence any model for φB (m) must
contain at least 2m nodes.
That is the basic idea. To carry it out, we ﬁrst deﬁne two macros: Bi , and
S(pi , ¬pi ). For i = 0, . . . , m − 1, Bi is deﬁned as follows:
Bi := qi → (3(qi+1 ∧ pi+1 ) ∧ 3(qi+1 ∧ ¬pi+1 )) .
(6.12)
Given that we are going to use the qi s to mark the levels, the effect of Bi should be
clear: it will force a branching to occur at level i, set the value of pi+1 to true at
one successor at level i + 1, and set pi+1 to false at another.
Our other macro is closely related. For i = 0, . . . , m − 1, S(pi , ¬pi ) is deﬁned
as follows:
S(pi , ¬pi ) := (pi → 2pi ) ∧ (¬pi → 2¬pi ).
(6.13)
This formula sends the truth values assigned to pi and its negation one level down.
The idea is that once Bi has forced a branching in the model by creating a pi+1
and a ¬pi+1 successor, S(pi+1 , ¬pi+1 ) ensures that these newly set truth values
are sent further down the tree; ultimately we want them to reach the leaves.
We are ready to deﬁne φB (m). It is the conjunction of the formulas listed in
Figure 6.5. Note that φB (m) has the required effect. The ﬁrst conjunct, q0 , ensures6.7 PSPACE
(i) q0
(ii) 2(m) (qi →
(iii) B0 ∧ 2B1
(iv)

i=j ¬qj )
383
(0 ≤ i ≤ m)
2
∧ 2 B2
∧ 23 B3
∧ · · · ∧ 2m−1 Bm−1
2S(p1 , ¬p1 ) ∧ 22 S(p1 , ¬p1 ) ∧ 23 S(p1 , ¬p1 ) ∧ · · · ∧ 2m−1 S(p1 , ¬p1 )
∧ 22 S(p2 , ¬p2 ) ∧ 23 S(p2 , ¬p2 ) ∧ · · · ∧ 2m−1 S(p2 , ¬p2 )
∧ 23 S(p3 , ¬p3 ) ∧ · · · ∧ 2m−1 S(p3 , ¬p3 )
..
.
∧ 2m−1 S(pm−1 , ¬pm−1 )
Fig. 6.5. The formula φ B (m)
that any node that satisﬁes φB (m) is marked as having level 0. The effect of (ii) is
to ensure that no two distinct level marking atoms qi and qj can be true at the same
node (at least, this will be the case all the way out to level m, which is all we care
about). To see this, recall that 2(m) φ is shorthand for φ ∧ 2φ ∧ 22 φ ∧ · · · ∧ 2m φ.
Thus our level markers are beginning to work as promised.
But the real work is carried out by (iii) and (iv). Because of the preﬁxed blocks
of 2 modalities, the Bi macros in (iii) force m successive levels of branching;
and each such branching ‘splits’ the truth value of one of the pi s. Then, again
because of the preﬁxed 2 modalities, (iv) uses the S(pi , ¬pi ) macro to send each
of these newly split truth values all the way down to the m-th level. In short,
(iii) creates branching, and (iv) preserves it. It is worthwhile sitting down with a
pencil and paper to check the details. If you do, it will become clear that φB (m) is
satisﬁable, and that any satisfying model for φB (m) must contain a submodel that
is isomorphic to the binary branching tree of depth m. It follows that any model of
φB (m) must contain at least 2m nodes, as we claimed.
In spite of its appearance, φB (m) is indeed a small formula. To see this, consider
what happens when we increment m by 1. The answer is: not much. For example
(iii) simply gains an extra conjunct, becoming
2B0 ∧ 22 B1 ∧ 23 B2 ∧ · · · ∧ 2m−1 Bm−1 ∧ 2m Bm .
Similarly, each row in (iv) gains an extra conjunct (as does the next empty row)
thus we gain a new column containing m formulas. The biggest change occurs in
(ii). If you write (ii) out in full, you will see that it gains an extra row, and an extra
column, and an extra atomic symbol in each embedded conjunct, and this means
that |φB (m)| increases by O(m2 log m) (that is, slightly faster than quadratically).
This is negligible compared with the explosion in the size of the smallest satisfying
model: this doubles in size every time we increase m by one.384
6 Computability and Complexity
Theorem 6.42 K lacks the polysize model property.
That is, K lacks a property enjoyed by all the NP-complete logics examined in
the previous section, and there is no obvious way of using NP guess-and-check
algorithms to solve K-satisﬁability. What sort of algorithms will work?
A PSPACE algorithm for K
We will now deﬁne a PSPACE-algorithm called Witness whose successful termi-
nation guarantees the K-satisﬁability of the input. It may seem surprising that we
can do this. After all, we have just seen that there are satisﬁable formulas φB (m)
whose smallest satisfying model contains 2m nodes. What happens if we give
φB (m) as input to Witness? Will it be forced to use an exponential amount of
space to determine the satisﬁability of φB (m)? The answer is: no. Witness will
take an exponential amount of time to terminate on difﬁcult input, but it uses space
efﬁciently. As we will see, if a formula φ is satisﬁable in some model, it is sat-
isﬁable in a tree-based model of polynomial depth. While some formulas require
models with exponentially many nodes, we can always ﬁnd a shallow satisfying
model: the length of each branch is polynomial in |φ|. Witness tests for the exis-
tence of shallow models, and does so one branch at a time. It does not need to keep
track of the entire model, and hence can be made to run in PSPACE.
Witness is essentially an abstract tableaux system for K: it explores spaces of
Hintikka sets (see Deﬁnition 6.24). Recall that Hintikka sets need not be satisﬁable,
and that we call satisﬁable Hintikka sets atoms. Witness will take two ﬁnite sets
of formulas H and Σ as input, and determine whether or not H is an atom over
Σ. It does so by looking at the demands that H makes and recursively calculating
whether all these demands can be met. The following deﬁnition makes the idea of
a demand precise (compare Deﬁnition 4.62, and recall our convention concerning
single negations from Deﬁnition 4.79):
Deﬁnition 6.43 Suppose H is a Hintikka set over Σ, and 3ψ ∈ H. Then the
demand that 3ψ creates in H (notation: Dem(H, 3ψ)) is
{ψ} ∪ {∼θ | ¬3θ ∈ H}.
We use H3ψ to denote the set of Hintikka sets over Cl(Dem(H, 3ψ)) that contain
Dem(H, 3ψ). (Recall that for any set of sentences Σ, Cl(Σ) denotes the closure
of Σ; see Deﬁnition 6.23.)
Remark 6.44 Suppose that A is an atom over Σ, and that 3ψ ∈ A. As A is
satisﬁable, so is Dem(A, 3ψ). From this it follows that there is at least one atom
in A3ψ that contains Dem(A, 3ψ). For suppose M, w  Dem(A, 3ψ). Let Ψ be6.7 PSPACE
385
the set of all formulas satisﬁed in M at w. Then Ψ ∩ Cl(Dem(A, 3ψ)) is an atom
over Cl(Dem(A, 3ψ)) that contains Dem(A, 3ψ).
Furthermore, as the reader can easily ascertain, for any formula φ, φ is satisﬁable
iff there is an atom A over Cl(()φ) that contains φ.
Deﬁnition 6.45 Suppose H and Σ are ﬁnite sets of formulas such that H is a
Hintikka set over Σ. Then H ⊆ P(Σ) is a witness set generated by H on Σ if
H ∈ H and
(i) if I ∈ H, then for each 3ψ ∈ I, there is a J ∈ I3ψ such that J ∈ H,
(ii) if J ∈ H and J = H then for some n > 0 there are I0 , . . . , I n ∈ H such
that H = I 0 , J = I n , and for each 0 ≤ i < n there is some formula
i .
3ψ ∈ I i such that I i+1 ∈ I3ψ
The degree of a ﬁnite set of formulas Σ is simply the maximum of the degrees of
the formulas contained in Σ; that is, deg(Σ) = max{deg(φ) | φ ∈ Σ}.
For all choices of H and Σ, any witness set H generated by H on Σ must be ﬁnite,
for H ⊆ P(Σ), which is a ﬁnite set. Further, observe that if I, J ∈ H and J ∈ I3ψ
then the degree of J is strictly less than that of I. Moreover, observe that item (ii)
of the previous deﬁnition is essentially a ‘no junk’ condition: if J belongs to H, it
is there because it is generated by some other elements of H, and ultimately by H
itself.
Lemma 6.46 Suppose that H and Σ are ﬁnite sets of formulas such that H is a
Hintikka set over Σ. Then H is an atom iff there is a witness set generated by H
on Σ.
Proof. For the left to right direction we proceed by induction on the degree of Σ.
Let deg(Σ) = 0, and suppose H is an atom. Trivially, H = {H} is a witness set
generated by H. For the inductive step, suppose the required result holds for all
pairs H  and Σ  such that H  is an atom of Σ and deg(Σ  ) < n. Let H be an atom
of Σ such that deg(Σ) = n. Then, as we noted in Remark 6.44, for all 3ψ ∈ H
there exists at least one atom Iψ in H3ψ . As the degree of Cl(Dem(H, 3ψ)) < n,
for all 3ψ ∈ H, the inductive hypothesis applies and every such atom Iψ generates
a witness set I ψ on Cl(Dem(H, 3ψ)). Deﬁne
H = {H} ∪
Iψ.
3ψ∈H
Clearly H is a witness set generated by H on Σ.
For the right to left direction, we will show that if H is a witness set on Σ
generated by H, then H can be satisﬁed in a model (F, V ) where F is a ﬁnite tree
of depth at most deg(H). This is stronger than the stated result, and later it will386
6 Computability and Complexity
help us understand why K-satisﬁability is solvable in PSPACE. Assume we have
a countably inﬁnite set of new entities W = {w0 , w1 , w2 , w3 , . . .} at our disposal.
We will use (ﬁnitely many) elements of W to build a model for H, using a ﬁnitary
version of the step-by-step method discussed in Section 4.6. This model will be a
tree, thus showing once again that K has the tree model property.
Deﬁne W0 = {w0 }, R0 = ∅, f0 (w0 ) = H. Suppose Wn , Rn and fn have been
deﬁned. If for all w ∈ Wn such that 3ψ ∈ fn (w) there exists a w ∈ Wn such that
(i) ψ ∈ fn (w ) and (ii) fn (w ) ∈ fn (w)3ψ , then halt the step-by-step construction.
Otherwise, if there is a w ∈ Wn such that 3ψ ∈ fn (w), while for no w ∈ Wn are
these two conditions satisﬁed, then carry on to stage n + 1 and deﬁne:
Wn+1 = Wn ∪ {wn+1 },
Rn+1 = Rn ∪ {(w, wn+1 )},
fn+1 = fn ∪ {(wn+1 , I)},
where I ∈ H is such that I ∈ fn (w)3ψ . Note that because H is a witness set it
will always be possible to ﬁnd such an I.
This step-by-step procedure halts after ﬁnitely many steps since each I ∈ H
contains only ﬁnitely many formulas of the form 3ψ (thus ensuring that the tree
we are constructing is ﬁnitely branching), and whenever Rn ww , then
deg(fn (w )) < deg(fn (w))
(thus ensuring that the tree is not only ﬁnite, but shallow: it has depth at most
deg(H)). Let m be the stage at which it halts, and deﬁne F to be (Wm , Rm ). To
construct the desired model for H, it only remains to deﬁne a suitable valuation
V , and we do this as follows: choose V to be any function from Σ to P(Wm )
satisfying w ∈ V (p) iff p ∈ fm (w), for all p ∈ Σ. Let M = (F, V ). Exercise 6.7.1
asks the reader to show that M, w0  H; an immediate consequence is that H is
an atom.
Two remarks. The above proof shows that every atom is satisﬁable in a shallow
tree-based model – a fact which will prove to be important below. Second, we now
have a syntactic criterion – namely the existence or non-existence of witness sets
– for determining whether a Hintikka set is K-satisﬁable. (In short, we have just
proved a completeness result.) Moreover, the criterion is intuitively computable:
witness sets are simple ﬁnite structures, thus it seems reasonable to expect that we
can algorithmically test for their existence. And indeed we can.
We now deﬁne the Witness algorithm. This takes as input two ﬁnite sets of
formulas H and Σ and returns the value true if and only if there is a witness set
generated by H on Σ.
*function Witness(H, Σ) returns boolean*6.7 PSPACE
387
begin
if H is a Hintikka set over Σ
and for each subformula 3ψ ∈ H there is a set of formulas
I ∈ H3ψ such that Witness(I, Cl(Dem(H, 3ψ)))
then return true
else return false
end
Note that Witness is an intuitively acceptable algorithm – and hence (by Church’s
thesis) implementable on a Turing machine. Checking that H is a Hintikka set
over Σ involves ascertaining that Σ is subformula closed, and that H satisﬁes the
properties demanded of Hintikka sets; these tasks involve only simple syntactic
checking. Moreover, both the ‘and for each subformula . . . there is’ clause and the
recursive call to Witness are clearly computable: the ﬁrst involves search through
a ﬁnite space, while the recursive call performs the same tasks on input of lower
degree. Thus Witness is indeed an algorithm. Moreover, it is correct: if H and Σ
are ﬁnite sets of formulas, then Witness(H, Σ) returns true iff H is a Hintikka set
over Σ that generates a witness set in Σ. This follows by induction on the degree
of Σ. The right to left direction is easy, while the left to right direction is similar
to the proof of Lemma 6.46; see Exercise 6.7.2.
We are now ready for the main result.
Theorem 6.47 K-satisﬁability is in PSPACE.
Proof. It follows from Lemma 6.46 and the correctness of Witness that for any
formula φ, φ is satisﬁable iff there is an H ⊆ Cl(()φ) such that φ ∈ H and
Witness(H, Cl(()φ)) returns the value true. Thus, if we can show that Witness
can be given a PSPACE implementation, we will have the desired result. We will
implement Witness on a non-deterministic Turing machine. Given any formula
φ, this machine will non-deterministically pick a Hintikka set H in Cl(()φ) that
contains φ, and run Witness(H, Cl(()φ)). It will be easy to show that this machine
runs in non-deterministic PSPACE (that is, NPSPACE). But then it follows by an
appeal to Savitch’s Theorem (PSPACE = NPSPACE; see Appendix C) that the
required PSPACE implementation exists.
So how do we implement Witness on a non-deterministic Turing machine? The
key points are the following:
(i) All sets of formulas used in the execution of the program are subsets of
Cl(()φ), and we can represent any such subset by using pointers to the con-
nectives and proposition letters in φ’s representation: a pointer to a propo-
sition letter will mean that the letter belongs to the subset, and a pointer to
a connective means that the subformula built using that connective belongs388
6 Computability and Complexity
to it. Thus encoding a subset of Cl(()φ) requires only space O(|φ|) (that
is, space of the order of the size of φ).
(ii) The ‘and for each subformula 3ψ ∈ H’ part can be handled by treating
each subformula in turn. As any subformula can be represented using a
pointer to φ’s representation, we can cycle through all possible subformu-
las, using only polynomial space, by cycling through these pointers. More-
over, as we are using a non-deterministic Turing machine, the ‘there is a set
of formulas . . . ’ clause can be implemented by making non-deterministic
choices. Note that, even though H3ψ is a set of sets of formulas, it is a
rather trivial task to verify whether I belongs to H3ψ , given the deﬁnition
of H3ψ .
(iii) To enable recursive calls to be made, we implement a stack on our Turing
machine. To perform the recursion, we copy the formula φ onto the stack
and point to proposition letters and connectives to indicate the subsets of
interest.
So, suppose we run Witness on input H and Σ. The crucial point that must be
investigated is whether the recursive calls to Witness cause a blow-up in space
requirements. From items (i), (ii) and (iii) it is clear that at each level of recur-
sion we use space O(|φ|). How long does it take for the recursion to bottom out?
Note that after deg(φ) recursive calls, Σ = ∅. That is, the depth of recursion is
bounded by deg(φ) and hence by |φ|. Thus, when we implement Witness on a
non-deterministic Turing machine the total amount of space required is O(|φ|2 ),
hence the algorithm runs in NPSPACE. Thus, by Savitch’s Theorem, we conclude
that K-satisﬁability is in PSPACE.
The appeal to Savitch’s Theorem in the above proof can be avoided: Witness can
be implemented on a deterministic Turing machine. This involves replacing the
non-deterministic choice used in item (iii) by a brute force search through subsets
of Cl(()φ) that uses only polynomial space, and the reader is asked to do this in
Exercise 6.7.4. But the above proof illustrates why Savitch’s Theorem is so useful
in practice: by freeing us to think in terms of non-deterministic computations, it
reduces the required bookkeeping to a minimum.
Let us try and pin down the key intuition underlying Theorem 6.47. K lacks
the polysize model property, but in spite of this the K-satisﬁability problems can
be determined in PSPACE. Why? The key lies in the proof of Lemma 6.46 which
showed that every atom is satisﬁable in a shallow ﬁnite tree-based model. Such
models make it easy to visualize the explorations that Witness makes as it tests
the satisﬁability of φ: it just works out what each branch of such a model must
contain. While the size of the entire model may be exponential in |φ| it is not
necessary to keep track of all this information. The locally relevant information is
simply the information on each branch – and we know that the tree has depth at6.7 PSPACE
389
most deg(φ) + 1. In short, Witness exploits the fact that only shallow tree-based
models are needed to determine K-satisﬁability.
PSPACE algorithms have been devised for a number of well-known logics in-
cluding T, K4 and S4, the temporal counterparts of K, T, K4 and S4, and multi-
modal K, T, K4, S4 and S5. While proofs of these results are essentially reﬁne-
ments of the proof of Theorem 6.47, some are rather tricky. The reader who does
Exercise 6.7.3, which asks for a PSPACE algorithm for K4, will ﬁnd out why. In
some cases alternative methods are preferable; see the Notes for pointers.
Ladner’s Theorem
We are ready to prove the major result of the section: every normal modal logic
between K and S4 is PSPACE-hard, and hence (assuming PSPACE = NP) the
satisﬁability problems for all these logics are tougher than the satisﬁability problem
for propositional logic. We prove this by giving a polynomial time reduction of
the validity problem for prenex quantiﬁed boolean formulas to all these modal
satisﬁability problems. The reduction boils down to forcing the existence of certain
tree-based models, and we will be able to reuse much of our previous work.
Deﬁnition 6.48 The set of quantiﬁed boolean formulas is the smallest set X con-
taining all formulas of propositional calculus such that if β ∈ X and p is a proposi-
tion letter, then both ∀p β and ∃p β ∈ S. The quantiﬁers range over the truth values
1 (true) and 0 (false), and a quantiﬁed boolean formula without free variables is
valid if and only if it evaluates to 1.
A quantiﬁed boolean formula is said to be in prenex form if it is of the form
Q1 p1 · · · Qm pm θ(p1 , . . . , pm );
here Q is either ∀ or ∃, and θ(p1 , . . . , pm ) is a formula of propositional logic. We
will refer to such prenex formulas as QBFs.
The problem of deciding whether a QBF containing no free variables is valid is
called the QBF-validity problem, and it is known to be PSPACE-complete.
We are going to deﬁne a polynomial time translation fL from QBFs to modal
formulas, and prove that it has the following two properties:
(i) If β is a QBF-validity, then fL (β) is S4-satisﬁable.
(ii) If fL (β) is K-satisﬁable, then β is a QBF-validity.
These two properties – together with the known PSPACE-hardness of the QBF-
validity problem – will lead directly to the desired theorem.
Let us think about what is involved in evaluating a QBF. We start by peeling off
the outermost quantiﬁer. If it is of the form ∃p we choose one of the truth values
1 or 0 and substitute for the newly freed occurrences of p. On the other hand, if it390
6 Computability and Complexity
is of the form ∀p we must substitute both 1 and 0 for the newly freed occurrences
of p. In this fashion, we work our way successively through the preﬁxed list of
quantiﬁers until we reach the matrix, a formula of propositional logic.
We are essentially generating a tree. This tree consists of the root node, and then
– working inwards along the quantiﬁer string – each existential quantiﬁer extends
it by adding a single branch, and each universal quantiﬁer extends it by adding
two branches. Indeed, we are even generating an annotated tree: we can label
each node with the substitution it records. For example, corresponding to the QBF
∀p∃q (p ↔ ¬q) we have the following annotated tree:
1/q
0/p
tt 0/q
66
tt
@
I
@
@ t

1/p
The information in such annotated trees – we will call them quantiﬁer trees – will
play a crucial role. For a start, QBF-validity is witnessed by certain quantiﬁer
trees: β is a QBF-validity if and only if there is a quantiﬁer tree for β such that the
substitutions it records ensure that the matrix evaluates to 1. Moreover, quantiﬁer
trees give us a bridge between the QBF world and the modal world: fL (β) will be
a modal formula that describes the structure of a quantiﬁer tree evaluating β.
We deﬁne the translation fL by modifying the way we forced the existence of
binary trees in the proof of Theorem 6.42, and we will reuse the macros Bi and
S(pi , ¬pi ) deﬁned on page 382 in (6.12) and (6.13), respectively.
Deﬁnition 6.49 Given any QBF β = Q1 p1 · · · Qm pm θ(p1 , . . . , pm ), choose new
propositional variables q0 , . . . , qm . Then fL (β) is the conjunction of the formulas
displayed in Figure 6.6.
The idea underlying fL is this: for any QBF β, fL (β) describes the peel-off-
quantiﬁers-and-substitute evaluation process for β. (That is, it describes how we
generate a quantiﬁer tree for β.) Moreover, it does so using ideas we have met
already: note that (i), (ii) and (iv) are exactly the same formulas we used when
forcing the existence of binary trees.
In fact, the major difference between these formulas and our earlier work lies in
the word binary. Here we do not always want binary branching: we only want it
when we encounter the quantiﬁer ∀. Thus, instead of the earlier (iii) which forced
branching all the way down to level m, we have the pair of formulas (iiia) and
(iiib). (iiia) guarantees that if qi is true and i < m then there is a next level qi+1 ;
which simply amounts to saying that if i < m then we have not yet peeled off6.7 PSPACE
(i) q0
(ii) 2(m) (qi →

i=j ¬qj )
391
(0 ≤ i ≤ m)
(m)
(iiia) 2 (qi → 3qi+1 ) (0 ≤ i < m)

(iiib) {i|Qi =∀} 2i Bi
(iv) 2S(p1 , ¬p1 ) ∧ 22 S(p1 , ¬p1 ) ∧ 23 S(p1 , ¬p1 ) ∧ · · · ∧ 2m−1 S(p1 , ¬p1 )
∧ 22 S(p2 , ¬p2 ) ∧ 23 S(p2 , ¬p2 ) ∧ · · · ∧ 2m−1 S(p2 , ¬p2 )
∧ 23 S(p3 , ¬p3 ) ∧ · · · ∧ 2m−1 S(p3 , ¬p3 )
..
.
∧ 2m−1 S(pm−1 , ¬pm−1 )
(v) 2m (qm → θ)
Fig. 6.6. The formula f L (β)
all the quantiﬁers and a new level will be necessary. But it does not force binary
branching. The task of forcing binary branching, when necessary, is left to (iiib).
Note that this formula is simply a selection of conjuncts from our earlier (iii). There
is only one other difference: (v) insists that after m quantiﬁers have been peeled
off, the propositional matrix θ must be true.
Clearly, fL (β) is polysize in |β|, thus this translation causes no blowup in space
requirements.
Theorem 6.50 (Ladner’s Theorem) If Λ is a normal modal logic such that K ⊆
Λ ⊆ S4, then Λ has a PSPACE-hard satisﬁability problem. Moreover, Λ has a
PSPACE-hard validity problem.
Proof. Fix a modal logic Λ with K ⊆ Λ ⊆ S4. We are going to prove that fL is a
(polynomial time) reduction from the QBF-validity problem to the Λ-satisﬁability
problem. The crucial step in this proof is summarized in the following two state-
ments:
if β is a QBF-validity, then fL (β) is satisﬁable on a frame for S4,(6.14)
if fL (β) is satisﬁed in a K-model then β is a QBF-validity.(6.15)
and
From these two statements the desired result follows immediately. For suppose β
is a QBF-validity. Then by (6.14) fL (β) is S4-satisﬁable and hence Λ-satisﬁable.
Conversely, if fL (β) is Λ-satisﬁable then it is also K-satisﬁable, and by (6.15)
β is a QBF-validity. Thus Λ-satisﬁability is PSPACE-hard. That the Λ-validity392
6 Computability and Complexity
problem is also PSPACE-hard follows immediately from the fact that PSPACE =
co-PSPACE.
It remains to prove (6.14) and (6.15). For (6.14), assume that β is a QBF-validity.
Generate a quantiﬁer tree witnessing the validity of β; if β is valid, such a tree
must exist. This tree gives rise to an S4-model for fL (β) as follows. First, take
the transitive and reﬂexive closure of the ‘daughter-of’ relation of the tree; this
gives us the S4-frame we require. Then make the variable qi true precisely at the
nodes of level i; pi is to be made true at a node of level j ≥ i iff the substitution
connected to that node, or its predecessor at level i returns the value 1 for pi . (For
nodes at level j < i it does not matter what truth value we choose for pi .) It is
straightforward to check that the formula fL (β) is true in this model at the root of
the tree; see Exercise 6.7.5.
For (6.15), suppose that β is a QBF of quantiﬁer depth m, and that fL (β) is
K-satisﬁable. Note that deg(fL (β)) = m, hence from the proof of Lemma 6.46
we know that fL (β) holds at the root r of a tree-based model M = (T, R, V ) of
depth at most m. Using clauses (iiia) and (iiib) of the deﬁnition of fL (β), it is
easily veriﬁed that we may cut off branches from this tree such that in the resulting
tree, a node at level i < m has either one or two successors. This number is one
iff Qi+1 = ∃. And if Qi+1 = ∀, then one of the successors satisﬁes pi+1 and the
other one, ¬pi+1 . But then this reduced tree model is a quantiﬁer tree witnessing
the validity of β.
Among other things, Ladner’s Theorem tells us that K, T, K4 and S4 all have
PSPACE-hard satisﬁability problems. It follows that the temporal counterparts
of K, T, K4 and S4, and multi-modal K, T, K4, and S4, are PSPACE-hard too,
for they contain the unimodal satisﬁability problems as a special case. Hence, as
PSPACE algorithms are known for these logics, they all have PSPACE-complete
satisﬁability problems. As PSPACE = co-PSPACE, these logics have PSPACE-
complete validity problems too.
Exercises for Section 6.7
6.7.1 Show that in the model M constructed in the proof of Lemma 6.46, M, w 0  H.
6.7.2 We claimed that Witness is a correct algorithm. That is, if H and Σ are ﬁnite sets of
formulas, then Witness(H, Σ) returns true iff H is a Hintikka set over Σ that generates a
witness set in Σ. Prove this.
6.7.3 Adapt the Witness algorithm so that it decides K4 satisﬁability correctly. (Hint:
since you cannot consider smaller and smaller Hintikka sets (why not?) make use of lists
of Hintikka sets, rather than the single Hintikka sets used in the proof for K, and show that
the length of such lists can always be kept polynomial.)
6.7.4 Show how to avoid the use of Savitch’s Theorem in the proof of Theorem 6.47. That6.8 EXPTIME
393
is, show that the Witness function can be implemented on a deterministic Turing machine.
(Hint: implement the ‘and for each subformula . . . there is’ clause by cycling through all
possible subsets of Cl(()φ). This cycling process has a simple implementation using only
space O(|φ|): generate all binary strings of length |φ|, and decide of each whether or not
it encodes a subset of Cl(φ).)
6.7.5 Supply the missing details in the proof of Ladner’s Theorem.
6.7.6 Show that the satisﬁability problem for bimodal S5 is PSPACE-hard.
6.7.7 In this exercise we examine the effects of bounding the number of proposition letters
and of restricting the degree of formulas.
(a) Show that for any ﬁxed k, the satisﬁability problem for K with respect to a language
consisting of all formulas whose degree is at most k, is NP-complete.
(b) Show that, in contrast, the satisﬁability problem for S4 remains PSPACE-complete
for languages consisting of all formulas of degree at most k (k ≥ 2).
(c) Now suppose that Φ, the set of proposition letters, is ﬁnite. Show that for any ﬁxed
k, the satisﬁability problems for K and S4 with respect to a language consisting of
all formulas whose degree is at most k, is decidable in linear time.
6.8 EXPTIME
EXPTIME, the class of problems deterministically solvable in exponential time, is
an important complexity class for many modal languages. In particular, when a
modal language has operators [a] and [a∗ ] which explore a relation Ra and its re-
ﬂexive transitive closure (Ra )∗ , its satisﬁability problem is likely to be EXPTIME-
hard, which means that the worst cases are computationally intractable. As such
operator pairs are important in many applications, we need to understand the com-
plexity theoretic issues they give rise to. In this section we examine the satisﬁability
problem for PDL; our discussion illustrates some key themes and introduces some
useful techniques.
Forcing exponentially deep models
By Corollary 6.14 we know that PDL has a decidable satisﬁability problem – but
just how difﬁcult is it? Clearly it is PSPACE-hard, for each basic modality [a]
is a K operator, and we saw in the previous section (Theorem 6.50) that K has a
PSPACE-hard satisﬁability problem. But can we prove a matching PSPACE upper
bound?
We used a tableaux-like algorithm called Witness to show that K-satisﬁability
was solvable in PSPACE. Witness traded on the following insight: while a K-
consistent formula φ may require a satisfying model of size 2|φ| , it is always possi-
ble to build a satisfying tree model of this size in which each branch has less than
|φ| nodes. Witness tests for K-satisﬁability by building such trees one branch6 Computability and Complexity
394
at a time; as each branch is polynomial in the size of the input, Witness runs in
PSPACE. However, as we will now show, even small fragments of PDL are strong
enough to force the existence of exponentially deep models.
Proposition 6.51 For every natural number n there is a satisﬁable PDL formula κn
of size O(n2 ) such that every model which satisﬁes κn contains an Ra -path con-
taining 2n distinct nodes. Moreover, κn contains occurrences of only two modali-
ties [a] and [a∗ ], where a is an atomic program.
Proof. We will show how to count using this PDL-fragment. Given a natural num-
ber n, we select n distinct proposition letters q1 , . . . , qn . Using 1 for true, and 0
for false, the list of truth values [V (qn , w), . . . , V (qi , w), . . . , V (q1 , w)] is the n-bit
binary encoding of a natural number. We take V (q1 , w) to be the least signiﬁcant
digit, and V (qn , w) to be the most signiﬁcant.
We now construct a formula κn which, when satisﬁed at some state w0 , forces
the (n-bit representation of) zero to hold at w0 , and forces the existence of a path
of distinct successors of w0 which correctly count from 0 to 2n−1 in binary. For
example, if n = 2, the model will contain a path of length 4 from w0 to w3 , and as
we move along this path we will successively encounter the following truth value
lists: [0, 0], [0, 1], [1, 0], [1, 1].
To do the encoding, we need to know what happens when we add 1 to a binary
number m. First suppose that the least signiﬁcant bit of m is 0; for example,
suppose that m is 010100. When we add 1 we obtain 010101; that is, we ﬂip the
least signiﬁcant digit to 1 and leave everything else unchanged. We can force this
kind of incrementation in PDL as follows:
⎛
⎞

INC0 := ¬q1 → ⎝[a]q1 ∧
((qj → [a]qj ) ∧ (¬qj → [a]¬qj )⎠ .
j>1
This guarantees that the value of q1 changes to 1 at any successor state, while the
truth values of all the other qj s remain unchanged.
Now suppose that the least signiﬁcant digit of m is 1. For example, suppose that
m is 01011. When we add 1 we obtain 01100. We can describe this incrementation
as follows. First, we locate the longest unbroken block of 1s containing the least
signiﬁcant digit and ﬂip all these 1s to 0s. Second, we ﬂip the following digit from 0
to 1 (we have to ‘carry one’). Finally, we leave all remaining digits unchanged. The
following formula forces this kind of incrementation when the longest unbroken
block of 1s containing the least signiﬁcant digit has length i, where 0 < i < n:
INC1 (i) :=
⎛
⎝¬qi+1 ∧
i

j=1
⎞
qj ⎠ →⎛
⎝[a](qi+1 ∧
6.8 EXPTIME
i


¬qj ∧
j=1
⎞
395
((qk → [a]qk ) ∧ (¬qk → [a]¬qk ))⎠ .
k>i+1
We can now deﬁne the required formula κn :
∗

∗
(¬qn ∧ · · · ∧ ¬q1 ) ∧ [a ]a ∧ [a ] INC0 ∧
n−1


INC1 (i) .
i=1
The ﬁrst conjunct of κn initializes the counting at 0, the second guarantees that
there will always be successor states, while the third guarantees that incrementation
is carried out correctly. Clearly κn is of size O(n2 ) and uses only the allowed
modalities.
Proposition 6.51 is suggestive. It does not prove that no PSPACE algorithm is pos-
sible, but it does tend to conﬁrm our suspicions that PDL-satisﬁability is computa-
tionally difﬁcult. And indeed it is. The remainder of the chapter is devoted to prov-
ing the following result: the PDL-satisﬁability problem is EXPTIME-complete.
The proof methods we use are important in their own right and well worth master-
ing: we will prove EXPTIME-hardness by reduction from the two person corridor
tiling game, and demonstrate the existence of an EXPTIME algorithm using elim-
ination of Hintikka sets.
EXPTIME-hardness via tiling
In Section 6.5 we used tiling problems to prove two undecidability results. We
remarked that tiling problems were also useful for proving complexity results, and
in this section we give an example. We will describe the two person corridor tiling
game and use it to prove the EXPTIME-hardness of PDL-satisﬁability; we make
use of notation and ideas introduced in our discussion of undecidability.
As with our earlier tiling problems, the two person corridor tiling game involves
placing tiles on a grid so that colors match, but there are some extra ingredients.
There are two players, and we assume that there is a third person present – the
referee – who starts the game correctly and keeps it ﬂowing smoothly. The referee
will give the players a ﬁnite set {T1 , . . . , Ts } of tile types; the players will use tiles
of these types to attempt to tile a grid so that colors match. In addition, the referee
will set aside two special tile types: T0 and Ts+1 . T0 is there solely to mark the
boundaries of the corridor (we think of the boundaries as having some distinctive
color, say white), while Ts+1 is a special winning tile, whose role will be described
later.
At the start of play, the referee places n initial tiles I1 , . . . , In in a row. To the
left of I1 and to the right of In he places copies of the white tile T0 . That is, the
following sequence of tiles is the initial position:396
6 Computability and Complexity
I1
I2
...
In−1
In
This is the ﬁrst row of the corridor. The white tiles in column 0 and column n + 1
mark the boundaries of the corridor. Columns 1 through n are the corridor proper.
Actually, we may as well stipulate that the referee immediately ﬁlls in columns 0
and n + 1 with the special boundary-marking white tile. That is, the players are
going to be playing into the grid inside the following n-column corridor:
..
..
.
.
I1
I2
...
In−1
In
Now the players are ready to start. There are two players, Eloise and Abelard. The
players take turn placing tiles in the corridor, and it is always Eloise who moves
ﬁrst. The rules for tile placement are strict: the corridor has to be ﬁlled in from
the bottom, from left to right. For example, after Eloise has placed her ﬁrst tile the
corridor will look like this:
..
..
.
.
T
I1
I2
...
In−1
In
When Abelard replies, he must place his tile immediately to the right of tile T .
When the players have completed tiling a row, they start tiling the next one, starting
at column 1. In short, the players have no choice about where to place a tile,
only about which type of tile they will place there. The player’s choice of tiles is
subject to the usual color-matching rules of tiling, and any tile placed in column
0 or column n has to match the white of the corridor tile. (For example, in the
previous diagram, it must be the case that left(T ) = white.)
When do the players win or lose? As follows. If after ﬁnitely many rounds a
tiling is constructed in which the special winning tile Ts+1 is placed in column 1,
Eloise wins. Otherwise (that is, if one of the players cannot make a legal move and
Ts+1 is not in column 1, or if the game goes on inﬁnitely long) Abelard wins.
Now for the EXPTIME-complete problem: given a game, does Eloise have a6.8 EXPTIME
397
winning strategy in that game? That is, can she win the game no matter what
Abelard does? It is useful to think of winning strategies in terms of game trees.
For any game, a game tree for that game records all possible responses Abelard
can make to Eloise’s moves. (Note that we do not insist that game trees encode all
of Eloise’s options; but it is vital that game trees record all of Abelard’s options.)
Note that Abelard has only ﬁnitely many possible responses, for there are only
ﬁnitely many tile types. Clearly, if Eloise has a winning strategy in a game, then
there is a game tree that describes that strategy: such a tree spells out exactly what
she has to do, and takes all Abelard’s possible responses into account.
Now that we know about game trees, let us think about winning strategies for
Eloise. In fact, we can recursively characterize this concept. We ﬁrst deﬁne the
notion of a winning position for Eloise in a game tree:
(i) Whenever the winning tile Ts+1 is placed in column 1, that position is a
winning position for Eloise.
(ii) In case Eloise is to move in position x, then x is a winning position for
Eloise if there exists a move to a winning position for Eloise.
(iii) In case Abelard is to move in position x, then x is a winning position for
Eloise if Abelard can make a move and all his moves lead to a winning
position for Eloise.
We now say that Eloise has a winning strategy iff there is a game tree such that
the root of the game tree is a winning position for her. The problem of determin-
ing whether Eloise has a winning strategy is called the two person corridor tiling
problem, which is known to be EXPTIME-complete (see the Notes for references).
Theorem 6.52 The satisﬁability problem for PDL is EXPTIME-hard.
Proof. We show this by reducing the two person corridor tiling problem to the
PDL satisﬁability problem. We will view a game tree as a rooted regular PDL
model with one atomic transition Rm which codes one move of the game. Given
an instance T = (n, {T0 , . . . , Ts+1 }) of the two person corridor tiling game (here
n is the width of the corridor, and the Ti are the tile types), we will show how to
create a formula φT such that
(i) If Eloise has a winning strategy, φT is satisﬁable at the root of some game
tree for T (viewed as a regular PDL model).
(ii) If φT is satisﬁable, then Eloise has a winning strategy in the game T ; in
fact, she will be able to read off her winning strategy by following a path
through the satisfying model (starting at the point that satisﬁes φT ).
(iii) The formula φT can be computed in time polynomial in n and s.
The formula φT contains two kinds of information: it fully describes the structure398
6 Computability and Complexity
of the game tree, and states necessary and sufﬁcient conditions for Eloise to win.
The ﬁrst part boils down to using PDL to describe the initial conﬁguration, that
players move alternately, that colors match, and so on; this is a little tedious, but
straightforward. Stating necessary and sufﬁcient conditions for Eloise to win in-
volves ﬁnding PDL formulas that capture the recursive characterization of winning
strategies, and prevent the game from running for inﬁnitely many moves; this is the
interesting part of the proof.
We use the following proposition letters to construct φT :
(i) t0 , t1 , . . . , ts , and ts+1 . These will be used to represent the tiles. We will
often write t0 as white.
(ii) eloise. This will be used to indicate that Eloise has the next move. Its
negation will indicate that Abelard has the next move.
(iii) pos1 , . . . , posn . We use posi to indicate that in the current round, a tile is to
be placed in column i.
(iv) coli (t), for all 0 ≤ i ≤ n + 1 and all t ∈ {t0 , t1 , . . . , ts , ts+1 }. These will
be used to indicate that the tile previously placed in column i is of type t.
(v) win. This means that the current position is a winning position for Eloise.
In addition, we make use of the modalities [m] and m (‘after every possible
move’ and ‘after some possible move’ respectively) and [m∗ ], which can be read
as ‘after every possible sequence of moves.’
So let us describe the structure of the game tree. The following formula records
the situation at the start of play:
eloise ∧ pos1 ∧ col0 (white) ∧ col1 (tI1 ) ∧ · · · ∧ coln (tIn ) ∧ coln+1 (white).
The ﬁrst conjunct says that Eloise has to make the ﬁrst move, while the second
says that she has to place her tile in column 1. The remaining conjuncts simply say
that the tiles previously placed in all columns are those of the initial conﬁguration.
(Of course, these were not placed by the players but by the referee.) That is, they
say that columns 1 through n contain the initial tiles I1 , . . . , In , and that there is a
white corridor tile on each side.
We now write down a series of formulas which regulate the way that further play
takes place. (Note that all these conditions are preceded by the [m∗ ] modality, thus
ensuring that they continue to hold after any ﬁnite sequence of moves.) We start
by giving the desired meaning to posi and coli (t).
• Tiles always have to be placed in one of columns 1 through n:
[m∗ ](pos1 ∨ · · · ∨ posn ),
and indeed, in exactly one of these columns:
[m∗ ](posi → ¬posj )
(1 ≤ i = j ≤ n).6.8 EXPTIME
399
• In every column i, at least one tile type was previously placed:
[m∗ ](coli (t0 ) ∨ · · · ∨ coli (ts+1 ))
(0 ≤ i ≤ n + 1).
• In every column i, at most one tile type was previously placed:
[m∗ ](coli (tu ) → ¬coli (tv ))
(0 ≤ i ≤ n + 1 and 0 ≤ u = v ≤ s + 1).
• Moreover, the referee has already placed white tiles in columns 0 and n + 1:
[m∗ ](col0 (white) ∧ coln+1 (white)).
• In the course of play, tiles are placed left to right (ﬂipping back to column 1
when a row has been completed):
[m∗ ]((pos1 → [m]pos2 ) ∧ (pos2 → [m]pos3 ) ∧ · · · ∧ (posn → [m]pos1 )).
• In columns where no tile is placed, nothing changes when a move is made:
[m∗ ](¬posi → ((coli (tu ) → [m]coli (tu )) ∧ (¬coli (tu ) → [m]¬coli (tu )).
(Here 0 ≤ i ≤ n + 1 and 0 ≤ u ≤ s + 1.)
With these preliminaries behind us, we can now describe the structure of the game
tree.
• First of all, players alternate:
[m∗ ]((eloise → [m]¬eloise) ∧ (¬eloise → [m]eloise)).
• Next, both players make legal moves; that is, they only place tiles which cor-
rectly match adjacent tiles. It will be helpful to deﬁne the following ternary
relation of ‘compatibility’ between propositional variables:
C(t , t, t ) iff right(T  ) = left(T ) and down(T ) = up(T  ),
where T , T  and T are the tiles that correspond to the propositional variables t,
t and t respectively. That is, C(t , t, t ) holds iff the tile T can be placed to the
right of tile T  and above tile T  . With the aid of this relation we can formulate
the ﬁrst constraint on tile placement as follows:
(
)
[m∗ ] posi ∧ coli−1 (t ) ∧ coli (t ) → [m] {coli (t) | C(t , t, t )} .

(Here 0 ≤ i ≤ n, and, by convention, ∅ = ⊥.)
• However this constraint is not quite enough; it only ensures matching to the left
and downwards. We also need to ensure that tiles placed in column n match the
white corridor tile to their right, and we can do this as follows:
(
)
[m∗ ] posn → [m] {coln (t) | right(T ) = white} .
(Here t is the proposition letter corresponding to tile T .)400
6 Computability and Complexity
• Next, we need to ensure that all of Abelard’s possible responses are encoded in
the model:
(
)

[m∗ ] ¬eloise ∧ pos i ∧ coli (t ) ∧ coli−1 (t ) → {mcoli (t) | C(t , t, t )} .

(Here 1 ≤ i < n, and, by convention, ∅ = .)
That completes our description of the game tree. So let us turn to our other task:
ensuring that Eloise indeed has a winning strategy. We will do this with the help of
our recursive characterization of winning strategies, thus the ﬁrst step is easy; we
simply state that the initial position is a winning position for Eloise:
win.
Next, we spell out the recursive conditions:
[m∗ ] (win → (col1 (ts+1 ) ∨ (¬eloise ∧ m ∧ [m]win) ∨ (eloise ∧ mwin))).
We are almost there – but we do not have quite enough. If a game does not ter-
minate, Abelard wins, so we need to rule out this possibility. Now, any inﬁnite
branch must involve repetition of rows. Indeed, if N = ns+2 , then if a game runs
N moves, repetition must have occurred.
Repetitions do not help Eloise: if she can win, she can do so in fewer than
N moves. So we are simply going to insist that games run fewer than N moves
– and we can do this with the help of the PDL counter deﬁned in the proof of
Proposition 6.51. To use the notation of that proof, we make use of propositional
variables q1 , . . . , qn , all initially set to zero, and increment the counter by 1 at every
move. If the counter reaches N (that is, if all these propositional variables are true
in some successor state) then the game has gone on too long and Abelard wins.
The following formula encodes this observation:
[m∗ ]((counter = N ) → [m]¬win).
Let φT be the conjunction of all these formulas. We must now verify the three
claims made about φT at the start of the proof.
First we need to show that if Eloise has a winning strategy, then there is a game
tree such that φT is satisﬁable at the root of the game tree viewed as a PDL model. If
Eloise has a winning strategy, then she can win in at most N moves. If M is the PDL
model corresponding to this at-most-N move strategy, then it is straightforward to
check that φT is satisﬁed at the root of M.
The second claim is more interesting: we need to show that if M, w  φT , then
Eloise has a winning strategy in the game T – and that her winning strategy is
encoded in M. So suppose there is such a model. Imagine Eloise facing Abelard
across the playing board and consulting this model to choose her moves. As φT is
satisﬁed at w, win is satisﬁed at w (remember that the initial position is marked as6.8 EXPTIME
401
winning), hence eloise ∧ mwin, the third disjunct of our recursive characteriza-
tion of winning strategy, is true at w too. Eloise simply needs to pick a successor
state in the model marked as winning to see which tile to place. In short, she plays
the move described in the model, and continues doing so in subsequent rounds.
Though this guarantees that Eloise can keep moving to winning positions, can
she actually win the game after ﬁnitely many moves? Yes! In fact she can win
in at most N moves. For suppose the N -th move has just been played (that is,
counter = N has just become true). As Eloise has always been moving to winning
positions, the N -th position is also winning, which means that one of the following
formulas is satisﬁed there:
• col1 (ts+1 ), or
• ¬eloise ∧ m ∧ [m]win, or
• eloise ∧ mwin.
As the counter has reached N , [m]¬win is satisﬁed too. This means there are no
further winning positions, and so the second and third disjuncts are false. Hence
col1 (ts+1 ) is satisﬁed: the winning tile was placed in the ﬁrst column in the previ-
ous round. Thus Eloise has already won.
It remains to check that φT is polynomial in n and s. The only point that requires
comment is that we can encode N . Encoding any natural number m ≥ 2 in binary
requires at most lg(m) + 1 bits (lg denotes the logarithm to base 2). So encoding
N takes at most lg(ns+2 ) = (s + 2) lg(n) ≤ (s + 2)n bits, which is polynomial
in n and s. Thus we have reduced the two person corridor tiling problem to the
satisﬁability problem for PDL, hence the latter is EXPTIME-hard.
As the previous proof makes clear, the EXPTIME-hardness of PDL largely stems
from the fact that it contains a pair of modalities, one for working with a relation
Rm and the other for reﬂexive transitive closure (Rm )∗ ; this is what enabled us
to force exponentially deep models, and to code the corridor tiling problem. Now,
this is not the entire story, for there are logics containing such modality pairs whose
satisﬁability problem is in PSPACE: one example is the modal logic of the frame
(N, S, <), in a language with two diamonds s and <. Here N is the set of
natural numbers, S is the successor-of relation, and < is the usual ordering of
N. And an even more expressive language – one involving the until operator U
– has a PSPACE-complete satisﬁability problem over (N, S, <); see the Notes for
references.
Despite this, the following is a reliable rule of thumb: when working with a
modal language containing a pair of modalities for working with a relation and its
transitive closure, suspect EXPTIME-hardness. Do not begin your investigations
by looking for a PSPACE-algorithm, unless you are working with a class of frames402
6 Computability and Complexity
that allows little or no branching. And as this section has demonstrated, an elegant
way of proving EXPTIME-hardness is via the two person corridor tiling game.
Elimination of Hintikka sets
By Theorem 6.52 there are instances of the PDL-satisﬁability problem which will
require exponentially many steps to solve. As yet we have no matching upper
bound. In fact, so far the best solution to PDL-satisﬁability we have is the fol-
lowing non-deterministic algorithm: given a formula φ, let Σ be the set of all φ’s
subformulas, form the collection of all Hintikka sets in Σ, non-deterministically
choose a model of size at most 2c|φ| , and check φ on this model. By the decidabil-
ity result for PDL (Corollary 6.14), if φ is satisﬁable, it is satisﬁable in a model of
at most this size, hence PDL-satisﬁability is solvable in NEXPTIME.
As we will now show, the EXPTIME-hardness result of the previous section can
be matched by an EXPTIME algorithm. Like the PSPACE Witness algorithm de-
veloped in the previous section, the EXPTIME algorithm for PDL is based around
the idea of Hintikka sets. Here is how we deﬁne this notion for PDL.
Deﬁnition 6.53 (Hintikka set for PDL) Let Σ be a set of PDL formulas and
¬FL(Σ) the closure under single negations of its Fischer-Ladner closure (see Deﬁ-
nition 4.79). A Hintikka set over Σ is any maximal subset of ¬FL(Σ) that satisﬁes
the following conditions:
(i) If ¬φ ∈ ¬FL(Σ), then ¬φ ∈ H iff φ ∈ H.
(ii) If φ ∧ ψ ∈ ¬FL(Σ), then φ ∧ ψ ∈ H iff φ ∈ H and ψ ∈ H.
(iii) If π1 ; π2 φ ∈ ¬FL(Σ), then π1 ; π2 φ ∈ H iff π1 π2 φ ∈ H.
(iv) If π1 ∪ π2 φ ∈ ¬FL(Σ), then π1 ∪ π2 φ ∈ H iff π1 φ or π2 φ ∈ H.
(v) If π∗ φ ∈ ¬FL(Σ), then π ∗ φ ∈ H iff φ ∈ H or ππ∗ φ ∈ H.
We denote the set of all Hintikka sets over Σ by Hin(Σ).
The ﬁrst clause of Deﬁnition 6.53 ensures the maximality of Hintikka sets: if H ∈
Hin(Σ) then there is no H ∈ Hin(Σ) such that H ⊂ H  . So, when the effect
of clause (ii) is taken into account, we see that Hintikka sets are maximal subsets
of ¬FL(Σ) that contain no blatant propositional inconsistencies. Hintikka sets for
PDL are a generalization of something we met in Chapter 4, namely atoms (see
Deﬁnition 4.80). Clearly At(Σ) ⊆ Hin(Σ); indeed, At(Σ) contains precisely the
PDL-consistent Hintikka sets.
We use Hintikka sets as follows. We deﬁne a model M0 that is built out of
Hin(Σ). We then iteratively eliminate Hintikka sets from this model, thus forming
a sequence of ever smaller models. This process is deterministic, and terminates
after at most exponentially many steps yielding a model M. We will then show
that a PDL formula φ is satisﬁable iff it is satisﬁable in M.6.8 EXPTIME
403
Elimination of Hintikka sets:
Base case. Let Σ be a ﬁnite set of PDL formulas, and let Π be the set of
programs that occur in Σ. Deﬁne W 0 to be Hin(Σ). For all basic programs
a, and all H, H  ∈ W 0 , deﬁne a binary relation Q0a by HQ0a H  iff for every
φ ∈ H  , if aφ ∈ ¬FL(Σ) then aφ ∈ H. For all other programs π ∈
Π, deﬁne Q0π to be the usual inductively deﬁned PDL relations, and let F0
be (W 0 , Q0π )π∈Π . Deﬁne V 0 by V 0 (p) = {H ∈ W 0 | p ∈ H}, for all
propositional variables p. Finally, let M0 be (F0 , V 0 ).
Inductive step. Suppose that n ≥ 0 and that Fn = (W n , Qnπ )π∈Π and Mn =
(Fn , V n ) are deﬁned. Say that H ∈ W n is demand-satisﬁed iff for all π ∈ Π,
and all formulas ψ, if πψ ∈ H then there is an H ∈ W n such that HQnπ H 
and ψ ∈ H  . Then deﬁne:
(i) W n+1 = {H ∈ W n | H is demand-satisﬁed}.
(ii) Qn+1
is Qnπ ∩ (W n+1 × W n+1 ), and Fn+1 is (W n+1 , Qn+1
π
π )π∈Π .
n+1
n
n+1
n+1
n+1
n+1
(iii) V
is V
W
, and M
is (F
,V
).
As Hin(Σ) is ﬁnite and W n+1 ⊆ W n , then for some m ≥ 0 this inductive
process stops creating new structures. (That is, for all j ≥ m, Mj = Mm .)
Deﬁne F (= (W, Qπ )π∈Π ) to be Fm and deﬁne M (= (F, V )) to be Mm .
The reader should contrast this use of Hintikka sets with the way we used them in
our discussion of PSPACE. The Witness algorithm carefully builds sequences of
ever smaller Hintikka sets using only PSPACE resources. In sharp contrast to this,
the ﬁrst step of Elimination of Hintikka sets forms all possible Hintikka sets (and
there are exponentially many), and subsequent steps ﬁlter out the useless ones.
Theorem 6.54 The satisﬁability problem for PDL is solvable in deterministic ex-
ponential time.
Proof. Given a PDL formula ψ, we will test for its satisﬁability as follows. Letting
Σ be the set of all ψ’s subformulas, we form Hin(Σ) and perform elimination of
Hintikka sets. This process terminates yielding a model M = (W, Qπ , V )π∈Π . We
will shortly prove the following claim, for all formulas φ ∈ Σ:
φ is satisﬁable iff φ ∈ H for some H ∈ W.
(6.16)
If we can prove this claim, the theorem follows. To see this, note that the number
of Hintikka sets over Σ is exponential in the size of ψ, and the process of con-
structing Mn+1 out of Mn is a deterministic process that can be performed in time
polynomial in the size of the model, and hence elimination of Hintikka sets is an
EXPTIME algorithm.
So it remains to establish (6.16). For the right to left direction, we will show that
if φ ∈ H for some H ∈ W , then M itself satisﬁes φ at H. Indeed, we will show404
6 Computability and Complexity
that for all φ ∈ ¬FL(Σ) and all H ∈ W , M, H  φ iff φ ∈ H. This proof is by
induction. The clause for propositional symbols is clear, and the step for boolean
combinations follows using clauses (i) and (ii) in the deﬁnition of Hintikka sets.
For the step involving the modal operators we need the following subclaim:
for all πχ ∈ ¬FL(Σ), πχ ∈ H iff
for some H  ∈ W we have Qπ HH  and χ ∈ H  .
(6.17)
The left to right direction of (6.17) is immediate from the construction of M, for at
the end of the elimination process only the demand-satisﬁed Hintikka sets remain.
The right to left direction follows by induction on the structure of π; we demon-
strate the base case and the step for modalities constructed using ∗. Suppose that
for some basic program a there are Hintikka sets H and H such that HQa H  and
χ ∈ H  . As we built the relation Qa by a sequence of eliminations and restrictions,
it follows that if HQa H  then HQ0a H  – and hence it follows by deﬁnition that
aχ ∈ H  . Next, suppose that for some program π∗ there are Hintikka sets H and
H  such that HQπ∗ H  and χ ∈ H  . But this means there is a ﬁnite sequence
H = H0 Qπ H1 . . . Hn−1 Qπ Hn = H  .
As χ ∈ H  it follows by the deﬁnition of Hintikka sets that π∗ χ ∈ H  = Hn ,
so inductively we ﬁnd that ππ∗ χ ∈ Hn−1 ; hence, by the deﬁnition of Hintikka
sets, π∗ χ ∈ Hn−1 . Again, by induction on π it follows that ππ∗ χ ∈ Hn−2 ,
whence π∗ χ ∈ Hn−2 since this set if Fischer-Ladner closed. By repeating this
argument we obtain that π∗ χ ∈ H0 = H. This establishes the inductive proof of
(6.17), which in turn completes the inductive proof of the right to left direction of
(6.16).
The fastest way to prove the left to right direction of (6.16) is to make use of
ideas developed when proving the completeness of PDL in Chapter 4. Recall that
we deﬁned P, the PDL model over Σ, to be (At(Σ), {RπΣ }π∈Π , V Σ ). Here At(Σ)
is the set of all atoms over Σ, V Σ is the natural valuation, and RπΣ is deﬁned as
follows: for any two atoms A and B, and any basic program a, ARaΣ B holds iff
 ∧ aB
 is consistent. We deﬁned Rπ for arbitrary programs by closing these
A
basic relations under composition, union, and reﬂexive transitive closure in the
usual way.
Now, we ﬁrst claim that for all programs π, RπΣ ⊆ Q0π . To see this, ﬁrst observe
that as At(Σ) ⊆ Hin(Σ), all atoms A and B are in W 0 . So suppose ARaΣ B.
 ∧ aB
 is consistent, by the maximality of Hintikka sets we have that
Then, as A
for all φ ∈ B, if aφ ∈ ¬FL(Σ) then aφ ∈ A, that is, AQ0π B. Thus for
all atomic programs, the desired inclusion holds. But the relations Rπ and Q0π
corresponding to arbitrary programs π are generated out of Ra and Q0a in the usual
way, hence the inclusion follows for all programs.
The importance of this observation is the following consequence: atoms can6.8 EXPTIME
405
never be discarded in the process of elimination of Hintikka sets. This follows
from the Existence Lemma for PDL (Lemma 4.89), which states that for all atoms
A, and all formulas πψ ∈ ¬FL(Σ), if πψ ∈ A, there is an atom B such that
ARπΣ B and ψ ∈ B. As all atoms belong to W 0 , and as RπΣ ⊆ Q0π , it follows
that every atom in W 0 is demand-satisﬁed. Moreover, this demand satisﬁability
depends only on the presence of other atoms. It follows that Hintikka elimination
cannot get rid of atoms; that is, At(Σ) ⊆ W .
But now the left to right direction of (6.16) follows easily. Suppose that φ is
satisﬁable. Then φ is PDL-consistent, which means it belongs to at least one atom
in Σ. This atom will survive the elimination process, and we have the result.
This establishes the result we wanted: an EXPTIME algorithm for deciding the
satisﬁability problem for PDL. One question may be bothering some readers: what
is the relationship between the models M and P in the proof of Theorem 6.54?
Let us consider the matter. In the proof, we observed that all atoms survive the
Hintikka elimination process. In fact, only atoms can survive. (To see this, simply
observe that if some inconsistent Hintikka set H survived the Hintikka process,
then by (6.16), every formula in H would be satisﬁed in M at H. But as M is a
regular model, this is impossible.) Hence M, like P, is a model built over the set
of atoms. Moreover, we showed in the course of proving the previous theorem that
every relation in P is a subrelation of the corresponding relation in M. It follows
that P is a submodel of M.
Actually, we can say a little more. Recall from Exercise 4.8.4 that P is isomor-
phic to a certain ﬁltration. In fact, M is isomorphic to a ﬁltration over the same
set of sentences. Which ﬁltration? We leave this as an exercise for the reader; see
Exercise 6.8.4.
Exercises for Section 6.8
6.8.1 Enrich the basic modal language with the global modality A. (This was deﬁned in
Section 6.5.) Show that the satisﬁability problem for the enriched language over the class
of all frames is EXPTIME-hard.
6.8.2 As in the previous exercise, enrich the basic modal language with the global modality
A. Use elimination of Hintikka sets to show that the satisﬁability problem for the enriched
language over the class of all frames is solvable in EXPTIME.
6.8.3 In this exercise we investigate the complexity of deterministic PDL.
(a) Change the PDL-hardness proof so that it works for deterministic PDL. How many
programs do you need? Are two programs sufﬁcient?
(b) Encode with just one functional program that a model has an exponential deep path.
Use this to describe n-corridor tiling. What can you conclude?
(c) So by now we might have a suspicion that with only one program, the satisﬁability
problem for deterministic PDL might be in PSPACE. But how to prove that? The406
6 Computability and Complexity
best way is to ﬁnd a proof in the literature which can be used almost immediately.
What are the crucial features of functional PDL with one program? Think of a tem-
poral logic which has precisely these same features. Can you interpret functional
PDL into that temporal logic, using some kind of translation function? If so, what
is the complexity of that function? What can you conclude?
6.8.4 Determine the exact relationship between the models P and M discussed following
the proof of Theorem 6.54.
6.8.5 PDL has an EXPTIME-complete satisﬁability problem. Suppose we add the global
modality to the language. What is the complexity of the resulting satisﬁability problem?
6.9 Summary of Chapter 6
 Decidability and Undecidability: A logic is called decidable if its satisﬁability
problem (or equivalently, its validity problem) is decidable. Otherwise it is
called undecidable.
 Decidability via the Finite Model Property: While possession of the ﬁnite model
property does not guarantee decidability, ﬁnite models can be used to prove
decidability given some extra information about the models or the logic. The
decidability of many of the more important modal logics, including PDL, can
be established using such arguments.
 Decidability via Interpretations: Another important technique for establishing
decidability is via interpretation in decidable logical theories, most notably the
monadic second-order theories of countable ﬁnitely- or ω-branching trees. If a
modal logic is complete with respect to a class of models that can be viewed
as monadic second-order deﬁnable substructures of such a tree, its decidability
follows.
 Quasi-Models and Mosaics: Even when a modal logic lacks the ﬁnite model
property, it is sometimes possible to prove decidability using ﬁnite represen-
tations of the information contained in satisfying models. Quasi-models and
mosaics are such representations.
 Undecidability: Undecidability arises easily in modal logic. Moreover, not all
undecidable modal logics have the simplest degree of undecidability; many are
highly undecidable.
 Tiling Problems: Tiling problems can be used to classify the difﬁculty of both
decidable and undecidable problems. The simple geometric ideas underlying
them make them a useful tool for investigating modal satisﬁability problems.
 The Modal Signiﬁcance of NP: Only modal logics with the polysize model prop-
erty with respect to particularly simple classes of structures can be expected to
have satisﬁability problems in NP. Some important logics, such as the normal
logics extending S4.3, fall into this category.Notes to Chapter 6
407
 The Modal Signiﬁcance of PSPACE: Assuming that PSPACE = NP, most
modal satisﬁability problems are not solvable in NP, but are at least PSPACE-
hard. For example, every normal logic between K and S4 has a PSPACE-hard
satisﬁability problem. Explicit PSPACE algorithms are known for some of these
logics.
 The Modal Signiﬁcance of EXPTIME: Modal languages containing a modal-
ity r and a matching reﬂexive transitive closure modality r∗  often have
EXPTIME-hard satisﬁability problems. The two person corridor tiling game
is an attractive tool for proving modal EXPTIME-hardness results, and elimina-
tion of Hintikka sets is a standard way of deﬁning EXPTIME algorithms.
Notes
Finite models have long been used to establish decidability, both in modal logic and
elsewhere. Arguments based on ﬁnite axiomatizability together with the f.m.p. are
widely used (Theorem 6.15); this approach traces back to Harrop [213]. Also pop-
ular is the use of the strong ﬁnite model property; our formulation (Theorem 6.7) is
based on Goldblatt’s [177]. The fact that a recursive axiomatization together with
the f.m.p. with respect to a recursively enumerable class of models guarantees de-
cidability (Theorem 6.13) seems to have ﬁrst been made explicit in Urquhart [440].
The main point of Urquhart’s article is to prove the result we presented as Exer-
cise 6.2.5: there is a normal modal logic which is recursively axiomatizable, and
has the f.m.p., but is undecidable. This shows that the use of ﬁnite axiomatizations
in the statement of Theorem 6.15 cannot be replaced by recursive axiomatizations,
and Urquhart states Theorem 6.13 as the correct generalization. Exercise 6.2.4
is due to Hemaspaandra (née Spaan); see Spaan [419]. For Craig’s Lemma, see
Craig [98].
The original proof of Rabin’s Tree Theorem may be found in Rabin [368]. Rabin
shows that the decidability of SnS for n > 2 or n = ω is reducible to the decidabil-
ity of S2S, and the bulk of his paper is devoted to proving that S2S is decidable.
Rabin’s paper is demanding, and simpler proofs have subsequently been found;
for an up to date survey of Rabin’s Theorem and related material, see Gecseg and
Steinby [167] and Thomas [432]. Rabin’s Theorem was applied in modal logic al-
most immediately: Fine [127] used it to prove decidability results in second-order
modal logic (that is, modal logic in which it is possible to bind propositional vari-
ables), and Gabbay [145, 146, 147] applied it to a wide range of modal logics in
many different languages. Gabbay, Hodkinson, and Reynolds [156] is a valuable
source on the subject.
Two kinds of variations on Rabin’s Tree Theorem are relevant to our readers.
First, the weak monadic second-order theory of n successor functions (WSnS)
constrains the set variables to range over ﬁnite sets only. The decidability of WSnS408
6 Computability and Complexity
– which is due to Thatcher and Wright [429] and Doner [113] – is based on a close
correspondence between formulas in WSnS and ﬁnite automata; any relation φ
deﬁnable in WS2S can also be deﬁned by a tree automaton Aφ that encodes the
satisfying assignments to the formula in the labels on the nodes of the tree that it
accepts. The MONA system [220] implements this decision procedure. Despite
the non-elementary worst-case complexity of WS2S, MONA works well in prac-
tice on a large range of problems; Basin and Klarlund [29] offer empirical evidence
and an analysis of why this is the case. At the time of writing there are no exper-
imental results evaluating the performance of tools such as MONA on logics such
as propositional dynamic logic. Muller et al. [338] use reductions to WS2S to
explain why many temporal and dynamic logics are decidable in EXPTIME.
A second variation is important when working with expressive modal languages
(for example, those containing the until operator U ) over highly restricted classes
of models (for example, models isomorphic to the real numbers in their usual or-
der). It may be necessary to appeal to stronger results about speciﬁc classes of
structures; Burgess and Gurevich [80] and Gurevich and Shelah [201] are essential
reading here.
Prenex normal form fragments of ﬁrst-order logic are deﬁned using strings over
{∃, ∃∗ , ∀, ∀∗ }; for instance, ∃∀∗ represents the class of ﬁrst-order formulas in
prenex normal form where the quantiﬁer preﬁx starts with an existential quanti-
ﬁer and is followed by a (possibly empty) sequence of universal quantiﬁers. The
decidability of prenex normal form fragments seems to have been studied at least
since the early 1920s, which is when Skolem showed that ∀∗ ∃∗ is undecidable. In
1928, Bernays and Schönﬁnkel gave a decision procedure for the satisﬁability of
∃∗ ∀∃∗ sentences. Gödel, Kalmár and Schütte, independently in 1931, 1933 and
1934 respectively, discovered decision procedures for the satisﬁability of ∃∗ ∀2 ∃∗
sentences. In 1933, Gödel showed that ∀3 ∃∗ sentences form a reduction class for
satisﬁability (that is, arbitrary ﬁrst-order satisﬁability problems can be reduced to
such satisﬁability problems). More recently, Kahr in 1962 proved the undecidabil-
ity of ∀∃∀. Consult Börger et al. [71] for references and an encyclopedic account of
prenex normal form fragments. For recent work on the relevance of such fragments
to modal logic, see Hustadt [237].
That the two-variable fragment of any ﬁrst-order language is decidable is rel-
evant to a number of modal decidability problems. The ﬁrst decidability result
for this fragment (without equality) was obtained by Scott [401]; Mortimer [337]
established decidability of the two-variable fragment with equality. In contrast,
for k ≥ 3, the k-variable fragment is undecidable. Consult Grädel, Kolaitis, and
Vardi [195] for complexity results, and Grädel, Otto, and Rosen [196] for related
results.
But perhaps the most natural way to reduce a modal logic is – to another modal
logic! Such reductions are far likelier to yield not only decidability results, butNotes to Chapter 6
409
information about complexity as well. Embeddings of temporal logic into the basic
modal language were ﬁrst studied by Thomason in the mid 1970s (see, for example,
[437]). The approach has gained a new lease of life recently – important results on
the approach can be found in Kracht and Wolter [282] and Kracht [279].
Our use of quasi-models and mosaics has its roots in the work of Zakharyaschev
and others. In particular, Zakharyaschev and Alekseev [468] use such arguments
to show that all ﬁnitely axiomatizable normal logics extending K4.3 are decidable,
and Wolter [457] uses them to show that all ﬁnitely axiomatizable tense logics
extending Kt 4.3 are decidable too.
The mosaic method for proving decidability of a logic stems from Németi [340]
who proved that various classes of relativized cylindric algebras have a decidable
equational theory. It has since been used for a wide range of logics, often with a
multi-dimensional ﬂavor; see for instance Marx and Venema [320], Mikulás [329],
Reynolds [377], Wolter and Zakharyaschev [462], Wolter [460], or the references
in our Notes on the guarded fragment in Chapter 7. With hindsight, even Gödel’s
proof of the decidability of the satisﬁability problem for the ∀2 ∃∗ prenex sentences
can be called a mosaic style proof as well; see the very clear exposition in the
monograph [71]. Mosaics can also be used to investigate modal complexity theory;
see Marx [316] for further details.
Constructing speciﬁc examples of undecidable modal logics is not trivial, and
Thomason [434] contains the earliest explicit example of an undecidable normal
logic in the basic modal language that we know of. Undecidable logics can be
constructed in a variety of ways. Urquhart’s [440] deﬁnition of ΛU (see Exer-
cise 6.2.5) is neat, if abstract. For undecidable logics in the basic modal language
constructed by detailed simulation of a concrete model of computation (namely,
Minsky machines), see Chagrov and Zakharyaschev [88, Chapter 16].
We have chosen to focus on tiling problems (or domino problems, as they are
sometimes called). These were introduced in Wang [453] and have since been
used in a variety of forms to prove undecidability and complexity results. Proofs
that the N × N tiling problem is undecidable can be found in Berger [52], Robin-
son [389], and Lewis and Papadimitriou [301]. Two important papers on tiling
are Harel [210, 211]: these demonstrate the ﬂexibility of the method as a tool for
measuring the complexity of logics. Harel uses tiling to give an intuitive account
of highly undecidable (and in particular, Σ11 -complete) problems, and these two
papers are probably the best starting point for readers interested in learning more.
The logic KR used in the text to illustrate the tiling method is a notational variant
of Kasper Rounds logic, which is used in computational linguistics to analyze the
notion of feature structure uniﬁcation. Decidability and complexity results for (var-
ious versions of) Kasper Rounds logic can be found in Kasper and Rounds [266]
and Blackburn and Spaan [61]; the latter is the source for Theorems 6.31 and 6.34.
A wide range of related results can be found in the literature (see for example410
6 Computability and Complexity
Harel [209], Halpern and Vardi [206], and Passy and Tinchev [358]). Even in quite
modest languages, asserting something about all paths through a model can lead to
extremely high complexity; for a deeper understanding of why this is so, we refer
the reader to Harel [210, 211], and to Harel, Kozen and Tiuryn [212].
As to complexity-theoretic classiﬁcations of modal satisﬁability and validity
problems, Ladner [292] is one of the earliest analyses; this classic paper is the
source of Ladner’s Theorem and much else besides – it is required reading! Hal-
pern and Moses [205] is an excellent introduction to the decidability and complex-
ity of multi-modal languages. We strongly recommend this article to our readers –
especially those who are encountering complexity theoretic ideas for the ﬁrst time.
But to return to the results in this chapter, the NP-completeness of S5 was proved
in Ladner [292]. Ono and Nakamura [348] is the source of Theorem 6.38; in
that paper it is also shown that the complexity of the satisﬁability problems in
the language with F and P with respect to the following ﬂows of time are all
NP-complete: linear transitive ﬂows of time without endpoints, and dense linear
transitive ﬂows of time without endpoints (see Exercise 6.6.3). Hemaspaandra’s
Theorem, that all normal modal logics extending S4.3 are NP-complete, may be
found in Spaan [419] and Hemaspaandra [215]. As an aside, the satisﬁability
problem for the ﬂow of time (N, ≤) in the language with just F was shown to be
NP-complete by Sistla and Clarke [415]; the satisﬁability problem is also shown
to be NP-complete for formulas using F and the so-called nexttime operator. NP-
complete modal-like logics were also investigated in the area of description logic;
see below for references. Many NP-completeness results make use of Lemma 6.36,
that frame membership is decidable in polynomial time for ﬁrst-order deﬁnable
frame classes (see in Exercise 6.6.1). This is a standard result in ﬁnite model the-
ory, and you can ﬁnd a proof in Ebbinghaus and Flum [118].
The key results on PSPACE come from Ladner [292]. Ladner ﬁrst establishes
the existence of PSPACE algorithms for K, T, and S4. His proof of the PSPACE-
completeness of K is like that given in the text, save that Ladner uses ‘concrete
tableaux’ (that is, his algorithm speciﬁes how to construct the required atoms)
rather than ‘abstract tableaux’ (which factor out the required boolean reasoning).
Concrete tableaux are also used by Halpern and Moses [205] to construct PSPACE
algorithms for multi-modal versions of K, S4 – and indeed S5; as they show, log-
ics containing two S5 modalities are PSPACE-hard. This paper gives a very clear
exposition of how to use tableaux systems to establish decidability and complexity
results. The abstract tableaux systems used in this chapter are based on the work of
Hemaspaandra [420, 419, 215]. In the description logic community, tableaux sys-
tems are often called constraint systems [115]; description logics (also known as
concept languages or terminological logics) are essentially multi-modal languages,
equipped with additional operators to facilitate the representation of knowledge,
with global constraints (the so-called TBox), or with means to reason about indi-Notes to Chapter 6
411
viduals and properties (the so-called ABox). Unlike the modal logic community, in
the description logic community considerable attention has been paid to reasoning
tasks other than satisﬁability or validity checking, such as subsumption checking,
instance checking, and reasoning in the presence of a background theory [114].
In the text (page 401) we also mentioned the fact that, over the natural num-
bers (with < and the successor function S), the temporal logic with the until op-
erator has a PSPACE-complete satisﬁability problem; this result is due to Sistla
and Clarke [415]. In the same paper, the authors also show that the satisﬁability
problem for (N, <) is PSPACE-complete for each of the following systems: F
and X; U (until); U , S (since), X; and the extended temporal logic ETL due to
Wolper [456].
The effect of bounding the number of proposition letters and the degree of modal
formulas has been studied by Halpern [203]. In addition to the results mentioned
in Exercises 6.6.5 and 6.7.7, he shows that the PSPACE-completeness results of
Ladner and Halpern and Moses hold for multi-modal versions of K, T, S4, S5, even
with a single proposition letter in the language. If we restrict to a ﬁnite degree, the
satisﬁability problem is NP-complete for all the logics considered, but S4; if we
impose both restrictions, the complexity goes down to linear time in all cases.
The EXPTIME-hardness of PDL (Theorem 6.52) is due to Fischer and Lad-
ner [135], who explicitly construct a PDL formula which simulates the actions of
a linear space bounded alternating Turing machine. The (simpler) proof given in
the text stems from Chlebus [93], which establishes the EXPTIME hardness of the
two person corridor tiling game (via a reduction from alternating Turing machines)
and uses it to provide a new proof of EXPTIME hardness for PDL. Another proof
of this via two person corridor tiling can be found in van Emde Boas [120]; the
recursive formulation of the game halting condition is due to Marx.
The existence of an EXPTIME algorithm for PDL, and the method of eliminat-
ing Hintikka sets, comes from Pratt [363]. Other applications of the method can
be found in multi-modal logics of knowledge equipped with a common knowledge
operator (see Halpern and Vardi [206], or Fagin et al. [125]); in computational
tree logic (CTL; see Emerson [121]); in expressive description logics (see Donini
et al. [115]); and in work on the global modality (see Marx [316] or Spaan [419]).
One important approach to the analysis of modal complexity has not been dis-
cussed in this chapter: the use of ﬁnite automata. The theory of automata has
been a subject of research since the 1960s (Büchi [72], Thatcher and Wright [429],
Rabin [368]). Especially relevant to temporal and dynamic logics has been a resur-
gence of interest in ﬁnite automata on inﬁnite objects in the 1980s and 1990s; see
Gecseg and Steinby [167], Hayashi [214], and Thomas [431, 432]. A wide variety
of automata have been studied, and complexity results for their acceptance prob-
lems are known. It is often possible to analyze the complexity of modal satisﬁabil-
ity problems by reducing them to acceptance problems for automata. For example,412
6 Computability and Complexity
general automata-theoretic techniques for reasoning about relatively simple logics
using Büchi tree automata have been described by Vardi and Wolper [442].
We conclude on a more general note. In this chapter we have focused mainly on
satisﬁability and validity problems – what about the decidability and complexity of
other reasoning tasks? For a start, the global satisﬁability problem (whether there
is a model which satisﬁes a formula at all its points) is important in many applica-
tions and quite different from the (local) satisﬁability problem discussed here. The
discussion of the global modality in Section 6.5 and Exercise 6.8.1 has given the
reader some of the ﬂavor of such problems; for more, see Marx [316]. Other rea-
soning tasks that are closely related to the global satisﬁability problem, are often
studied in the area of description logic mentioned before; see De Giacomo [106]
or Areces and de Rijke [15].
Furthermore, there is a great deal of interest in building practical systems that
evaluate formulas (not necessarily modal ones) in models; this ﬁeld is known as
model checking. Many interesting problems can be usefully viewed as model
checking problems, and representations which enable evaluation to be performed
efﬁciently – even when the models contain a very large number of states – have
been developed. For an intuitive, modally oriented, introduction to the basic ideas,
see Halpern and Vardi [207]. For further pointers to the model checking literature,
see [326, 95, 96, 239].
Third, it is interesting to inquire into the decidability or otherwise of a wide range
of metalogical properties of logics. One such result was mentioned in Section 3.7:
Chagrova’s Theorem tells us that it is undecidable whether a ﬁrst-order property
of frames can be deﬁned by a modal formula. And many other questions along
these lines can be raised (for example: is it decidable whether a new proof rule
is admissible in a given logic?). The best sources for further information on such
topics are Chagrov and Zakharyaschev [88, Chapters 16 and 17] and Kracht [279].
Another line of results that we should mention here is work on the following ques-
tion: given two (ﬁnite) models M and N, how hard is it to decide whether they are
bisimilar? Ponse et al. [360] contains a number of valuable starting points for such
questions.7
Extended Modal Logic
As promised in the preface, this chapter is the party at the end of the book. We
have chosen six of our favorite topics in extended modal logic, and we are going
to tell you a little about them. There is no point in offering detailed advice here:
simply read these introductory remarks and the following Chapter Guide and turn
to whatever catches your fancy.
Roughly speaking, the chapter works its way from fairly concrete to more ab-
stract. A recurrent theme is the interplay between modal and ﬁrst-order ideas. We
start by introducing a number of important logical modalities (and learn that we
have actually been using logical modalities all through the book). We then exam-
ine languages containing the since and until operators, and show that ﬁrst-order
expressive completeness can be used to show modal deductive completeness. We
then explore two contrasting strategies, namely the strategy underlying hybrid logic
(import ﬁrst-order ideas into modal logic, notably the ability to refer to worlds) and
the strategy that leads to the guarded fragment of ﬁrst-order logic (export the modal
locality intuition to classical logic). Following this we discuss multi-dimensional
modal logic (in which evaluation is performed at a sequence of states), and see that
ﬁrst-order logic itself can be viewed as modal logic. We conclude by proving a
Lindström Theorem for modal logic.
Chapter guide
Section 7.1: Logical Modalities (Basic track). Logical modalities have a ﬁxed in-
terpretation in every model. We introduce two of the most important (the
global modality, and the difference operator) and brieﬂy discuss Boolean
Modal Logic (a system which contains an entire algebra of diamonds).
Section 7.2: Since and Until (Basic track). We introduce the since and until op-
erators (and their stronger cousins, the Stavi connectives), discuss the ex-
pressive completeness results they give rise to, and use expressive com-
pleteness to prove deductive completeness.
413414
7 Extended Modal Logic
Section 7.3: Hybrid Logic (Basic track). Hybrid languages are modal languages
which can refer to worlds. They do so using atomic formulas called nom-
inals which are true at exactly one world in any model. We introduce the
basic hybrid language and discuss its completeness theory.
Section 7.4: The Guarded Fragment (Advanced track). As is clear from the stan-
dard translation, modal operators perform a ‘guarded’ form of quantiﬁca-
tion across states. What happens when this idea is exported to ﬁrst-order
logic and generalized? This section provides some answers.
Section 7.5: Multi-Dimensional Modal Logic (Advanced track). By viewing as-
signments as possible worlds and quantiﬁers as diamonds, one can treat
ﬁrst-order logic itself as a modal formalism. In fact, orthodox Tarskian
semantics for ﬁrst-order logic provides a prime example of multi-dimen-
sional modal logic: formulas are evaluated at a sequence of points.
Section 7.6: A Lindström Theorem for Modal Logic (Advanced track). As a fa-
mous theorem due to Lindström tells us, any logic satisfying complete-
ness, compactness, and Löwenheim-Skolem is essentially ﬁrst-order logic.
Is there an analogous abstract characterization of modal logic?
7.1 Logical Modalities
Pure ﬁrst-order logic has a signiﬁcant expressive weakness: it is not strong enough
to express the concept of equality in arbitrary structures. But because equality is
such an important relation, logicians introduce a special binary relation symbol
(namely =) and stipulate that it denotes the equality relation. As the interpretation
of = is ﬁxed, and as the relation it denotes is so fundamental, the equality symbol
is called a logical predicate.
Logical modalities trade on the same idea. Are there important relations which
ordinary modal languages cannot express? Very well then: let us add new modali-
ties and stipulate that they be interpreted by the relation in question. In this section
we will discuss two of the most important logical modalities: the global modality
(which is interpreted by the relation W × W ) and the difference operator (which
is interpreted by =, the inequality relation). We will also make a few remarks
about Boolean Modal Logic (BML), a system containing an entire family of logical
modalities.
But before going any further, let us get one thing absolutely clear: we have
been using logical modalities all through the book. Here is the simplest example.
Suppose we are working with the basic modal language. Now, for many purposes
we may be happy simply using 3 to talk about the relation R – but sometimes
we may want to talk about Rˇ, the converse of R, as well. Now, we know (see
Exercise 2.1.2) that this cannot be done in the basic modal language, so we have
to add a new backward-looking modality as a primitive; doing so, of course, gives7.1 Logical Modalities
415
us the basic temporal language. But note: we do not have to bring in the concept
of time to justify this extension. If a binary relation R is important, its converse is
likely to be too – so it is simply common sense to consider adding a diamond for
Rˇ. In short, the ‘temporal operator’ P is really a logical modality.
The other important example is PDL. To motivate PDL we told a story about pro-
grams and transition systems – but a more abstract motivation is not only possible,
it is more satisfying. The point is this. As soon as we ﬁx a collection of relations
Rα , regular algebra is staring us in the face: we can combine these relations using
union and composition, and form transitive closures. Any model containing the
initial Rα relations implicitly contains many other interesting relations as well –
so it is natural to add extra modalities to deal with them explicitly, and doing so
yields PDL. As this example shows, we can go way beyond the idea of adding a
single new logical modality: we can add an entire algebra of diamonds. We will
see another example of this when we discuss BML.
The global modality
Throughout the book we have emphasized the locality of modal logic, and for
many purposes local languages are ideal. For example, suppose we are working
with a modal language for talking about computer networks, and in this language φ
means Server 1 is active and ψ means Server 2 is active. Then
we can check whether the network makes it possible for Server 1 to be active
by checking whether φ is satisﬁable, and we can check whether it is possible for
Server 2 to be inactive by testing for the satisﬁability of ¬ψ.
But suppose we want to know if whenever Server 1 is active, then so is
Server 2. There is no obvious way to test this. Testing for the satisﬁability
of φ → ψ does not answer this question: if φ → ψ is satisﬁable, this only means
that there is a state where either φ is false or ψ is true. We want to know whether
every state that makes φ true is also a state that makes ψ true. This is clearly a
global query. What are we to do?
Here is an elegant answer: enrich the language with the global modality. To
keeps things simple, suppose we are working in the basic modal language over
some ﬁxed choice of proposition letters; to simplify our notation, let us call this
language ML(3). We will now add a second diamond, written E, and call the
resulting language ML(3, E). The interpretation of E is ﬁxed: in any model M =
(W, R, V ), E must be interpreted using the relation W × W . That is:
M, w  Eφ iff there is a u ∈ W such that M, u  φ.
Thus E scans the entire model for a state that satisﬁes φ. Its dual Aφ := ¬E¬φ has
the following interpretation:
M, w  Aφ iff M, u  φ, for all u ∈ W .416
7 Extended Modal Logic
That is, Aφ asserts that φ holds at all points in the model. In effect, A brings the
metatheoretic notion of global truth in a model down into the object language: for
any model M, and any formula φ, we have that M  φ iff Aφ is satisﬁable in M.
We will call E the global diamond, and A the global box. When it is irrelevant
whether we mean E or its dual, we will simply say global modality.
It should now be clear how to handle the computer network problem: to test
whether Server 2 is active whenever Server 1 is, we test the satisﬁability
not of φ → ψ, but of A(φ → ψ). This query has exactly the global force required.
Well – this looks appealing. But what are the properties of this (obviously richer)
new language? Maybe introducing the global modality destroys the properties that
make model logic attractive in the ﬁrst place! We have made an important change,
and we need to take a closer look at the consequences.
Now, we could begin by discussing the sublanguage ML(E) – but this is not
very interesting (it is easy to see that E is just an S5 modality). Anyway (as our
server example shows) the main reason for adding logical modalities is to have
them available as additional tools. So the real question is: what does ML(3, E)
offer that ML(3) does not? The most obvious answer is expressivity. Let us ﬁrst
consider expressivity at the level of frames:
(R = W 2 )
Ep → 3p,
(R = ∅)
E3,
(∃x∀y ¬Rxy)
E2 ⊥,
(∀x∃y Ryx)
p → E3p,
(|W | = 1)
Ep → p,
n+1

(|W | ≤ n)
i=j E(pi ∧ pj ),
i=1 Epi →
(R is trichotomous) (p ∧ 2q) → A(q ∨ p ∨ 3p),
(Rˇ is well-founded) A(2p → p) → p.
None of the frame classes listed is deﬁnable in ML(3), but (as we ask the reader
to check in Exercise 7.1.1) the ML(3, E) formulas to their right do deﬁne the
corresponding property.
Where does this extra frame expressivity come from? From trivializing the no-
tion of generated submodel (generating on W × W always yields W × W ) and
rendering inapplicable the notion of disjoint union (for any disjoint frames (W, R)
and (W  , R ), (W × W )  (W  × W  ) = (W  W  ) × (W  W  )). By insisting that
E be interpreted using W × W , we have trashed two of the classic modal preser-
vation results and thereby bought ourselves more expressivity. How much more?
For ﬁrst-order deﬁnable frame classes, the answer is elegant:
Theorem 7.1 A ﬁrst-order deﬁnable class of frames is deﬁnable in ML(3, E) iff it
is closed under taking bounded morphic images, and reﬂects ultraﬁlter extensions.7.1 Logical Modalities
417
This is exactly the Goldblatt-Thomason Theorem – minus closure under disjoint
unions and generated subframes.
There is also a gain of expressivity at the level of models (the server example
makes this clear, and we already know from Section 2.1 that the global modality
is not deﬁnable in the basic modal language). Moreover, we can measure the gain
using our old friends: bisimulations. It is an easy exercise to adapt the deﬁnition of
bisimulation for the basic modal language to ML(3, E), and a rather more demand-
ing one to prove a bisimulation-based characterization result for the language. The
reader is asked to attend to these matters in Exercises 7.1.3 and 7.1.4.
What about completeness? The set of valid ML(3, E) formulas can be axioma-
tized as follows. Take the minimal normal logic in 3 and E (that is, apply Deﬁni-
tion 4.13 to this two-diamond similarity type), and add the following axioms:
(reﬂexivity)
(symmetry)
(transitivity)
(inclusion)
p → Ep,
p → AEp ,
EEp → Ep,
3p → Ep.
Note that the ﬁrst three axioms are the familiar T, B, and 4 axioms (written in E
and A rather than 3 and 2). We discussed inclusion in Example 1.29(iv). We will
call this logic Kg .
Theorem 7.2 Kg is strongly complete with respect to the class of all frames.
This theorem says that to lift the minimal logic K (for the basic modal language)
to ML(3, E), we need merely treat the global modality as a normal operator that
satisﬁes four further axioms. In fact, we can lift any canonical ML(3) logic in
this way. If KΓ is a normal modal logic in ML(3), let Kg Γ be the normal modal
logic in ML(3, E) obtained by treating E as a normal operator and adding the four
axioms listed above. Then:
Theorem 7.3 Let Γ be a set of ML(3) formulas, and let F be the class of frames
that Γ deﬁnes. If KΓ is canonical, then Kg Γ is strongly complete with respect to
F.
Proof. Let M = (W, R3 , RE , V ) be the canonical model for Kg Γ. Note that as
KΓ ⊆ Kg Γ, we have that (W, R3 ) belongs to F, for KΓ is canonical. Indeed,
any generated subframe of (W, R3 ) belongs to F, for validity in the basic modal
language is closed under generated subframes.
Given a Kg Γ-consistent set of sentences Σ, use Lindenbaum’s Lemma to ex-
pand it to a Kg -MCS Σ + . By the Canonical Model Theorem, M, Σ+  Σ. Now,
(reﬂexivity), (symmetry), and (transitivity) are canonical formulas, thus RE is an
equivalence relation. And although there is no guarantee that RE is W × W , this418
7 Extended Modal Logic
 , R , V ) be the submodel of M generated by
is easy to correct: let M = (W  , R3
E
 = W  × W  , so we have the global relation
Σ + using the RE -relation. Then RE
we need. Furthermore, because of inclusion, R3 ⊆ RE , thus M is also a gen-
erated submodel of M with respect to R3 , hence M , Σ +  Σ. It only remains
 ) is in F, hence the result follows.
to observe that (by our initial remarks) (W , R3
(Theorem 7.2 is the special case in which Γ = ∅.)
Example 7.4 Suppose we are working with ML(3) over transitive frames (so the
relevant logic is K4, which is canonical). Now, we may want to state global con-
straints on models, or insist that certain information holds somewhere or other, and
of course we can do this if we add the global modality. But how do we obtain a
complete logic for transitive frames in the enriched language?
Simply enrich K4 by treating the global modality as a normal operator and
adding the (reﬂexivity), (transitivity), (symmetry), and (inclusion) axioms. Doing
so yields Kg 4, and by the theorem just proved this logic is strongly complete with
respect to the class of transitive frames.
What about decidability and complexity? We brieﬂy met the global modality in
Section 6.5, and we saw that its global reach makes it possible to force the existence
of gridlike models. This led to undecidability results for languages containing
several diamonds, and it is not difﬁcult to adapt these arguments to ﬁnd frame
classes with decidable ML(3) logics and undecidable ML(3, E) logics (we give
such an example in Exercise 7.1.5). Moreover, although undecidability does not
strike over the class of all frames, Kg is probably more complex than K, for Kg
has an EXPTIME-complete satisﬁability problem (the reader was asked to prove
this in Exercises 6.8.1 and 6.8.2) while K is PSPACE-complete (see Section 6.7).
On the other hand, there is a rather nice transfer result concerning the ﬁltration
method: if we can prove the decidability of an ML(3) logic by using ﬁltrations to
establish the strong ﬁnite frame property, then we can also do so after adding the
global modality. For example, it follows that the logic Kg 4 (see Example 7.4) is
decidable. We will state and prove a stronger version of this result when we discuss
the difference operator.
All in all, the global modality is a strikingly natural extension of modal logic –
and at ﬁrst glance this seems surprising. How can something so obviously global
blend so well with the locality of modal logic? Basically, because the enriched
language still takes an internal perspective on relational structure. Although we
now have a global operator at our disposal, we still place formulas inside models
and evaluate them at a particular state. To put it another way, the intuition that
a modal formula is an automaton scanning accessible states is remarkably robust:
even if we add a special automaton programmed to regard all states as accessible,
we retain much of the characteristic ﬂavor of ordinary modal logic.7.1 Logical Modalities
419
A lot more could be said about the global modality. For a start, it is natural
when viewed from an algebraic perspective (it gives rise to discriminator vari-
eties). Moreover, the global modality can be added to many richer modal systems,
including PDL and the hybrid and multi-dimensional logics discussed later in the
chapter, often without raising the computational complexity (for example PDL is
EXPTIME-complete, and adding E does not change this). But for more informa-
tion the reader will have to consult the Notes and Exercises, for it is time to discuss
an even more powerful logical modality.
The difference operator
At the bottom of every toolbox lies a heavy cast-iron hammer. It is not the sort
of tool we use every day – for delicate jobs it is inappropriate, and we may feel
slightly embarrassed about using it at all. Still, there will always come a time when
something simply will not budge, and then we ﬁnd ourselves reaching for it. Think
of the difference operator as that hammer.
Once again, we will start with ML(3). We will add a second diamond D, the
difference operator, and call the resulting language ML(3, D). The interpretation
of D is ﬁxed: in any model M = (W, R, V ), D must be interpreted using the
inequality relation =. That is:
M, w  Dφ iff there is a u = w such that M, u  φ.
Thus the difference operator scans the entire model looking for a different state that
satisﬁes φ. Its dual D := ¬D¬φ has the following interpretation
M, w  Dφ iff M, u  φ for all u = w.
In what follows we discuss ML(3, D), but the sublanguage ML(D) is quite inter-
esting in its own right, and we ask the reader is asked to explore it in Exercise 7.1.6.
Using the difference operator, we can deﬁne the global modality: Eφ := φ∨Dφ.
Thus all our earlier examples of frame classes deﬁnable in ML(3, E) are deﬁnable
in ML(3, D) too. But ML(3, D) can deﬁne even more:
(irreﬂexivity) 3p → Dp,
(antisymmetry) (p ∧ ¬Dp) → 2(3p → p),
(∃xy (x = y)) D,


(|W | > n)
A( 1≤i≤n pi ) → E 1≤i≤n (pi ∧ Dpi ).
None of these frame classes is closed under bounded morphic images hence (by
Theorem 7.1) none of them is deﬁnable in ML(3, E); but it is easy to see that the
listed ML(3, D) formulas successfully capture them. Incidentally, we have already
seen that ML(3, E) can deﬁne |W | ≤ n, thus as ML(3, D) can deﬁne |W | > n,
the difference operator can count states, at least as far as frames are concerned; in420
7 Extended Modal Logic
Exercise 7.1.7 we ask the reader to investigate whether it can count over models as
well. Furthermore, note the p ∧ ¬Dp antecedent in the deﬁnition of antisymmetry.
This is only true when p is true at exactly one state in the model: in effect we are
using the power of D to force p to act as ‘name’ for a state; we will put this power
to good use shortly.
What about completeness? The set of valid ML(3, D) formulas can be axioma-
tized as follows. Take the minimal normal logic in 3 and D, and add the following
axioms:
(symmetry)
p → DDp,
(pseudo-transitivity) DDp → (p ∨ Dp),
(D-inclusion)
3p → p ∨ Dp.
We will call this logic Kd . Now, it is not particularly difﬁcult to prove the com-
pleteness of Kd (we ask the reader to do so in Exercise 7.1.8) – but it is harder
than with Kg (we have to do more than simply take a generated submodel) and the
result does not extend to stronger logics so easily (there is no obvious analog of
Theorem 7.3). It is also easy to ﬁnd frame incompleteness results, indeed we can
even ﬁnd them in the sublanguage ML(D)! Things are not looking too good . . . .
Enter the hammer. When we discussed rules for the undeﬁnable (Section 4.7) we
learned that proof rules which rely on ‘names’ can lead to general frame complete-
ness results. And as we noted above, the difference operator is powerful enough
to simulate state names, thus we can formulate the following rule of proof (the
D-rule):
 (p ∧ ¬Dp) → θ
.
θ
(Here p is a proposition letter that does not occur in θ. The intuitions underlying
this rule are analogous to those underlying the IRR rule discussed in Section 4.7,
and we will leave it to the reader to verify that it preserves validity.) And now for
a remarkable result. The D-rule neatly meshes with our earlier work on Sahlqvist
formulas to yield one of the most general completeness results known in modal
logic, the D-Sahlqvist theorem.
Here we only formulate a version in the basic temporal language. Consider the
language with operators F , P and D; let, for a set Σ of axioms in this logic, Ktd Σ
be the normal modal logic generated by the axioms of basic temporal logic, the
D-axioms and D-rule given above, and the formulas in Σ.
Theorem 7.5 Let Σ be a collection of Sahlqvist formulas in the basic temporal
language. Then Ktd Σ is strongly sound and complete with respect to the class of
bidirectional frames deﬁned by (the ﬁrst-order frame correspondents of) the axioms
in Σ.7.1 Logical Modalities
421
Proof. We will prove weak completeness only. The ﬁrst step of the proof is to
prove the existence of a collection W of maximal consistent sets such that
(i) each Γ in W contains a name, that is, a formula of the form φ ∧ ¬Dφ,
(ii) for each Γ in W and each formula F ψ ∈ Γ , there is a Δ in W such that Γ
and Δ are in the canonical accessibility relation RFc for F ; and, likewise,
for the operators P and D.
c Γ Δ.
(iii) for each pair of distinct points Γ and Δ in W we have RD
All of this can be proved in the style of Proposition 4.71.
c is the inequality relation on W .
It easily follows from (i) and (iii) above that RD
But then the model on W given by V (p) = {Γ ∈ W | p ∈ Γ } is named; that
is, for every point in the model there is a formula which is true only at this point,
see Deﬁnition 4.76. However, condition (ii) allows us to prove a Truth Lemma
which implies that all axioms of the logic are true throughout the model. But then
it follows from Theorem 4.77 that the Sahlqvist axioms are valid on the underlying
frame as well.
The pinch of Theorem 7.5 lies in the fact that the ﬁrst-order frame correspondents
it mentions use inequality for the ‘relation symbol’ referring to the accessibility
relation of D. This means that we can automatically axiomatize frame properties
like irreﬂexivity or antisymmetry. The reader may doubt the usefulness of this:
surely, the logic of the class of irreﬂexive frames is identical to the logic of the class
of all frames? True, but this may change when we consider irreﬂexivity in addition
with other properties. Conditions like irreﬂexivity, undeﬁnable in themselves, may
nevertheless have ‘side effects’ so to speak. What we mean is that there are frame
classes K such that the logic of K differs from the logic of the irreﬂexive frames in
K. In such cases the above theorem can be of tremendous help.
In a surprisingly large number of cases we ﬁnd ourselves in the situation that
over a certain class of frames, the difference operator is deﬁnable in the underlying
modal language. For example, over the class of strict linear orders, the temporal
formula F p ∨ P p holds at a point if and only if p holds at a different point. In
general, we say that a formula δ(p) acts as D on a frame F if F  δ(p) ↔ Dp; if
δ(p) acts as the difference operator on every frame in a class K then we say that δ
deﬁnes D over K.
Deﬁnability of the difference operator is of great use for axiomatizability, as the
following result shows. For a formula δ(p), let Ktδ Σ be the ‘δ’-version of Ktd ,
that is, the logic in the language without the D-operator obtained by replacing, in
all axioms and derivation rules of Ktd , every formula Dφ with δ(φ).
Theorem 7.6 Let Σ be a collection of Sahlqvist formulas. Then Ktδ Σ is strongly
sound and complete with respect to the class of those bidirectional frames on which
Σ is valid and on which δ acts as the difference operator.422
7 Extended Modal Logic
In the section on multi-dimensional modal logic we will see an application of this
theorem; for a proof, we refer the reader to Exercise 7.1.9. We will examine another
name-driven proof rule (called PASTE) in detail when we discuss hybrid logic. First
we turn to decidability issues concerning the difference operator.
ML(3, D) is a strong language. As it can deﬁne the global modality, Kd must
have an EXPTIME-hard satisﬁability problem (in fact, the problem is EXPTIME-
complete; see Exercise 7.1.10) and it is even easier to ﬁnd undecidable logics
than in ML(3, E). Nonetheless, decidability is often retained. In particular, if
the ML(3) logic of a class of frames can be proved decidable by using a ﬁltration
argument to establish the strong ﬁnite frame property, then the ML(3, D) logic of
that same frame class can be proved decidable in the same way. Let us prove this.
Deﬁnition 7.7 Let Λ be a logic, and let F be a class of frames for Λ. We say that
Λ admits ﬁltrations on F if for any model M which is based on a frame in F, and
for any ﬁnite subformula closed set Σ of ML(3) formulas, there is a ﬁltration Mf
of M through Σ which is based on a frame in F.
Theorem 7.8 Suppose that F is a class of frames, and that ΛF (the set of all
ML(3)-formulas valid on F) admits ﬁltrations on F. Then the logic ΛdF (the set
of all ML(3, D)-formulas valid on F) has the strong ﬁnite frame property with
respect to F.
Proof. Let ξ be an ML(3, D)-formula satisﬁable in a model M = (W, R, V ) of
which the underlying frame (W, R) is in F. We want to show that ξ is satisﬁable in
an F-frame of bounded size.
Let Σ be the set of subformulas of ξ. First consider the relation Σ which
holds between two points if they satisfy the same formulas in Σ. As the points of
our ﬁnite model we would like to take the equivalence classes of this relation but
this would not work out well (it is instructive to see how the proof of the ﬁltration
lemma fails in the inductive step of the difference operator). The key idea of the
proof of the theorem is to solve this problem by splitting each equivalence class in
two parts – unless the original class is a singleton. To achieve this we add a new
proposition letter d to the language and we make d true at exactly one point of each
equivalence class. We would then like to ﬁltrate the new model according to the
equivalence relation Σ∪{d} .
There is still a problem, however: we can only guarantee that the underlying
frame of the ﬁltrated model is in F if we ﬁltrate through a set of ML(3) formulas.
But Σ may contain formulas with occurrences of D. In order to get rid of these, we
employ a little technical trick. For every formula of the form Dψ in Σ, choose a
distinct propositional variable qψ that does not occur in any formula in Σ. Let V  be
the valuation that differs from V , if at all, only in that V  (qψ ) = {w | M, w  Dψ}
and that V  (d) is as indicated above. Let M be the model (W  , R , V  ).7.1 Logical Modalities
423
Now deﬁne the set Σ as follows. It is not difﬁcult to see that for every φ ∈
Σ there is a unique ML(3) formula φ such that φ can be obtained from φ by
replacing in φ every proposition letter qψ by Dψ. Put
Σ  = {φ | φ ∈ Σ} ∪ {d, qψ | Dψ ∈ Σ}.
Observe that the formulas in Σ are D-free and that Σ is subformula closed. The
model M is (or can be seen as) an ML(3)-model satisfying
M, s  φ iff M , s  φ
(7.1)
for all formulas φ in Σ. Let Σ  hold between two points iff they satisfy the
same formulas in Σ ; it is easy to see that every Σ -equivalence class |s| splits
into either one or two Σ  -equivalence classes, depending on whether |s| has one
or more elements.
In any case, it follows from the assumption in the theorem that there is a ﬁltration
Mf through Σ which is based on a frame in F. Note that by deﬁnition, the points
of Mf are the Σ  -equivalence classes. We claim that this model Mf satisﬁes
the following property for all ML(3, D)-formulas φ in Σ and all states s in M:
M, s  φ iff Mf , |s|  φ.
(7.2)
From this, the theorem is almost immediate.
The proof of (7.2) proceeds by a formula induction of which we omit the stan-
dard inductive steps concerning the boolean operators; the clauses for 3 are fairly
easy as well – but note that for one direction, one needs (7.1). For the case that
φ is of the form Dψ we also omit the easy right to left direction of (7.2). For the
other direction, suppose that M, s  Dψ. Then there is a point s = s such that
M, s  ψ. If |s| and |s | are distinct then we are ﬁnished, so suppose otherwise.
But from s Σ  s it follows on the one hand that M, s  d iff M, s  d, and
on the other hand, that s and s belong to the same Σ -equivalence class. Since
we chose exactly one point in each Σ -class to satisfy d, this means that neither
s nor s can be this special point. Hence, there must be another point s in this
Σ -equivalence class which does make d true. From s Σ s it follows that
M, s  ψ, so by the inductive hypothesis we have that Mf , |s |  ψ. But |s | is
distinct from |s| since d holds at s and not at s. This gives that Mf , |s|  Dψ, as
required.
How does decidability follow? Any logic Λ that admits ﬁltrations on F has the
strong ﬁnite frame property with respect to F – so if F is recursive we can apply
Theorem 6.7 and conclude that ΛF is decidable. But then by the result just proved,
we know that ΛdF also has the strong ﬁnite frame property with respect to F, so we
can apply the model enumeration idea underlying the proof of Theorem 6.7 to for-
mulas of the richer languages. As D is always interpreted by the inequality relation,7 Extended Modal Logic
424
and as this relation is obviously computable on ﬁnite structures, the decidability of
ΛdF follows.
A great deal more could be said about the difference operator (in particular,
bisimulations are easily adapted to cope with D, and a bisimulation-based charac-
terization result is forthcoming; see Exercises 6.8.1 and 6.8.2) but it is time to take
a brief look at a system containing a whole family of logical modalities.
Boolean Modal Logic
As we have remarked, as soon as we ﬁx a collection of relations Rα , we can form
the regular algebra over this base; building an algebra of diamonds corresponding
to these leads to PDL. But an even more obvious algebra demands attention: we can
also form the boolean algebra over base relations Rα . Why not deﬁne an algebra
of diamonds corresponding to 1, −, ∩, and ∪? Doing so leads to Boolean Modal
Logic (BML).
We deﬁne the language of BML as follows. As with PDL, we ﬁx a set of primitive
relation symbols a, b, c, . . . , and in addition a distinguished relation symbol 1.
From these we build complex relations using the relation constructors −, ∩ and
∪: that is, if α and β are relation symbols, then so are ¬α, α ∩ β, and α ∪ β.
BML is the modal language containing a diamond α for each relation symbol α.
In principle we can interpret BML on any model of appropriate similarity type –
that is triples M = (W, {Rα | α is a relation symbol }, V ) – but most such models
are inappropriate. We are only interested in boolean models, the models in which
R1 = W × W , and such that, for all relation symbols α and β, R−α = Rα (that
is, (W × W ) \ Rα ), Rα∩β = Rα ∩ Rβ , and Rα∪β = Rα ∪ Rβ .
BML is an expressive language – for a start, it contains the global modality – and
it may seem that we have bitten off more than we can chew. While the ∪ constructor
is well-behaved (in particular F  α ∪ βp ↔ αφ ∨ βp iff Rα∪β = Rα ∪ Rβ ),
the ∩ constructor is difﬁcult to work with. However, as we will now see, with the
help of the − constructor we can get an exact grip on the relations of interest.
First we deﬁne the following operator (often called window): for any relation
symbol α:
[|α|]φ := [−α]¬φ.
That is:
M, w  [|α|]φ iff ∀u (M, u  φ ⇒ Rα wu).
Window is an extremely natural operator – once you have seen it, you wonder how
you ever managed without it (see the Notes for various interpretations). But what
concerns us here is the following result: window allows very smooth deﬁnitions of
the relations we are interested in.7.1 Logical Modalities
425
Proposition 7.9 Let F be a frame (W, {Rα | α is a relation symbol }). Then:
(i) F  [−α]p ↔ [|α|]¬p iff Rα ⊆ Rα ,
(ii) F  [α]¬p ↔ [| − α|]p iff Rα ⊆ Rα ,
(iii) F  [|α ∩ β|]p ↔ [|α|]p ∧ [|β|]p iff Rα∩β = Rα ∩ Rβ .
Proof. We prove the third claim. The right to left direction is trivial. For the left
to right direction, assume that F  [|α ∩ β|]p ↔ [|α|]p ∧ [|β|]p. We need to show
that Rα∩β = Rα ∩ Rβ . To see that Rα∩β ⊆ Rα ∩ Rβ , suppose that Rα∩β wu, and
let V be any valuation on F such that V (p) = {u}. Then (F, V ), w  [|α ∩ β|]p.
As F  [|α ∩ β|]p ↔ [|α|]p ∧ [|β|]p we have (F, V ), w  [|α|]p ∧ [|β|]p. But u is the
only point satisfying p, hence Rα wu and Rβ wu. A similar argument shows that
Rα ∩ Rβ ⊆ Rα∩β .
In a sense, the relations are divided into two kingdoms: the ordinary [α] modalities
govern relations built with ∪, the window modalities [|α|] govern the relations built
with ∩, and the − constructor acts as a bridge between the two realms. Moreover
the bridging function of − also ﬁnds expression in a new rule of proof, BR. Unlike
the other additional rules discussed in this book, BR is not name-driven:
 [α]p → ([β]p → [γ]p)
 [α]p → ([|γ|]¬p → [|β|]¬p)
(BR)
While it is possible to prove a completeness result for BML without using BR, its
use leads to an elegant axiomatization, for it enables us to thread negations through
the structured modalities.
A ﬁnal surprise is in store. In Theorem 6.31 we showed that the fragment con-
taining the ∩ constructor and the global modality was undecidable over determin-
istic frames. Nonetheless, the minimal logic in BML actually turns out to be de-
cidable. All in all, BML is a fascinating system. For more information, see the
Notes.
Exercises for Section 7.1
7.1.1 We listed numerous frame conditions deﬁnable in ML(3, E) and ML(3, D) which
were not deﬁnable in ML(3). Show that these deﬁnability claims are correct.
7.1.2 Show that ML(3, E) validity is preserved under bounded morphisms and reﬂects
ultraﬁlter extensions. (That is, show the easy direction of the Goldblatt-Thomason style
result for ML(3, E) stated in Theorem 7.1.) Can you prove the (far more demanding)
converse?
7.1.3 Extend the standard translation to the global modality and the difference opera-
tor. Extend the notion of bisimulation for the basic modal language to ML(3, E) and
ML(3, D), and show that your deﬁnition leads to an invariance result.426
7 Extended Modal Logic
7.1.4 Building on the previous exercise, characterize the expressivity of ML(3, E) and
ML(3, D) over models.
7.1.5 Let 2-3 be the class of frames (W, R) such that every state has 2 R-successors, and
3 R-successors of R-successors. First show that the satisﬁability problem in ML(3) over
2-3 is decidable (note: this can not be proved using a ﬁltration argument). Then show that
the satisﬁability problem in ML(3, E) over 2-3 is undecidable. (It may be helpful to note
that this exercise is related to Exercise 6.5.2.)
7.1.6 Show that a class of frames is deﬁnable in ML(D) if and only if it is deﬁnable in
the ﬁrst-order language over = (that is, the ﬁrst-order language of equality). What is the
complexity of the satisﬁability problem for ML(D)?
7.1.7 Clearly we can deﬁne in ML(3, D) an operator Q with the following satisfaction
deﬁnition: for any model M, any state w in M, and any formula φ, M, w |= Qφ iff there is
exactly one state u in M such that M, u |= Qφ. But it is also possible to deﬁne modalities
Q2 φ, Q3 φ, Q4 φ, and so on, that are satisﬁed when φ holds at precisely Q n states (n ≥ 2)
in the model?
7.1.8 Show that K d is complete with respect to the class of all frames. (No need to try
anything fancy here – just ﬁddle with the canonical model.)
7.1.9 Prove Theorem 7.6. That is, let Σ be a collection of Sahlqvist formulas in the basic
modal language. Show that K tδ Σ is strongly sound and complete with respect to the
class of those frames on which Σ is valid and on which δ acts as the difference operator.
(Hint: use an auxiliary logic K tδ Σ+ in the temporal language expanded with the difference
operator. Simply deﬁne this logic as having both the D and the δ versions of the D-axioms
and rules. Now ﬁrst use Theorem 7.5 to prove that this logic is sound and strongly complete
with respect to the class of Σ-frames on which δ acts as the difference operator. Then,
prove that Ktδ Σ+ is conservative over K tδ Σ; that is, show that for every purely temporal
formula φ, we have that φ belongs to K tδ Σ iff it belongs to K tδ Σ+ .)
7.1.10 Use an elimination of Hintikka sets argument to show that the K d satisﬁability
problem is solvable in EXPTIME.
7.2 Since and Until
The modal operators considered in previous chapters all have satisfaction deﬁni-
tions involving only existential or only universal quantiﬁers. In this section we
look at a popular temporal logic whose operators are based on modalities with
more complex satisfaction deﬁnitions: S (since) and U (until). The main rea-
son for considering these modalities is, again, to achieve an increase in expressive
power. We will ﬁrst give some examples demonstrating why the increased expres-
sivity is useful. We will then learn that (over Dedekind complete frames) we have
actually achieved expressive completeness: any expression in the ﬁrst-order corre-
spondence language (in one free variable) has an equivalent in the modal language
in S and U . Finally, we will show that this (ﬁrst-order) expressive completeness
leads to (modal) deductive completeness.7.2 Since and Until
427
Basic deﬁnitions
The basic operators needed for temporal reasoning seem to be F and P . These
allow us to say things like ‘Something good will happen’ and ‘Something bad has
happened.’


q?



p
?
-
P q, F p
But in several application areas this is not enough. For example, in the semantics of
concurrent programs one often needs to be able to express properties of executions
of programs that have the general format ‘Something good is going to happen, and
until that time nothing bad will happen.’ Or, more concretely: p will be the case,
and until that time q will hold:



p
. . . . . . . . .q. . . . . . . . . . ?
-
U (p, q)
Such properties are sometimes called guarantee properties in the computational
literature. To state them, the binary until operator U can be used; its satisfaction
deﬁnition reads:
t  U (φ, ψ) iff
there is a v > t such that v  φ and for all s with t < s < v: s  ψ.
The mirror image of U is the since operator S:
t  S(φ, ψ) iff
there is a v < t such that v  φ and for all s with v < s < t: s  ψ.
That is the basic idea – but before going further, let us make our discussion a
little more precise. The set of S, U -formulas is built up from a collection Φ of
proposition letters, the usual boolean connectives, and the binary operators S and
U . The mirror image of a formula φ is obtained by simultaneously substituting S
for U and U for S in φ.
S, U -formulas are interpreted on frames of the form F = (T, <), where T is a
set of time points and < is a binary relation on T . U looks forwards along <, and
S looks backwards. We use the notation (T, <) for frames (rather than our usual
(T, R)) because here we are primarily interested in the temporal interpretation of
S and U . In fact, will be working with frames (T, <) such that < is a Dedekind
complete order – more on this below. To emphasize our interest in the temporal7 Extended Modal Logic
428
interpretation, we will often refer to frames as ﬂows of time. As usual, a valuation
is a function assigning subsets of T to the proposition letters in the language.
How does the language in S and U relate to the basic temporal language? First,
observe that F and P are deﬁnable in the language with S and U : we can deﬁne
F φ := U (φ, ), P φ := S(φ, ), Gφ := ¬F ¬φ and Hφ := ¬P ¬φ. Thus the
language with S and U is at least as strong as the basic temporal language. In fact,
it is strictly stronger. For a start, we saw in Exercise 2.2.4 that the basic temporal
language could not deﬁne U . Moreover, as the following proposition shows, even
if we restrict attention to models based on the real numbers, the basic temporal
language still is not strong enough to deﬁne U .
Proposition 7.10 U is not deﬁnable over (R, <) using F and P .
Proof. We will give two models that agree on all formulas in the language with
F and P only, but that can be distinguished using the until operator. Consider the
following model M1 based on the reals:

p q p
.....
−3 −2
p
p
. . . . . .q. . . . .
−1
0
1
0  U (p, q)
p q p
.....
2
3
p q p
.....
4
5
-
So, V1 (p) = {r | r ∈ Z}, and V1 (q) = {0} ∪ {r | ∃n ∈ N (−2n − 1 < r <
−2n)} ∪ {r | ∃n ∈ N (2n < r < 2n + 1)}.
Next, consider the model M2 given by the following picture:

p q p
.....
−3 −2
. . . . . .q. . . . .
−1
0
1
0  U (p, q)
p q p
.....
2
3
p q p
.....
4
5
-
We leave it to the reader to show that the models M1 and M2 agree on all for-
mulas in F and P , but that M1 , 0  U (p, q), whereas M2 , 0  U (p, q) (see
Exercise 7.2.1).
So the temporal language in S and U is expressive – but just how expressive is
it? To answer such questions we need a correspondence language and a standard
translation of S and U into the correspondence language. Let Φ be a collection of
proposition letters, and let L1< (Φ), or simply L1< , be the ﬁrst-order language with
unary predicate symbols corresponding to the proposition letters in Φ, and with =
and < as binary relation symbols. We use L1< (x) to denote the set of L1< formulas
having one free variable x. Note: this is the familiar correspondence language for
the basic temporal language, except that we are using < rather than R as the binary
relation symbol.7.2 Since and Until


t
ψ


h
g
φ

. . . ← ¬ψ
429

-
s
Fig. 7.1. The Stavi connectives
The standard translation ST x for the until operator U is
ST x (U (φ, ψ)) = ∃z (x < z ∧ ST z (φ) ∧ ∀y (x < y < z → ST y (ψ))).
The standard translation of S is the mirror image of that of U . Observe that we need
3 variables to specify the translation of since and until! We only needed 2 variables
to specify the translation of the basic modal operators (see Proposition 2.49).
Let K be a class of models, ML a modal or temporal language, and L a classical
language. Then ML is expressively complete over K, if every L1< (x)-formula has
an equivalent (over K) in the modal language ML. The study of expressive com-
pleteness is an important theme in temporal logics with since and until because of
the following remarkable result: the language with S and U is expressively com-
plete over the class of all Dedekind complete ﬂows of time (we will deﬁne this
class shortly). Moreover, below we will deﬁne an even richer temporal language
that is expressively complete for the class of all linear ﬂows of time. In the remain-
der of this section we will brieﬂy explain these expressive completeness results,
and use them to obtain a deductive completeness result for since and until over
well-ordered ﬂows of time.
Further preliminaries
A ﬂow of time is called Dedekind complete if every subset with an upper bound has
a least upper bound. The standard examples are the reals (R, <) and the natural
numbers (N, <). A ﬂow of time is well-ordered if every non-empty subset has a
smallest element; the canonical example here is (N, <).
To arrive at our goal of axiomatizing the well-ordered ﬂows of time, we make a
detour through a still richer temporal language built using the Stavi connectives.
Deﬁnition 7.11 (The Stavi Connectives) To introduce the Stavi connectives we
need the notion of a gap. A gap of a frame F = (T, <) is a proper subset g ⊂ T
which is downward closed (that is, t ∈ g and s < t implies s ∈ g), and which
does not have a supremum. One can think of a gap as a hole in a Dedekind-
incomplete ﬂow of time; see Figure 7.1 Now, U  (φ, ψ) holds at a point t if the
situation depicted in the above ﬁgure holds; that is, if430
7 Extended Modal Logic
(i) there are a point s and a gap g such that t ∈ g and s ∈
/ g;
(ii) ψ holds between t and g;
(iii) φ holds between s and g; and
(iv) ¬ψ is true arbitrarily soon after g.
S  (φ, ψ) is the mirror image of U  (φ, ψ).
The above informal second-order deﬁnition (we quantify over gaps, and hence
over sets) can be replaced by a ﬁrst-order deﬁnition; see Exercise 7.2.2.
Theorem 7.12 (Expressive Completeness)
(i) U , S are complete over Dedekind complete ﬂows of time.
(ii) U , S, U  , S  are complete over all linear ﬂows of time.
Next, we need a complete axiom system for the class of linear ﬂows of time:
Deﬁnition 7.13 Consider the following collection of axioms:
(A1a) G(p → q) → (U (p, r) → U (q, r))
(A2a) G(p → q) → (U (r, p) → U (r, q))
(A3a) p ∧ U (q, r) → U (q ∧ S(p, r), r)
(A4a) U (p, q) ∧ ¬U (p, r) → U (q ∧ ¬r, q)
(A5a) U (p, q) → U (p, q ∧ U (p, q))
(A6a) U (q ∧ U (p, q), q) → U (p, q)
(A7a) U (p, q) ∧ U (r, s) →
U (p ∧ r, q ∧ s) ∨ U (p ∧ s, q ∧ s) ∨ U (q ∧ r, q ∧ s)
(Aib) the mirror images of (A1a)–(A7a)
(D)
(F  → U (, ⊥)) ∧ (P  → S(, ⊥))
(L)
H⊥ ∨ P H⊥
(W)
F p → U (p, ¬p)
(N)
D ∧ L ∧ F
Axioms (D), (L), (W), and (N) are discussed in Lemma 7.14 and Exercise 7.2.3
below. As to the other axioms, (A1a) and (A2a) can be viewed as counterparts of
the familiar distribution or K axiom 2(p → q) → (2p → 2q). (A3a) captures
the fact that U and S explore relations that are each other’s converse. (A4a) and
(A5a) connect the current and the future point (at which something good is going
to happen) on the one hand with the points in between on the other hand. (A6a)
expresses transitivity of the ﬂow of time, and, ﬁnally, (A7a) forces the ﬂow of time
to be linearly ordered.
Lemma 7.14 Let F be a linear ﬂow of time. Then
(i) F |= D iff F is a discrete ordering.7.2 Since and Until
431
(ii) F |= W ∧ L iff F is a well-ordering.
(iii) F |= W ∧ N iff F ∼
= (N, <).
The proof of Lemma 7.14 is left as Exercise 7.2.3.
Next, we deﬁne three axiom systems: B, BW, and BN. The set of axioms of B
consists of all classical tautologies, (A1a)–(A7a), and (A1b)–(A7b). BW extends
B with W, and BN extends BW with N. All three derivation systems have modus
ponens, temporal generalization, and uniform substitution as derivation rules:
(MP) If  φ and  φ → ψ, then  ψ.
(TG) If  φ, then  Gφ and  Hφ.
(SUB) If  φ, then  [ψ/p]φ.
A model M is called an X-model if it has M |= φ for all X-theorems φ, where
X ∈ {B, BW, BN}.
For future use we state the following axiomatic completeness result:
Theorem 7.15 For all sets of S, U -formulas Σ and formulas φ: Σ B φ iff Σ |=B
φ.
We need one more preliminary result, on deﬁnable properties. By Exercise 7.2.4,
well-foundedness is a condition on linear frames which cannot be expressed in ﬁrst-
order logic: it involves an essential second-order quantiﬁcation over all subsets of
the universe. However, to arrive at our expressive completeness result we can get
by with less, namely the condition that every ﬁrst-order deﬁnable non-empty subset
must have a smallest element; one can show that deﬁnably well-ordered models are
sufﬁciently similar to genuine well-ordered models.
The following deﬁnition and lemma capture what we need.
Deﬁnition 7.16 Let α be a ﬁrst-order formula in L1< (x), M = (T, <, V ) a model
for L1< . Deﬁne Xα to be the set deﬁned by α, that is, Xα := {t ∈ T | M |= α[t]}.
Then, M is called deﬁnably well-ordered if for all α(x) ∈ L1< , the set Xα has a
smallest element.
Two L1< -models M1 and M2 are called n-equivalent, notation M1 ≡nFOL M2 ,
if for all ﬁrst-order sentences α ∈ L1< of quantiﬁer depth at most n, M1 |= α iff
M2 |= α.
Proviso. For the remainder of this section we will assume that our collection of
proposition letters Φ is ﬁnite. This is not an essential restriction, but it simpliﬁes
some of the arguments below (see Exercise 7.2.5 for a way of circumventing the
assumption).
Lemma 7.17 Let n ∈ N. Then every deﬁnably well-ordered linear model is n-
equivalent to a fully well-ordered model.432
7 Extended Modal Logic
Proof. Let M = (T, <, V ) be a deﬁnably well-ordered linear model. For a, b ∈ T
such that b < a, deﬁne [b, a) = {t ∈ T | b ≤ t < a}, and (∞, a) = {t ∈ T | t <
a}. Obviously, we can view such sets – with the ordering and valuation induced by
M – as linear L1< -models in their own right. Deﬁne
Z := {a ∈ T | ∀b < a ([b, a) has a well-ordered n-equivalent)}.
By Exercise 7.2.6 there are only ﬁnitely many ﬁrst-order formulas α(x, y) of quan-
tiﬁer depth at most n, say α1 (x, y), . . . , αm (x, y). Let β1 (x, y), . . . , βk (x, y) ∈
{α1 (x, y), . . . , αm (x, y)} be such that if M |= βi (x, y)[ab] then [b, a) has a well-
ordered n-equivalent. Then Z is deﬁned by the formula
⎛
⎞
α(x) := ∀y ⎝y ≤ x →
β(x, y)⎠ .
i≤k
As a consequence, T \ Z (the complement of Z in M) is deﬁnable as well. We
will now show that T \ Z is empty. For, suppose otherwise. Then Z must have
a smallest element a (as M is deﬁnably well-ordered). Distinguish the following
cases:
(i) a is the ﬁrst element of T ,
(ii) a has an immediate successor, and
(iii) there exists an ascending sequence (bξ )ξ<λ , which is coﬁnal in [b, a) and
such that b0 = b. (That is, b0 = b, bi < bj whenever i < j, and for all
c ∈ [b, a) there exists a bi > c.)
It is easy to see that the ﬁrst two cases lead to contradictions. As to the third
case, since a is the minimal element of T \ Z, all bξ are in Z. So, by deﬁnition,
every interval [bξ , bξ+1 ) has a well-ordered n-equivalent Mξ . By Exercise 7.2.7
,
the lexicographic sum ξ<λ Mξ is well-ordered and an n-equivalent to [b, a). But
then a ∈ Z – a contradiction.
Therefore T \ Z = ∅, and hence Z = T , so every interval [b, a) of T has an
n-equivalent well-ordered model. By using Exercise 7.2.7 again, we see that M
must have a well-ordered n-equivalent, as required.
Completeness via completeness
With the above preliminaries out of the way, we are now in a position to use the
expressive completeness result recorded in Theorem 7.12 to arrive at an axiomatic
completeness result for BW over well-ordered ﬂows of time.
We need the following lemma:
Lemma 7.18 Every linear BW-model is deﬁnably well-ordered.7.2 Since and Until
433
Proof. Let M be a linear model satisfying all instances of the BW-theorems. We
will prove that every non-empty L1< -deﬁnable subset of T has a smallest element
via detour using the Stavi connectives S and U  .
Let X be a non-empty L1< -deﬁnable subset of T . By Theorem 7.12(ii) it follows
that X has a deﬁning formula φ in the language with S, U , S , U  . If we can show
that φ does in fact belong to the sublanguage with S and U , then we are done,
because then we can use the validity of the axioms W and L to show that there
must be a minimal element in X.
It sufﬁces to show that every formula in the language with S, U , S , U  is equiv-
alent to an S, U -formula over M. To this end we argue by induction of formulas in
the richer language. The only non-trivial case is for formulas of the form U (φ, ψ)
(and their mirror images), where φ and ψ are already assumed to be equivalent to
S, U formulas by the induction hypothesis. So assume M, t  U (φ, ψ). Then
there is a gap g after t such that (i) ψ holds everywhere between t and g, and (ii) ψ
is false arbitrarily soon after g. Now (i) implies that M, t  F ψ, so by the validity
of the W axiom in M it follows that M, t  U (¬ψ, ψ), which contradicts (ii).
Theorem 7.19 BW is (weakly) complete for the class of all well-ordered ﬂows of
time.
Proof. Let φ be a BW-consistent formula. Construct a maximal BW-consistent set
Δ with φ ∈ Δ. As BW extends B, Δ must also be B-consistent. By Theorem 7.15
there exists a linear model M = (T, <, V ) in which Δ is satisﬁable. Clearly, for
every S, U -formula ψ, the formula HW(ψ) ∧ W(ψ) ∧ GW(ψ) is in Δ, where
W(ψ) is the W axiom instantiated for ψ. Thus M is a BW-model, and hence, by
Lemma 7.18 it is deﬁnably well-ordered.
Now, for the ﬁnal step, let n be the quantiﬁer rank of ST (φ). By Lemma 7.17
there is a well-ordered model M that is (n + 1)-equivalent to M. Therefore,
M |= ∃x ST (φ)(x), and we are done.
Using Theorem 7.19 it is easy to obtain a further completeness result, for the tem-
poral logic of the natural numbers.
Theorem 7.20 BN is weakly complete for (ω, <), the natural numbers with their
standard ordering.
The proof of Theorem 7.20 is left as Exercise 7.2.8.
Exercises for Section 7.2
7.2.1 Supply the missing details for the proof of Proposition 7.10.
7.2.2 Give a ﬁrst-order deﬁnition for the Stavi connectives introduced in Deﬁnition 7.11 –
you may assume that we are working on linear ﬂows of time.434
7 Extended Modal Logic
7.2.3 Prove Lemma 7.14. That is, show that D deﬁnes discrete orderings, that W ∧ L
deﬁnes well-orderings, and that W∧N picks out the natural numbers in their usual ordering
up to isomorphism.
7.2.4 Show that well-foundedness is a condition on linear frames which cannot be ex-
pressed in ﬁrst-order logic.
7.2.5 Throughout this section we assumed that the collection of proposition symbols that
we are working with is ﬁnite. Show that this assumption can be lifted.
7.2.6 Show that, over a ﬁnite vocabulary, there are only ﬁnitely many non-equivalent ﬁrst-
order formulas α(x, y) of quantiﬁer depth at most n.
7.2.7 Show that the lexicographic sum of a collection of structures that are well-ordered
and n-equivalent to a given structure M, is again well-ordered and n-equivalent to M.
7.2.8 Prove Theorem 7.20: show that BN is weakly complete for (ω, <), the natural num-
bers with their standard ordering.
7.3 Hybrid Logic
An oddity lurks at the heart of modal logic: although states are the cornerstone
of modal semantics, they are not directly reﬂected in modal syntax. We evaluate
formulas inside models, at some state, and use the modalities to scan accessible
states. But modal syntax offers no grip on the states themselves: it does not let us
name them, and it does not let us reason about state equality. Modal syntax and
semantics dance to different tunes.
For many applications, this is a drawback. As we mentioned in Example 1.17,
both feature and description logics can be viewed as modal logics – or at least,
they can up to a point. Real feature logics contain mechanisms for asserting that
two sequences of transitions lead to the same state, and description logics allow
us to name and reason about individuals. Such capabilities (which are crucial)
take us beyond the kinds of modal language we have considered so far. Similarly,
it is often important to reason about what is going on at particular times, and the
temporal formalisms used in artiﬁcial intelligence usually provide expressions such
as Holds(i, φ), asserting that the information φ holds at the time named by i, to
make this possible. The modal logics considered so far contain no analogs of these
important tools.
In their simplest form, hybrid languages are modal languages which put this
right. Hybrid languages treat states as ﬁrst class citizens, and they do so in a par-
ticularly simple way. The key idea is simply to sort the atomic formulas, and to
use one sort of atom – the nominals – to refer to states. Because this mechanism
is so simple, many of the attractive properties of modal logic (such as robust de-
cidability) are unaffected. Indeed, in certain respects hybrid logics are arguably7.3 Hybrid Logic
435
better-behaved than their ordinary modal counterparts: their completeness theory
is particularly straightforward, and they are proof theoretically natural.
In this section we examine one of the simplest hybrid languages: a two-sorted
system with names for states. To build such a language, take a basic modal lan-
guage (built over propositional variables p, q, r, and so on) and add a second sort
of atomic formula. These new atoms are called nominals, and are typically writ-
ten i, j and k. Both types of atom can be freely combined to form more complex
formulas in the usual way. For example,
3(i ∧ p) ∧ 3(i ∧ q) → 3(p ∧ q)
is a well-formed formula. And now for the key idea: insist that each nominal be
true at exactly one state in any model. Thus a nominal names a state by being
true there and nowhere else. This simple idea gives rise to richer logics. Note,
for example, that the previous formula is valid: if the antecedent is satisﬁed at a
state w, then the unique state named by i must be accessible from w, and both p
and q must be true there. And note that the use of the nominal i is crucial: if we
substituted the ordinary propositional variable r for i, the resulting formula could
be falsiﬁed.
Actually, what we call the basic hybrid language offers more than this: it also
enables us to build formulas of the form @i φ, where i is a nominal. The composite
symbol @i is called a satisfaction operator, and it has the following interpretation:
@i φ is true at any state in a model if and only if φ is satisﬁed at the (unique) state
named by i (so @i φ is analogous to Holds(i, φ)). Satisfaction operators play an
important role in hybrid proof theory.
Our discussion of basic hybrid logic is largely conﬁned to a single topic: the
link between frame deﬁnability and completeness. We will show that when pure
formulas are used as axioms they always yield systems which are complete with
respect to the class of frames they deﬁne. Now, a pure formula is simply a formula
whose only atoms are nominals, so in effect this result tells us that frame complete-
ness is automatic for axioms constructed solely out of names. Our discussion will
center on a proof rule called PASTE which is related to the IRR rule discussed in
Section 4.7 and the D-rule of Section 7.1.
The basic hybrid language
Given a basic modal language built over propositional variables Φ = {p, q, r, . . .},
let Ω = {i, j, k, . . .} be a nonempty set disjoint from Φ. The elements of Ω are
called nominals; they are a second sort of atomic formula which will be used to
name states. We call Φ ∪ Ω the set of atoms and deﬁne basic hybrid language (over
Φ ∪ Ω) as follows:
φ ::= i | p | ⊥ | ¬φ | φ ∧ ψ | 3φ | @i φ.7 Extended Modal Logic
436
For any nominal i, the symbol @i is called a satisfaction operator. Note that, syn-
tactically speaking, the basic hybrid language is simply a multimodal language (the
modalities being 3 and all the @i ), whose atomic symbols are subdivided into two
sorts. If a formula contains no propositional variables (that is, if its only atoms
are nominals) we call it a pure formula. In what follows we assume that we are
working with a ﬁxed basic hybrid language L in which both Φ and Ω are countably
inﬁnite.
The basic hybrid language is interpreted on models. As usual, a model M is
a triple (W, R, V ), where (W, R) is a frame, and V is a valuation. But although
the deﬁnition of a frame is unchanged, we want nominals to act as names, so we
will insist that a valuation V on a frame (W, R) is a function with domain Φ ∪ Ω
and range P(W ) such that for all i ∈ Ω, V (i) is a singleton subset of W . That
is, as usual, we place no restrictions on the interpretation of ordinary propositional
variables, but we insist that a valuation makes each nominal true at a unique state.
We call the unique state w that belongs to V (i) the denotation of i under V . We
interpret the basic hybrid language by adding the following two clauses to the sat-
isfaction deﬁnition for the basic modal language:
M, w  i iff w ∈ V (i),
M, w  @i φ iff M, d  φ where d is the denotation of i under V .
As usual, M  φ means that φ is true at all states in M, F  φ means that φ is
valid on the frame F, and  φ means that φ is valid on all frames.
Note that a formula of the form @i j expresses the identity of the states named
by i and j. Further, note that a formula of the form @i 3j says that the state named
by i has as an R-successor the state named by j.
Although it allows us to refer to states, and talk about state equality, the basic
hybrid language is very much a modal language. Nominals name, but they are sim-
ply a second sort of atomic formula. Moreover, satisfaction operators are normal
modal operators: note that for every nominal i,  @i (φ → ψ) → (@i φ → @i ψ),
is valid; and if  φ, then  @i φ.
Moreover, the basic hybrid language is quite a simple modal language. For
example, its satisﬁability problem is known to be no more complex than the satis-
ﬁability problem for the basic modal language:
Theorem 7.21 The satisﬁability problem for the basic hybrid logic is PSPACE-
complete.
But in spite of its simplicity the basic hybrid language is surprisingly strong when
it comes to frame deﬁnability. For a start, many properties deﬁnable in the basic
modal language can be deﬁned using pure formulas:
(reﬂexivity)
i → 3i,7.3 Hybrid Logic
437
(symmetry)
i → 23i,
(transitivity) 33i → 3i,
(density)
3i → 33i,
(determinism) 3i → 2i.
Moreover, pure formulas also enable us to deﬁne many properties not deﬁnable in
the basic modal language, as the reader can easily verify:
(irreﬂexivity)
(asymmetry)
(antisymmetry)
(intransitivity)
(universality)
(trichotomy)
(at most 2 states)
i → ¬3i,
i → ¬33i,
i → 2(3i → i),
33i → ¬3i,
3i,
@j 3i ∨ @j i ∨ @i 3j,
@i (¬j ∧ ¬k) → @j k.
All the frame properties deﬁned above are ﬁrst-order. This is no coincidence: all
pure formulas deﬁne ﬁrst-order frame conditions. This is easy to prove: there is a
natural way of extending the standard translation to cover nominals and satisfaction
operators which explains why (see Exercise 7.3.1).
But not only do pure formulas deﬁne ﬁrst-order properties, when used as axioms
they are automatically complete with respect to the class of frames they deﬁne.
More precisely, there is a proof system called Kh + RULES such that for any set of
pure formulas Π:
If P is the normal hybrid logic (which we will shortly deﬁne) obtained by
adding the formulas in Π as axioms to Kh + RULES , then P is complete with
respect to the class of frames deﬁned by P.
The rest of the section is devoted to proving this, but before diving into the tech-
nicalities it is worth noting that the result hinges on a rather simple observation.
Let us say that a model (W, R, V ) is named if every state in the model is the de-
notation of some nominal (that is, for all w ∈ W there is some nominal i such that
V (i) = {w}). Furthermore, if φ is a pure formula, we say that ψ is a pure instance
of φ if ψ is obtained from φ by uniformly substituting nominals for nominals. Then
we have:
Lemma 7.22 Let M = (F, V ) be a named model and φ a pure formula. Suppose
that for all pure instances ψ of φ, M  ψ. Then F  φ.
Proof. Exercise 7.3.3.
That is, for named models and pure formulas the gap between truth in a model and
validity in a frame is non-existent. So if we had a way of building named models,7 Extended Modal Logic
438
we would not need to appeal to relatively complex syntactic criteria (such as being a
Sahlqvist formula) to obtain general completeness results: any pure formula would
give rise to a strongly complete logic for the class of frames it deﬁned. In essence,
the work that follows can be summed as follows: we are going to isolate the logic
Kh + RULES and show that we can build named models from its MCSs and prove an
Existence Lemma. Once this is done, a wide range of frame completeness results
will be immediate by an appeal to Lemma 7.22.
Pure extensions of Kh + RULES
Let us ﬁrst say what a normal hybrid logic is:
Deﬁnition 7.23 A set of formulas Λ in the basic hybrid language is a normal hy-
brid logic if it contains all tautologies, 2(p → q) → (2p → 2q), 3p ↔ ¬2¬p,
the axioms listed below, and it is closed under the following rules of proof: modus
ponens, generalization, @i -generalization (if φ is provable then so is @i φ, for any
nominal i) and sorted substitution (if φ ∈ Λ, and θ results from φ by uniformly re-
placing proposition letters by arbitrary formulas, and nominals by nominals, then
θ ∈ Λ). We call the smallest normal hybrid logic Kh .
The motivation for the sorted substitution rule should be clear: while propositional
variables are placeholder for arbitrary information, nominals are names, and sub-
stitution must respect the distinction.
The axioms needed to complete our deﬁnition of Kh fall into three groups. The
ﬁrst identiﬁes the basic logic of satisfaction operators:
(K@ )
@i (p → q) → (@i p → @i q),
(self-dual)
@i p ↔ ¬@i ¬p,
(introduction) i ∧ p → @i p.
As satisfaction operators are normal modal operators, the inclusion of K@ should
come as no surprise. As for self-dual, note that self-dual modalities are those whose
transition relation is a function: given the jump-to-the-named-state interpretation of
satisfaction operators, this is exactly the axiom we would expect. Introduction tells
us how to place information under the scope of satisfaction operators. Actually,
it also tells us how to get hold of such information, for if we replace p by ¬p,
contrapose, and make use of self-dual, we obtain (i ∧ @i p) → p; we call this the
elimination formula.
The second group is a modal theory of naming (or to put it another way, a modal
theory of state equality):
(ref)
(sym)
@i i,
@i j ↔ @j i,7.3 Hybrid Logic
439
(nom) @i j ∧ @j p → @i p,
(agree) @j @i p ↔ @i p.
Note that the transitivity of naming follows from the nom axiom; for example,
substituting the nominal k for the propositional variable p yields @i j∧@j k → @i k.
The ﬁnal axiom pins down the interaction between @ and 3:
(back) 3@i p → @i p.
Note that 3i ∧ @i p → 3p is another valid @-3 interaction principle; it is called
bridge and we will use it when we prove the Existence Lemma. However bridge is
provable in Kh as the reader is asked to show in Exercise 7.3.4.
The soundness of these axioms is clear – but what about completeness? Let
us say that a Kh -MCS is named if and only if it contains a nominal, and call any
nominal belonging to a Kh -MCS a name for that MCS. Now, Kh is strong enough to
prove a lemma which is fundamental to our later work: hidden inside any Kh -MCS
are a collection of named MCSs with a number of desirable properties:
Lemma 7.24 Let Γ be a Kh -MCS. For every nominal i, let Δi be {φ | @i φ ∈ Γ }.
Then:
(i) For every nominal i, Δi is a Kh -MCS that contains i.
(ii) For all nominals i and j, if i ∈ Δj , then Δj = Δi .
(iii) For all nominals i and j, @i φ ∈ Δj iff @i φ ∈ Γ .
(iv) If k is a name for Γ , then Γ = Δk .
Proof. (i) First, for every nominal i we have the ref axiom @i i, hence i ∈ Δi .
Next, Δi is consistent. For assume for the sake of a contradiction that it is not.
Then there are δ1 , ..., δn ∈ Δi such that  ¬(δ1 ∧ · · · ∧ δn ). By @i -necessitation,
 @i ¬(δ1 ∧ · · · ∧ δn ), hence @i ¬(δ1 ∧ · · · ∧ δn ) is in Γ , and thus by self-dual
¬@i (δ1 ∧ · · · ∧ δn ) is in Γ too. On the other hand, as δ1 , ..., δn ∈ Δi , we have
@i δ 1 , ..., @i δ n ∈ Γ . As @i is a normal modality, @i (δ1 ∧ · · · ∧ δn ) ∈ Γ as well,
contradicting the consistency of Γ . So Δi is consistent.
Is Δi maximal? Assume it is not. Then there is a formula χ such that neither
χ nor ¬χ is in Δi . But then both ¬@i χ and ¬@i ¬χ belong to Γ , and this is
impossible: if ¬@i χ ∈ Γ , then by self-duality @i ¬χ ∈ Γ as well. We conclude
that Δi is a Kh -MCS named by i.
(ii) Suppose i ∈ Δj ; we will show that Δj = Δi . As i ∈ Δj , @j i ∈ Γ .
Hence, by sym, @i j ∈ Γ too. But now the result is more-or-less immediate. First,
Δj ⊆ Δi . For if φ ∈ Δj , then @j φ ∈ Γ . Hence, as @i j ∈ Γ , it follows by nom
that @i φ ∈ Γ , and hence that φ ∈ Δi as required. A similar nom-based argument
shows that Δi ⊆ Δj .
(iii) By deﬁnition @i φ ∈ Δj iff @j @i φ ∈ Γ . By agree, @j @i φ ∈ Γ iff7 Extended Modal Logic
440
@i φ ∈ Γ . (We call this the @-agreement property; it plays an important role
in the completeness proof.)
(iv) Suppose Γ is named by k. Let φ ∈ Γ . Then as k ∈ Γ , by introduction
@k φ ∈ Γ , and hence φ ∈ Δk . Conversely, if φ ∈ Δk , then @k φ ∈ Γ . Hence, as
k ∈ Γ , by elimination we have φ ∈ Γ .
In what follows, if Γ is a Kh -MCS and i is a nominal, then we will call {φ | @i φ ∈
Γ } a named set yielded by Γ .
We have reached an important crossroad. It is now reasonably straightforward to
prove that Kh is the minimal hybrid logic. We would do so as follows. Given a Kh -
consistent set of sentences Σ, use the ordinary Lindenbaum’s Lemma to expand
it to a Kh -MCS Σ + , and build a model by taking the submodel of the ordinary
canonical model generated by Σ+ ∪ {Δi | Δi is a named set yielded by Σ+ }.
The reader is asked to do this in Exercise 7.3.5.
But we have a more ambitious goal in mind: we do not want to build just any
model, we want a named model. This will enable us to apply Lemma 7.22 and
prove the completeness of pure axiomatic extensions. However we face two prob-
lems. The ﬁrst is this. Given a Kh -consistent set of formula, we can certainly
expand it to an MCS using Lindenbaum’s Lemma – but nothing guarantees that
this MCS will be named. The second problem is much deeper. Suppose we over-
came the ﬁrst problem and learned how to expand any consistent set of sentences
Σ to a named MCS Σ + . Now, as we want to build a named model, this pretty much
dictates that only the named MCSs yielded by Σ+ should be used in the model con-
struction. And now for the tough part: nothing we have seen so far guarantees that
there are enough MCSs here to support an Existence Lemma. Incidentally, note that
the completeness-via-generation method sketched in the previous paragraph does
not face this problem: generation automatically gives us all successor MCSs, so we
can make use of the ordinary modal Existence Lemma. Unfortunately, not all these
successor MCSs need be named, so the generation method will not help with the
stronger result we have in mind.
But these difﬁculties are similar to those we faced when discussing rules for
the undeﬁnable, and this suggests a solution. In Section 4.7 we simulated names
using tense operators, and used the forwards-and-backwards interplay of F and P
to create a coherent network of named MCSs which supported a suitable Existence
Lemma. Moreover, simulated names were used to deﬁne the D-rule mentioned
in Section 7.1. But nominals are genuine names, and satisfaction operators are
an excellent way of enforcing coherence – surely it must be possible to deﬁne
analogous proof rules for the basic hybrid language? Indeed it is:
(NAME )
j→θ
θ
(PASTE )
 @i 3j ∧ @j φ → θ
 @i 3φ → θ7.3 Hybrid Logic
441
In both rules, j is a nominal distinct from i that does not occur in φ or θ. The
NAME rule is going to solve our ﬁrst problem, the PASTE rule our second. These
rules are clearly close cousins of the IRR rule and the D-rule, but let us defer further
discussion till the end of the section, and put them to work right away.
Let Kh + RULES be the logic obtained by adding the NAME and PASTE rules to
Kh . We say that a Kh + RULES -MCS Γ is pasted iff @i 3φ ∈ Γ implies that for
some nominal j, @i 3j ∧ @j φ ∈ Γ . And now for the key observation: our new
rules guarantee we can extend any Kh + RULES -consistent set of sentences to a
named and pasted Kh + RULES -MCS, provided we enrich the language with new
nominals:
Lemma 7.25 (Extended Lindenbaum Lemma) Let Ω  be a (countably) inﬁnite
collection of nominals disjoint from Ω, and let L be the language obtained by
adding these new nominals to L. Then every Kh + RULES -consistent set of formu-
las in language L can be extended to a named and pasted Kh + RULES -MCS in
language L .
Proof. Enumerate Ω . Given a consistent set of L-formulas Σ, deﬁne Σk to be
Σ ∪ {k}, where k is the ﬁrst new nominal in our enumeration. Σk is consistent.
For suppose not. Then for some conjunction of formulas θ from Σ,  k → ¬θ.
But as k is a new nominal, it does not occur in θ; hence, by the NAME rule,  ¬θ.
But this contradicts the consistency of Σ, so Σk must be consistent after all.
We now paste. Enumerate all the formulas of L , deﬁne Σ 0 to be Σk , and sup-
pose we have deﬁned Σm , where m ≥ 0. Let φm+1 be the (m + 1)-th formula
in our enumeration of L . We deﬁne Σ m+1 as follows. If Σm+1 ∪ {φm+1 } is
inconsistent, then Σm+1 = Σ m . Otherwise:
(i) Σ m+1 = Σ m ∪ {φm+1 } if φm+1 is not of the form @i 3φ. (Here i can be
any nominal.)
(ii) Σ m+1 = Σ m ∪ {φm+1 } ∪ {@i 3j ∧ @j φ}, if φm+1 is of the form @i 3φ.
(Here j is the ﬁrst nominal in the new nominal enumeration that does not
occur in Σm or @i 3φ.)
Let Σ + = n≥0 Σ n . Clearly this set is named (by k), maximal, and pasted.
Furthermore, it is consistent, for the only non-trivial aspects of the expansion is
that deﬁned by the second item, and the consistency of this step is precisely what
the PASTE rule guarantees. Note the similarity of this argument to the standard
completeness proof for ﬁrst-order logic: in essence, PASTE gives us the deductive
power required to use nominals as Henkin constants.
And now we can deﬁne the models we need. We are basically going to use the
named sets examined in Lemma 7.24, but with one small but crucial change: in-442
7 Extended Modal Logic
stead of starting with an arbitrary Kh -MCS, we will insist on using the named sets
yielded by a named and pasted Kh + RULES -MCS.
Deﬁnition 7.26 Let Γ be a named and pasted Kh + RULES -MCS. The named
model yielded by Γ , is MΓ = (W Γ , RΓ , V Γ ). Here W Γ is the set of all named sets
yielded by Γ , R is the restriction to W Γ of the usual canonical relation between
MCSs (so RΓ uv iff for all formulas φ, φ ∈ v implies 3φ ∈ u) and V Γ is the usual
canonical valuation (so for any atom a, V Γ (a) = {w ∈ W Γ | a ∈ w}).
Note that MΓ really is a model: by items (i) and (ii) of Lemma 7.24, V Γ assigns
every nominal a singleton subset of WΓ . And, because we insisted that Γ be
named and pasted, we can prove the Existence Lemma we require:
Lemma 7.27 (Existence Lemma) Let Γ be a named and pasted Kh + RULES -
MCS, and let M = (W, R, V ) be the named model yielded by Γ . Suppose u ∈ W
and 3φ ∈ u. Then there is a v ∈ W such that Ruv and φ ∈ v.
Proof. As u ∈ W , for some nominal i we have that u = Δi . Hence as 3φ ∈ u,
@i 3φ ∈ Γ . But Γ is pasted so for some nominal j, @i 3j ∧ @j φ ∈ Γ , and so
3j ∈ Δi and φ ∈ Δj . If we could show that RΔi Δj , then Δj would be a suitable
choice of v. So suppose ψ ∈ Δj . This means that @j ψ ∈ Γ . By @-agreement
(item (iii) of Lemma 7.24) @j ψ ∈ Δi . But 3j ∈ Δi . Hence, by bridge, 3ψ ∈ Δi
as required.
In short, we have successfully blended the ﬁrst-order idea of Henkin constants with
the modal idea of canonical models, and it is plain sailing all the way to the desired
completeness result.
Lemma 7.28 (Truth Lemma) Let M = (W, R, V ) be the named model yielded
by a named and pasted Kh + RULES -MCS Γ , and let u ∈ W . Then, for all formulas
φ, φ ∈ u iff M, u  φ.
Proof. Induction on the structure of φ. The atomic, boolean, and modal cases are
obvious (we use the Existence Lemma just proved for the modalities). What about
the satisfaction operators? Suppose M, u  @i ψ. This happens iff M, Δi  ψ (for
by items (i) and (ii) of Lemma 7.24, Δi is the only MCS containing i, and hence,
by the the atomic case of the present lemma, the only state in M where i is true) iff
ψ ∈ Δi (inductive hypothesis) iff @i ψ ∈ Δi (using the fact that i ∈ Δi together
with introduction for the left to right direction and elimination for the right to left
direction) iff @i ψ ∈ u (@-agreement).
Theorem 7.29 (Completeness) Every Kh + RULES -consistent set of formulas in
language L is satisﬁable in a countable named model. Moreover, if Π is a set7.3 Hybrid Logic
443
of pure formulas (in L), and P is the normal hybrid logic obtained by adding all
the formulas in Π as extra axioms to Kh + RULES , then every P-consistent set
of sentences is satisﬁable in a countable named model based on a frame which
validates every formula in Π.
Proof. For the ﬁrst claim, given a Kh + RULES -consistent set of formulas Σ, use
the Extended Lindenbaum Lemma to expand it to a named and pasted set Σ+ in
a countable language L . Let M = (W, R, V ) be the named model yielded by
Σ + . By item (iv) of Lemma 7.24, because Σ+ is named, Σ + ∈ W . By the Truth
Lemma, M, Σ +  Σ. The model is countable because each state is named by
some L nominal, and there are only countably many of these.
For the ‘moreover’ claim, given a P-consistent set of formulas Ξ, use the Ex-
tended Lindenbaum Lemma to expand it to a named pasted P-MCS Ξ+ . The named
model MΞ that Ξ + gives rise to will satisfy Ξ at Ξ+ ; but in addition, as ev-
ery formula in Π belongs to every P-MCS, we have that MΞ  Π. Hence, by
Lemma 7.22, the frame underlying MΞ validates Π.
Example 7.30 We know that i → ¬3i deﬁnes irreﬂexivity and 33i → 3i de-
ﬁnes transitivity, hence adding these formulas as axioms to Kh + RULES yields a
logic (let us call it I4) which is complete with respect to the class of strict preorders.
Hence 33p → 3p, the ordinary modal transitivity axiom, must be I4-provable.
Furthermore, as i → ¬33i is valid on any asymmetric frame, and i → 2(3i → i)
is valid on any antisymmetric frame, these must be I4-provable too. The reader is
asked to supply I4-proofs in Exercise 7.3.6.
The PASTE rule has played a pivotal role in our work; is there anything we can
say about it apart from ‘Hey, it works!’? There is. As we will now see, PASTE is
actually a lightly-disguised sequent rule.
A sequent is an expression of the form Γ −→ Θ, where Γ and Θ are multisets of
formulas (that is, Γ and Θ may contain multiple occurrences of the same formula).
Note that the sequent arrow −→ is longer than the material implication arrow →.
Sequents can be read as follows: whenever all the formulas in Γ are true at some
state in a model, at least one formula in Θ is true at that state too. A sequent rule
takes a sequent as input, and returns another sequent as output.
Now, here is PASTE as we stated it above:
 @i 3j ∧ @j φ → θ
.
 @i 3φ → θ
Let us get rid of the  symbols and replace the implications by sequent arrows:
@i 3j ∧ @j φ −→ θ
.
@i 3φ −→ θ444
7 Extended Modal Logic
Splitting the formula in the top line into two simpler formulas yields:
@i 3j, @j φ −→ θ
.
@i 3φ −→ θ
This rule works in arbitrary deductive contexts, so let us add a left-hand multiset
Γ , and turn θ into a right-hand multiset Θ, thus obtaining:
@i 3j, @j φ, Γ −→ Θ
.
@i 3φ, Γ −→ Θ
But this is just a sequent rule, and a useful one at that. Let us read it from bottom
to top: to prove Θ given the information @i 3φ and Γ (that is, the bottom line),
introduce a brand new nominal j and try to prove Θ from @i 3j, @j φ and Γ (that
is, the top line). That is, we should search for a proof by decomposing the formula
@i 3φ into a near-atomic formula @i 3j and simpler formula @j φ. In fact, this
decomposition is the key idea needed to deﬁne sequent calculi, tableaux, and natu-
ral deduction systems for hybrid logics, and several systems which work this way
have been developed (see the Notes for details). In effect, such systems discard Kh
from Kh + RULES (after all, why bother keeping the clumsy Hilbert-style part?)
and strengthen the RULES component so it can assume full deductive responsibility.
To conclude, a general remark. As should now be clear (especially if you have
already done Exercises 7.3.1, 7.3.2, and 7.3.3), the basic hybrid language is a gen-
uine hybrid between ﬁrst-order and modal logic: it makes available a number of
key ﬁrst-order capabilities (such as names for states and state-equality assertions)
in a decidable (indeed, PSPACE-complete) propositional modal logic. But now
that we are used to viewing names as formulas, it is easy to go even further. For
example, instead of thinking of nominals as names, we could think of them as
variables over states and bind them with quantiﬁers. For example, we could allow
ourselves to form expressions such as
∃x (x ∧ 3∃y (y ∧ φ ∧ @x 2(3y → ψ))).
This expression captures the effect of the until operator: it says U (φ, ψ). Note that
in this example the ∃ quantiﬁer is only used to bind nominals to the current state.
This is such an important operation that a special notation, ↓, has been introduced
for it. Using this notation the deﬁnition of U (φ, ψ) can be written as
↓x (x ∧ 3↓y (y ∧ φ ∧ @x 2(3y → ψ))).
It turns out that when the basic hybrid language is enriched only with ↓ (that is,
not with the full power of ∃) then the resulting language picks out exactly the frag-
ment of the ﬁrst-order correspondence language that is invariant under generated
submodels. See the Notes for more details.7.3 Hybrid Logic
445
Exercises for Section 7.3
7.3.1 Extend the standard translation to the basic hybrid language by adding clauses for
nominals and satisfaction operators. Use your translation to show that all classes of frames
deﬁned by pure formulas are ﬁrst-order deﬁnable. (Hint: translate nominals to free ﬁrst-
order variables.)
7.3.2 For any n ≥ 1, let R n xy be the ﬁrst-order formula ∃z 1 · · · ∃zn (Rxz1 ∧ Rz1 z2 ∧
· · · ∧ Rzn y). Let ψ be a ﬁrst-order formula that is a boolean combination of formulas of
the form R n xy, Rxy, and x = y. Show that the class of frames deﬁned by the universal
closure of ψ is deﬁnable in the basic hybrid language. (Hint: look at the way we deﬁned
trichotomy.)
7.3.3 Prove Lemma 7.22. That is, if M = (F, V ) is a named model and φ is a pure formula
and for all pure instances ψ of φ we have that M  ψ, then F  φ.
7.3.4 Show that 3i ∧ @ i p → 3p, the bridge formula, is provable in K h . (Hint: prove the
contraposed form 3i ∧ 2p → @ i p with the help of 3q ∧ 2p → 3(q ∧ p), introduction,
and back.)
7.3.5 Prove that K h is the minimal hybrid logic by ﬂeshing out the completeness-via-
generation argument sketched in the text.
7.3.6 Find I4-proofs of 33p → 3p, i → ¬33i, and i → 2(3i → i). (The logic I4 was
introduced in Example 7.30.)
7.3.7 The PASTE rule makes crucial use of @-operators. Prove an analog of Theorem 7.29
for the @-free sublanguage of the basic hybrid language. (Hint: you need to simulate the
satisfaction operators using the modalities. So for all n, m ≥ 0, add the axiom 3 n (i∧p) →
2m (i → p). Furthermore, let 3 i φ be shorthand for 3(i ∧ φ), and add all rules of the form
 3 k · · · 3i 3j φ → θ
.
 3k · · · 3i 3φ → θ
Here j is a nominal distinct from k, · · · , i that does not occur in φ or θ.)
7.3.8 Let I4D be the normal hybrid logic obtained by adding the axiom 3(i ∨ ¬i) to
I4. Clearly I4D lacks the ﬁnite frame property. Show that it possesses the ﬁnite model
property (and hence that Theorem 3.28 fails for hybrid languages). Exploit this by proving
the decidability of I4D using a ﬁltration argument.
7.3.9 Add the global diamond E to the basic hybrid language. Use a ﬁltration argument
to show that the satisﬁability problem for the resulting language is decidable. What is
its complexity? (Note that @ i φ can be deﬁned to be E(i ∧ φ), so you do not have to
deal explicitly with the satisfaction operators.) Show that a class of frames is deﬁnable
in this language if and only if it is deﬁnable in the basic modal language enriched with
the D-operator. (Here ‘deﬁnable’ means deﬁnable by an arbitrary formula, not just a pure
formula.)446
7 Extended Modal Logic
7.4 The Guarded Fragment
In Chapter 2 we saw that modal languages can be viewed as fragments of ﬁrst-
order logic, and in Chapter 6 we discovered that these fragments have some nice
computational properties. It thus seems natural to try and see how far we can
generalize these properties to larger fragments of ﬁrst-order logic. This will be the
main aim of this section: we will deﬁne and discuss two extensions of the modal
fragment with reasonably nice computational behavior.
In order to isolate such fragments, what properties of the modal fragment of
ﬁrst-order logic should we concentrate on? In particular, what makes modal logic
decidable? If we conﬁne ourselves to the basic modal language, is it perhaps the
fact that the standard translation can be carried out entirely within the two variable
fragment of ﬁrst-order logic (which has a decidable satisﬁability problem)? This
argument immediately breaks down if we consider languages with modal operators
of higher arity: while giving rise to decidable logics as well, these languages have
standard translations that really need more than two variables. But as soon as we
are considering n-variable fragments of ﬁrst-order logic with n > 2, we face an
undecidable satisﬁability problem.
Rather, it seems to be the fact that the modal fragment of ﬁrst-order logic allows
quantiﬁcation only in a very restricted form, as is obvious from the modal clause
in the deﬁnition of the standard translation function:
ST x (3φ) = ∃y (Rxy ∧ ST y (φ)).
(7.3)
It is this restricted form of quantiﬁcation which ensures that modal logic is the
bisimulation invariant fragment of ﬁrst-order logic, and bisimulation invariance of
modal truth was critical in the ﬁrst method of proving the ﬁnite model property for
the basic modal language (see Section 2.3). Recall that the starting point of this
method was the observation that modal logic has the tree model property (meaning
that every satisﬁable modal formula is satisﬁable on a tree model), and that bisimu-
lation invariance is pivotal in proving this result. In short, there seems to be a direct
line from the restricted quantiﬁer pattern in (7.3), via bisimulation invariance and
the tree model property, to the ﬁnite model property and decidability.
This provides our ﬁrst search direction: look for ﬁrst-order fragments charac-
terized by restricted quantiﬁcation. It turns out that one can easily relax many
constraints applying to the (basic) modal fragment. For example, we do not have
to conﬁne ourselves to formulas using two variables only, to formulas having pre-
cisely one free variable, or to formulas with predicates of arity at most two. Relax-
ing these constraints naturally leads to the so-called guarded fragment of ﬁrst-order
logic; the idea here is that quantiﬁers may appear only in the following form:
∃y (G(x, y) ∧ ψ(x, y))
(7.4)
in which G(x, y) is an atomic formula that we will call the guard of the quantiﬁ-7.4 The Guarded Fragment
447
cation (or, of the formula). The crucial ingredient that we keep from (7.3) is that
all free variables of ψ are also free in the guard G(x, y). And indeed, it can be
shown that the guarded fragment has various nice properties, such as a decidable
satisﬁability problem and the ﬁnite model property.
However, there are some very natural modal-like languages, or alternative but
intuitive interpretations for standard modal languages, that correspond to a decid-
able fragment of ﬁrst-order logic as well, but are not covered by this deﬁnition. For
example, consider the language with the since and until operators: it is straightfor-
ward to turn the truth deﬁnitions for these operators into a standard translation to
ﬁrst-order logic. The interesting clauses are
ST x (U (φ, ψ)) = ∃y (Rxy ∧ ST y (φ) ∧ ∀z ((Rxz ∧ Rzy) → ST z (ψ))),
(∗)
and a similar one for the since operator. We can prove that this kind of clause
takes us outside the guarded fragment of ﬁrst-order logic: the problem concerns
the ‘betweenness conjunct’ ∀z ((Rxz ∧ Rzy) → ST z (ψ)) which has a ‘compos-
ite’ guard, (Rxz ∧ Rzy). Nevertheless, the language with since and until has a
decidable satisﬁability problem; apparently, some composite guards are admissible
as well.
Examples such as (∗) lead to extensions of the guarded fragment to fragments
in which one is more liberal in the precise conditions imposed on the guard. One
can be a bit more liberal here because in the ‘direct line’ mentioned earlier there
are some steps that could be skipped on the way. In particular, if we are interested
in decidability rather than the ﬁnite model property, we could just as well settle
for fragments of ﬁrst-order logic to which we may apply the mosaic method of
Section 6.4. Recall that the mosaic method is a way of proving decidability by
‘deconstructing’ a model into a ﬁnite number of ﬁnite pieces, and then using such
ﬁnite toolboxes for constructing models again, models that usually hang together
quite loosely (in a sense to be made precise later). This provides the second di-
rection in our quest: try to ﬁnd fragments of ﬁrst-order logic to which the mosaic
method applies, leading to a loose model property. Implementing this idea one
naturally ﬁnds quantiﬁer restrictions of the form
∃y (π(x, y) ∧ ψ(x, y))
(7.5)
in which there are constraints on the presence of variables in certain subformulas
of the guard π. For such fragments one may ﬁnd a direct line from the restricted
quantiﬁer pattern in (7.5), via an appropriate notion of bisimulation invariance and
the loose model property, to some ﬁnite mosaic property and decidability.
The particular extension that we discuss in this section is that of the packed
fragment; it ﬁts very nicely in the mosaic approach. On a ﬁrst reading of the
section the reader may choose to skip the parts referring to this packed fragment,
and concentrate on the guarded fragment.448
7 Extended Modal Logic
The guarded and the packed fragment
We need some preliminaries. The ﬁrst-order language that we will be working
in is purely relational, with equality; the language contains neither constants nor
function symbols. For a sequence of variables x = x1 , . . . , xn , we frequently
write ∃x φ, which, as usual, has the same meaning as ∃x1 . . . ∃xn φ. However,
in this section we view ∃x not as an abbreviation, but as a primitive operator. In
particular this means that the subformulas of ∃x φ are just ∃x φ itself, together with
the subformulas of φ. As usual, by writing φ(x) we indicate that the free variables
of φ are among x1 , . . . , xn .
Deﬁnition 7.31 We say that a formula φ packs a set of variables {x1 , . . . , xk } if
(i) Free(φ) = {x1 , . . . , xk } and (ii) φ is a conjunction of formulas of the form
xi = xj or R(xi1 , . . . , xin ) or ∃xj1 . . . ∃xjm R(xi1 , . . . , xin ) such that (iii) for
every xi = xj , there is a conjunct in φ in which xi and xj both occur free.
The packed fragment PF is deﬁned as the smallest set of ﬁrst order formulas
which contains all atomic formulas and is closed under the boolean connectives
and under packed quantiﬁcation. That is, whenever ψ is a packed formula, π packs
Free(π), and Free(ψ) ⊆ Free(π), then ∃x (π ∧ ψ) is packed as well; π is called
the guard of this formula. The guarded fragment GF is the subfragment of PF in
which we only allow guarded quantiﬁcation as displayed in (7.4); that is, packed
quantiﬁcation in which the guard π is an atomic formula.
PF n and GF n denote the restrictions to n variables and at most n-ary predicate
symbols of PF and GF , respectively.
Examples of guarded formulas are
(i) the standard translation of any modal formula (in any language),
(ii) the standard translation of any formula in the basic temporal language,
(iii) formulas like ∀xy (Rxy → Ryx), ∃xy (Rxy ∧ Ryx ∧ (Rxx ∨ Ryy)), . . . .
For an example of a packed formula which is not guarded, consider ∃xyz ((Rxy ∧
Rxz ∧Ryz)∧¬Cxyz). For another example, ﬁrst consider the standard translation
∃y (Rxy ∧ P y ∧ ∀z ((Rxz ∧ Rzy) → Qz)) of the formula U (p, q). This formula is
not packed itself, because the guard of the subformula ∀z ((Rxz ∧ Rzy) → Qz))
has no conjunct in which the variables x and y occur together. But of course, the
formula is equivalent to
∃x (Rxy ∧ P y ∧ ∀z ((Rxz ∧ Rzy ∧ Rxy) → Qz))
which is packed. It is not hard to convert this example into a proof showing that
every formula in the since and until language is equivalent to a packed formula.
Second, note that the notion of packedness only places meaningful restrictions
on pairs of distinct variables: since the formula x = x packs the set of variables7.4 The Guarded Fragment
449
{x}, the formula ∃x (x = x ∧ ψ(x)), (that is, with a single quantiﬁcation over the
variable x) is a packed formula, at least, provided that ψ(x) is packed. Since the
given formula is equivalent to ∃x ψ(x) this shows that packedness allows a fairly
mild form of ordinary quantiﬁcation, namely over formulas with one free variable
only. A nice corollary of this is that we may perform the standard translation of the
global diamond E within the two variable guarded fragment:
ST x (Eφ) = ST y (Eφ) = ∃x (ST x (φ)) ≡ ∃x (x = x ∧ ST x (φ)).
Finally, not all formulas are packed, or equivalent to a packed formula. For exam-
ple, the transitivity formula ∀yz ((Rxy ∧ Ryz) → Rxz) is not packed, and neither
is the standard translation of the difference operator: ∃y (x = y ∧ P y).
Nice properties
Having deﬁned the packed and the guarded fragment of ﬁrst-order logic, let us
see now what we can prove about these fragments. To start with, for each of the
two fragments we can ﬁnd a suitable notion of bisimulation which characterizes
the fragment in the same way as the ordinary bisimulation characterizes the modal
fragment of ﬁrst-order logic. Unfortunately we do not have the space to go into
detail here. Nevertheless, we will show that both fragments have what we call the
loose model property: in Theorem 7.33 we will show that every satisﬁable packed
formula can be satisﬁed on a loose model. What, then, is a loose model?
Deﬁnition 7.32 Let A = (A, I) be a ﬁrst-order structure. A tuple (a1 , . . . , an ) of
objects in A is called live in A if either a1 = · · · = an or (a1 , . . . , an ) ∈ I(P )
for some predicate symbol P . A subset X of A is called guarded if there is some
live tuple (a1 , . . . , an ) such that X ⊆ {a1 , . . . , an }. In particular, singleton sets
are always guarded; note also that guarded sets are always ﬁnite. X is packed or
pairwise guarded if it is ﬁnite and each of its two-element subsets is guarded.
We say that A is a loose model of degree k ∈ N if there is some acyclic connected
graph G = (G, E) and a function f mapping nodes of G to subsets of A of size
not exceeding k such that for every live tuple s̄ from A, the set L(s) = {g ∈ G |
si ∈ f (g) for all si }, is a non-empty and connected subset of G.
In words, we call a model A = (A, I) loose if we can associate a connected graph
G = (G, E) with it in the following way. Each node t of the graph corresponds
to a small subset f (t) of the model; a good way of thinking about this is that t
‘describes’ f (t). One then requires that the graph ‘covers’ the entire model in the
sense that any a ∈ A belongs to one of these sets (this follows from the fact that for
any a ∈ A, the ‘tuple’ a is live). The fact that each set L(a) is connected whenever
a is live, implies that various nodes of the graph will not give contradictory descrip-
tions of the model. Finally, the looseness of the model stems from the acyclicity of450
7 Extended Modal Logic
G and the connectedness of the sets L(a); for, this ensures that in walking through
the graph we may describe different parts of the model, but we never have to worry
about returning to the same part once we have left it. Summarizing, we may see
the graph as a loose, coherent collection of descriptions of local submodels of the
model. Loose models are the ones for which we can ﬁnd such a graph.
The following result states that the packed fragment of ﬁrst-order logic has the
loose model property.
Theorem 7.33 Every satisﬁable packed formula can be satisﬁed on a loose model
(of degree at most the number of ∃x subformulas of ξ).
But the big question is of course whether following this looseness principle we
have indeed arrived at a decidable fragment of ﬁrst-order logic. The next theorem
states that we have.
Theorem 7.34 The satisﬁability problems for the guarded and the packed frag-
ment are decidable; both problems are DEXPTIME-complete (complete for doubly
exponential time). However, for a ﬁxed natural number n, the satisﬁability problem
for formulas in the packed fragment PFn is decidable in EXPTIME.
And ﬁnally, what about the ﬁnite model property? Will every satisﬁable packed
formula have a ﬁnite model? Here as well, the packed fragment displays very nice
behavior. Unfortunately, we do not have the space for a proof of the ﬁnite model
property for the packed fragment – sufﬁce it to say that it involves some quite
advanced techniques from ﬁnite model theory. For some further information the
reader is referred to the Notes at the end of the section.
Mosaics
The remainder of the section is devoted to proving the Theorems 7.33 and 7.34.
The main idea behind the proof is to use the mosaic method that we met in Chap-
ter 6. Roughly speaking, this method is based on the idea of deconstructing models
into a ﬁnite collection of ﬁnite submodels, and, conversely, of building up new,
‘loose’ models from such parts. We will see that the packed fragment is in a sense
tailored towards making this idea work.
The proof is structured as follows. We start by formally deﬁning mosaics and
some related concepts. After that we state the main result concerning the mosaic
method, namely the Mosaic Theorem stating that a packed formula is satisﬁable if
and only if there is a so-called linked set of mosaics for it, of bounded size. This
equivalence enables us to deﬁne our decision algorithm and establish the com-
plexity upper bounds mentioned in Theorem 7.34. We then continue to prove the7.4 The Guarded Fragment
451
Mosaic Theorem. In doing so we obtain the loose model property for the packed
fragment as a spin-off.
For a formal deﬁnition of the concept of a mosaic we ﬁrst need some syntactic
preliminaries. Given a ﬁrst-order formula ξ, we let Var (ξ) and Free(ξ) denote
the sets of variables and free variables occurring in ξ, respectively. Let V be a
set of variables. A V -substitution is any partial map σ : V → V . The result of
performing the substitution σ on the formula ψ is denoted by ψσ . (We can and
may assume that such substitutions can be carried out without increasing the total
number of variables involved; more precisely, we assume that if Var (ψ) ⊆ V then
Var (ψ σ ) ⊆ V .)
As usual, we will employ a notion of closure to delineate a ﬁnite set of relevant
formulas, that is formulas that for some reason critically inﬂuence the truth of a
given formula ξ. Let the single negation ∼φ of a formula φ denote the formula ψ
if φ is of the form ¬ψ; otherwise, ∼φ is the formula ¬φ; we say that a set Σ of
formulas is closed under single negations if ∼φ ∈ Σ whenever φ ∈ Σ.
Deﬁnition 7.35 Let Σ be a set of packed formulas in the set V of variables.
We call Σ V -closed if it is closed under subformulas, single negations and V -
substitutions (that is, if ψ belongs to Σ, then so does ψσ for every V -substitution
σ). With Clg (ξ) we denote the smallest Var (ξ)-closed set of formulas containing
ξ.
For the remainder of this section, we ﬁx a packed formula ξ – all deﬁnitions to
come should be understood as being relativized to ξ. The number of variables oc-
curring in ξ (free or bound) is denoted by k; that is, k is the size of Var (ξ). It
can easily be veriﬁed that the sets of guarded and packed formulas are both closed
under taking subformulas; hence, the set Clg (ξ) consists of guarded (packed, re-
spectively) formulas. An easy calculation shows that the cardinality of Clg (ξ) is
bounded by kk · (2|ξ|).
The following notion is the counterpart of the atoms that we have met in earlier
decidability proofs (see Lemma 6.29, for instance). All three deﬁning conditions
are fairly obvious.
Deﬁnition 7.36 Let X ⊆ Var (ξ) be a set of variables. An X-type is a set Γ ⊆
Clg (ξ) with free variables in X satisfying, for all formulas φ ∧ ψ, ∼φ, φ in Clg (ξ)
with free variables in X, the conditions (i) φ ∧ ψ ∈ Γ iff φ ∈ Γ and ψ ∈ Γ ,
(ii) φ ∈ Γ iff ∼φ ∈ Γ and (iii) if φ, xi = xj ∈ Γ then φσ ∈ Γ for any substitution
σ mapping xi to xj and/or xj to xi , while leaving all other variables ﬁxed.
The next deﬁnition introduces our key tool in proving the decidability of the packed
fragment: mosaics and linked sets of them. Basically, a mosaic consists of a subset
X of Var (ξ) together with a set Γ encoding the relevant information on some452
7 Extended Modal Logic
small part of a model. Here ‘small’ means that its size is bounded by the number of
objects that can be named using variables in X, and ‘relevant’ refers to all formulas
in Clg (ξ) whose free variables are in X. It turns out that a ﬁnite set of such mosaics
contains sufﬁcient information to construct a model for ξ provided that the set links
the mosaics together in a nice way. Here is a more formal deﬁnition.
Deﬁnition 7.37 A mosaic is a pair (X, Γ ) such that X ⊆ Var (ξ) and Γ ⊆ Clg (ξ).
A mosaic is coherent if it satisﬁes the following conditions:
(C1) Γ is an X-type,
(C2) if ψ(x, z) and π(x, z) are in Γ , then so is ∃y (π(x, y) ∧ ψ(x, y)),
(provided that the latter formula belongs to Clg (ξ)).
A link between two mosaics (X, Γ ) and (X , Γ  ) is a renaming (that is, an injec-
tive substitution) σ with dom σ ⊆ X and range σ ⊆ X which satisﬁes, for all
formulas φ ∈ Clg (ξ): φ ∈ Γ iff φσ ∈ Γ  .
A requirement of a mosaic is a formula of the form ∃y (π(x, y) ∧ ψ(x, y)) be-
longing to Γ . A mosaic (X , Γ  ) fulﬁlls the requirement ∃y (π(x, y) ∧ ψ(x, y))
of a mosaic (X, Γ ) via the link σ if for some variables u, v in X we have that
σ(x) = u and π(u, v) and ψ(u, v) belong to Γ  . A set S of mosaics is linked if
every requirement of a mosaic in S is fulﬁlled via a link to some mosaic in S. S is
a linked set of mosaics for ξ if it is linked and ξ ∈ Γ for some (X, Γ ) in S.
Note that a mosaic (X, Γ ) may fulﬁll its own requirements, either via the identity
map or via some other map from X to X.
The key result concerning mosaics is the following Mosaic Theorem:
Theorem 7.38 (Mosaic Theorem) Let ξ be a packed formula. Then ξ is satisﬁ-
able if and only if there is a linked set of mosaics for ξ.
Proof. The hard, right to left, direction of the theorem is treated in Lemma 7.39
below; here we only prove the other direction.
Suppose that ξ is satisﬁed in the model A = (A, I). In a straightforward way
we can ‘cut out’ from A a linked set of mosaics for ξ. Consider the set of partial
assignments of elements in A to variables in Var (ξ). For each such α, let (Xα , Γα )
be the mosaic given by Xα = dom α and
Γα = {φ ∈ Clg (ξ) | A |= φ[α]}.
We leave it to the reader to verify that this collection forms a linked set of mosaics
for ξ.
When establishing the hard direction of this proposition we will in fact prove some-
thing stronger: starting from a linked set of mosaics for a formula ξ we will show,
via a step-by-step argument, that there is a loose or tree-like model for ξ. First,7.4 The Guarded Fragment
453
however, we want to show that the Mosaic Theorem is the key towards proving
the decidability of the packed fragment, and also for ﬁnding an upper bound for its
complexity.
The decision algorithm and its complexity
The mosaic theorem tells us that any packed formula ξ is satisﬁable if and only if
there is a linked set of mosaics for ξ. Thus an algorithm answering the question
whether a linked set of mosaics exists for ξ, also decides whether ξ is satisﬁable.
By providing such an algorithm we establish the upper complexity bound for the
satisﬁability problem of the packed fragment.
Recall that k denotes the number of variables occurring in ξ. The following
observations are fairly straightforward consequences of our deﬁnitions:
k
(i) up to isomorphism there are at most 2k · 22|ξ|·k mosaics. Using the O
k log k
notation, this is at most 2O(|ξ|)·2
,
(ii) given sets X, Γ with |X| ≤ k and Γ ⊆ Clg (ξ) it is decidable in time
polynomial in kk and |ξ| whether (X, Γ ) is a coherent mosaic,
(iii) given a set X of coherent mosaics and a requirement φ(x) it is decidable in
time polynomial in |X| and |φ(x)| whether X fulﬁlls the requirement φ(x).
Using methods similar to the elimination of Hintikka sets that we saw in the de-
cidability proof for propositional dynamic logic (see Section 6.8), we now give an
algorithm which decides the existence of a linked set of mosaics for ξ. Let S0 be
the set of all coherent mosaics. By the observations above, S0 contains at most
k log k
2O(|ξ|)·2
elements and can be constructed in time polynomial in |S0 |. We now
inductively construct a sequence of sets of mosaics S0 ⊇ S1 ⊇ S2 ⊇ S3 · · ·. If
every requirement of a mosaic μ in a set Si is fulﬁlled we call μ happy. If every
mosaic in Si is happy then return ‘there is a linked set of mosaics for ξ’ if Si con-
tains a mosaic (X, Γ ) with ξ ∈ Γ , and return ‘there is no linked set of mosaics for
ξ’ otherwise. If, on the other hand, Si contains unhappy mosaics, let Si+1 consist
of all happy mosaics in Si and continue the construction. Since our sets decrease in
size at every step, the construction must halt after at most |S0 | many stages. By the
observations above, computing which states in Si are happy can be done in time
polynomial in ξ and |Si |. Thus the entire computation can be performed in time
polynomial in |S0 |. Clearly the algorithm is correct.
Hence, if we consider a formula ξ in a packed fragment with a ﬁxed number of
variables, |S0 | is exponential in |ξ|. In general, however, the number of variables
occurring in a formula depends on the formula’s length and, hence, |S0 | is dou-
bly exponential in |ξ|. Thus, pending the correctness of Lemma 7.39 below, this
establishes the complexity upper bounds in Theorem 7.34.7 Extended Modal Logic
454
Loose models
Finally, we show the hard direction of the Mosaic Theorem; as a spin-off we estab-
lish the ‘loose model property’ mentioned in Theorem 7.33.
Lemma 7.39 Let ξ be a packed formula. If there is a linked set of mosaics for ξ,
then ξ is satisﬁable in a loose model of degree |Var (ξ)|.
Proof. Assume that S is a linked set of mosaics for ξ. Using a step-by-step con-
struction, we will build a loose model for ξ, together with an acyclic graph asso-
ciated with the model. At each stage of the construction we will be dealing with
some kind of approximation of the ﬁnal model and tree; these approximations will
be called networks and are slightly involved structures.
A network is a quintuple (A, G, μ, α, σ) such that A = (A, I) is a model for the
ﬁrst-order language; G = (G, E) is a connected, acyclic graph; μ : G → S is a
map associating a mosaic μt = (Xt , Γt ) in S with each node t of the graph; α is
a map associating an assignment αt : Xt → A with each node t of the graph; and
ﬁnally, σ is a map associating with each edge (t, t ) of the graph a link σtt from μt
to μt (we will usually simplify our notation by writing σ instead of σtt ).
The idea is that each mosaic μt is meant to give a complete description of the
relevant requirements that we impose on a small part of the model-to-be. Which
part? This is given by the assignment αt . And the word ‘relevant’ refers to the
fact that we are only interested in the formulas inﬂuencing the truth of ξ; that is,
the formulas in Clg (ξ). The links between neighboring mosaics are there to ensure
that distinct mosaics agree on the part of the model that they both have access to.
Now obviously, if we want all of this to work properly we have to impose some
conditions on networks. In order to formulate these, we need some auxiliary no-
tation. For a subset Q ⊆ A, let L(Q) denote the set of nodes in G that have
‘access’ to Q; formally, we deﬁne L(Q) = {t ∈ G | Q ⊆ range(αt )}. For a
tuple a = (a1 , . . . , an ) of elements in A we set L(a) = L({a1 , . . . , an }). Now
a network is called coherent if it satisﬁes the following conditions (all to be read
universally quantiﬁed):
(C1)
(C2)
(C3)
(C4)
(C5)
P x ∈ Γt iff A |= P x[αt ],
xi = xj ∈ Γt iff αt (xi ) = αt (xj ),
L(Q) is non-empty for every guarded set Q ⊆ A,
L(Q) is connected for every guarded set Q ⊆ A,
if Ett then σtt (x) = x iff αt (x) = αt (x ).
A few words of explanation about these conditions: (C1) and (C2) ensure that every
mosaic is a complete description of the atomic formulas holding in the part of the
model it refers to. Condition (C3) states that no live tuple of the model remains
unseen from the graph, while the conditions (C4) and (C5) are the crucial ones7.4 The Guarded Fragment
455
making that remote parts of the graph cannot contain contradictory information
about the model – how this works precisely will become clear further on. Note that
condition (C5) has two directions: the left-to-right direction states that neighboring
mosaics have common access to part of the model, while the other direction ensures
that they agree on their requirements concerning this common part.
The motivation for using these networks is that in the end we want any formula
φ(x) ∈ Clg (ξ) to hold in A under the assignment αt if and only if φ(x) belongs
to Γt . Coherence on its own is not sufﬁcient to make this happen. A defect of
a network consists of a formula ∃y (π(x, y) ∧ ψ(x, y)) which is a requirement of
the mosaic μt for some node t while there is no neighboring node t such that μt
fulﬁlls ∃y (π(x, y) ∧ ψ(x, y)) via the link σtt . A coherent network N is perfect if
it has no defects. We say that N is a network for ξ if for some t ∈ G, μt = (Xt , Γt )
is such that ξ ∈ Γt .
Claim 1 If N = (A, G, μ, α, σ) is a perfect network for ξ, then
(i) A is a loose model of degree |Var (ξ)|, and
(ii) for all formulas φ(x) ∈ Clg (ξ) and all nodes t of G: φ ∈ Γt iff A |= φ[αt ].
Proof of Claim. For part (i) of the claim, let N = (A, G, μ, α, σ) be the perfect
network for ξ. Let A = (A, I). As the function f mapping nodes of G to subsets
of A, simply take the map that assigns the range of αt to the node t. Since the
domain of each map αt is always a subset of Var (ξ), it follows immediately that
f (t) will always be a set of size at most |Var (ξ)|. Now take an arbitrary live tuple
s in A; it follows from (C3) and (C4) that L(s) is a non-empty and connected part
of the graph G. Thus A is a loose model of degree |Var (ξ)|.
We prove part (ii) of the claim by induction on the complexity of φ. For atomic
formulas the claim follows by conditions (C1) and (C2), and the boolean case of
the induction step is straightforward (since Γt is an X–type) and left to the reader.
We concentrate on the case that φ(x) is of the form ∃y (π(x, y) ∧ ψ(x, y)).
First assume that φ(x) ∈ Γt . Since N is perfect there is a node t in G and
variables u, v in Xt such that Ett , π(u, v) and ψ(u, v) belong to Γt , while the
link σ from μt to μt maps x to u. By the induction hypothesis we ﬁnd that
A |= π(u, v) ∧ ψ(u, v)[αt ].
(7.6)
But from condition (C5) it follows that αt (x) = αt (u), whence (7.6) implies that
A |= ∃y (π(x, y) ∧ ψ(x, y))[αt ],
which is what we were after. Here and in the sequel, if x = (x1 , . . . , xn ), then
α(x) abbreviates (α(x1 ), . . . , α(xn )).
Now suppose, in order to prove the converse direction, that A |= φ(x)[αt ]. Let a456
7 Extended Modal Logic
denote αt (x), then there are b in A such that A |= π(x, y)[ab] and A |= ψ(x, y)[ab].
Our ﬁrst aims are to prove that
L(ab) = ∅,(7.7)
L(Q) is connected for every Q ⊆ {a, b}.(7.8)
and
Note that if we are working in the guarded fragment, then π(x, y) is an atomic
formula, whence it follows from A |= π(x, y)[ab] that ab is live. Thus {a, b} is
guarded, and hence (7.7) is immediate by condition (C3). In fact, every Q ⊆ {a, b}
is guarded in this case, so (7.8) is immediate by condition (C4).
In the more general case of the packed fragment we have to work a bit harder.
First, observe that it does follow from A |= π(x, y)[ab] and the conditions on
π(x, y) in the deﬁnition of packed quantiﬁcation, that {c, d} is guarded, and thus,
L(c, d) = ∅, for every pair (c, d) of points taken from ab. It follows from (C4)
that {L(c) | c taken from ab} is a collection of non-empty, connected, pairwise
overlapping subgraphs of the acyclic graph G. It is fairly straightforward to prove,
for instance, by induction on the size of the graph G, that any such collection must
have a non-empty intersection. From this, (7.7) and (7.8) are almost immediate.
Thus, we may assume the existence of a node t in G such that {a, b} ⊆ range αt .
Let u and v in Xt be the variables such that αt (u) = a and αt (v) = b. The
induction hypothesis implies that π(u, v) and ψ(u, v) belong to Γt , whence φ(u) ∈
Γt by coherence of μt . Since both t and t belong to L(a), it follows from (7.8)
that there is a path from t to t within L(a), say t = s0 Es1 E . . . Esn = t. Let σi
be the link between the mosaics of si and si+1 , and deﬁne ρ to be the composition
of these maps. It follows by an easy inductive argument on the length of the path
that ρ is a link between μt and μt such that ρ(u) = x. Hence, by deﬁnition of a
link we have that φ(x) ∈ Γt .
By Claim 1, in order to prove Lemma 7.39 it sufﬁces to construct a perfect network
for ξ. This construction uses a step-by-step argument; to start the construction we
need some coherent network for ξ.
Claim 2 There is a coherent network for ξ.
Proof of Claim. By our assumption on ξ there is a coherent mosaic μ = (X, Γ )
such that ξ ∈ Γ . Without loss of generality we may assume that X is the set
{x1 , . . . , xn } (otherwise, take an isomorphic copy of μ in which X does have this
form). Let a1 , . . . , an be a list of objects such that for all i and j we have that
ai = aj if and only if the formula xi = xj belongs to Γ . Deﬁne A = {a1 , . . . , an }
and put the tuple (ai1 , . . . , aik ) in the interpretation I(P ) of the k-ary predicate
symbol P precisely if P xi1 . . . xin ∈ Γ . Let A be the resulting model (A, I) and7.4 The Guarded Fragment
457
deﬁne G as the trivial graph with one node 0 and no edges. Let μ(0) be the mosaic
μ; α0 : X → A is given by α(xi ) = ai ; and ﬁnally, σ00 is the identity map from
X to X.
We leave it to the reader to verify that the quintuple (A, G, μ, α, σ) is a coherent
network for ξ.
The crucial step of this construction will be to show that any defect of a coherent
network can be repaired.
Claim 3 For any coherent network N = (A, G, μ, α, σ) and any defect of N there
is a coherent network N+ extending N and lacking this defect.
Proof of Claim. Suppose that φ(x) is a defect of N because it is a requirement of
the mosaic μt and not fulﬁlled by any neighboring mosaic μt . We will deﬁne an
extension N+ of N in which this defect is repaired.
Since S is a linked set of mosaics and μt belongs to S, μt is linked to a mosaic
(X  , Γ  ) ∈ S in which the requirement is fulﬁlled via some link ρ. Let Y be
the set of variables in X that do not belong to the range of ρ; suppose that Y =
{y1 , . . . , yk } (with all yi being distinct). For the sake of a smooth presentation,
assume that Γ  contains the formulas ¬x = y for all variables x ∈ X  and y ∈ Y
(this is not without loss of generality – we leave the general case as an exercise to
the reader). Take a set {c1 , . . . , ck } of fresh objects (that is, no ci is an element
of the domain A of A), and let γ be the assignment with domain X deﬁned as
follows:
αt (x) if x = ρ(x),
γ(x ) =
ci
if x = yi ,
and let t be an object not belonging to G. Now deﬁne the network N+ = (A+ ,
G+ , μ+ , α+ , σ + ) as follows:
A+ = A ∪ {c1 , . . . , ck },
I + (P ) = I(P ) ∪ {d | for some x, d = γ(x) and P x ∈ Γ  },
G+ = G ∪ {t },
E + = E ∪ {(t, t )},
while μ+ , α+ and σ+ are given as the obvious extensions of μ, α and σ, namely
+



by putting μ+
t = (X , Γ ), αt = γ and σtt = ρ.
+
Since the interpretation I agrees with I on ‘old’ tuples it is a straightforward
exercise to verify that the new network N+ satisﬁes the conditions (C1)–(C3) and
(C5).
In order to check that condition (C4) holds, take some guarded subset Q from
A+ ; we will show that L+ (Q) is a connected subgraph of G+ . It is rather easy7 Extended Modal Logic
458
to see that L+ (Q) is identical to either L(Q) or L(Q) ∪ {t }; hence by the con-
nectedness of L(Q) it sufﬁces to prove, on the assumptions that t ∈ L+ (Q) and
L(Q) = ∅, that t ∈ L(Q). Hence, suppose that t ∈ L+ (Q); that is, each a ∈ Q
is in the range of γ. But if L(Q) = ∅, each such point a must be old; hence, by
deﬁnition of γ, each a ∈ Q must belong to range αt . This gives that t ∈ L(Q), as
required.
As in our earlier step-by-step proofs, the previous two claims show that using some
standard combinatorics we can construct a chain of networks such that their limit
is a perfect network. This completes the proof of Lemma 7.39.
Exercises for Section 7.4
7.4.1 In the loosely guarded fragment the following quantiﬁcation patterns are allowed:
∃x (π(x, y) ∧ ψ(x, y)) is a loosely guarded formula if ψ(x, y) is loosely guarded, π(x, y)
is a conjunction as in the packed fragment, and any pair z, z  of distinct variables from xy
occurs free in some conjunct of the guard π, unless z and z  are both from y. For example,
∃x ((Ryx ∧ Rxy  ) ∧ ¬Cxyy  ) is loosely guarded, but not packed since there is no conjunct
having both y and y  free.
Show that for every loosely guarded sentence ξ there exists an equivalent packed sen-
tence ξ  in the same language.
7.4.2 Deﬁne the universal packed fragment as the fragment of ﬁrst-order logic that is gen-
erated from atoms, negated atoms, conjunction, disjunction, ordinary existential quantiﬁ-
cation, and packed universal quantiﬁcation. (With the latter we mean that ∀x (π → ψ) is
in the fragment if ψ is universally packed, π packs its own free variables, and Free(ψ) ⊆
Free(π).)
Show that satisﬁability is decidable for the universal packed fragment.
7.4.3 Fix a natural number n, and suppose that we are working in an n-bounded ﬁrst-order
signature; that is, all predicate symbols have arity at most n. Prove that in such a signature,
every guarded sentence is equivalent to a guarded sentence using at most n variables. Does
this hold for packed sentences as well? What are the consequences for the complexity of
the respective satisﬁability problems?
7.4.4 Let ξ be a packed formula, and suppose that ξ is satisﬁable. Prove that ξ is satisﬁable
in a loose model with an associated graph G of which the out-degree is bounded by some
recursive function on ξ. In particular, this out-degree should be ﬁnite. (The out-degree of
a node k of a graph (G, E) is deﬁned as the number of its neighbors, or, formally, as the
size of the set {k  ∈ G | kEk  }; the out-degree of a graph is deﬁned as the supremum of
the out-degrees of the individual nodes.)
7.5 Multi-Dimensional Modal Logic
In Chapter 2 we backed up our claim that logical formalisms do not live in isola-
tion by developing the correspondence theory of modal logic: we studied modal
languages as fragments of ﬁrst-order languages. In this section we will turn the7.5 Multi-Dimensional Modal Logic
459
looking glass around and examine ﬁrst-order logic as if it were a modal formalism.
The basic observations enabling this perspective are that we may view assignments
(the functions that give ﬁrst-order variables their value in a ﬁrst-order structure) as
states of a modal model, and that this makes standard ﬁrst-order quantiﬁers behave
just like modal diamonds and boxes. First-order logic thus forms an example of
a multi-dimensional modal system. Multi-dimensional modal logic is a branch of
modal logic dealing with special relational structures in which the states, rather
than being abstract entities, have some inner structure. More speciﬁcally, these
states are tuples or sequences over some base set, in our case, the domain of the
ﬁrst-order structure. Furthermore, the accessibility relations between these states
are (partly) determined by this inner structure of the states.
Reverse correspondence theory
To simplify our presentation, in this section we will not treat modal versions of
ﬁrst-order logic in general, but restrict our attention to certain ﬁnite variable frag-
ments. A precise deﬁnition of these fragments will be given later on (see Deﬁni-
tion 7.40). For the time being, we ﬁx a natural number n ≥ 2 and invite the reader
to think of a ﬁrst-order language with equality, but without constants or function
symbols, in which all predicates are n-adic. Consider the basic declarative state-
ment in ﬁrst-order logic concerning the truth of a formula in a model under an
assignment s:
M |= φ [s].
(7.9)
The basic observation underlying our approach, is that we can read (7.9) from a
modal perspective as: ‘the formula φ is true in M at state s.’ But since we have
only n variables at our disposal, say v0 , . . . , vn−1 , we can identify assignments
with maps: n (= {0, . . . , n − 1}) → U , or equivalently, with n-tuples over the
domain U of the structure M – we will denote the set of such n-tuples by Un .
But then we ﬁnd ourselves in the setting of multi-dimensional modal logic: the
universe of our modal models will be of the form Un for some base set U . Now
recall that the truth deﬁnition of the quantiﬁers reads as follows:
M |= ∃vi φ[s] iff there is an u ∈ U such that M |= φ [siu ],
where siu is the assignment deﬁned by siu (k) = u if k = i and siu (k) = s(k) other-
wise. We can replace the above truth deﬁnition with the more ‘modal’ equivalent,
M |= ∃vi φ[s] iff there is an assignment s with s ≡i s and M |= φ [s ],
where ≡i is given by
s ≡i s iff for all j = i, sj = sj .
(7.10)460
7 Extended Modal Logic
In other words: existential quantiﬁcation behaves like a modal diamond, having ≡i
as its accessibility relation.
Since the semantics of the boolean connectives in the predicate calculus is the
same as in modal logic, this shows that the inductive clauses in the truth deﬁnition
of ﬁrst-order logic neatly ﬁt a modal mould. So let us now concentrate on the
atomic formulas. To start with, we observe that equality formulas do not cause any
problem: the formula vi = vj , with truth deﬁnition
M |= vi = vj [s] iff s ∈ Id ij ,
can be seen as a modal constant. Here Idij is deﬁned by
s ∈ Id ij iff si = sj .
(7.11)
The case of the other atomic formulas is more involved, however. Since we con-
ﬁned ourselves to the calculus of n-adic relations and do not have constants or func-
tion symbols, our atomic predicate formulas are of the form P vσ(0) . . . vσ(n−1) .
Here σ is an n-transformation, that is, a map: n → n. In the model theory of ﬁrst-
order logic the predicate symbol P will be interpreted as a subset of Un ; but this is
precisely how modal valuations treat propositional variables in models where the
universe is of the form U n ! Therefore, we can identify the set of propositional vari-
ables of the modal formalism with the set of predicate symbols of our ﬁrst-order
language. In this way, we obtain a modal reading of (7.9) for the case where φ is the
atomic formula P v0 . . . vn−1 : M |= P v0 . . . vn−1 [s] iff s belongs to the interpreta-
tion of P . However, as a consequence of this approach our set-up will not enjoy a
one-to-one correspondence between atomic ﬁrst-order formulas and atomic modal
ones: the atomic formula P vσ(0) . . . vσ(n−1) will correspond to the modal atom p
only if σ is the identity function on n. For the cases where σ is not the identity map
we still have to ﬁnd some kind of solution. There are many options here.
Since we are working in a ﬁrst-order language with equality, atomic formulas
with multiple occurrences of a variable can be rewritten as formulas with only
‘unproblematic’ atomic subformulas, for instance
P v1 v0 v0 ↔ ∃v2 (v2 = v0 ∧ P v1 v2 v2 )
↔ ∃v2 (v2 = v0 ∧ ∃v0 (v0 = v1 ∧ P v0 v2 v2 ))
↔ ∃v2 (v2 = v0 ∧ ∃v0 (v0 = v1 ∧ ∃v1 (v1 = v2 ∧ P v0 v1 v2 ))).
This leaves the case of what to do with atoms of the form P vσ(0) . . . vσ(n−1) , where
σ is a permutation of n, or in other words, atomic formulas where variables have
been substituted simultaneously. The previous trick does not work here: for ex-
ample, to write an equivalent of the formula P v1 v0 v2 one needs extra variables as
buffers, for instance, when replacing P v1 v0 v2 by
∃v3 ∃v4 (v3 = v0 ∧ v4 = v1 ∧ ∃v0 ∃v1 (v0 = v4 ∧ v1 = v3 ∧ P v0 v1 v2 )).7.5 Multi-Dimensional Modal Logic
461
One might consider a solution where a predicate P is translated into various modal
propositional variables pσ , one for every permutation σ of n, but this is not very
elegant. One might also forget about simultaneous substitutions and conﬁne one-
self to a fragment of n-variable logic where all atomic predicate formulas are of
the form P v0 . . . vn−1 – this fragment of restricted ﬁrst-order logic is deﬁned be-
low. A third solution is to take substitution seriously, so to speak, by adding special
‘substitution operators’ to the language. The key observation is that for any trans-
formation σ ∈ nn , we have that
M |= P vσ(0) . . . vσ(n−1) [s] iff M |= P v0 . . . vn−1 [s ◦ σ],
(7.12)
where s ◦ σ is the composition of σ and s (recall that s is a map: n → U ). So, if
we deﬁne the relation 1σ ⊆ U n × U n by
s 1σ t iff t = s ◦ σ,
(7.13)
we have rephrased (7.12) in terms of an accessibility relation (in fact, a function):
M |= P vσ(0) . . . vσ(n−1) [s] iff, for some t with s 1σ t, M |= P v0 . . . vn−1 [t]. So
if we add an operator σ to the modal language for every n-transformation σ in
nn , with 1σ as its intended accessibility relation, we have got the desired modal
equivalent for any atomic formula P vσ(0) . . . vσ(n−1) – in the form σ p. (As a
special case, for the formula P v0 . . . vn−1 one can take the identity map on n.)
Deﬁnition 7.40 Let n be an arbitrary but ﬁxed natural number. The alphabet of
Ln and of Lrn consists of a set of variables {vi | i < n}, a countable set of n-adic
relation symbols (P0 , P1 , . . .), equality (=), the boolean connectives ¬, ∨ and the
quantiﬁers ∃vi . The collection of formulas is deﬁned as usual in ﬁrst-order logic,
with the restriction that the atomic formulas of Lrn are of the form vi = vj or
Pl (v0 . . . vn−1 ); for Ln we allow all atomic formulas (but note that all predicates
are of arity n).
A ﬁrst-order structure for Ln (Lrn ) is a pair M = (U, V ) such that U is a set
called the domain of the structure and V is an interpretation function mapping
every P to a subset of U n . The notion of a formula φ being true in a ﬁrst-order
structure M under an assignment s is deﬁned as usual. For instance, given our
notation we have, for any atomic formula:
M |= P (v0 . . . vn−1 ) [s] if s ∈ V (P ),
M |= P (vσ(0) . . . vσ(n−1) ) [s] if s ◦ σ (= (sσ(0) . . . sσ(n−1) )) ∈ V (P ).
An Ln -formula φ is true in M (notation: M |= φ), if M |= φ [s] for all s ∈ Un ;
it is valid (notation: |=fo φ), if it is true in every ﬁrst-order structure of Ln . The
same deﬁnition applies to Lrn .
From now on, we will concentrate on the modal versions of Lrn and Ln , which are
given in the following deﬁnition:7 Extended Modal Logic
462
Deﬁnition 7.41 Let n be an arbitrary but ﬁxed natural number. MLRn (short for:
modal language of relations) is the modal similarity type having constants ιδij and
diamonds 3i , σ (for all i, j < n, σ ∈ nn ). CMLn , the similarity type of cylindric
modal logic, is the fragment of MLRn -formulas in which no substitution operator
σ occurs.
A ﬁrst-order structure M = (U, V ) can be seen as a modal model based on the
universe U n , and formulas of these modal similarity types are interpreted in such a
structure in the obvious way; for instance, we have
M, s  ιδij
M, s  σ φ
iff
iff
(iff
M, s  3i φ iff
si = sj ,
M, s ◦ σ  φ
there is a t with s 1σ t and M, t  φ),
there is a t with s ≡i t and M, t  φ.
If an MLRn -formula φ holds throughout any ﬁrst-order structure, we say that it is
ﬁrst-order valid, notation: Cn  φ (this notation will be clariﬁed further on).
The modal disguise of Ln in MLRn and of Lrn in CML is so thin, that we give the
translations mapping ﬁrst-order formulas to modal ones without further comments.
Deﬁnition 7.42 Let (·)t be the following translation from Ln to MLR n :
(P vσ(0) . . . vσ(n−1) )t =
σ p,
t(vi = vj )= ιδij ,
t= ¬φt ,
(¬φ)
(φ ∨ ψ)t = φt ∨ ψ t ,
(∃vi φ)t = 3i φt .
This translation allows us to see Lrn and CMLn as syntactic variants: (·)t is easily
seen to be an isomorphism between the formula algebras of Lrn and CMLn . Note
that in the case of Ln versus MLRn , we face a different situation: where in MLR
the simultaneous substitution of two variables for each other is a primitive operator,
in ﬁrst-order logic it can only be deﬁned by induction. Nevertheless, we could
easily deﬁne a translation mapping MLRn -formulas to equivalent Lrn -formulas. In
any case, the following proposition shows that we really have developed a reverse
correspondence theory; we leave the proof as an exercise to the reader.
Proposition 7.43 Let φ be a formula in Ln , then
(i) for any ﬁrst-order structure M, and any n-tuple/assignment s, we have that
M |= φ[s] if and only if M, s  φt ;
(ii) as a corollary, we have that |=fo φ iff Cn  φt .7.5 Multi-Dimensional Modal Logic
463
Let us now put the modal machinery to work and see whether we can ﬁnd out
something new about ﬁrst-order logic.
Degrees of validity
Perhaps the most interesting aspect of this modal perspective on ﬁrst-order logic is
that it allows us to generalize the semantics of ﬁrst-order logic, and thus offers a
wider perspective on the standard Tarskian semantics. The basic idea is fairly ob-
vious: now that we are talking about modal languages, it is clear that the ﬁrst-order
structures of Deﬁnition 7.41 are very speciﬁc modal models for these languages.
We may abstract from the ﬁrst-order background of these models, and consider
modal models in which the universe is an arbitrary set and the accessibility rela-
tions are arbitrary relations (of the appropriate arity).
Deﬁnition 7.44 An MLRn -frame is a tuple (W, Ti , Eij , Fσ )i,j<n,σ∈nn such that
every Eij is a subset of the universe W , and such that every Ti and every Fσ is a
binary relation on W . An MLRn -model is a pair M = (F, V ) with F an MLRn -
frame and V a valuation, that is, a map assigning subsets of W to propositional
variables. CMLn -models and frames are deﬁned likewise.
For such models, truth of a formula at a state is deﬁned via the usual modal induc-
tion, for instance:
M, w  σ φ iff there is a v with Fσ wv and M, v  φ.
In this very general semantics, states (that is, elements of the universe) are no
longer real assignments, but, rather, abstractions thereof. First-order logic now re-
ally has become a poly-modal logic, with quantiﬁcation and substitution diamonds.
It is interesting and instructive to see how familiar laws of the predicate calculus
behave in this new set-up. For example, the axiom schema φ → ∃vi φ will be valid
only in n-frames where Ti is a reﬂexive relation (this follows from the fact that the
modal formula p → 3i p corresponds to the frame condition ∀x Ti xx). Likewise,
the axiom schemes ∃vi ∃vi φ → ∃vi φ and φ → ∀vi ∃vi φ will be valid only in
frames where the relation Ti is transitive and symmetric, respectively.
Later on we will see more of such correspondences; the point to be made here
is that the abstract perspective on the semantics of ﬁrst-order logic imposes a cer-
tain ‘degree of validity’ on well-known theorems of the predicate calculus. Some
theorems are valid in all abstract assignment frames, like distribution:
∀vi (φ → ψ) → (∀vi φ → ∀vi ψ),
which is nothing but the modal K-axiom. Other theorems of the predicate cal-
culus, like the ones mentioned above, are only valid in some classes of frames.464
7 Extended Modal Logic
Narrowing down the class of frames means increasing the set of valid formu-
las, and vice versa. In particular, we now have the option to look at classes of
frames that are only slightly more general than the standard ﬁrst-order structures,
but have much nicer computational properties. This new perspective on ﬁrst-order
logic, which was inspired by the literature on algebraic logic, provides us with
enormous freedom to play with the semantics for ﬁrst-order logic. In particu-
lar, consider the fact that ﬁrst-order structures can be seen as frames of the form
(U n , ≡i , Idij , 1σ )i,j<n,σ∈nn where all assignments s ∈ U n are available. But why
not study a semantics where states are still real assignments on the base set U , but
not all such assignments are available?
There are at least two good reasons to make such a move. First, it turns out that
the logic of such generalized assignment frames has much nicer meta-properties
than the logic of the cubes such as decidability, see for instance Theorem 7.46.
These logics will provide less laws than the usual predicate calculus, but their sup-
ply of theorems may be sufﬁcient for particular applications. Note for instance,
that the schemes φ → ∃vi φ, ∃vi ∃vi φ → ∃vi φ and φ → ∀vi ∃vi φ are still valid in
every generalized assignment frame, since ≡i W is always an equivalence relation.
In some situations it may even be useful not to have all familiar validities. Con-
sider for instance the schema
∃vi ∃vj φ → ∃vj ∃vi φ.
(7.14)
It follows from correspondence theory that (7.14) is valid in a frame F iff (7.15)
below holds in F.
∀xz (∃y (Ti xy ∧ Tj yz) → ∃u (Tj xu ∧ Ti uz)).
(7.15)
The point is this. The schema (7.14) prevents us from making the dependency
of variables explicit in the language (that is, whether vj is dependent of vi or the
other way around), while these dependencies play an important role in some proof-
theoretical approaches. So, the second motivation for generalizing the semantics
of ﬁrst-order logic is that it gives us a ﬁner sieve on the notion of equivalence
between ﬁrst-order formulas. Note for instance that (7.14) is not valid in frames
with assignment ‘holes’: take n = 2. In a square (that is, 2-cubic) frame we have
(a, b) ≡0 (a , b) ≡1 (a , b ), but if (a, b ) is not an available tuple, then there is no
s such that (a, b) ≡1 s ≡0 (a , b ) – hence this frame will not satisfy (7.15). So,
the schema (7.14) will not be valid in this frame.
In this new paradigm, a whole landscape of frame classes and corresponding
logics arises. In the most general approach, any subset of Un may serve as the uni-
verse of a multi-dimensional frame, but it seems natural to impose restrictions on
the set of available assignments. Unfortunately, for reasons of space limitations we
cannot go into further detail here, conﬁning ourselves to the following deﬁnition.7.5 Multi-Dimensional Modal Logic
465
Deﬁnition 7.45 Let U be some set, and W a set of n-tuples over U , that is, W ⊆
U n . The cube over U or full assignment frame over U is deﬁned as the frame
Cn (U ) = (U n , ≡i , Idij , 1σ )i,j<n,σ∈nn .
The W -relativized cube over U or W -assignment frame on U is deﬁned as the
frame
CW
n (U ) = (W, ≡i W , Idij ∩ W, 1σ W )i,j<n,σ∈nn .
Cn and Rn are the classes of cubes and relativized cubes, respectively.
Observe that this deﬁnition clariﬁes our earlier notation ‘Cn  φ’ for the fact that
the modal formula φ is ‘ﬁrst-order valid’.
Decidability
As we already mentioned, one of the reasons for developing the abstract and gen-
eralized assignment semantics is to ‘tame’ ﬁrst-order logic by looking for core
versions with nicer computational behavior. This idea is substantiated by the fol-
lowing theorem.
Theorem 7.46 It is decidable in exponential time whether a given MLRn -formula
is satisﬁable in a given relativized cube. As a corollary, the problem whether a
given ﬁrst-order formula in Ln can be satisﬁed in a general assignment frame is
also decidable in exponential time.
Proof. This theorem can be proved directly by using the mosaic method that we
encountered in Section 6.4 – in fact, the mosaic method was developed for this
particular proof! However, space limitations prevent us from giving the mosaic
argument here. Therefore, we prove the theorem by a reduction of the Rn satisﬁ-
ability problem to the satisﬁability problem of the n-variable guarded fragment of
Section 7.4.
This reduction is quite interesting in itself: the key idea is that we ﬁnd a syn-
tactic counterpart to the semantic notion of restricting the set of available assign-
ments. There is a very simple way of doing so, namely by introducing a special
n-adic predicate G that will be interpreted as the collection of available assign-
ments. One can then translate modal formulas (or Ln -formulas) into ﬁrst-order
ones, with the proviso that this translation is syntactically relativized to G. The
formula Gv0 . . . vn−1 acts as a guard of the translated formula, and, indeed, it will
easily be seen that the range of this translation falls inside the guarded fragment.
Now for the technical details. Given a collection Φ of propositional variables,
assume that with each p ∈ Φ we have an associated n-adic predicate symbol P .
Also, ﬁx a new n-adic predicate symbol G; let Φ+ denote the expanded signature7 Extended Modal Logic
466
{P | p ∈ Φ} ∪ {G}. Consider the following translation (·)• mapping MLRn -
formulas to ﬁrst-order formulas:
p• = P v0 . . . vn−1 ,
•
ιδij
•
(¬φ)
= vi = vj ,
= Gv0 . . . vn−1 ∧ ¬φ• ,
(φ ∧ ψ)• = φ• ∧ ψ • ,
(σ φ)• = (Gv0 . . . vn−1 ∧ φ• )σ ,
(3i φ)• = ∃vi (Gv0 . . . vn−1 ∧ φ• ).
Here, for a given transformation σ, (·)σ denotes the corresponding syntactic sub-
stitution operation on ﬁrst-order formulas.
Claim 1 For any MLRn -formula φ we have that Rn  φ if and only if the formula
Gv0 . . . vn−1 → φ• is a ﬁrst-order validity.
Proof of Claim. In order to prove this claim, we need a correspondence between
modal models and ﬁrst-order models for the new language. Given a relativized
assignment model M = (CW
n (U ), V ), deﬁne the corresponding ﬁrst-order model
•
M as the structure (U, I) where I(P ) = V (p) for every propositional variable p,
and I(G) = W . Conversely, given a ﬁrst-order structure A = (A, I) for the ex-
I(G)
panded ﬁrst-order signature Φ, let A• be the relativized cube model (Cn (A), V ),
where the valuation V is given by V (p) = I(P ).
For any relativized assignment model M, and any available assignment s, we
have
M, s  φ iff M• |= φ• [s].
(7.16)
This sufﬁces to prove Claim 1, because of the following. First suppose that the
modal formula φ is satisﬁable in some relativized cube model M, say at state s.
Since s is an available tuple, it follows from (7.16) that φ• is satisﬁable in the ﬁrst-
order structure M• under the assignment s; but also, since s is available we have
M• |= Gv0 . . . vn−1 [s]. This shows that φ• ∧ Gv0 . . . vn−1 is satisﬁable.
Conversely, if the latter formula is satisﬁable, there is some ﬁrst-order structure
A for the language Φ+ , and some assignment s such that A |= φ• ∧Gv0 . . . vn−1 [s].
It is not difﬁcult to see that (A• )• = A. Since A |= Gv0 . . . vn−1 [s], it follows by
deﬁnition that s is an available assignment of A• . But then we may apply (7.16)
which yields that A• , s  φ; in particular, φ is satisﬁable in Rn . The proof of (7.16)
proceeds by a standard induction, which we leave to the reader.
Finally, we leave it to the reader to verify that the range of (·)• indeed falls entirely
inside the n-variable guarded fragment Fn . From Claim 1 and this observation the
theorem is immediate.7.5 Multi-Dimensional Modal Logic
467
Axiomatization
To ﬁnish off the section we will sketch how to prove completeness for the class of
cube models. For simplicity we conﬁne ourselves to the similarity type of cylindric
modal logic – but observe that this completeness result will immediately transfer
to the restricted n-variable fragment Lrn .
Multi-dimensional modal logic is an area with a very interesting completeness
theory. For instance, if one only admits the standard modal derivation rules (modus
ponens, necessitation and uniform substitution), then ﬁnite axiomatizations are few
and far between. For instance, concerning the CMLn -theory of the class Cn , it
is known that if Σ is a set of CMLn -formulas axiomatizing Cn , then for each
natural number m, Σ contains inﬁnitely many formulas that contain all diamonds
3i , at least one diagonal constant ιδij and at least m propositional variables . . . .
However, if we allow special derivation rules, in the style of Section 4.7, then a
nice ﬁnite axiomatization can be obtained, as we will see now. A key role in our
axiomatization and in our proof will be played by a deﬁned operator Dn p which
acts as the difference operator on the class of cube frames, see Section 7.1. For its
deﬁnition we need some auxiliary operators:
= 3i (ιδij ∧ φ)
(i = j),
= 30 . . . 3i−1 3i+1 . . . 3n−1 φ,

n
Dn φ =
j =i ji 3i (¬ιδij ∧ Ei φ).
ij φ
Eni φ
The deﬁnition of Dn may look fairly complex, but it is directly based on the obser-
vation that two n-tuples s and t are distinct if and only for some coordinate i, si is
distinct from ti .
Proposition 7.47 Dn acts as the difference operator on the class of cubes.
Proof. Let M = (Cn (U ), V ) be a cube model. We will show that
M, s  Dn p iff M, t |= p for some t such that s = t.
(7.17)
For the sake of a clear exposition we assume that n = 3, so that we may write
s = (s0 , s1 , s2 ).
For the left to right direction of (7.17), suppose that M, s  Dn p. Without loss
of generality we may assume that s  10 30 (¬ιδ01 ∧ En0 p). By deﬁnition of 10
it follows that (s0 , s0 , s2 )  30 (¬ιδ01 ∧ En0 p). This in its turn implies that there is
some s0 such that (s0 , s0 , s2 )  ¬ιδ01 and (s0 , s0 , s2 )  En0 p. It is easily seen that
the meaning of En0 is given by
M, u  Eni ψ iff M, v |= ψ for some v such that ui = vi ,
so (s0 , s0 , s2 )  En0 p means that there is some n-tuple t such that t  p and
s0 = t0 . But it follows from (s0 , s0 , s2 )  ¬ιδ01 that s0 = s0 , so that we ﬁnd that7 Extended Modal Logic
468
t0 = s0 . But then, indeed, t is distinct from s. We leave it to the reader to prove
the right to left direction of (7.17).
However, the connection between Dn and the class of cubes is far tighter than this
proposition suggests. In fact, the cubes are the only frames on which Dn acts as
the difference operator, at least, against the right background of the class HCFn of
hypercylindric frames.
Deﬁnition 7.48 A CMLn -frame is called hypercylindric if the following formulas
are valid on it:
(CM1 i )
(CM2 i )
(CM3 i )
(CM4 ij )
(CM5 i )
(CM6 ij )
(CM7 ijk )
(CM8 ij )
p → 3i p,
p → 2i 3i p,
3i 3i p → 3i p,
3i 3j p → 3j 3i p,
ιδii ,
3i (ιδij ∧ p) → 2i (ιδij → p)) (i = j),
ιδij ↔ 3k (ιδik ∧ ιδkj ) (k ∈ {i, j}),
(ιδij ∧ 3i (¬p ∧ 3j p)) → 3j (¬ιδij ∧ 3i p)
(i = j).
All these axioms are Sahlqvist formulas and thus express ﬁrst-order properties of
frames. Clearly, the axioms CM1 –3 together say that each Ti is an equivalence
relation. CM6 ij then means that in every Ti -equivalence class there is at most one
element on the diagonal Eij (i = j). One can combine this fact with the (ﬁrst-
order translations of) CM5 j and CM7 jji to show that every Ti -equivalence class
contains exactly one representative on the Eij -diagonal. Apart from this effect, the
contribution of CM7 is rather technical. Finally, the meaning of CM4 and CM8
is best made clear by Figure 7.2, where the straight lines represent the antecedent
of the ﬁrst-order correspondents, and the dotted lines, the relations holding of the
‘old’ states and the ‘new’ ones given by the consequent.
q
z
Ti
Tj
q
y
q
u
q
q
x
Ti
q
Tj , =
Tj
Ti
z
q
u ∈ Eij
Tj
Ti
q
y
x ∈ Eij
Eij
Fig. 7.2. The meaning of CM4 ij (left) and CM8 ij (right)7.5 Multi-Dimensional Modal Logic
469
The key theorem in our completeness proof is the following.
Theorem 7.49 For any frame F in HCFn , Dn acts as the difference operator on F
iff F is a cube.
Proof. We have already proved the left to right direction of this equivalence in
Proposition 7.47. The proof of the other direction is technically rather involved
and falls outside the scope of this book.
In fact, with Theorem 7.49 we have all the material in our hands to prove the
desired completeness result.
Deﬁnition 7.50 Consider the following modal derivation system Ωn . Its axioms
are (besides the ones of the minimal modal logic for the similarity type CMLn ),
the formulas CM1 –8 ; as its derivation rules we take, besides the standard ones,
also the Dn -rule:
 (p ∧ ¬Dn p) → θ
.
θ
As usual, Ωn will also denote the logic generated by this derivation system.
Theorem 7.51 Ωn is sound and strongly complete with respect to the class Cn .
Proof. It follows immediately from Theorem 7.6 and Theorem 7.49 that we obtain
a complete axiomatization for Cn if we extend Ωn with the Dn -versions of the
axioms symmetry, pseudo-transitivity and D-inclusion. However, as its turns out,
these axioms are valid on the class of hypercylindric frames, so they are already
derivable in Ωn (even without the use of the Dn -rule). From this, the theorem is
immediate.
Exercises for Section 7.5
7.5.1 Let n and m be natural numbers such that n < m, and consider a CML n -formula φ.
First, observe that φ is also a CML m -formula. Prove that C n  φ iff Cm  φ. Conclude
that our deﬁnition of an MLR n -formula being ﬁrst-order valid, is unambiguous.
7.5.2 Prove that the formula 3 0 · · · 3n−1 p acts as the global modality on the class of
hypercylindric frames. That is, show that for any model M based on such a frame we have
that
M, s  30 · · · 3n−1 p iff M, t  p for some t in M.
Which of the axioms CM1 –CM8 are actually needed for this?
r
7.5.3 Let L−
n denote the equality-free fragment of L n ; that is, all atomic formulas are of
the form P v0 . . . vn−1 . In an obvious way we can deﬁne relativized assignment frames for
this language. Prove that the satisﬁability problem for L −
n in this class of frames can be
solved in PSPACE.470
7 Extended Modal Logic
7.5.4 Prove that every hypercylindric CML 2 -frame is the bounded morphic image of a
square frame (that is, a 2-cube). Use this fact to ﬁnd a complete axiomatization for the
class C2 that only uses the standard modal derivation rules.
7.5.5 Let CFn be the class of cylindric frames, that is, those CML n -frames that satisfy the
axioms CM1 –CM7 . The class of n-dimensional cylindric algebras is deﬁned as CA n =
SPCmCFn . The classes HCFn and HCAn are deﬁned similarly, now using all axioms
CM1 –CM8 .
(a) Prove that CA n and HCAn are canonical, that is, closed under taking canonical
embedding algebras.
(b) Prove that CA n and HCAn are varieties.
7.5.6 A full n-dimensional cylindric set algebra is an algebra of the form
(P(U n ), ∪, −, ∅, Ci , Id ij )i,j<n .
Here the i-th cylindriﬁcation is deﬁned as the map C i : P(U n ) → P(U n ) given by
Ci (X) = {s ∈ U n | t ∈ X for some t in X with s ≡ i t }.
If we close the class of these algebras under products and subalgebras, we arrive at the
variety RCAn of representable n-dimensional cylindric algebras.
(a) Prove that every representable n-dimensional cylindric algebra is a boolean algebra
with operators.
(b) Prove that RCAn is contained in the classes CAn and HCAn of the previous exer-
cise.
(c) Prove that RCAn is canonical. (Hint: use Theorem 7.49 to show that the class C n
of n-dimensional cubes is ﬁrst-order deﬁnable in the frame language of CML n .)
7.6 A Lindström Theorem for Modal Logic
Throughout this book we have seen many examples of modal languages, espe-
cially in the present chapter. To get a clear picture of the emerging spectrum, these
languages may be classiﬁed according to their expressive power or their semantic
properties. But what – if any – is the special status of the familiar modal languages
deﬁned in Chapter 1. If we focus on characteristic semantic properties, then clearly
their invariance under bisimulations must be a key feature. But what else is needed
to single out the (standard) modal languages?
The answer to this question is a modal analog of a classic result in ﬁrst-order
model theory: Lindström’s Theorem. It states that, given a suitable explication
of what ‘classical logic’ is, ﬁrst-order logic is the strongest logic to possess the
Compactness and Löwenheim-Skolem properties. To prove an analogous charac-
terization result for modal logic we need to agree on a number of things:
• What will be the distinguishing property of the logic that we want to characterize
(on top of its invariance for bisimulations)? To answer this question we will
exploit the notion of degree introduced in Deﬁnition 2.28.7.6 A Lindström Theorem for Modal Logic
471
• What is a suitable notion of an abstract modal logic? To answer this question we
will introduce some bookkeeping properties from the formulation of the original
Lindström Theorem for ﬁrst-order logic, and add a further property having to do
with invariance under bisimulations.
Our plan for this section is to discuss each of the above items, one after the other,
and to conclude with a Lindström Theorem for modal logic.
Background material
Throughout this section models for modal languages are pointed models of the
form (M, w), where M is a relational structure and w is an element of M (its
distinguished point) at which evaluation takes place. Our main reasons for adopting
this convention are the following. First, the basic semantic unit in modal logic
simply is a structure together with a distinguished node at which evaluation takes
place. Second, some of the results below admit smoother formulations when we
adopt the local perspective of pointed models.
Bisimulations between pointed models (M, w) and (N, v) are required to link
the distinguished points w and v.
Deﬁnition 7.52 (In-degree) Let τ be a modal similarity type, and let M be a
τ -model. The in-degree of a state u in M is the number of times u occurs as a
non-ﬁrst argument in a relation: Rw . . . u . . .. More formally, it is deﬁned as
|{w
 ∈ M<ω | for some R and i > 1, u = wi and RMw1 . . . wi . . . wn ) }|,
where Mω is the collection of all ﬁnite sequences of elements in M.
In addition to the in-degree of an element of a model, we will also need to use the
notion of height as deﬁned in Deﬁnition 2.32.
Below we will need models with nice properties, such as a low in-degree or ﬁnite
height for each of its elements. To get such models, we use the notion of forcing.
Fix a similarity type τ . A property P of models is ↔τ -enforceable, or enforce-
able, iff for every pointed τ -model (M, w), there is a pointed τ -model (N, v) with
(M, w) ↔τ (N, v) and (N, v) has P. For example, the property ‘every element
has ﬁnite height’ is enforceable. To see this, let (M, w) be a pointed τ -model; we
may assume that M is generated by w. Let (N, w) be the submodel of M whose
domain consists of all elements of ﬁnite height. Then (M, w) ↔τ (N, w).
Proposition 7.53 The following properties of models are enforceable:
(i) tree-likeness, and
(ii) the conjunction of ‘having a root with in-degree 0’ and ‘every element (ex-
cept the root) has in-degree at most 1’.472
7 Extended Modal Logic
Proof. Item (ii) follows from item (i). A proof of item (i) for similarity types
only involving diamonds is given in Proposition 2.15; for the general case, consult
Exercise 2.1.7.
We will characterize modal logic (in the sense of Deﬁnitions 1.12 and 1.23) by
showing that it is the only modal logic satisfying a modal counterpart of the original
Lindström conditions: having a notion of ﬁnite degree which gives a ﬁxed upper
bound on the height of the elements that need to be considered to verify a formula;
recall Deﬁnition 2.28 for the deﬁnition.
To wrap up our discussion of background material needed for our Lindström
Theorem, let us brieﬂy recall some basic facts related to degrees and height. Here
is the ﬁrst of these facts; recall that ((M, w) n, w) denotes the submodel of M
that is generated from w and that only has states of height at most n.
Proposition 7.54 Let φ be a modal formula with deg(φ) ≤ n. Then (M, w)  φ
iff ((M, w) n, w)  φ.
Next, recall from Proposition 2.29 that, up to logical equivalence, there are only
ﬁnitely many non-equivalent modal formulas with a ﬁxed ﬁnite degree over a ﬁnite
similarity type.
We say that (M, w) and (N, v) are n-equivalent if w and v satisfy the same
modal formulas of degree at most n.
Proposition 7.55 Let τ be a ﬁnite similarity type. Let (M, w), (N, v) be two
rooted models such that the roots have in-degree 0, every element different from
the root has in-degree at most 1, and all nodes have height at most n.
If (M, w) and (N, v) are (n + 1)-equivalent, then (M, w) ↔ (N, v).
Proof. Deﬁne Z ⊆ A × B by xZy iff:
height(x) = height(y) = m and (M, x) and (N, y) are (n − m)-equivalent.
We claim that Z : (M, w) ↔ (N, v). To prove this, we only show the forth
condition. Assume xZy and RMxx1 . . . xk , where height(x) = height(y) = m.
Then n − m ≥ 1. Let  be the modal operator whose semantics is based on R.
As τ is ﬁnite, there are only ﬁnitely many non-equivalent formulas of degree at
most n − m − 1. Let ψi be the conjunction of all non-equivalent modal formu-
las of at most this degree that are satisﬁed at xi (1 ≤ i ≤ k). Then (M, x) 
(ψ1 , . . . , ψk ), and (ψ1 , . . . , ψk ) has degree n − m. Hence, as xZy, (N, y) 
(ψ1 , . . . , ψk ). So there are y1 , . . . , yk in N such that RNyy1 . . . yk and (N, yi ) 
ψi (1 ≤ i ≤ k).
Now, as all states have in-degree at most 1, height(xi ) = height(yi ) = m + 1,
and (M, xi ) and (N, yi ) (1 ≤ i ≤ k) are (n − (m + 1))-equivalent. Hence,
(M, xi ) ↔τ (N, yi ). This proves the forth condition.7.6 A Lindström Theorem for Modal Logic
473
Abstract modal logic
The original Lindström Theorem for ﬁrst-order logic starts from a deﬁnition of an
abstract classical logic as a pair (L, |=L ) consisting of a set of formulas L and a
satisfaction relation |=L between L-structures and L-formulas that satisﬁes three
bookkeeping conditions, an Isomorphism property, and a Relativization property
which allows one to consider deﬁnable submodels. Then, an abstract logic extend-
ing ﬁrst-order logic coincides with ﬁrst-order logic if and only if it satisﬁes the
Compactness and Löwenheim-Skolem properties. We will now set up our modal
analog of Lindström’s Theorem along similar lines.
The deﬁnition runs along the same lines as the deﬁnition of an abstract classical
logic. An abstract modal logic is characterized by three properties: two bookkeep-
ing properties, and a Bisimilarity property to replace the Isomorphism property.
Deﬁnition 7.56 (Abstract Modal Logic) By an abstract modal logic we mean
a pair (L, L ) with the following properties (here L is the set of formulas, and
L is its satisfaction relation, that is, a relation between (pointed) models and L-
formulas):
(i) Occurrence property. For each φ in L there is an associated ﬁnite language
L(τφ ). The relation (M, w) L φ is a relation between L-formulas φ and struc-
tures (M, w) for languages L containing L(τφ ). That is, if φ is in L, and M is
an L-model, then the statement (M, w) L φ is either true or false if L contains
L(τφ ), and undeﬁned otherwise.
(ii) Expansion property. The relation (M, w) L φ depends only on the reduct of
M to L(τφ ). That is, if (M, w) L φ and (N, w) is an expansion of (M, w) to a
larger language, then (N, v) L φ.
(iii) Bisimilarity property. The relation (M, w) L φ is preserved under bisimu-
lations: if (M, w) ↔τ (N, v) and (M, w) L φ, then (N, v) L φ.
If we compare the above deﬁnition to the list of properties deﬁning an abstract
classical logic, we see that it is the Bisimilarity property that determines the modal
character of an abstract modal logic.
Obviously, ordinary modal formulas provide an example of an abstract modal
logic, but so does propositional dynamic logic. In contrast, the language of basic
temporal logic provides an example of a logic that is not an abstract modal logic,
as formulas from basic temporal logic are not preserved under bisimulations.
Next, we need to say what we mean by ‘(L, L ) extends basic modal logic’ and
by closure under negation.7 Extended Modal Logic
474
Deﬁnition 7.57 We say that (L, L ) extends modal logic if for every basic modal
formula there exists an equivalent L-formula, that is, if for each basic modal for-
mula φ there exists an L-formula ψ such that for any model (M, w) we have
(M, w)  φ iff (M, w) L ψ.
Also, (L, L ) is closed under negation if for all L-formulas φ there exists an
L-formula ¬φ such that for all models (M, w), (M, w)  φ iff (M, w)  ¬φ.
Of course, propositional dynamic logic is an example of an abstract modal logic
that extends (basic) modal logic.
Logics in the sense of Deﬁnition 7.56 deal with the same class of pointed mod-
els as (basic) modal logic, and only the formulas and satisfaction relation may be
different. This implies, for example, that intuitionistic logic or the hybrid logics
considered in Section 7.3 are not abstract modal logics: their models need to sat-
isfy special constraints. The original Lindström characterization of ﬁrst-order logic
suffers from similar limitations (by not allowing ω-logic as a logic, for example).
As a ﬁnal step in our preparations, we need to say what the notion of degree
means in the setting of an abstract modal logic.
Deﬁnition 7.58 (Notion of Finite Degree) An abstract modal logic has a notion
of ﬁnite degree if there is a function degL : L → ω such that for all (M, w), all φ
in L,
(M, w) L φ iff
((M, w) degL (φ)), w L φ.
If L extends (basic) modal logic, we assume that degL behaves regularly with
respect to standard modal operators and proposition letters. That is, if  is a modal
operator (see Deﬁnition 1.12), then degL (p) = 0 and degL ((φ1 , . . . , φn )) =
1 + max{degL (φi ) | 1 ≤ i ≤ n}.
Finally, two models (M, w) and (N, v) for the same language are L-equivalent
if for every φ in L, (M, w)  φ iff (N, v)  φ.
Having a ﬁnite degree is a very restrictive property, which is not implied by the
ﬁnite model property (f.m.p.). To see this, recall that propositional dynamic logic
has the f.m.p.: it has the property that every satisﬁable formula φ is satisﬁable on a
model of size at most |φ|3 , where φ is the length of φ. However, it does not have a
notion of ﬁnite degree. To see this, consider the model (ω, Ra , V ), where Ra is the
successor relation and V is an arbitrary valuation, and let φ = [a∗ ]a; clearly
(ω, Ra , V ), 0  φ. But for no n ∈ ω does the restriction (ω, Ra , V ) n satisfy φ
at 0. It follows that PDL does not have a notion of ﬁnite degree.
Characterizing modal logic
We are almost ready now to prove our characterization result. The following lemma
is instrumental.7.6 A Lindström Theorem for Modal Logic
475
Lemma 7.59 Let (L, L ) be an abstract modal logic which is closed under nega-
tion. Assume L has a notion of ﬁnite degree degL . Let φ be an L-formula with
degL (φ) = n. Then, for any two models (M, w), (N, v) such that (M, w) and
(N, v) are n-equivalent, we have that (M, w) L φ implies (N, v) L φ.
Proof. Assume that the conclusion of the lemma does not hold. Let (M, w), (N, v)
be such that (M, w) and (N, v) are n-equivalent, but (M, w) L φ and (N, v) L
¬φ.
By the Occurrence and Expansion properties we may assume that L = L(τφ ),
where L(τφ ) is the ﬁnite language in which φ lives.
By Proposition 7.53 we can assume that (M, w) and (N, v) are rooted such that
the roots have in-degree 0, while all other nodes have in-degree at most 1. Then
((M, w) n, w) and ((N, v) n, v) are n-equivalent, and ((M, w) n, w) L φ
but ((N, v) n, v) L ¬φ. In addition ((M, w) n, w) and ((N, v) n, v)
both have in-degree 1 and roots of in-degree 0. By Proposition 7.55 it follows that
((M, w) n, w) and ((N, v) n, v) are bisimilar – but now we have a contra-
diction with the Bisimilarity property as ((M, w) n, w) and ((N, v) n, v) are
bisimilar but do not agree on φ.
Theorem 7.60 Let (L, L ) extend modal logic. If (L, L ) has a notion of ﬁnite
degree, then it is equivalent to the modal language as deﬁned in Deﬁnition 1.12.
Proof. We must show that every L-formula φ is L-equivalent to a basic modal
formula ψ, that is, for all (M, w), (M, w) L φ iff (M, w) L ψ. As before,
by the Occurrence and Expansion properties we may restrict ourselves to a ﬁnite
language. Moreover, φ has a basic modal equivalent iff it has such an equivalent
with the same degree; so we have to locate the equivalent we are after among the
basic modal formulas whose degree equals the L-degree of φ.
Assume n = degL (φ). By Proposition 2.29 there are only ﬁnitely many (non-
equivalent) basic modal formulas whose degree equals n; assume that they are all
contained in Γn . It sufﬁces to show the following:
if (M, w) and (N, v) agree on all formulas in Γn , then they agree on φ.
(7.18)
For then, φ will be equivalent to a boolean combination of formulas in Γn . To see
this, reason as follows. The relation ‘satisﬁes the same formulas in Γn ’ is an equiv-
alence relation on the class of all models; as Γn is ﬁnite, there can only be ﬁnitely
many equivalence classes. Choose representatives (M1 , w1 ), . . . , (Mm , wm ), and
for each i, with 1 ≤ i ≤ m, let ψi be the conjunction of all formulas in Γn that are

satisﬁed by (Mi , wi ). Then φ is equivalent to {ψi | (Mi , wi ) L φ}.
Now to conclude the proof of the theorem we need only observe that condition
(7.18) is exactly the content of Lemma 7.59.476
7 Extended Modal Logic
To conclude this section a few remarks are in order. First, the property of having a
notion of ﬁnite degree can be characterized algebraically in terms of preservation
under ultraproducts over the natural numbers; Theorem 7.60 can then be reformu-
lated accordingly.
Second, in the proof of the Lindström Theorem the basic modal formula ψ that is
found as the equivalent of the abstract modal formula φ is in the same vocabulary
as φ. This means, for example, that the only abstract modal logic over a binary
relation that has a notion of ﬁnite degree is the standard modal logic with a single
modal operator 3.
Here, we have only covered the modal logics as deﬁned in Deﬁnition 1.12; in
some cases extensions beyond this pattern can easily be obtained. As a ﬁrst exam-
ple, consider the basic temporal language with operators F and P , where x  F p
(x  P p) iff for some y, Rxy and y  φ (Ryx and y  φ). Consider temporal
bisimulations in which one not only looks forward along the binary relation, but
also backward, and adopt the notion of height accordingly. Given the obvious def-
inition of an abstract temporal logic, standard temporal logic is the only temporal
logic over a single binary relation that has a notion of ﬁnite degree.
7.7 Summary of Chapter 7
 Logical Modalities: Logical modalities receive a ﬁxed interpretation in every
model. Simple examples are the past tense operator P , the global diamond E,
and the difference operator D. As well as enhancing expressivity, some of them
(notably P and D) make it possible to prove general completeness theorems
using additional rules of proof.
 Algebra of Diamonds: Some modal languages offer not just a single logical
modality but an entire algebra of diamonds. Good examples are PDL and BML.
 Since and Until: The since and until operators are interesting in applied logic
because they enable us to specify guarantee properties. They are mathematically
interesting because they are expressively complete over Dedekind complete to-
tal orders.
 Completeness-via-Completeness: While deductive completeness of since/until
logic can be proved using standard modal techniques, for Dedekind complete
total order there is an interesting alternative: taking a detour via expressive
completeness.
 Hybrid Logic: The basic hybrid language lets us refer to states using nominals,
atomic symbols true at exactly one state in every model. Some stronger hybrid
languages allow us to bind nominals.
 Hybrid Proof Theory: We can deﬁne a rule of proof called PASTE in the basic
hybrid language. This rule is essentially a sequent rule lightly disguised. WithNotes to Chapter 7
477
its help, a frame completeness result covering all pure formulas can be proved
fairly straightforwardly.
 Guarded Fragment: As the standard translation shows, modalities are essen-
tially macros which permit restricted forms of quantiﬁcation. Abstracting from
this insight leads to the guarded fragment, a decidable fragment of ﬁrst-order
logic with the ﬁnal model property.
 Packed Fragment: By taking this observation even further, and noting that the
mosaic method sufﬁces to prove decidability, it is possible to isolate an even
larger decidable fragment of ﬁrst-order logic: the packed fragment. This frag-
ment also has the ﬁnite model property.
 Multi-Dimensional Modal Logic: Multi-dimensional modal logic is essentially
modal logic in which evaluation is performed at a sequence of states, rather than
at a single state. By viewing variable assignments as sequences of states, it is
possible to view ﬁrst-order logic itself as a multi-dimensional modal logic.
 Lindström’s Theorem: Given a suitable (bisimulation centered) explication of
what an abstract modal logic is, our Lindström Theorem for modal logic says
that the general modal languages deﬁned in Deﬁnition 1.12 are the strongest
ones to have a notion of ﬁnite degree.
 Extended Modal Logic: In many ways, this chapter is badly named. Among
other things, we have just seen that not only is it possible to introduce global-
ity, more complex quantiﬁer alternations in satisfaction deﬁnitions, names for
states, and evaluation at sequences of states, but we can do so without losing
the properties that made modal logic attractive in the ﬁrst place. So forget the
‘extended’. As we said in the Preface: it is all just modal logic!
Notes
A really serious guide to extended modal logic would have to cover the (vast)
literature on temporal logics, ﬁxed point logics, and variants of PDL discussed in
the theoretical computer science literature, plus formalisms such as feature and
description logic, and much else besides. We do not have space to do all that, and
the following Notes stick to the six topics discussed in the text. Nonetheless, with
the help of the following remarks (coupled with a little judicious reference chasing)
the reader should be able to form a coherent map of territory.
Logical Modalities. It is hard to precise about when the idea of adding ﬁxed in-
terpretation operators to modal languages came to be seen as standard. Certainly
the writings of Johan van Benthem (for example, his book on temporal logic, his
‘manual’ on intensional logic, and his inﬂuential survey of correspondence theory)
played an important role. So did the new applications of modal logic, particularly
in computer science (once you have seen PDL it is hard to believe that the basic478
7 Extended Modal Logic
modal language is the be-all and end-all of modal logic). At any rate, by the end
of the 1980s the idea that modal languages are abstract tools for talking about re-
lational structures – tools that it was not only legitimate, but actually interesting
to extend – was well established in both Amsterdam and Bulgaria. Nowadays this
view is taken for granted by many (perhaps most) modal logicians, and given this
perspective the use of logical modalities is as natural as breathing.
Of course, many of the operators we now call ‘logical’ have been around a lot
longer than that. In a way, the global modality has always been there (after all its
just a plain old S5 operator). But when did it ﬁrst emerge as an additional operator?
We are not sure. Prior used it on a number of occasions (see, for example, [365,
Appendix B4]), though sometimes Prior’s global modality is actually the master
modality [∗] discussed in Section 6.5 (that is, sometimes Prior views globality as
the reﬂexive transitive closure of the underlying relation).
But it seems fair to say that it was the Bulgarian-school who ﬁrst exploited it
systematically: it is the Swiss Army knife underlying their investigation of BML,
and their work on hybrid logic. Goranko and Passy [192] is a systematic study of
the global modality as an additional operator, and is the source of Theorem 7.1, the
Goldblatt-Thomason theorem for ML(3, E). The operator has also been studied
from an algebraic angle, being closely connected to the notion of a discriminator
variety; these classes display nice algebraic behavior and have been intensively
investigated in universal algebra. For, in the context of boolean algebra with oper-
ators, having the global modality is equivalent to having a so-called discriminator
term; this is why in algebraic circles this modality is sometimes dubbed a ‘unary
discriminator term’; see Jipsen [247] for some information. The basic complexity
results for the global modality were proved in Spaan’s thesis [419]. Incidentally,
the global modality is usually referred to as the ‘universal’ modality in the litera-
ture. However the word ‘universal’ suggests that we are working with a box, so we
prefer the term ‘global’, which is appropriate for both boxes and diamonds.
The history of the difference operator is harder to untangle. It is probably due
to von Wright [465] (who viewed it as a ‘logic of elsewhere’) and Segerberg gave
an axiomatization in a festschrift for von Wright (see [406]). Segerberg’s axiom-
atization, together with a more detailed completeness proof, was later published
in [408]. But Segerberg treats D as an isolated modality. The use of D as an ad-
ditional modality seems to have been proposed independently by Koymans [271]
and Sain [397]. The difference operator is also discussed in Goranko [189]. For a
systematic investigation of D as an additional, logical modality, see de Rijke [378].
The D-Sahlqvist theorem in the text is due to Venema [444]. Theorem 7.8 is an
unpublished result due to Szabolcs Mikulás.
B ML is a Bulgarian school invention. The system is ﬁrst described in Gargov,
Passy and Tinchev [166] (as part of a wide ranging discussion of extended modal
logic) and Gargov and Passy [165] concentrates on BML and gives proofs of the keyNotes to Chapter 7
479
completeness and decidability results. See also the results on modal deﬁnability in
Goranko [189]. All these papers view modal languages as general tools for talking
about structures, very much in the spirit of the present book. The window operator
has an interesting independent history: van Benthem [38] used it as part of a logic
of permissions and obligations, Goldblatt [176] used it to deﬁne negation in quan-
tum logic, Humberstone [236] used it in a discussion of inaccessible worlds, while
Gargov, Passy and Tinchev [166] view it as a ‘logic of sufﬁciency’ that balances
the usual ‘logic of necessity’ provided by 2. Complexity-theoretic aspects of BML
have been studied and surveyed by Lutz and Sattler [303], while resolution-based
decision procedures for extensions of BML and related languages are explored by
Hustadt and Schmidt [238].
As we pointed out in the text, both BML and PDL are examples of modal lan-
guages equipped with highly structured collections of modal operators. The dy-
namic modal logic of de Rijke [384] is a further example, and many description
logics allow for the construction of complex roles (that is, accessibility relations)
by means of some or all of the booleans, converse, and sometimes even transitive
closure and least ﬁxed point constructors; see Donini et al. [115].
The algebraic counterparts of modal languages with structured collections of
modal operators can best be phrased in terms of multi-sorted algebras, where the
(algebraic counterparts of the) modal operators provide the links between the sorts.
Kleene algebras [272] and Peirce algebras [382, 385] are two important examples.
The former provide an algebraic semantics for PDL and consist of a boolean algebra
and a regular algebra together with systematic links between them that are used
to interpret the diamonds. The latter provide an algebraic semantics of dynamic
modal logic and consist of a boolean and a relation algebra together with various
links between them to interpret the modalities in the language.
Since and Until. The invention of since/until logic was a major breakthrough in
the study of modal logic. Hans Kamp tells the story this way. In a semester-long
course Arthur Prior gave on tense logic at UCLA in the fall of 1965, when Kamp
had just started his PhD, Prior stressed that the P and F operators were strictly
topological, and asked whether it was possible to develop some notion of met-
ric time within the framework of tense logic. Now, a ﬁrst requirement on such
an enterprise is that it can express what it is for some proposition q to have been
true since the last time some periodically true proposition p was true. Trying to
ﬁnd a genuinely topological tense logic in which these kinds of relations could be
expressed lead Kamp to the deﬁnitions of since and until. As the technical inter-
est of the new operators became clear, the original motivation seems to have been
shelved (Kamp, personal communication, remarks that ‘The question of how to
embed a logic of metric temporal notions within a topological tense logic unfortu-
nately never got properly off the ground.’). Kamp ﬁrst showed that P and F cannot480
7 Extended Modal Logic
express since and until, and eventually succeeded in proving Theorem 7.12(i), the
expressive completeness of the since and until operators over Dedekind complete
total orders (see his thesis [258]). At that time, deductive completeness was the
dominant interest in modal logic. Kamp’s result showed that the neglected topic of
modal expressivity deserved further attention, and can be regarded as a precursor
to the study of correspondence theory that emerged in the 1970s.
The next step was taken by Dov Gabbay. Kamp’s result was clearly important,
but his direct proof was complex, and although Jonathan Stavi [422] succeeded in
providing a direct proof of Theorem 7.12(ii), it was not obvious how to proceed.
Matters were greatly simpliﬁed when Gabbay introduced the notion of separability
(see [148, 150]). Roughly speaking, a language is separable over a class of models
if every formula is equivalent to a boolean combination of atomic formulas, formu-
las that only talk about the past, and formulas that only talk about the future. This
idea drastically simpliﬁes the proofs of Theorem 7.12(i) and Theorem 7.12(ii), and
opens the way to more general investigations. Nowadays a variety of techniques are
used for proving expressive completeness results for modal (and other) languages;
game-based approaches (see Immerman and Kozen [240]) have proved particularly
useful. The best introduction to expressive completeness is the encyclopedic Gab-
bay, Hodkinson, and Reynolds [156]; both separability and game-based proofs are
discussed, as well as many other results on since/until logic.
But what really made the until operator so popular is the simple observation
made in the text: it offers precisely what is needed to express guarantee properties
(this was ﬁrst noted in Gabbay, Pnueli, Shelah, and Stavi [160]). Nowadays, until
may well be the single best known modal operator (at least in computer science)
and it occurs both in its original form, and in a number of variant forms in the
study of linear and branching time temporal logics (see Clarke and Emerson [94],
Goldblatt [177]).
Good discussions of step-by-step completeness proofs for since and until can
be found in Burgess [78] and Xu [466]. The classiﬁcation of properties of ﬂows
of time (in terms of safety, liveness, and guarantees) referred to in Section 7.2
can be found in Manna and Pnueli’s textbook [312] on using temporal logic for
specifying concurrent and reactive systems. Theorem 7.19 is due to Venema [443];
the strategy of using expressive completeness to obtain axiomatic completeness
results goes back at least to Gabbay and Hodkinson [155].
One ﬁnal remark: in spite of the fact that its satisfaction deﬁnition makes use of a
more complex patterns of quantiﬁcation, the since and until operators are genuinely
modal. In particular, the notion of bisimulation can be adapted to these operators:
the only complication is that, instead of the simple ‘complete the square’ idea il-
lustrated in Figure 2.3 (65), bisimulations now need to match relational steps plus
intermediate intervals in suitable ways. Kurtonina and de Rijke [288] contain a
solution to this issue as well as a survey of earlier proposals.Notes to Chapter 7
481
Hybrid Logic. Arthur Prior introduced and made systematic use of hybrid logic;
see Prior [365] (in particular, Chapter 5 and Appendix B.3), several of the papers
in Prior [366], and the posthumously published Prior and Fine [367]. Prior’s sys-
tems typically allowed explicit quantiﬁcation over states using ∀ and ∃, and con-
tained the global modality. Technical aspects of such languages were explored in
Bull [73], an important paper, which among other things notes that pure formulas
give rise to easy frame completeness results. In the mid 1980s Passy and Tinchev
independently reinvented the idea of ‘names as formulas’. Their earliest paper
[356] added nominals and the global modality to a rich version of PDL; in [357]
they considered ∀ and ∃ (again in the setting of PDL); and [358], their beautiful
essay on hybrid languages, remains one of the key papers on hybrid logic.
The subsequent history of hybrid logic revolves around attempts to ﬁnd well-
behaved sublanguages of such strong systems. The most obvious way to do this is
the one explored in the text: treat nominals as names, rather than variables open
to binding, and keep the underlying modal language relatively weak. Early papers
which explore this option include Gargov and Goranko [164] (the basic modal
language enriched with nominals and the global modality) and Blackburn [54] (the
basic tense language enriched with nominals alone). The basic hybrid language
discussed in the text can be viewed as an interesting compromise between simply
adding nominals to the basic modal language (which makes the axiomatics messier,
as Exercise 7.3.7 shows) and adding both nominals and the global modality (which
raises the complexity to EXPTIME-complete). A proof of Theorem 7.21 (that the
basic hybrid language has a PSPACE-complete satisﬁability problem) can be found
in Areces, Blackburn and Marx [14]. For a more detailed look at the complexity
of hybrid logic, see [13] by the same authors. Theorem 7.29 is a modiﬁcation of
results proved in Blackburn and Tzakova [63]. It simpliﬁes a similar result proved
in Gargov and Goranko [164] with the aid of the global modality.
But the idea of binding variables to states turns out to be important. Binding
admits a rich expressivity hierarchy. For a start, even if binding with ∀ and ∃
is allowed, when there are no satisfaction operators in the language, the result-
ing language does not have full ﬁrst-order expressivity; see Blackburn and Selig-
man [59]. Moreover, as we mentioned in the text, the ↓ binder simply binds vari-
ables to the current state; in effect, it lets us create a name for the here-and-now (see
Goranko [190], Blackburn and Seligman [59, 60], Blackburn and Tzakova [63]). If
we enrich the basic hybrid language with the ↓ binder we obtain a hybrid language
which corresponds to precisely the fragment of the ﬁrst-order correspondence lan-
guage which is invariant under generated submodels. This is proved in Areces,
Blackburn and Marx [14] by isolating notions of bisimulation suitable for various
hybrid languages and proving a characterization theorem. The paper also links
these notions of bisimulation to restricted forms of Ehrenfeucht-Fraı̈ssé games.
Hybrid logic provides a natural setting for modal proof theory. Seligman [411]482
7 Extended Modal Logic
is the pioneering paper here, and Seligman [412] discusses satisfaction operator
based natural deduction and sequent systems. Blackburn [56] deﬁnes satisfaction
operator driven tableaux and sequent systems and uses Hintikka sets to prove an
analog of Theorem 7.29. Tzakova [439] combines the use of nominals with the
preﬁx systems of Fitting [137]. Demri [107] deﬁnes a sequent calculus for the
basic tense language enriched with nominals, and Demri and Goré [108] introduce
a display calculus for the basic tense language enriched with nominals and D.
Hybrid logics turn up naturally in a number of applications. The AVMs used
in computational linguistics (recall Example 1.17) can be viewed as modal log-
ics: path re-entrancy tags are treated as nominals (see, for example, Blackburn and
Spaan [61]). And while it has long been known that description logics are nota-
tional variants of modal logics, this relation only holds at the level of concepts.
So-called A-Box (or assertional) reasoning – that is, reasoning about how concepts
apply to particular individuals – corresponds to a restricted use of satisfaction op-
erators, while the ‘one-of’ operators used in some versions of description logic
are essentially disjunctions of nominals; see Blackburn and Tzakova [62], Are-
ces and de Rijke [15], and Areces’s PhD thesis [12]. Nominals also turn up in
the Polish tradition of modal logics for information systems and rough-set theory:
see Konikowska [269, 270]. They also provide a natural model of tense and other
forms of temporal reference in natural language (see Blackburn [55]).
A ﬁnal remark. The basic hybrid language shows that sorting is interesting
in the setting of modal logic – so why not introduce further sorts? In fact, this
step was already taken in Bull [73] who introduced a third sort of atomic sym-
bol: path nominals, true at precisely the points belonging to some path through the
model. For more information on hybrid logic, see the Hybrid Logic home page at
www.hylo.net. For a recent ‘manifesto’ on hybrid logic that touches on most
of the themes just mentioned, see Blackburn [57].
The Guarded Fragment. The guarded fragment was introduced by Andréka, van
Benthem and Németi in 1994. The roots of the decidability proof date back to
1986, when Németi [340] showed that the equational theory of the class of so-
called relativized cylindric set algebras is decidable. The ﬁrst-order counterpart of
this result is that a certain subfragment of the guarded fragment is decidable.
The importance of this result for ﬁrst-order logic was realized in 1994 when
Andréka, van Benthem and Németi introduced the guarded fragment and showed
that many nice properties of the basic modal system K generalize to it. In par-
ticular, the authors established a characterization in terms of guarded bisimula-
tions, decidability and a kind of tree model property. The journal version of their
paper is [9]. Some time later van Benthem was able to generalize some of the
results, introducing the loosely guarded fragment in [49]. The slightly more gen-
eral packed fragment was introduced in Marx [317] in order to give a semanticNotes to Chapter 7
483
characterization in terms of packed bisimulations. (An example of a packed sen-
tence which is not equivalent to a loosely guarded sentence in the same signature
is ∃xyz (∃wCxyw ∧ ∃w Cxzw ∧ ∃w Czyw ∧ ¬Cxyz).)
The mosaic based decision algorithms of Andréka, van Benthem and Németi
were essentially optimal: a result established by Grädel [194]. In this paper, Grädel
also deﬁnes and establishes the loose model property for the loosely guarded frag-
ment. Our deﬁnition of a loose model is based on the deﬁnition of a tree model
given there. Grädel and Walukiewicz [197] showed that the same bounds obtain
when the guarded fragment is expanded with least and greatest ﬁxed point oper-
ators. Marx, Mikulás and Schlobach [319] deﬁned a PSPACE-complete guarded
fragment (both locality principles) with the ﬁnite tree model property.
The ﬁnite model property for the guarded fragment, and several subfragments of
the packed fragment, was established in an algebraic setting by Andréka, Hodkin-
son and Németi [7]. Grädel [194] provides a direct proof for the guarded fragment.
The remaining open question for the full packed fragment was solved afﬁrmatively
by Hodkinson [231]. All these results are based on variants of a result due to Her-
wig [222]. The use of Herwig’s Theorem to establish the ﬁnite model property and
to eliminate the need for step-by-step constructions is due to Hirsch et al. [227].
Multi-Dimensional Modal Logic. The idea of evaluating modal languages at se-
quences of points, rather than at the points simpliciter, is extremely natural, so it
is no surprise that over the years modal logicians with very diverse interests have
devised multi-dimensional systems.
It seems that logicians interested in natural language were ﬁrst off the mark.
Natural language utterances are so context dependent, that evaluating at sequences
of points (each coordinate modelling a different aspect of context) proved a useful
idea. Evaluation at pairs of points is built into Montague’s [336] general framework
for natural language semantics. Kamp’s [259] classic analysis of the word ‘now’
uses a second coordinate to keep track of utterance time. Vlach [452] provided an
analysis of the word ‘then’, and in a series of papers, Åqvist and co-workers [11]
developed rich multi-dimensional modal logics for analyzing temporal phenomena
in natural language. Before long, such systems were subjected to rigorous logical
investigation: see, for example, Segerberg’s elegant decidability and completeness
result in [405], and Gabbay’s work on expressiveness and other topics (much of
which reappeared in later work by Gabbay, Hodkinson and Reynolds [156]).
Somewhat later, a rich source of inspiration came from logic itself. Some work
here, such as the sorted modal logic PREDBOX of Kuhn [286], ﬁtted in the tradition
of Quine-style ﬁrst-order logic without variables, but most of it was linked, one
way or another, with the algebraic logic framework of the Tarskian school (see the
Notes of Chapter 5). This certainly applies to the multi-dimensional logics that we
presented in Section 7.5. Venema [445], from which our Theorem 7.51 originates,484
7 Extended Modal Logic
made the connection between modal logic and cylindric algebras. Subsequent re-
search drew on existing ideas on relativized cylindric algebras (see Németi [340])
to use the modal framework to ‘tame’ ﬁrst-order logic and its ﬁnite variable frag-
ments (see our discussion of the abstract and relativized assignment frames in
the text; more information on this program can be found in van Benthem [48]
or Mikulás [329]). This line of work is closely related to arrow logic, which is
a multi-dimensional modal logic in its own right (see Marx et al. [318] for more
information) and in fact this strand of work ultimately lead to the isolation of the
guarded fragment. All of these (and more) multi-dimensional modal logics are cov-
ered in the monograph Marx and Venema [320]; readers interested in complexity
results should consult Marx [316].
Computer scientists have different motivations for studying multi-dimensional
modal logics. In order to build formal models of an application domain, they need
to take account of various features simultaneously. Of the wealth of literature on
this topic we will just mention Fagin et al. [125], which concentrates on the com-
bination of temporal and epistemic logics in the context of distributed systems.
Such applications have led logicians to study various ways of constructing complex
logics from relatively simple ones. A particularly interesting and mathematically
non-trivial branch of multi-dimensional modal logics arises if one studies a modal
language with various modal operators over a semantics in which the frames are
cartesian products of frames for the individual operators. This area of so-called
product logics, which has an early predecessor in Shehtman [413], has recently
become very active; a monograph Gabbay et al. [159] is on its way.
Finally, multi-dimensional modal logic remains one of the most philosophically
important branches of modal logic. Important references include Kaplan [264,
265], Stalnaker [421], and Chalmers [90].
The Lindström Theorem for Modal Logic. Theorem 7.60, a Lindström-type
characterization of the modal languages deﬁned in Deﬁnitions 1.9 and 1.12 is due
to de Rijke [381]; the result was obtained as part of a general program to come up
with modal counterparts of model-theoretic results in ﬁrst-order logic [380]. The
original ﬁrst-order version of Lindström’s Theorem was ﬁrst presented in Lind-
ström [302]. The original result states that, given a suitable explication of a ‘clas-
sical logic’, ﬁrst-order logic is the strongest logic to possess the Compactness and
Löwenheim-Skolem properties; it formed an important source of inspiration for
the area of model-theoretic logics [26]. Deﬁnitions of the abstract notion of a logic
can be found in Chang and Keisler [91] and in Barwise [25]. A very accessible pre-
sentation of Lindström’s Theorem for ﬁrst-order logic can be found in Doets [111,
Chapter 4].Appendix A
A Logical Toolkit
In this appendix we review basic ﬁrst-order logic, deﬁne some model-theoretic
concepts, introduce the ultraproduct construction, and brieﬂy discuss second-order
and inﬁnitary logic. But it is not a self-contained introduction to ﬁrst-order (or any
other) logic: we assume the reader has had some prior exposure to formal logic and
is comfortable with the basic ideas. If a signiﬁcant portion of what follows is un-
familiar, you should consult an introduction to mathematical logic (Enderton [122]
and Hodges [228] are good choices).
There are many sources for further information about model theory: Doets [111]
is an approachable introductory text, Hodges [229] gives an encyclopedic view of
the ﬁeld, and Bell and Slomson [33] is a detailed guide to the ultraproduct construc-
tion. But the single most important source is probably Chang and Keisler [91]; our
presentation of ultraproducts is largely based on theirs. For second-order logic, see
Doets and van Benthem [112], Chapter 4 of Enderton [122], and Fitting [139]. For
inﬁnitary logic, see Keisler [267].
Languages, Models, and Satisfaction
A language of ﬁrst-order logic is built from terms and formulas. Terms t are built
from variables x, constants c, and function symbols f as follows:
t ::= x | c | f (t1 , . . . , tn ).
The atomic formulas β are expressions of the form:
β ::= t1 = t2 | R(t1 , . . . , tn ).
Here R is an n-ary relation symbol, and the ti are terms of the language.
Arbitrary ﬁrst-order formulas α are built from atomic formulas β using boolean
operators and quantiﬁers as follows:
α ::= β | ¬α | α ∨ α | ∃x α.
485486
A A Logical Toolkit
We deﬁne ∀x α to be ¬∃x ¬α. Other boolean connectives (in particular, ∧, →, ↔,
⊥, ) can be deﬁned in the standard way, as can the notions of free and bound
variables of a formula. A ﬁrst-order sentence is a formula without free variables.
Models for a ﬁrst-order language L1 are tuples A = (A, R, . . . , f, . . . , c, . . .).
Here A is a non-empty set (the domain, or universe), each R is a relation on the
domain (a subset of An , for some n), each f is a function on the domain (a mapping
from An to A, for some n) and each c is an element of the domain (the elements
of A singled out in this way are often called distinguished elements). Models are
essentially relational structures (see Deﬁnition 1.1), for n-place functions are (n +
1)-ary relations, and distinguished elements can be viewed as 0-ary functions.
The models used to interpret a language must ‘match’ it in certain obvious re-
spects. First, the model must supply enough relations to interpret all the relation
symbols of the language, enough functions to interpret all the function symbols of
the language, and enough distinguished elements to interpret all the constants of the
language. Furthermore, relations of arity n must be used to interpret n-ary relation
symbols, and n-ary functions must be used to interpret n-ary function symbols. We
will usually employ the same notation for a relation symbol and the actual relation
interpreting this symbol, and likewise for function symbols and constants.
We need a mechanism to interpret free variables. Given a model A = (A, R,
. . . , f , . . . , c, . . .), an assignment on A is a function g that assigns an element of A
to each variable of the language. Thus, given a model and an assignment we can
interpret arbitrary terms through the obvious inductive deﬁnition: constants denote
the corresponding distinguished elements, variables are interpreted using the as-
signment, and terms f (t1 , . . . , tn ) are interpreted by applying the interpretation of
f to the interpretations of t1 , . . . , tn . We often call the interpretation of a term its
value; tA[g] denotes the value of term t in model A under assignment g.
The satisfaction deﬁnition is a 3-place relation |= between a model, formula,
and assignment: A |= α[g] means that formula α is satisﬁed in model A under
assignment g. But before deﬁning this relation, a notational point. Rather than
using g, g , and so on to name arbitrary assignments, it is more common to use
a notation that speciﬁes which element has been assigned to which free variable.
Thus if α(x1 , . . . , xn ) is a formula in which x1 , . . . , xn occur free, A is a model,
and a1 , . . . , an are elements of A, then A |= α[a1 , . . . , an ] means that we are
evaluating with respect to an assignment that assigns ai to xi (for 1 ≤ i ≤ n).
Sometimes this notation is convenient when deﬁning the value of terms: in our
discussion of ultraproducts we use expressions such as tA[a1 , . . . , an ] to denote the
value of term t in model A under an assignment that sends xi to ai , for 1 ≤ i ≤ n.
The satisfaction relation is deﬁned by induction on the structure of formulas.
The atomic cases are as follows: A |= R(t1 , . . . , tn )[a1 , . . . , an ] iff the values of
the terms t1 , . . . , tn are R-related in the model A; and A |= t1 = t2 [a1 , . . . , an ]
iff the values of terms t1 and t2 in A are equal. The boolean cases are deﬁnedA Logical Toolkit
487
in the obvious way by A |= ¬α[a1 , . . . , an ] iff A |= α[a1 , . . . , an ]; and A |=
α ∨ α [a1 , . . . , an ] iff either A |= α[a1 , . . . , an ] or A |= α [a1 , . . . , an ]. The case
of the quantiﬁer is deﬁned as follows:
A |= ∃x α[a1 , . . . , an ] iff there exists a in A such that
A |= α[a1 , . . . , an , x → a],
where [a1 , . . . , an , x → a] is the assignment that differs from [a1 , . . . , an ], if at
all, only in that the variable x is assigned the value a. Clearly, we have that A |=
∀x α[a1 , . . . , an ] iff for all a in A, A |= α[a1 , . . . , an , x → a].
If A |= α[a1 , . . . , an ] then we say that the sequence a1 , . . . , an satisﬁes α in A.
It is easy to see that if a sentence is satisﬁed in a model under one assignment,
then it is satisﬁed under all assignments; accordingly, if a sentence α is satisﬁed in
a model A under some assignment, then we write A |= α and say that α is true in
A, or that A is a model for α. Two models A and B are elementarily equivalent
(notation: A ≡ B), if every sentence true in A is true in B, and vice versa.
Deﬁnition A.1 (Validity and Semantic Consequence) A formula α is valid if for
every model A and every assignment, A |= α[a1 , . . . , an ].
Given a set of formulas Π (the premises) and a formula γ (the conclusion), we
say that γ is a semantic consequence of Π (notation: Π |= γ), if for every model
A and every assignment
A |= Π[a1 , a2 , . . .] implies A |= γ[a1 , a2 , . . .].
That is, satisﬁability of the premises (with respect to some assignment) guarantees
satisﬁability of the conclusion (with respect to the same assignment).
Basic Properties of First-Order Logic
First-order logic is undecidable: it is impossible to write a computer program that,
given an arbitrary ﬁrst-order formula as input, will stop after ﬁnitely many steps
and (correctly) tell us whether the formula is valid or not. On the other hand,
ﬁrst-order validity is recursively enumerable. That is, it is possible to write a com-
puter program that successively generates all valid formulas. (The relationship
between decidability, undecidability, and recursive enumerability is discussed in
Appendix C.)
The usual way of showing that the collection of ﬁrst-order validities is recur-
sively enumerable is to devise a (sound and complete) proof system for it. Many
such systems are known (axiom systems, sequent systems, natural deduction sys-
tems) and though very different, they have one fundamental thing in common: they488
A A Logical Toolkit
are purely syntactic. Proofs are essentially simple ﬁnite data structures (for exam-
ple, lists or trees of formulas). Such a data structure is a proof of a formula if the
symbols it contains fulﬁll certain (usually quite simple) syntactic criteria.
Let us write  α to indicate that α is provable in a standard proof system. We
would like  α to hold if and only if |= α, for if we could do this we would have
reduced a complex semantic notion (|= α means satisﬁed in all models under all
assignments, and there are lots of models and assignments) to a relatively simple
syntactic one (patterns of symbols in ﬁnite data structures). It is not obvious that
this can be done, but it can. Indeed, something better is the case. If we write Π  γ
to indicate that the conclusion γ follows syntactically from the premises Π (this
concept can be deﬁned for any standard proof system) then we have:
Theorem A.2 (Soundness and Completeness) Let Π be a set of ﬁrst-order for-
mulas, and α a ﬁrst-order formula. Then Π  α iff Π |= α. When Π = ∅ we
have as a special case that  α iff |= α.
Proof. Completeness is the right to left implication: this assures us that the proof
system captures all semantically correct inferences. Detailed proofs can be found
in Chang and Keisler [91] and Enderton [122]. Hodges [228] has a good discussion
of completeness proof strategies.
The left to right direction assures that the proof system does not produce seman-
tic nonsense; this is called soundness. It is far easier to prove than completeness
(typically, a fairly simple inductive argument sufﬁces) and proofs for various types
of proof system can be found in any standard text on mathematical logic.
So ﬁrst-order semantic consequence, and ﬁrst-order validity, can be reduced to
syntactic criteria on simple data structures. Thus ﬁrst-order validities can be re-
cursively enumerated: we merely write a program that systematically generates all
ﬁnite data structures of the appropriate kind, and checks whether they fulﬁll the
criteria demanded of proofs.
The Completeness Theorem is one of the fundamental theorems of ﬁrst-order
logic, but it plays a relatively modest role in this book. More important for us are
the two theorems that follow:
Theorem A.3 (Compactness) Let Σ be a set of ﬁrst-order formulas. If each ﬁnite
subset of Σ has a model, then Σ itself has a model.
Theorem A.4 (Löwenheim-Skolem Theorem) Let Σ be a set of ﬁrst-order for-
mulas. If Σ has a model, then it has a countable model.
We will make use of both these results (actually, we will generally use a stronger
version of the Löwenheim-Skolem Theorem which is discussed below).A Logical Toolkit
489
Both the Compactness and Löwenheim-Skolem Theorems are purely model the-
oretic: they make no reference to provability in some proof system. The Com-
pleteness, Compactness and Löwenheim-Skolem Theorems together characterize
ﬁrst-order logic.
This completes our survey of the basics of ﬁrst-order logic. If much of it was
unfamiliar, we suggest you consult Enderton [122] or Hodges [228].
Basic Model-Theoretic Concepts
Now for some basic model-theoretic concepts. First we need to know when two
models are isomorphic.
Deﬁnition A.5 (Isomorphism) Two models A and A for the same ﬁrst-order lan-
guage are isomorphic if there is a bijective function f mapping A onto A such
that
(i) For each n-place relation R of A and the corresponding relation R of A ,
R(a1 , . . . , an ) iff R (f a1 , . . . , f an ).
(ii) For each m-place function F of A and the corresponding function F of A ,
f (F (a1 , . . . , an )) = F  (f a1 , . . . , f an ).
(iii) For each distinguished element c of A and the corresponding distinguished
element c of A , f (c) = c .
A function f that satisﬁes these requirements is called an isomorphism between A
and A . The notation f : A ∼
= A means that f is an isomorphism between A and

A.
In essence, isomorphic models are mathematically identical. Thus the following
proposition (which can be proved by induction on the structure of formulas) is
unsurprising:
Proposition A.6 Let f be an isomorphism between A and B. Then for all formu-
las α(x1 , . . . , xn ) and n-tuples a1 , . . . , an ∈ A, we have
A |= α[a1 , . . . , an ] iff B |= α[f a1 , . . . , f an ].
We are often confronted with situations in which a model we are interested in is
part of a larger one, or when we need to extend a given model to a bigger one. We
now deﬁne the basic model-theoretic notions useful in such cases.
Deﬁnition A.7 (Submodels and extensions) A model A is called a submodel of
A (notation: A ⊆ A), if A ⊆ A and490
A A Logical Toolkit
(i) Each n-place relation R of A is the restriction to A of the corresponding
relation R of A.
(ii) Each n-place function f  of A is the restriction to A of the corresponding
function f of A.
(iii) Each distinguished element of A is the corresponding distinguished ele-
ment of A.
If A is a submodel of A, then we say that A is an extension of A .
That A ⊆ A is no guarantee that A and A satisfy the same formulas – and in
general, that is what we care about. This prompts the following deﬁnition:
Deﬁnition A.8 (Elementary Extension) B is said to be an elementary extension
of A, (notation: A B), if
(i) B is an extension of A.
(ii) For any ﬁrst-order formula α(x1 , . . . , xn ) and any sequence a1 , . . . , an of
elements in A, a1 , . . . , an satisﬁes α in A iff it satisﬁes α in B.
When B is an elementary extension of A we also say that A is an elementary
submodel of B.
A mapping f : A → B is called an elementary embedding of A into B, (nota-
tion: f : A B), if for all formulas α(x1 , . . . , xn ) and n-tuples a1 , . . . , an ∈ A,
we have
A |= α[a1 , . . . , an ] iff B |= α[f a1 , . . . , f an ].
That is, an elementary embedding of A into B is an isomorphism of A onto an
elementary submodel of B.
When working with some model, it is often useful to move from the original lan-
guage to a richer language in which every element on the model has a name:
Deﬁnition A.9 (Expansion) Let L be a ﬁrst-order language, and A a model for L.
We expand L to a new language LA = L ∪ {ca | a ∈ A} by adding a new constant
symbol ca for each element a ∈ A (if a = b, then ca and cb are different symbols).
We expand A to the model AA = (A, a)a∈A for LA by stipulating that each ele-
ment a of A is a distinguished element. Each new constant ca of LA is interpreted
by the distinguished element a. If X is a subset of A, then LX is the language
L ∪ {ca | a ∈ X}, and AX = (A, a)a∈X is the obvious expansion of A to a model
for LX ; that is, all the elements of X become distinguished elements.
Proposition A.10 B is an elementary extension of A iff A ⊆ B and
(A, a)a∈A ≡ (B, a)a∈A .A Logical Toolkit
491
We can now state the version of the Löwenheim-Skolem Theorem that will be most
useful to us:
Theorem A.11 Let A be a model of cardinality α, and let the |L| ≤ β ≤ α,
where |L| is the number of non-logical symbols in the language. Then A has an
elementary submodel of cardinality β. Furthermore, given any set X ⊆ A of
cardinality ≤ β, A has an elementary submodel of cardinality β which contains
X.
Actually, in two respects this result is more general than we need. First, we nearly
always work with languages with at most countably many non-logical symbols.
Secondly, we will always be interested in forming countable submodels (that is,
we are interested in the case when β is ℵ0 ). But the other two generalizations will
be useful. First this form of the theorem guarantees that we can ﬁnd not merely
a submodel, but an elementary submodel. Second, we can select any (sufﬁciently
small) subset of the original model we ﬁnd interesting, and ﬁnd an elementary
submodel containing it.
Ultraproducts
This ultraproduct construction is an important tool for building new models out of
old. Roughly speaking, it tells us how we can multiply together a collection of
models to form a new model with the following property: any formula satisﬁed in
most of the original models is satisﬁed in the new model, and vice versa. Math-
ematically, the notion ‘most of’ is cashed out with the aid of ultraﬁlters. Readers
that are not familiar with this notion are advised to have a look at some of the
exercises in Section 2.5.
Deﬁnition A.12 (Filters and Ultraﬁlters) Let W be a non-empty set. A ﬁlter F
over W is a set F ⊆ P(W ) such that
(i) W ∈ F .
(ii) If X, Y ∈ F , then X ∩ Y ∈ F .
(iii) If X ∈ F and X ⊆ Z ⊆ W , then Z ∈ F .
Obviously P(W ) is itself a ﬁlter. A ﬁlter is called proper if it is distinct from
P(W ). An ultraﬁlter over W is a proper ﬁlter U such that for all X ∈ P(W ),
X ∈ U if and only if (W \ X) ∈
/ U.
A non-trivial example of a ﬁlter is the collection of all co-ﬁnite subsets of an inﬁnite
set. (A subset of an inﬁnite set is co-ﬁnite if its complement is ﬁnite.) A large
supply of ﬁlters is provided by the following deﬁnition.A A Logical Toolkit
492
Deﬁnition A.13 Let W be a non-empty set, and let E be a subset of P(W ). By
the ﬁlter generated by E we mean the intersection F of the collection of all ﬁlters
over W which include E:

F = {G | E ⊆ G and G is a ﬁlter over W }.
E has the ﬁnite intersection property if the intersection of any ﬁnite number of
elements of E is non-empty.
We have deﬁned ultraﬁlters as a special kind of ﬁlters, satisfying an additional
property. An alternative deﬁnition states that ultraﬁlters are maximal proper ﬁlters;
that is, a ﬁlter is an ultraﬁlter if and only if it is proper but has no proper extensions.
In many cases where we need to prove the existence of an ultraﬁlter containing a
certain collection of sets, we apply the Ultraﬁlter Theorem.
Fact A.14 (Ultraﬁlter Theorem) Fix a non-empty set W . Any proper ﬁlter over
W can be extended to an ultraﬁlter over W . As a corollary, any subset of P(W )
with the ﬁnite intersection property can be extended to an ultraﬁlter over W .
A special role is often played by the so-called principal ultraﬁlters.
Deﬁnition A.15 Let W be a non-empty set. Given an element w ∈ W , the prin-
cipal ultraﬁlter πw generated by w is the ﬁlter generated by the singleton set {w}.
An equivalent deﬁnition would be to put πw = {X ⊆ W | w ∈ X}.
Are such sets really ultraﬁlters? Yes – see Exercise 2.5.2.
We are ready to introduce the ultraproduct construction. We ﬁrst apply the con-
struction to sets, and then to models. Suppose that U is an ultraﬁlter over a non-

empty set I, and that for each i ∈ I, Ai is a non-empty set. Let C = i∈I Ai
be the cartesian product of those sets. That is: C is the set of all functions f with
domain I such that for each i ∈ I, f (i) ∈ Ai . For two functions f , g ∈ C we say
that f and g are U -equivalent (notation f ∼U g) if {i ∈ I | f (i) = g(i)} ∈ U .
Proposition A.16 The relation ∼U is an equivalence relation on the set C.
Deﬁnition A.17 Let fU be the equivalence class of f modulo ∼U , that is: fU =
{g ∈ C | g ∼U f }. The ultraproduct of the sets Ai modulo U is the set of all

equivalence classes of ∼U . It is denoted by U Ai . So

U Ai = {fU | f ∈

i∈I Ai }.
Let us now apply the same idea to models:
Deﬁnition A.18 Fix a ﬁrst-order language L1 , and let Ai (i ∈ I) be L1 -models.

The ultraproduct U Ai of Ai modulo U is the model described as follows:A Logical Toolkit

493

(i) The universe AU of U Ai is the set U Ai , where Ai is the universe of
Ai .
(ii) Let R be an n-place relation symbol, and Ri its interpretation in the model

Ai . The relation RU in U Ai is given by
RU fU1 . . . fUn iff {i ∈ I | Ri f 1 (i) . . . f n (i)} ∈ U.
(iii) Let F be an n-place function symbol, and Fi its interpretation in Ai . The

function FU in U Ai is given by
FU (fU1 , . . . , fUn ) = {(i, Fi (f 1 (i), . . . , f n (i))) | i ∈ I}U .
(iv) Let c be a constant, and ai its interpretation in Ai . Then c is interpreted by

the element c ∈ U Ai where c = {(i, ai ) | i ∈ I}U .
In the case where all the structures are the same, say, Ai = A for all i, we speak of

the ultrapower of A modulo U , notation: U A.
To show that the above deﬁnition is coherent, we should check that the above
clauses depend only on the equivalence classes fU1 , . . . , fUn+1 . We leave this to
the reader and go straight to the fundamental result.
Theorem A.19 (Łoś’s Theorem) Let U be an ultraﬁlter over a non-empty set I.
For each i ∈ I, let Ai be a model.

(i) For every term t(x1 , . . . , xn ) and all elements fU1 , . . . , fUn of B = U Ai
we have
tB[x1 → fU1 , . . . , xn → fUn ] = {(i, tAi [f 1 (i), . . . , f n (i)]) | i ∈ I}U .
(ii) Given any ﬁrst-order formula α(x1 , . . . , xn ) in L1τ and fU1 , . . . , fUn in

U Ai we have

1
n
U Ai |= α[fU , . . . , fU ] iff
(A.1)
{i ∈ I | Ai |= α[f 1 (i), . . . , f n (i)]} ∈ U.
Proof. We leave item (i) to the reader. To prove item (ii) we argue by induction
on α. The atomic case holds by deﬁnition. Suppose that α ≡ ¬β(x1 , . . . , xn ) and
(A.1) holds for β(x1 , . . . , xn ). Then


1
n
1
n
U Ai |= α[fU . . . fU ] iff not
U Ai |= β[fU , . . . , fU ]
iff {i ∈ I | Ai |= β[fU1 , . . . , fUn ]} ∈
/U
iff {i ∈ I | Ai |= β[f 1 (i), . . . , f n (i)]} ∈ U
iff {i ∈ I | Ai |= α[f 1 (i), . . . , f n (i)]} ∈ U.
Here, the second equivalence follows from the inductive hypothesis, and the third
from the fact that U is an ultraﬁlter.494
A A Logical Toolkit
Next we have to prove that if β and γ satisfy (A.1), then so does β ∧ γ. This
uses the fact that ﬁlters are closed under intersections and supersets.
Finally, suppose that α(x1 , . . . , xn ) ≡ ∃x0 β(x0 , x1 , . . . , xn ) and that (A.1)
holds for β. Then the following are equivalent:


1
n
0
0 1
n
U Ai |= α[fU , . . . , fU ] iff for some fU ,
U Ai |= β[fU fU , . . . , fU ]
iff for some fU0 , {i ∈ I | Ai |= β[f 0 (i)f 1 (i), . . . , f n (i)]} ∈ U. (A.2)
As Ai |= β[f 0 (i), . . . , f n (i)] implies Ai |= α[f 1 (i), . . . , f n (i)], (A.2) implies
{i ∈ I | Ai |= α[f 1 (i), . . . , f n (i)]} ∈ U.

(A.3)
Conversely, if (A.3) holds, then we can easily select a function f0 in i∈I Ai ,
where Ai is the universe of Ai , such that (A.2) holds. So (A.2) is equivalent to
(A.3).

Corollary A.20 Let U A be an ultrapower of A. Then, for all ﬁrst-order sen-

tences α, A |= α iff U A |= α.
There is a natural embedding of a model A in each of its ultrapowers. Deﬁne the

diagonal mapping d of A into U A to be the function
a → (fa )U , where fa (i) = a, for all i ∈ I.

Corollary A.21 Let U A be an ultrapower of A. Then the diagonal mapping of

A into U A is an elementary embedding.
Proof. Let α(x1 , . . . , xn ) be a ﬁrst-order formula, and a1 , . . . , an elements of A.
By Theorem A.19 we have

U A |= α[d(a1 ), . . . , d(an )] iff {i ∈ I | A |= α[a1 , . . . , an ]} ∈ U
iff A |= α[a1 , . . . , an ].
The preceding results will be useful in our modal investigations. But ultraproducts
can also be employed to characterize the expressive power of ﬁrst-order languages,
and we will use this characterization on several occasions. First, we need to be
precise about what it means to deﬁne a class of models in a ﬁrst-order language.
Deﬁnition A.22 A class K of models for a ﬁxed ﬁrst-order language L1 is deﬁned
by a set Δ of L1 -sentences if every model for the language is in K iff it is a model
for Δ. A class of models is elementary if it is deﬁned by some set of ﬁrst-order
sentences.
Theorem A.23 A class of models K is deﬁnable by means of a set of ﬁrst-order
sentences iff it is closed under isomorphisms and ultraproducts, while its comple-
ment is closed under ultrapowers.A Logical Toolkit
495
Proof. See [91, Theorem 6.1.16]; a weaker version of the result states that K is
elementary iff it is closed under ultraproducts and elementary equivalence [91,
Theorem 4.1.12].
In Lemma 2.73 we made use of the following result: Let L be a countable ﬁrst-
order language, U a countably incomplete ultraﬁlter over a non-empty set I, and

M an L-model. The ultrapower U M is countably saturated. A proof of this
result can be found in [91, Theorem 6.1.1].
Extensions of First-Order Logic
We now brieﬂy review two important extensions of ﬁrst-order logic: second-order
logic and inﬁnitary logic.
In second-order logic quantiﬁcation is allowed not only over individuals, as in
ﬁrst-order logic, but also over sets of individuals. That is, we can write expressions
like
(well-orderedness) ∀X (∃y Xy → ∃y (Xy ∧ ¬∃z Xz ∧ z < y))
(induction)
∀X (X0 ∧ ∀n (Xn → X(n + 1)) → ∀n Xn)
Here the expression ∀X is a second-order quantiﬁer, and X is a variable over sets
of individuals. Second-order formulas are interpreted on the same models as ﬁrst-
order formulas are, and second-order quantiﬁers have the obvious meaning (for
example, ∀X means ‘for all subsets’).
The two formulas just given are relatively simple second-order formulas. For
a start, the only second-order quantiﬁers used are quantiﬁers over unary relations
(that is, subsets), thus these formulas are what is known as monadic second-order
formulas. Moreover, only universal quantiﬁers are used (indeed, in both examples
only one such quantiﬁer is used) and these stand right at the start of the formula,
thus these formulas are examples of universal second-order formulas. In Chap-
ter 3 we show that, when interpreted over frames, modal formulas are equivalent
to universal second-order formulas.
As these examples make clear, second-order logic (indeed, even the universal
monadic fragment of second-order logic) is far more expressive than ﬁrst-order
logic: neither well-orderedness nor induction is deﬁnable in ﬁrst-order logic. But
this increased expressive power comes at a price: many familiar results from ﬁrst-
order logic break down. For example, the validities of second-order logic are not
recursively enumerable, and the Compactness and Löwenheim-Skolem theorems
(A.3 and A.4) do not hold for second-order logic. However there is a method due
to Henkin [217] for ‘taming’ second-order logic. By working with a special class
of non-standard models (usually called generalized models or Henkin models), it
is possible to obtain a ﬁrst-order perspective on a useful fragment of second-order496
A A Logical Toolkit
logic, and to prove a natural completeness theorem for this fragment. Good dis-
cussions of the method can be found in Doets and van Benthem [112], Chapter 4
of Enderton [122], and Fitting [139]. The modal analog of the method – the use of
general frames – is discussed in detail in the text.
In inﬁnitary logic, we are allowed to form inﬁnitely long formulas. The inﬁnitary
logic Lω1 ω , for example, allows countably inﬁnite conjunctions and disjunctions
in addition to the usual ﬁrst-order repertoire. At ﬁrst glance, the idea of inﬁnitely
long formulas may seem bizarre – but in fact the the logic is a natural setting
for formalizing many computational issues. For example, ‘repeat the program α
ﬁnitely many times’ means the same as the inﬁnite disjunction
skip, or do α once, or do α twice, or do α three times, or . . . .
And likewise, the following inﬁnitary formula expresses that S is the reﬂexive,
transitive closure of R:

∀xy (Sxy ↔ i≥1 Ri xy),
where R0 xy := (x = y) and Rn+1 xy := ∃z (Rxz ∧ Rn zy). As we discuss in
Chapter 2, when interpreted on models, propositional dynamic logic is a fragment
of Lω1 ω .Appendix B
An Algebraic Toolkit
In this appendix we review some basic (universal) algebraic notions used in Chap-
ter 5. The ﬁrst part deals with algebras and operations on (classes of) algebras,
the second part is about algebraic model theory, and in the third part we discuss
equational logic. Birkhoff’s fundamental theorems are stated without proof.
For an introduction to universal algebra, see Burris and Sankappanavar [81] or
Grätzer [198]; McKenzie, McNulty and Taylor [321] provide more comprehensive
reading. Basic track readers may like the algebraic accounts of propositional logic
given in Chapter 3 of Bell and Machover [32] and Chapters 1 and 2 of Bell and
Slomson [33]. Many readers will ﬁnd Davey and Priestly [105] useful supplemen-
tary reading.
Universal Algebra
An algebra is a set together with a collection of functions over the set; these func-
tions are usually called operations. Algebras come in various similarity types,
determined by the number and arity of the operations.
Deﬁnition B.1 (Similarity Type) An algebraic similarity type is an ordered pair
F = (F, ρ) where F is a non-empty set and ρ is a function F → N. Elements
of F are called function symbols; the function ρ assigns to each operator f ∈ F a
ﬁnite arity or rank, indicating the number of arguments that f can be applied to.
Function symbols of rank zero are called constants. We will usually be sloppy in
our notation and terminology and write f ∈ F instead of f ∈ F .
Given a similarity type, it is obvious what an algebra of this type should be.
Deﬁnition B.2 (Algebras) Let A be some set, and n a natural number; an n-ary
operation on A is a function from An to A.
Let F be an algebraic similarity type. An algebra of type F is a pair A =
(A, I) where A is a non-empty set called the carrier of the algebra, and I is an
497498
B An Algebraic Toolkit
interpretation, a function assigning, for every n, an n-ary operation fA on A to
each function symbol f of rank n. We often use the notation A = (A, fA)f ∈F for
such an algebra. When no confusion is likely to arise, we omit the subscripts on
the operations.
We now deﬁne the standard constructions for forming new algebras from old. First
we deﬁne the natural notion of structure preserving maps between algebras.
Deﬁnition B.3 (Homomorphisms) Let A = (A, fA)f ∈F and B = (B, fB)f ∈F
be two algebras of the same similarity type. A map η : A → B is a homomorphism
if for all f ∈ F , and all a1 , . . . , an ∈ A (where n is the rank of f ):
η(fA(a1 , . . . , an )) = fB(ηa1 , . . . , ηan ).
(B.1)
(Here ηai is shorthand η(ai ).) The special case for constants c is
η(cA) = cB.
The kernel of a homomorphism f : A → B is the relation ker f = {(a, a ) ∈ A2 |
f (a) = f (a )}. We say that B is a homomorphic image of A (notation: A
B),
if there is a surjective homomorphism from A onto B. Given a class C of algebras,
HC is the class of homomorphic images of algebras in C.
Deﬁnition B.4 (Isomorphisms) A bijective homomorphism is called an isomor-
phism. We say that two algebras are isomorphic if there is an isomorphism between
them. Usually we do not distinguish isomorphic algebras, but if we do, we write
IC for the class of isomorphic copies of algebras in C.
The second way of making new algebras from old is to ﬁnd a small algebra inside
a larger one.
Deﬁnition B.5 (Subalgebras) Let A be an algebra, and B a subset of the carrier
A. If B is closed under every operation fA, then we call B = (B, fA B )f ∈F a
subalgebra of A. We say that C is embeddable in A (notation: C  A), if C is
isomorphic to a subalgebra of A; the isomorphism is called an embedding. Given
a class C of algebras, SC denotes the class of isomorphic copies of subalgebras of
algebras in C.
A third way of forming new algebras is to make a big algebra out of a collection of
small ones.
Deﬁnition B.6 (Products) Let (Aj )j∈J be a family of algebras. We deﬁne the

product j∈J Aj of this family as the algebra A = (A, fA)f ∈F where A is theAn Algebraic Toolkit
499

cartesian product j∈J Aj of the carriers Aj , and the operation fA is deﬁned co-

ordinatewise; that is, for elements a1 , . . . , an ∈ j∈J Aj , fA(a1 , . . . , an ) is the

element of j∈J Aj given by:
fA(a1 , . . . , an )(j) = fAj (a1 (j), . . . , an (j)).

When all the algebras Aj are the same, say A, then we call j∈J A a power of

A, and write AJ rather than j∈J A. Given a class C of algebras, PC denotes the
class of isomorphic copies of products of algebras in C.
Suppose you are working with a class of algebras from which you cannot obtain
new algebras by the three operations deﬁned above. Intuitively, such a class is
‘complete’, for it is closed under the natural algebra-forming operations. Such
classes play an important role in universal algebra. They are called varieties:
Deﬁnition B.7 (Varieties) A class of algebras is called a variety if it is closed
under taking subalgebras, homomorphic images, and products. Given a class C
of algebras, VC denotes the variety generated by C; that is, the smallest variety
containing C.
A well-known result in universal algebra states that VC = HSPC. That is, in order
to obtain the variety generated by C, you can start by taking products of algebras
in C, then go on to take subalgebras, and ﬁnish off by forming homomorphic im-
ages. You do not need to do anything else: subsequent applications of any of these
operations will not produce anything new.
Homomorphisms and Congruences
Homomorphisms on an algebra A are closely related to special equivalence rela-
tions on the carrier of A.
Deﬁnition B.8 (Congruences) Let A be an algebra for the similarity type F. An
equivalence relation ∼ on A (that is, a reﬂexive, symmetric and transitive relation)
is a congruence if it satisﬁes, for all f ∈ F
if a1 ∼ b1 & . . . & an ∼ bn , then fA(a1 , . . . , an ) ∼ fA(b1 , . . . , bn ),
(B.2)
where n is the rank of f .
The standard examples of congruences are the ‘modulo’ relations on the integers.
Consider the algebra Z = (Z, +, ∗, 0, 1) of the integers under addition and multi-
plication, and, for a positive integer n, let the relation ≡n be deﬁned by z ≡n z 
if n divides z − z . We leave it to the reader to verify that these relations are all
congruences.500
B An Algebraic Toolkit
The importance of congruences is that they are precisely the kind of equivalence
relations that allow a natural algebraic structure to be deﬁned on the collection of
equivalence classes.
Deﬁnition B.9 (Quotient Algebras) Let A be an F-algebra, and ∼ a congruence
on A. The quotient algebra of A by ∼ is the algebra A/∼ whose carrier is the set
A/∼ = {[a] | a ∈ A}
of equivalence classes of A under ∼, and whose operations are deﬁned by
fA/∼ ([a1 ], . . . , [an ]) = [fA(a1 , . . . , an )].
(This is well-deﬁned by (B.2).) The function ν taking an element a ∈ A to its
equivalence class [a] is called the natural map associated with the congruence.
As an example, taking the quotient of Z under the relation ≡n makes the algebra
Zn of arithmetic modulo n.
The close connection between homomorphisms and congruences is given by the
following proposition (the proof of which we leave to the reader).
Proposition B.10 (Homomorphisms and Congruences) Let A be an F-algebra.
Then
(i) If f : A → B is a homomorphism, its kernel is a congruence on A.
(ii) Conversely, if ∼ is a congruence on A, its associated natural map is a
surjective homomorphism from A onto A/∼.
Algebraic Model Theory
Universal algebra can be seen as a branch of model theory in which one is only
interested in structures where all relations are functions. The standard language
for talking about such structures is equational, where an equation is a statement
asserting that two terms denote the same element.
Deﬁnition B.11 (Terms and Equations) Given an algebraic similarity type F and
a set X of elements called variables, we deﬁne the set TerF (X) of F-terms over
X inductively: it is the smallest set T containing all constants and all variables in
X such that f (t1 , . . . , tn ) is in T whenever t1 , . . . , tn are in T and f is a function
symbol of rank n.
An equation is a pair of terms (s, t); the notation s ≈ t is usually used.
Having deﬁned the algebraic language, we now consider the way it is interpreted
in algebras. Obviously terms refer to elements of algebras, but in order to calculate
the meaning of a term we need to know what the variables in the term stand for.
This information is provided by an assignment.An Algebraic Toolkit
501
Deﬁnition B.12 (Algebraic Semantics) Let F be an algebraic similarity type, X a
set of variables, and A an F-algebra. An assignment on A is a function θ : X → A
associating an element of A with each variable in X. Given such an assignment θ,
we can calculate the meaning θ̃(t) of a term t in Ter F (X) as follows:
θ̃(x) = θ(x),
θ̃(c) = cA,
θ̃(f (t1 , . . . , tn )) = fA(θ̃(t1 ), . . . , θ̃(tn )).
The last equality bears an obvious resemblance to the condition (B.1) deﬁning
homomorphisms. In fact, we can turn the meaning function into a genuine homo-
morphism by imposing a natural algebraic structure on the set TerF (X) of terms:
Deﬁnition B.13 (Term Algebras) Let F be an algebraic similarity type, and X
a set of variables. The term algebra of F over X is the algebra TerF (X) =
(Ter F (X), I) where every function symbol f is interpreted as the operation I(f )
on Ter F (X) given by
I(f )(t1 , . . . , tn ) = f (t1 , . . . , tn ).
(B.3)
In other words, the carrier of the term algebra over F is the set of F-terms over the
set of variables X, and the operation I(f ) or fTer F (X) maps an n-tuple t1 , . . . , tn
of terms to the term f (t1 , . . . , tn ). Note the double role of f in (B.3): on the right-
hand side, f denotes a ‘static’ part of the syntactic term f (t1 , . . . , tn ), while on
the left-hand side I(f ) denotes a ‘dynamic’ interpretation of f as an operation on
terms.
The perspective on F-terms as constituting an F-algebra is extremely useful.
For example, we can view the operation of substituting terms for variables in terms
as an endomorphism on the term algebra, that is, a homomorphism from an algebra
to itself.
Deﬁnition B.14 Let F be a similarity type, and X a set of variables. A substitution
is a map σ : X → Ter F (X) mapping variables to terms. Such a substitution can
be extended to a map σ̃ : Ter F (X) → Ter F (X) by the following inductive
deﬁnition:
σ̃(x) := σ(x),
σ̃(f (t1 , . . . , tn )) := f (σ̃(t1 ), . . . , σ̃(tn )).
We sometimes use the word ‘substitution’ for a function mapping terms to terms
that satisﬁes the second of the conditions above (that is, we sometimes call σ̃ a
substitution).502
B An Algebraic Toolkit
Proposition B.15 Let σ : Ter F (X) → Ter F (X) be a substitution. Then σ :
TerF (X) → TerF (X) is a homomorphism.
Moreover, the meaning function associated with an assignment θ is now a homo-
morphism:
Proposition B.16 Given any assignment θ of variables X to elements of an alge-
bra A, the corresponding meaning function θ̃ is a homomorphism from TerF (X)
to A.
The standard way of making statements about algebras is to compare the meaning
of two terms under the same valuation – that is, to use equations.
Deﬁnition B.17 (Truth and Validity) An equation s ≈ t is true or holds in an
algebra A (notation: A |= s ≈ t), if for all assignments θ, θ̃(s) = θ̃(t).
A set E of equations holds in an algebra A (notation: A |= E), if each equation
in E holds in A. If A |= s ≈ t or A |= E we will also say that A is a model for
s ≈ t, or for E, respectively.
An equation s ≈ t is a semantic consequence of a set E of equations (notation:
E |= s ≈ t), if every model for E is a model for s ≈ t.
Algebraists are often interested in speciﬁc classes of algebras such as groups and
boolean algebras. Such classes are usually deﬁned by sets of equations.
Deﬁnition B.18 (Equational Class) A class C of algebras is equationally deﬁn-
able, or an equational class, if there is a set E of equations such that C contains
precisely the models for E.
The following theorem, due to Birkhoff, is one of the most fundamental results of
universal algebra:
Theorem B.19 (Birkhoff) A class of algebras is equationally deﬁnable if and only
if it is a variety.
Unfortunately, we do not have the space to prove this theorem here. The reader
is advised to try proving the easy direction (that is, to show that any equationally
deﬁnable class is closed under taking homomorphic images, subalgebras and direct
products) for him- or herself.
Equational Logic
Equational logic arises when we formalize the rules that enable us to deduce new
equations from old. Although we do not make direct use of equational logic in the
text, it will be helpful if the reader is acquainted with it. Here is a fairly standard
system.An Algebraic Toolkit
503
Deﬁnition B.20 (Equational Logic) Let F be an algebraic similarity type, and E
a set of equations. The set of equations that are derivable from E is inductively
deﬁned by the following schema:
The equations in E are derivable from E; they are called axioms.
Every equation t ≈ t is derivable from E.
If t1 ≈ t2 is derivable from E, then so is t2 ≈ t1 .
If the equations t1 ≈ t2 and t2 ≈ t3 are derivable from E, then so is
t1 ≈ t3 .
(congruence) Suppose that all equations t1 ≈ u1 , . . . , tn ≈ un are derivable from
E, and that f is a function symbol of rank n. Then the equation
f (t1 , . . . , tn ) ≈ f (u1 , . . . , un ) is derivable from E as well. This
schema is sometimes called replacement.
(substitution) If t1 ≈ t2 is derivable from E, then so is the equation σt1 ≈ σt2 ,
for every substitution σ.
(axioms)
(reﬂexivity)
(symmetry)
(transitivity)
The notation E  t1 ≈ t2 means that the equation t1 ≈ t2 is derivable from E.
A derivation is a list of equations such that every element is either an axiom, or
has the form t ≈ t, or can be obtained from earlier elements of the list using the
symmetry, transitivity, congruence/replacement, or substitution rules.
A fundamental completeness result, also due to Birkhoff, links this deductive ap-
paratus to the semantic consequence relation deﬁned earlier.
Theorem B.21 Let E be a set of equations for the algebraic similarity type F.
Then for all equations s ≈ t, E |= s ≈ t iff E  s ≈ t.Appendix C
A Computational Toolkit
In this appendix we introduce the basic ideas of computability theory (the study
of which problems are, and which problems are not, computationally solvable),
and provide some background information on complexity theory (the study of the
computational resources required to solve problems).
For detailed discussions of computability, see Rogers [391] or Odifreddi [343].
For accessible introductions to the subject, see Boolos and Jeffrey [70], or Cut-
land [103]. But the single most useful source is probably the (second edition of)
Lewis and Papadimitriou [301]; this introduces computability theory, and then goes
on to treat computational complexity. For more on computational complexity, try
Garey and Johnson [163] and Papadimitriou [352]. Garey and Johnson’s book is a
source for information on NP-complete problems, but it discusses the basic ideas
of computational complexity lucidly, and gives background information on other
complexity classes. Papadimitriou’s book is a well-written introduction to compu-
tational complexity covering far more than is needed to understand Chapter 6; if
you want to go deeper into computational complexity, it is a good place to start.
Computability and Uncomputability
To prove theorems about computability – and in particular to prove that some prob-
lem is not computable – we need a robust mathematical model of computability.
One of the most widely used models is the Turing machine. A Turing machine
is a device which manipulates symbols written on a tape. The symbols are taken
from some alphabet ﬁxed in advance (often the alphabet simply consists of the two
symbols 0 and 1). The tape is subdivided into squares, and only one symbol can be
written on each square (squares containing no symbols are called blank). The tape
is used to receive input, to present output, and acts as working memory. The tape
is assumed to be inﬁnitely long in both directions (so no ﬁnite upper bound on the
amount of working memory is assumed).
Turing machines scan the squares of such tapes and act on the information they
504A Computational Toolkit
505
see; they can only scan one square at a time. A Turing machine has a ﬁnite number
of internal states, and a ﬁnite number of rules which tell it what to do when it is
in a certain state scanning a certain symbol. Turing machines can perform three
basic actions: (1) move to the square immediately to the left of the square they are
currently scanning, (2) move to the square immediately to the right of the square
they are currently scanning, or (3) write a symbol (from the alphabet) on the square
currently being scanned (thereby overwriting any symbol already written on that
square). In addition to specifying which of these three actions will be performed,
the rules also specify which internal state the Turing machine is to move into on
completing the action. A Turing machine halts when (and if) it enters a special
halting state. For some simple (and not so simple) examples of computations on
Turing machines, see Chapter 4 of Lewis and Papadimitriou [301] and Chapters 1–
3 of Boolos and Jeffrey [70].
The ideas just sketched can be made precise as follows:
Deﬁnition C.1 (Turing Machines) A Turing machine is a 5-tuple (S, s, H, Σ, δ)
where S is a ﬁnite set of states, s ∈ S is the initial state, H ⊆ S is the set of
halting states, Σ (the alphabet) is a ﬁnite set of symbols, and δ is a function from
(S \ H) × Σ to S × (Σ ∪ {left, right}).
For example, the rule if you are in state 57 scanning the symbol 1, move one square
to the left and go into state 14 amounts to saying that δ(57, 1) = (14, left). The
rule if you are in state 30 scanning the symbol %, write the symbol 5 and go into
state 12 means that δ(30, %) = (12, 5). Since δ is a function, the action of such
a machine is deterministic: when the machine is put in the initial state scanning
some tape, what it does (if it does anything) is ﬁxed.
Let f be a function, and suppose we have ﬁxed some convention about how
the elements of the domain and range of the function are to be represented. (For
example, if f is a function from the natural numbers to the natural numbers, we
might decide to use binary notation – that is, base 2 notation – to represent the
numbers). Then f is computable (or recursive) if there is a Turing machine that
when given (the representation of) an item x in the domain of f will halt after
ﬁnitely many steps, leaving on an otherwise blank tape (the representation of) f (x).
We can use Turing machines to provide yes/no answers to problems. Many
logical problems – for example, is some formula φ satisﬁable or not – are of this
type. Suppose we have ﬁxed the alphabet of a Turing machine, and have decided
how we are going to represent the problems we are interested in (in Section 6.1,
we discuss how to encode modal formulas and models as strings of 0s and 1s).
Given our encoding conventions, some strings over the alphabet represent problem
instances for which the answer is yes, while others represent problem instances for
which the answer is no. A problem is computable (or recursive, or decidable) if506
C A Computational Toolkit
there is a Turing machine which when given (the representation of) any instance
of the problem, halts after ﬁnitely many steps leaving the (representation of) the
correct answer on an otherwise blank tape.
Turing machines essentially provide answers to set membership problems: a
yes answer means that the input belongs to a set of interest (for example, the set
of satisﬁable formulas) while a no means it does not. Thus it is common to talk
of computable (or recursive, or decidable) sets. Another important notion is that
of a recursively enumerable set. A set is recursively enumerable (r.e.) if there is
a Turing machine which successively writes, on an otherwise blank tape, all and
only the members of the set. If the set is inﬁnite, this listing process will never
ﬁnish – but after some ﬁnite time, any given element of an r.e. set will eventually
be listed.
All recursive sets are r.e., but there are r.e. sets that are not recursive. The
best known example is the set of valid ﬁrst-order formulas (in a sufﬁciently rich
language). This set is not recursive, but (as we mentioned in Appendix A) it is
recursively enumerable. Details for the following result may be found in Lewis
and Papadimitriou [301, pp. 198–200, 267–273])
Proposition C.2 A set is recursive iff both it and its complement are recursively
enumerable
Thus, from a computational perspective, the set of ﬁrst-order formulas that are
not valid is more complex than the set of valid formulas – the non-valid formulas
cannot even be recursively enumerated.
It is common practice to identify problems with the set of those strings of sym-
bols that provide the answer yes to the problem. For once an alphabet has been
ﬁxed, each subset of the set of all ﬁnite strings over the alphabet can be regarded
as the encoding of the problem. This abstract perspective is a convenient way of
stating abstract computability and complexity results, and we adopt it later in this
appendix; but in the text, when we apply these ideas to modal logic, we try to keep
our statement of problems fairly concrete.
Because of its simplicity, the Turing machine model is widely used in theoretical
computer science, particularly in complexity theory. But it is not a toy model
of computation: experience has shown that it is remarkably robust and general.
For example, we can allow Turing machines to have special read-only input tapes,
special write-only output tapes, and allow them to access several working tapes
independently – but none of these variations allows new functions to be computed
or new problems solved. Moreover, we can move away from the Turing machine
model in many different ways: for example, we can use Random Access Memory
machines which model more directly the workings of a physical computer. Such
variations make no difference: if a function is computable (or a problem decidable)A Computational Toolkit
507
in one of these alternative models then it is also computable (decidable) on some
Turing machine.
Another important variation is the use of non-deterministic Turing machines.
The action of such a machine is not ﬁxed by the symbol it is scanning and the state
it is in: for any such combination, it may have a (ﬁnite) range of options. (Formally,
we drop the requirement that the δ of Deﬁnition C.1 be a function and let it be an
arbitrary relation.) We think of such a machine as following all the options allowed
by δ simultaneously, and say that such a machine solves a problem if at least one
such computation path halts leaving the correct answer on an otherwise blank tape.
The beauty of non-determinism is that it factors out search. Many problems re-
quire us to ﬁnd a candidate solution and then see if it works, and if not, to look for
another candidate, and so on. This process may be the major computational over-
head. Non-deterministic machines abstract away from this: if there is a solution,
a non-deterministic machine can ﬁnd it far more efﬁciently (we will see a classic
example of this when we discuss complexity theory). But as far as computability
is concerned, non-determinism adds nothing: if a function (or problem) is com-
putable using a non-deterministic Turing machine, it is also computable using a
deterministic Turing machine, for we can (laboriously) work through all possible
choices.
Such observations give rise to Church’s thesis.
Thesis C.3 (Church’s Thesis) A function is computable (a problem decidable)
precisely when it can be computed (solved) using a Turing machine.
On the face of it, Church’s Thesis just stipulates that the notion of computation
deﬁned by Turing machines is so robust that it makes sense to think of it as pinning
down what we mean by computation. But its import is far wider: in essence it is
an acknowledgment of the fact that all the general ﬁnitary models of computation
that have been proposed (and there are probably several hundreds of these) have
turned out to be equivalent. That is, Church’s Thesis afﬁrms that we do have a
robust model of computation.
You may view Church’s Thesis as saying that computable functions and prob-
lems are those which can be calculated/solved by writing a program in your favorite
programming language when no limitations are placed on memory or execution
time. In fact, in Chapter 6 we rarely talk explicitly of Turing machines: rather, we
prove that problems are decidable by analyzing them till it becomes clear that any
competent programmer could write a program that carries out the task.
The most important beneﬁt of having a robust deﬁnition of computability is that
it gives us a way of proving that some function or problem is undecidable. And
many – indeed most – functions and problems are undecidable. For let M be a
set of natural numbers. Is each such M decidable? A simple cardinality argument508
C A Computational Toolkit
shows that the answer is no. Every Turing machine is a ﬁnite function over a
ﬁnite set of states and a ﬁnite alphabet. It follows that there are only countably
many Turing machines – but there are uncountably many M , so they cannot all be
computable. It is not difﬁcult to construct concrete examples of functions which
no Turing machine can compute (see Lewis and Papadimitriou [301, Chapter 5],
and Boolos and Jeffrey [70, Chapters 4, 5]).
But again, to prove undecidability it is not necessary to appeal to the deﬁnition
of a Turing machine. It is usually easier to show problems are undecidable via
reductions:
Deﬁnition C.4 Let Σ be an alphabet and let L1 , L2 ⊆ Σ ∗ be problems (note that
we are adopting the abstract view of problems here). A reduction from L1 to L2 is
a computable function f : Σ∗ → Σ ∗ such that s ∈ L1 iff f (s) ∈ L2 ; here, Σ ∗ is
simply the set of all ﬁnite strings over Σ.
Proposition C.5 Let L1 , L2 ⊆ Σ ∗ be problems, and f be a reduction from L1 to
L2 . If L1 is undecidable, then so is L2 .
Proof. Easily established using a proof by contradiction, and the reader may like
to try. You can ﬁnd a detailed account on pages 254–258 of the second edition of
Lewis and Papadimitriou [301].
Nowadays a vast range of problems are known to be undecidable, and we can try
to prove undecidability results by reduction from any one of these problems. We
follow this strategy in Chapter 6.
One ﬁnal remark: not all undecidable problems are alike. There is a precise
sense in which some are worse than others. The key idea is to equip Turing ma-
chines with oracles. A Turing machine equipped with an oracle is allowed to tem-
porarily halt in the middle of some computation, consult the oracle, and proceed
with its computation taking the oracle’s answer into account.
Oracles provide answers to undecidable problems (an oracle that provided an-
swers to decidable problems would offer nothing new: it could always be replaced
by a Turing machine). They are a mathematical abstraction which allow us to
remove the limitation to ﬁnitary computation inherent in Church’s thesis. It is
common to specify what oracles can do in logical terms – for example, we might
imagine we have a Turing machine hooked to an oracle that is able to determine
whether an arbitrary second-order sentence has a model or not. It turns out that
undecidable problems are not all the same: when we measure their difﬁculty with
respect to the oracles required to solve them, there is a whole hierarchy of difﬁ-
culty. A problem that is not merely undecidable, but requires the help of some
such oracle to solve it, is called highly undecidable. In Section 6.5 we show that
a certain modal satisﬁability problem is highly undecidable, and in fact, Σ11 -hard.A Computational Toolkit
509
Roughly speaking, this means that the problem is as difﬁcult as deciding whether
a prenex formula in the second-order language of arithmetic, that begins with a
block of existential quantiﬁers, is satisﬁable on the natural numbers. Such formulas
have immense expressive power, and Σ11 problems are highly complex (certainly
not recursively enumerable). Incidentally, ‘ordinary’ undecidable problems are of-
ten said to be Π10 -hard, and we use this terminology in Section 6.5 too. Roughly
speaking, this means that such problems are ‘only’ as difﬁcult as deciding whether
a prenex formula (with what is known as a recursive matrix) in the ﬁrst-order lan-
guage of arithmetic, and with a quantiﬁer preﬁx consisting of universal quantiﬁers
only, is satisﬁable on the natural numbers. Although such problems are undecid-
able, they are recursively enumerable. For more on highly undecidable problems,
see Harel [208]. For precise deﬁnitions and further discussion of the classes Σ11
and Π10 , see Odifreddi [343].
Complexity Theory
Complexity theory studies the computational resources required to solve (decid-
able) problems. The two main resources studied are time (the number of com-
putation steps required) and space (the amount of memory required). Both time
required and space required are measured as functions of the length of the input.
Ideally, complexity theory would give us a precise bound on the resources re-
quired to solve any problem that interested us. But this goal is far too ambitious.
Instead, complexity theory classiﬁes problems into various classes. In this book
we mention the classes
P ⊆ NP ⊆ PSPACE ⊆ EXPTIME ⊆ NEXPTIME
(C.1)
and we devote a lot of attention to NP, PSPACE, and EXPTIME.
Before deﬁning these classes, some general remarks. It is currently unknown
whether the inclusions in (C.1) are strict or not. It is widely conjectured that they
are, but nobody has been able to prove (or disprove) any of these strict inclusions.
All we know for sure is that P = EXPTIME.
Second, although a problem that belongs to any of these classes is decidable, P
(the class at the bottom of this putative hierarchy) is widely taken to be the class of
problems that are tractable, or efﬁciently solvable.
Deﬁnition C.6 A deterministic Turing machine is polynomially time bounded if
there is a polynomial p(n) such that the machine always halts after at most p(n)
steps, where n is the length of the input. A problem is solvable in polynomial time
(a function f is solvable in polynomial time) if there is a polynomially bounded
Turing machine that solves it (that computes it). The class of all problems solvable
in polynomial time is called P. A problem is called tractable if it belongs to P.510
C A Computational Toolkit
One word of warning. When we solve a problem on a Turing machine, we choose
a way of representing the problem (that is, encoding it in the symbols used by that
machine). Needless to say, there are sensible ways of representing problems, and
highly inefﬁcient ways of doing so. If a sufﬁciently bad representation is chosen,
this can give a completely misleading impression of the resources required to solve
the problem. For example, a really bad representation could ensure that a problem
solvable in polynomial time takes exponential time to compute.
Fortunately, for the complexity classes considered in this book, there is little to
worry about. The main pitfall to be avoided concerns the representation of num-
bers: unary representations should be avoided as they are exponentially longer than
binary (or higher base) representations. In the text, we assume we are working with
binary representations of numbers. We discuss the representation of modal logical
problems in Section 6.1.
Identifying tractable problems with those in P is not unproblematic, but it has
proved useful. For a start, if a problem is solvable in polynomial time, then typ-
ically the polynomial is of low degree. Moreover, if a problem is not solvable in
polynomial time, then (some instances of it) will be very hard to solve indeed. For
example, if a problem requires resources exponential in the length of the input (for
example, 2n , where n is the length of the input), then no algorithm is going to solve
all instances of the problem efﬁciently: on some input, even for quite small values
of n, the computation will not halt within the expected lifetime of the universe.
Hardness and completeness
In order to deﬁne the complexity classes of interest, we need some additional con-
cepts. We have already met the idea of reducing one problem to another (see Def-
inition C.4). To make further progress, we need the notion of tractably reducing
one problem to another. As we have identiﬁed ‘tractable’ with ‘computable in
polynomial time’, the following notion is what we require.
Deﬁnition C.7 (Polytime Reduction) Let L1 , L2 ⊆ Σ ∗ be problems. A polyno-
mial time computable function f : Σ∗ → Σ ∗ is called a polynomial time reduction
(or: a polytime reduction) from L1 to L2 if for each s ∈ Σ∗ we have that s ∈ L1
iff f (s) ∈ L2 .
A polytime reduction from L1 to L2 is essentially a tractable way of compiling
problem L1 down to problem L2 . It follows that if L2 is solvable in polynomial
time (that is, if L2 is tractable), then so is L1 : to test whether a string x is in L1 ,
simply compute f (x) (this compilation step is polynomial time computable) and
then test whether f (x) ∈ L2 (which by assumption is polynomial time solvable).
As x ∈ L1 iff f (x) ∈ L2 , and as the composition of two polynomials is a poly-
nomial, we have efﬁciently computed an answer to our original problem. On theA Computational Toolkit
511
other hand, if L1 is not solvable in polynomial time, then neither is L2 , as the
reader should verify. Summing up: if there is a polytime reduction from L1 to L2 ,
then L2 is at least as hard as L1 , and this observation leads us to the following
fundamental deﬁnition:
Deﬁnition C.8 (Hardness and Completeness) Let C be a class of problems. A
problem L is C-hard (with respect to polynomial time reductions) if every problem
in C is polynomial time reducible to L; L is C-complete if it is C-hard and moreover
L ∈ C. That is, the C-complete problems are the hardest problems in C.
The class P
This fundamental class does not play a direct role in the book, for it is widely be-
lieved that the problem of deciding whether a formula of classical propositional
logic is satisﬁable is not in P. (No proof of this is known – it is one of the best-
known open problems in theoretical computer science.) As the modal logics dis-
cussed in this book contain classical propositional logic as a subpart, their satisﬁa-
bility problems probably do not lie in P either.
The class NP
There are many naturally occurring problems which do not seem to belong to P but
which can be solved efﬁciently using a non-deterministic Turing machine.
Deﬁnition C.9 A non-deterministic Turing machine is polynomially time bounded
if there is a polynomial p(n) such that no computation of the machine continues
for more than p(n) steps where n is the length of the input. NP is the class of all
problems decided by a polynomially bounded non-deterministic machine.
The problems that seem not to be in P but which are in NP typically involve search.
The classic example is the satisﬁability problem for propositional logic: given a
propositional formula φ, is there an assignment of truth values (0 and 1) to its
proposition letters that makes the formula evaluate to 1? No deterministic poly-
nomial time algorithm for propositional satisﬁability is known, and it is widely
believed that none exists.
But it is easy to design an NP algorithm to solve propositional satisﬁability.
When it is given as input the formula φ, the ﬁrst step of the algorithm is to non-
deterministically try out all possible combinations of truth values on the proposi-
tional variables in φ. If there is a solution, this is returned; if not, an arbitrary truth
value assignment is returned instead. Either way, after one (non-deterministic) step
we are given an assignment. We can then deterministically compute in polynomial
time whether this assignment satisﬁes φ or not (all we have to do is perform one512
C A Computational Toolkit
operation for each logical connective in φ). If φ evaluates to true, φ is satisﬁable.
On the other hand, if φ evaluates to false, it must be unsatisﬁable, for the non-
deterministic step would have returned a satisfying assignment had one existed.
Does this mean that propositional satisﬁability is really an easy problem to
solve? Unfortunately, no. The only known way of implementing non-determinism
is to simulate it on a deterministic Turing machine. All known simulations require
exponential time to perform, and it is widely believed (though not proved) that no
efﬁcient simulation exists. Non-deterministic Turing machines are probably not a
realistic model of efﬁcient computation.
But non-determinism has proved to be a very useful way of thinking about prob-
lems consisting of a search for a solution, followed by a veriﬁcation step that can be
conducted in deterministic polynomial time. An extraordinary range of interesting
problems have this general proﬁle (see Garey and Johnson [163] for an extensive
list), and by reducing the search to a single non-deterministic step, we see that such
problems belong to NP.
Now for a more demanding question: are there any NP-hard problems? The
celebrated Cook-Levine Theorem tells us that there are.
Theorem C.10 (Cook-Levine Theorem) The propositional satisﬁability problem
is NP-complete.
Proof. We have just given an informal argument showing that the propositional
satisﬁability problem is in NP. As for NP-hardness, we need to show (in accordance
with Deﬁnition C.8) that any problem in NP whatsoever can be polytime reduced
to the propositional satisﬁability problem. It may seem that we do not have enough
information to prove something this general – but amazingly, we do. An elegant
proof is given by Lewis and Papadimitriou [301, pp. 309–317].
Once we have shown that one problem is NP-complete, it becomes much easier to
show that other problems are NP-complete. Given a problem L which we suspect
to be NP-complete, all we have to do is (i) show that it is in NP, and (ii) show
that some problem known to be NP-hard is polynomial time reducible to L. In this
book, showing point (ii) is trivial: all the logics we are interested in extend classical
propositional logic, so NP-hardness is immediate by the Cook-Levine Theorem.
The classes NP and coNP (that is, the class of problems whose complements
are in NP) seem to have very different complexity proﬁles. A classic problem in
coNP is the validity problem for propositional calculus – the problem of deciding
whether all assignments of truth values satisfy a propositional formula. The va-
lidity problem is widely believed not to be in P. However, (unlike the satisﬁability
problem) it does not seem to belong to NP either: because we need to consider all
possible truth assignments, non-determinism does not seem to help us solve it. ButA Computational Toolkit
513
we face another open problem here: although it is standardly conjectured that NP
= coNP, no-one has been able to prove or disprove it.
The class PSPACE
PSPACE is the complexity class of most relevance to modal logic. It is deﬁned in
terms of deterministic Turing machines.
Deﬁnition C.11 A deterministic Turing machine is polynomially space bounded
if there is a polynomial p(n) such that no computation of the machine scans more
than p(n) tape squares, where n is the length of the input. PSPACE is the class
of all problems that are decided by a polynomially space bounded deterministic
Turing machine.
Proposition C.12 NP ⊆ PSPACE.
Proof. This is a special case of a more general result: see Papadimitriou [352,
Theorem 7.4(b)].
What is the intuition behind this theorem? As we have remarked, a determinis-
tic Turing machine can simulate a non-deterministic Turing machine, though it is
widely believed that the simulation will in general run exponentially slower than
the non-deterministic machine. Proposition C.12 tells us for any problem in NP, it
is always possible to carry out the simulation in such a way that there is no blow-
up in space requirements. Roughly speaking, we work systematically through the
search space, with the search for each item taking only polynomial space. When it
is time to search for the next item, we reuse the same squares. There is a bookkeep-
ing overhead (we need to keep track of where we are in the search space) but (with
careful management) this can be done using a relatively small number of squares.
So while the simulation may take a long time, we do not need much memory.
It is widely conjectured that NP ⊂ PSPACE (that is, it is believed that there are
problems in PSPACE that are not in NP) and indeed that coNP ⊂ PSPACE too.
We will now describe an important problem in PSPACE that seems to belong to
neither NP nor coNP; we make use of this problem in Chapter 6.
The set of prenex quantiﬁed boolean formulas (QBFs) consists of expressions of
the form
Q1 p1 . . . Qm pm θ(p1 , . . . , pm ),
where each Qi is either ∀ or ∃, and θ(p1 , . . . , pm ) is a formula of propositional
calculus. The quantiﬁers range over the truth values 1 (true) and 0 (false), and a
quantiﬁed boolean formula without free variables is true if and only if it evaluates
to 1; the QBF-truth problem is to determine whether such a formula is true or not.514
C A Computational Toolkit
This problem contains both the satisﬁability and validity problems for propositional
logic as special cases (let the quantiﬁers be all existential, or all universal, respec-
tively). But the general problem of deciding the truth of QBF formulas seems to be
harder than either of these. Nonetheless there is a certain modularity to deciding
QBF-truth. We try out one sequence of truth value assignments: checking whether
it works takes polynomial space. We record what we have done, and reuse the
same space to check the next assignment sequence. In this way we check through
all possible assignments, and each check is performed in the same working space.
So it may take an awfully long time to solve the problem – but we do not have to
use much memory. And in fact we have the following result.
Theorem C.13 The QBF-truth problem is PSPACE-complete.
Proof. See Papadimitriou [352, Theorem 19.1].
PSPACE is deﬁned in terms of deterministic Turing machines. NPSPACE, the
class of problems computable by non-deterministic polynomial space bounded Tur-
ing machines, is deﬁned by rephrasing the deﬁnition in terms of non-deterministic
Turing machines. Intriguingly, NPSPACE contains nothing new:
Theorem C.14 (Savitch’s Theorem) PSPACE = NPSPACE.
Proof. See Papadimitriou [352, Theorem 7.5].
So if we want to show that a problem is in PSPACE, we can do so by showing that
it is in NPSPACE, and we take advantage of this in the text.
Finally, PSPACE = coPSPACE. Why? Well, any deterministic Turing machine
that decides a problem L in PSPACE can be converted to a machine that decides L
simply by ﬂipping yess to nos and vice versa. This invariance under complemen-
tation has nothing much to do with PSPACE: for any time or space class C deﬁned
in terms of deterministic Turing machines, C = coC, as the ‘switch the outputs’
argument shows. (Note that this argument does not work with non-deterministic
machines.)
The class EXPTIME
EXPTIME is deﬁned in terms of deterministic Turing machines:
Deﬁnition C.15 A deterministic Turing machine is exponentially time bounded if
there is a polynomial p(n) such that the machine always halts after at most 2p(n)
steps, where n is the length of the input.
A problem is solvable in exponential time if there is an exponentially time
bounded Turing machine that solves it. The class of all problems solvable in expo-
nential time is called EXPTIME.A Computational Toolkit
515
Incidentally, the use of 2 in this deﬁnition is arbitrary. If we can show that a Turing
machine is time bounded by a function of the form cp(n) , where c > 2, then we
can show that it is exponentially time bounded in the sense just deﬁned: simply
choose k such that 2k > c. Then the Turing machine is time bounded by 2k·p(n) ,
for cp(n) < (2k )p(n) = 2k·p(n) .
EXPTIME-hard problems are intractable. Some problems in EXPTIME are
provably outside P (see Lewis and Papadimitriou [301, Theorem 6.1.2]), hence
any EXPTIME-hard problem is at least as hard as such intractable problems.
The class NEXPTIME
NEXPTIME is the class of problems solvable using an exponentially bounded non-
deterministic Turing machine. Like NP algorithms, NEXPTIME algorithms have
a ‘guess and check’ proﬁle. The crucial difference is that guessed information may
be exponentially large in the size of the input, thus the deterministic checking that
follows may take exponentially many steps in the size of the input.
We have not mentioned NEXPTIME much in Chapter 6, but it is implicitly
present: when modal logics are proved decidable using the ﬁnite model property, a
NEXPTIME algorithm is usually being employed.
O notation
In the text we try to do as little combinatorial analysis as possible, and we are
often content simply to say that some procedure or other runs in polynomial, or
exponential, time. But sometimes we state more precise bounds, and when we do,
we use O notation. Basically, O notation is a way of stating bounds that ignores
multiplicative constants and low order terms. For example, instead of saying that
an algorithm runs in time 3n2 + 2n + 7 (where n is the size of the input) we would
say that it runs in time O(n2 ) (read this as: ‘of the order n2 ’). Roughly speaking,
this means that for all sufﬁciently large n, the fact that we square the length of the
input dominates all the other contributions. More precisely:
Deﬁnition C.16 Let f and g be functions from the natural numbers to the natural
numbers. We say that f = O(g) if there are positive constants c and k such that
for all n ≥ k, f (n) ≤ c · g(n).
Thus 3n2 + 2n + 7 = O(n2 ), as 3n2 + 2n + 7 ≤ 6n2 for all n ≥ 2.Appendix D
A Guide to the Literature
Here we list and brieﬂy describe a number of textbooks, survey articles, and more
specialized books which the reader may ﬁnd useful. We have not aimed for com-
prehensive coverage. Rather, we have commented on the sources the reader is most
likely to run into, provided pointers to topics not discussed in this book (in partic-
ular, modal proof theory and theorem proving, and ﬁrst-order modal logic) and
drawn attention to some interesting emerging themes.
This is a good place to mention the Advances in Modal Logic initiative, which
attempts to bring together scholars working in various areas of modal logic and its
applications. You can ﬁnd out more at: http://www.aiml.net. The collec-
tion Advances in Modal Logic, Volume 1, edited by Kracht et al. [281], contains
a selection of papers from the ﬁrst conference hosted by the initiative. Selections
from later workshops have also been published; see Advances in Modal Logic, Vol-
ume 2, edited by Zakharyaschev et al. [469]; Advances in Modal Logic, Volume 3,
edited by Wolter et al. [461]; and Advances in Modal Logic, Volume 4, edited by
Balbiani et al. [18].
Textbooks on Modal Logic
To start, here is an annotated list of textbooks on modal logic.
◦ A Manual of Intensional Logic, van Benthem [44]. What is modal logic? What
is not! This inspiring little book takes the reader on a whirlwind tour of the
many faces of modal logic. The book is deceptively easy to read; alert readers
will soon cotton onto the fact that the author indicates unexplored territory on
practically every page.
◦ The Logic of Provability, Boolos [69]. Clear, up-to-date, introduction to prov-
ability logic.
◦ Modal Logic, Chagrov and Zakharyaschev [88]. A recent advanced textbook
on modal logics in the basic modal language and their connections with super-
516A Guide to the Literature
517
intuitionistic logics. Concentrates on the ﬁne structure of the lattice of normal
modal logics, using methods not covered by our book, to prove general results
on various properties of logics.
◦ Modal Logic. An Introduction, Chellas [92]. A readable introductory text which
focuses on completeness-via-canonicity and decidability-via-ﬁltration for the
basic modal language. Also introduces neighborhood (or Montague-Scott) se-
mantics, a tool for analyzing non-normal modal logics (Chellas calls neighbor-
hood models minimal models).
◦ Proof Methods for Modal and Intuitionistic Logic, Fitting [137]. This beautiful
book explores in detail a number of proof methods (tableaux, sequent systems,
natural deduction) for modal logic; we have no hesitation in recommending this
classic work as a great source for ﬁnding out more about modal proof theory.
◦ Types, Tableaus, and Goedel’s God, Fitting [139]. An introduction to higher-
order modal logic that ends by formalizing Goedel’s ontological argument for
the existence of God! Quite apart from anything else, it is one of the best intro-
ductions to ordinary (non-modal) higher-order logic around. Tableaux-based.
◦ First-Order Modal Logic, Fitting and Mendelsohn [140]. An excellent intro-
duction to ﬁrst-order modal logic. Addresses both technical and philosophical
aspects of quantiﬁcation and equality. Provides both Hilbert-style and tableaux-
based proof systems.
◦ Modal Logics and Philosophy, Girle [172]. Readable introduction to modal
logic, including ﬁrst-order modal logic. Discusses temporal, dynamic, epis-
temic, and deontic interpretations, as well as the logic of necessity and possi-
bility.
◦ Logics of Time and Computation, Goldblatt [177]. Clearly written intermediate
level text which focuses on completeness results for the basic modal and tempo-
ral languages, and a variety of extended modal languages, including until-based
temporal languages, PDL, and ﬁrst-order PDL. A useful book to have around.
◦ Mathematics of Modality, Goldblatt [178]. This book brings together a number
of the author’s papers on modal logics. In particular, it contains his seminal PhD
thesis which can be hard to obtain in its article version [184, 185].
◦ Dynamic Logic, Harel, Kozen and Tiuryn [212]. A detailed, well written, intro-
duction to propositional dynamic logic, and many of its extensions, including
ﬁrst-order dynamic logic. A good choice for readers wanting to ﬁnd out more
about this important branch of modal logic.
◦ A Companion to Modal Logic, Hughes and Cresswell [234]. This was the ﬁrst
textbook to move beyond the staples of the classical period (relational seman-
tics, canonical models, ﬁltrations) and discuss distinctively modern topics (no-
tably frame incompleteness). Short, accessible, and clear, it is still a valuable
introductory text, though it has since been superseded by the next entry.518
D A Guide to the Literature
◦ A New Introduction to Modal Logic, Hughes and Cresswell [235]. An admirably
clear and wide ranging introductory text. Although many topics (such as the
standard translation) are not discussed, it manages to at least mention many mod-
ern themes such as frame deﬁnability and extended modal languages. Contains
a good discussion of ﬁrst-order modal logic.
◦ Tools and Techniques in Modal Logic, Kracht [279]. Advanced book on math-
ematical aspects of modal logic, taking a polymodal perspective. Contains an
in-depth study of correspondence and completeness, duality theory, the lattice
of modal logics, and transfer results from monomodal to polymodal logics.
◦ The ‘Lemmon Notes’: An Introduction to Modal Logic, Lemmon and Scott
[296]. All that exists of an unﬁnished monograph on modal logic (Lemmon’s
death in 1966 prevented its completion). The original source for work on ﬁltra-
tions and canonical models, for many years it was the deﬁnitive introduction to
modal logic. Although out of date, its quality still shines through.
◦ Epistemic Logic for AI and Computer Science, Meyer and van der Hoek [328].
An introductory text on epistemic logic. Covers the basic modal approach, as
well as more advanced models and default reasoning.
◦ A Short Introduction to Modal Logic, Mints [330]. This little book is a short
introduction to Gentzen-style proof systems for S5, S4 and T. A useful starting
point in modal proof theory.
◦ First Steps in Modal Logic, Popkorn [361]. If you ﬁnd the present book too
difﬁcult and feel the need to consult something simpler, we suggest you try
Popkorn’s text. Like the present book it is semantically oriented and takes for
granted that modal logic has more to offer than the basic modal language. It is
clearly written, mathematically precise, and besides the present book, it is the
only textbook we know that discusses bisimulations.
◦ Self-Reference and Modal Logic, Smoryński [416]. The classic introduction to
provability logic. Beautifully written. More demanding than the Boolos volume.
◦ From Modal Logic to Deductive Databases, edited by Thayse [430]. Wide-
ranging introduction to modal logic. Discusses links with natural language, tem-
poral reasoning, various forms of defeasible reasoning, and deductive databases.
Books in Other Languages
Next, here is a list of books in languages other than English, without comments.
◦ Essai de Logique Déontique, Bailhache [17].
◦ Logicaboek, Batens [30].
◦ Fondements Logiques du Raisonnement Contextuel. Une Etude sur les Logiques
des Conditionnels, Crocco [101].
◦ Logica, Signiﬁcato e Intelligenza Artiﬁciale, Frixione [143].A Guide to the Literature
519
◦ La Logique du Temps, Gardies [161].
◦ Essai sur les Logiques des Modalités, Gardies [162].
◦ Logique. Volume 3. Méthodes pour l’intelligence artiﬁcielle, Gochet, Gri-
bomont, and Thayse [174].
◦ Una Introducción a la Lógica Modal, Jansana [244].
◦ La Logique Déductive, Kalinowski [257].
◦ Glauben, Wissen und Wahrscheinlichkeit. Systeme der Epistemischen Logik,
Lenzen [298].
◦ Pour une Logique du Sens, Martin [315].
◦ Forcing et Sémantique de Kripke-Joyal, Moens [331].
◦ Essais sur les Logiques non Chrysipiennes, Moisil [332].
◦ Klassische und nichtklassische Aussagenlogik, Rautenberg [373].
Survey Articles
Note that virtually all the survey articles listed below are drawn from the following
sources:
◦ Handbook of Automated Reasoning, edited by Robinson and Voronkov [388].
◦ Handbook of Logic and Language, edited by van Benthem and ter Meulen [51].
◦ Handbook of Logic in Artiﬁcial Intelligence and Logic Programming, edited by
Gabbay, Hogger, and Robinson [157, 158].
◦ Handbook of Logic in Computer Science, edited by Abramsky, Gabbay, and
Maibaum [1].
◦ Handbook of Philosophical Logic, edited by Gabbay and Guenthner [154].
◦ Handbook of Proof Theory, edited by Buss [83].
◦ Handbook of Tableau Methods, edited by D’Agostino, Gabbay, Hähnle, and
Posegga [104].
◦ Handbook of Theoretical Computer Science, edited by van Leeuwen [293].
In fact, these handbooks contain surveys of many other topics in, or related to,
modal logic including: auto-epistemic logic, belief revision, combinations of tense
and modality, computational treatments of time, conditional logic, decision pro-
cedures, deontic logic, description logics, epistemic aspects of databases, general
decidable fragments, higher-order modal logic, logics of programs, non-monotonic
temporal reasoning, philosophical perspectives on ﬁrst-order modal logic, prov-
ability logic, reasoning about knowledge, time and change in AI.
◦ Correspondence Theory, van Benthem [43]. For many years this was the only
easily accessible general reference on correspondence theory, and it is still well
worth reading. Lots of telling examples, and propelled by a clear vision of what
the modal enterprise is all about.520
D A Guide to the Literature
◦ Temporal Logic, van Benthem [47]. A wide-ranging and thoughtful discussion
of key themes in temporal logic.
◦ Basic Modal Logic, Bull and Segerberg [75]. An interesting survey, rich in
historical detail, which provides a useful point of entry to a topic barely touched
on in the present book: the ﬁne structure of the lattice of normal modal logics in
the basic modal language.
◦ Basic Tense Logic, Burgess [79]. An accessible survey, mostly devoted to the ba-
sic temporal language, but touching on until-based logics and multi-dimensional
systems. Contains many useful examples of step-by-step completeness proofs.
◦ Advanced Modal Logic, Chagrov, Wolter and Zakharyaschev [87]. Takes up the
story where the Bull and Segerberg survey leaves off. Strong on the ﬁne structure
of the lattice of normal modal logics.
◦ Reasoning in Description Logics, Donini, Lenzerini, Nardi, and Schaerf [115].
Approachable overview article which discusses four types of reasoning impor-
tant in description logic. Both inference techniques and complexity results are
covered.
◦ Temporal and Modal Logic, Emerson [121]. A detailed introduction to temporal
logic from the perspective of theoretical computer science. Somewhat dated, but
still a good introduction.
◦ Basic Modal Logic, Fitting [138]. An extremely clear introductory survey. Starts
with a good discussion of the basic modal language (including Hilbert systems,
natural deduction, tableaux methods, the standard translation, and alternative
semantics), and then goes on to examine ﬁrst-order modal logic.
◦ Varieties of Complex Algebras and Algebraic Polymodal Logic, Goldblatt [186,
181]. Both of these provide an introduction to the study of varieties of BAOs,
emphasizing their connections with modal logics, and focusing on structural
properties (such as canonicity) that are related to natural properties of modal
logical systems.
◦ Tableau Methods for Modal and Temporal Logics, Goré [193]. Detailed survey
of tableaux based proof methods for temporal languages.
◦ Dynamic Logic, Harel [209]. If you want to learn more about PDL, this is a
good place to look, though it is more densely written than Harel, Kozen and
Tiuryn [212]. Discusses a wide range of variants and extensions of PDL.
◦ The Logic of Provability, Japaridze and de Jongh [245]. A thorough overview of
provability logic, covering propositional provability logic, interpretability logic
and related areas, as well as predicate provability logic.
◦ A Survey of Boolean Algebras with Operators, Jónsson [253]. Gives an algebraic
introduction to the theory of boolean algebras with operators. The papers by
Goldblatt and this one by Jónsson are highly recommended to readers who want
more on the algebraic side of modal logic than our Chapter 5 offers.A Guide to the Literature
521
◦ Logics of Programs, Kozen and Tiuryn [274]. Essentially (though not entirely)
an introduction to PDL. Useful, but Harel, Kozen and Tiuryn [212] is probably a
better choice.
◦ Resolution Decision Procedures, Leitsch, Fermüller and Tammet [294]. An ex-
tensive survey of resolution-based decision procedures for fragments of ﬁrst-
order logic. Covers procedures for modal and guarded fragments and fragments
corresponding to description logics.
◦ Encoding Non-Classical Logics in Classical Logic, Ohlbach, de Rijke, Non-
nengart, and Gabbay [345]. A computationally oriented overview of translation
methods for mapping modal and modal-like languages into ﬁrst-order logic. Dis-
cusses various ﬂavors of the standard (relational) translation and the functional
translation, from the point of view of both expressive power and decidability.
◦ Feature Logics, Rounds [394]. Authoritative survey of feature logic. Devotes a
lot of attention to the modal aspects of feature logic.
◦ Modal and Temporal Logics, Stirling [424]. An extremely useful, technically
oriented article which will appeal to many readers of this volume. Starting with
many of the same tools introduced in this book (transition systems, bisimula-
tions, correspondence theory, unraveling), it goes on to discuss many other top-
ics such as modal μ-calculi and links with automata theory.
◦ An Overview of Interpretability Logic, Visser [451]. An elegant overview of
interpretability logic, an extension of provability logic which deals with inter-
pretations between formal theories.
◦ Canonical Formulas for Modal and Superintuitionistic Logics: A Short Outline,
Zakharyaschev [467]. Canonical formulas are an important frame-theoretic ap-
proach to the classiﬁcation of modal formulas. This is an accessible survey, by
the inventor of the method, with plenty of motivations, examples and deﬁnitions.
Other Books
◦ Vicious Circles, Barwise and Moss [27]. An introduction to non-well-founded
set theory, a set theory where bisimulation rather than extensionality is the key
concept. The authors advocate using inﬁnitary modal logic to study such struc-
tures, and the area is becoming a research area in its own right.
◦ Modal Logic and Classical Logic, van Benthem [42]. This book (a reworking of
the author’s PhD thesis) is the primary source on what is now called correspon-
dence theory. Although most of the book is devoted to frame deﬁnability, this
is also where bisimulations (under the name p-relations) were introduced and
shown to capture modal expressivity over models. It may be hard to get hold of,
but it is well worth making the effort.
◦ Logic of Time, van Benthem [45]. Explores temporal logic model-theoretically;
modal logic is just one strand in the story. The book makes many interesting522
D A Guide to the Literature
technical contributions (notably in the study of interval structures) but its real
importance is methodological: it is by far the most convincing demonstration
we know of the light model-theoretic methods can throw on difﬁcult conceptual
issues.
◦ Reasoning about Knowledge, Fagin, Halpern, Moses and Vardi [125]. Looks set
to be the key reference on epistemic logic for quite some time to come. Treats a
wide range of topics from a modern semantically-oriented perspective. Clearly
written. Highly recommended.
◦ Labelled Deductive Systems, Gabbay [151]. This is not a book on modal logic,
but an introduction to a proof theoretical methodology. But modal logics provide
many of the nicest examples of the labeling method in action, and if you are
interested in modal proof theory you need to know about this.
◦ Temporal Logics. Mathematical Foundations and Computational Aspects. Vol-
ume 1, Gabbay, Hodkinson and Reynolds [156]. The ﬁrst of three projected
volumes, this book discusses basic completeness and incompleteness, the tem-
poral logics of special structures (such as R), multi-dimensional temporal logic,
ﬁxed-point logic and propositional quantiﬁcation, and much else besides. Con-
tains a detailed discussion of expressive completeness.
◦ Cylindric Algebras, Parts I & II, by Henkin, Monk and Tarski [218]. The deﬁni-
tive work on cylindric algebras, it also contains a wealth of results on other
branches of algebraic logic and on boolean algebras with operators in general.
◦ Relation Algebras by Games, by Hodkinson and Hirsch [226]. Still in manu-
script form at the time of writing, this work promises to become a standard
reference on relation algebras. Strong on the connections between relation alge-
bras and model theory and a convincing argument for the application of games
in algebraic logic.
◦ The Temporal Logic of Reactive and Concurrent Systems. Volume 1: Speciﬁca-
tion, Manna and Pnueli [312]. Textbook aimed at computer scientists interested
in specifying reactive systems. All the necessary temporal logic is introduced
and explained in the course of the book.
◦ The Temporal Veriﬁcation of Reactive Systems. Volume 2: Safety, Manna and
Pnueli [313]. Follow up to the previous volume, emphasizing safety issues.
◦ Multidimensional Modal Logic, Marx and Venema [320]. The key reference
for work in multi-dimensional modal logic. Discusses two-dimensional modal
logics, arrow logics, modal logics of intervals, modal logics of relations, and the
problem of deﬁning ‘concrete’ semantics (in the sense of Henkin) for arbitrary
modal languages.
◦ Temporal Logic, Øhrstrom and Hasle [347]. Introduction to temporal logic from
a historical perspective. A good way of getting to grips with Prior’s work.
◦ Past, Present and Future, Prior [365]. Arthur Prior seems to be one of those
authors more often cited than read. This is pity: if you push on past his use ofA Guide to the Literature
523
Polish notation you will discover a fascinating writer with a surprisingly up to
date range of concerns.
◦ Set Theory and the Continuum Problem, Smullyan and Fitting [418]. So why is
this one here? Because in Part III of the book the authors show how Cohen-style
forcing arguments can be formulated using ﬁrst-order S4. Roughly speaking,
they prove independence results using sophisticated step-by-step arguments.
◦ Proof Theory of Modal Logic, Wansing [454]. A collection of papers devoted to
proof-theoretical aspects of modal logic, covering many ﬂavors of proof theory:
sequents, resolution, tableaux, display calculi, and translation-based approaches.
◦ Displaying Modal Logic, Wansing [455]. A proof-theoretical monograph that
shows in detail how to deﬁne display calculi for modal logics.
◦ Modal Logic: The Lewis Modal Systems, Zeman [474]. Provides sequent proof
systems for the Lewis systems and some others. Written by a student of Arthur
Prior, it draws on some of Prior’s unpublished classroom material. Clearly writ-
ten. Uses Polish notation.
The Ω-bibliography
Finally, a fairly comprehensive bibliography of books and articles on modal (and
various non-classical) logics is provided by Volume II of the Ω-bibliography of
mathematical logic. The references in this volume, edited by Rautenberg [375],
stop somewhere in the 1980s; nevertheless, this work can be the starting point of a
fascinating quest for treasures in the earlier literature of modal logic.Bibliography
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
S. Abramsky, D.M. Gabbay, and T.S.E. Maibaum, editors. Handbook of Logic in
Computer Science, volume 2. Clarendon Press, 1992.
P. Aczel. Non-Well-Founded Sets. CSLI Publications, 1988.
M. Aiello and J. van Benthem. A modal walk through space. Journal of Applied
Non-Classical Logics, 12:319–364, 2002.
C.E. Alchourrón, P. Gärdenfors, and D. Makinson. On the logic of theory change:
partial meet contraction and revision functions. Journal of Symbolic Logic, 50:510–
530, 1985.
A. Andréka, A. Kurucz, I. Németi, and I. Sain. Applying algebraic logic to logic. In
M. Nivat and M. Wirsing, editors, Algebraic Methodology and Software Technology,
pages 201–221. Springer, 1994.
H. Andréka. Complexity of equations valid in algebras of relations. Annals of Pure
and Applied Logic, 89:149–229, 1997.
H. Andréka, I.M. Hodkinson, and I. Németi. Finite algebras of relations are repre-
sentable on ﬁnite sets. Journal of Symbolic Logic, 64:243–267, 1999.
H. Andréka, J.D. Monk, and I. Németi, editors. Algebraic Logic. (Proceedings of
the 1988 Budapest Conference), volume 54 of Colloquia Mathematica Societatis
János Bolyai. North-Holland Publishing Company, 1991.
H. Andréka, J. van Benthem, and I. Németi. Modal languages and bounded frag-
ments of predicate logic. Journal of Philosophical Logic, 27:217–274, 1998.
I.H. Anellis and N. Houser. Nineteenth century roots of algebraic logic and universal
algebra. In Andréka et al. [8], pages 1–36.
L. Åqvist, F. Guenthner, and C. Rohrer. Deﬁnability in ITL of some subordinate
temporal conjunctions in English. In F. Guenthner and C. Rohrer, editors, Studies
in Formal Semantics, pages 201–221. North Holland, 1978.
C. Areces. Logic Engineering: The Case of Description and Hybrid Logics. PhD
thesis, ILLC, University of Amsterdam, 2000.
C. Areces, P. Blackburn, and M. Marx. The computational complexity of hybrid
temporal logics. Logic Journal of the IGPL, 8(5):653–679, 2000.
C. Areces, P. Blackburn, and M. Marx. Hybrid logics: Characterization, interpola-
tion and complexity. Journal of Symbolic Logic, 66:977–1010, 2001.
C. Areces and M. de Rijke. Description and/or hybrid logic. In Workshop Proceed-
ings AiML-2000, pages 1–14. Institut für Informatik, Universität Leipzig, 2000.
524Bibliography
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
[33]
[34]
[35]
[36]
[37]
[38]
[39]
[40]
525
F. Baader and K. Schulz, editors. Frontiers of Combining Systems 1. Kluwer Aca-
demic Publishers, 1996.
P. Bailhache. Essai de Logique D éontique. Mathesis, 1991.
P. Balbiani, N.-Y. Suzuki, F. Wolter, and M. Zakharyaschev, editors. Advances in
Modal Logic, Volume 4. King’s College London Publications, 2003.
Ph. Balbiani, L. Fariñas del Cerro, T. Tinchev, and D. Vakarelov. Modal logics for
incidence geometries. Journal of Logic and Computation, 7:59–78, 1997.
A. Baltag. STS: A Structural Theory of Sets. PhD thesis, Indiana University, Bloom-
ington, Indiana, 1998.
A. Baltag. A logic for suspicious players: epistemic actions and belief updates
in games. Bulletin of Economic Research, to appear, 2000. Paper presented at
the Fourth Conference on Logic and the Foundations of the Theory of Games and
Decisions.
A. Baltag. STS: a structural theory of sets. In Zakharyaschev et al. [469].
B. Banieqbal, H. Barringer, and A. Pnueli, editors. Proc. Colloquium on Temporal
Logic in Speciﬁcation, volume 398 of LNCS. Springer, 1989.
H. Barendregt. The Lambda Calculus: Its Syntax and Semantics. North-Holland
Publishing Company, 1984.
J. Barwise. Model-theoretic logics: background and aims. In Barwise and Feferman
[26], pages 3–23.
J. Barwise and S. Feferman, editors. Model-Theoretic Logics. Springer, 1985.
J. Barwise and L. Moss. Vicious Circles, volume 60 of Lecture Notes. CSLI Publi-
cations, 1996.
J. Barwise and L.S. Moss. Modal correspondence for models. Journal of Philo-
sophical Logic, 27:275–294, 1998.
D. Basin and N. Klarlund. Automata based symbolic reasoning in hardware veriﬁ-
cation. Journal of Formal Methods in Systems Design, 13:255–288, 1998.
D. Batens. Logicaboek. Garant Leven, Apeldoorn, 1991.
P. Battigalli and G. Bonanno. Recent results on belief, knowledge and the founda-
tions of game theory. Research in Economics, 53:149–225, 1999.
J.L. Bell and M. Machover. A Course in Mathematical Logic. North-Holland Pub-
lishing Company, 1977.
J.L. Bell and A.B. Slomson. Models and Ultraproducts. North-Holland Publishing
Company, 1969.
B. Bennet, C. Dixon, M. Fisher, E. Franconi, I. Horrocks, U. Hustadt, and
M. de Rijke. Combinations of modal logic. Journal of AI Reviews, 17:1–20, 2002.
J. van Benthem. A note on modal formulas and relational properties. Journal of
Symbolic Logic, 40:85–88, 1975.
J. van Benthem. Modal Correspondence Theory. PhD thesis, Mathematisch Insti-
tuut & Instituut voor Grondslagenonderzoek, University of Amsterdam, 1976.
J. van Benthem. Two simple incomplete modal logics. Theoria, 44:25–37, 1978.
J. van Benthem. Minimal deontic logics. Bulletin of the Section of Logic, 8:36–42,
1979.
J. van Benthem. Syntactical aspects of modal incompleteness theorems. Theoria,
45:63–77, 1979.
J. van Benthem. Canonical modal logics and ultraﬁlter extensions. Journal of Sym-
bolic Logic, 44:1–8, 1980.526
[41]
[42]
[43]
[44]
[45]
[46]
[47]
[48]
[49]
[50]
[51]
[52]
[53]
[54]
[55]
[56]
[57]
[58]
[59]
[60]
[61]
[62]
[63]
[64]
Bibliography
J. van Benthem. Some kinds of modal completeness. Studia Logica, 39:125–141,
1980.
J. van Benthem. Modal Logic and Classical Logic. Bibliopolis, 1983.
J. van Benthem. Correspondence theory. In Gabbay and Guenthner [154], pages
167–247.
J. van Benthem. A Manual of Intensional Logic, volume 1 of Lecture Notes. CSLI
Publications, 1985.
J. van Benthem. The Logic of Time. Kluwer Academic Publishers, second edition,
1991.
J. van Benthem. Modal frame classes revisited. Fundamenta Informaticae, 18:307–
317, 1993.
J. van Benthem. Temporal logic. In Gabbay et al. [158], pages 241–351.
J. van Benthem. Exploring Logical Dynamics. Studies in Logic, Language and
Information. CSLI Publications, 1996.
J. van Benthem. Dynamic bits and pieces. Technical Report LP-97-01, Institute for
Language, Logic and Computation, 1997.
J. van Benthem and W. Meyer Viol. Logical semantics of programming. Unpub-
lished lecture notes. University of Amsterdam, 1993.
J. van Benthem and A. ter Meulen, editors. Handbook of Logic and Language.
Elsevier Science, 1997.
R. Berger. The undecidability of the domino problem. Technical Report 66, Mem.
Amer. Math. Soc., 1966.
G. Birkhoff. On the structure of abstract algebras. Proceedings of the Cambridge
Philosophical Society, 29:441–464, 1935.
P. Blackburn. Nominal tense logic. Notre Dame Journal of Formal Logic, 34:56–83,
1993.
P. Blackburn. Tense, temporal reference, and tense logic. Journal of Semantics,
11:83–101, 1994.
P. Blackburn. Internalizing labelled deduction. Journal of Logic and Computation,
10:137–168, 2000.
P. Blackburn. Representation, reasoning, and relational structures: a hybrid logic
manifesto. Logic Journal of the IGPL, 8:339–365, 2000.
P. Blackburn, C. Gardent, and W. Meyer-Viol. Talking about trees. In Proceedings
of the 6th Conference of the European Chapter of the Association for Computational
Linguistics, pages 21–29, 1993.
P. Blackburn and J. Seligman. Hybrid languages. Journal of Logic, Language and
Information, 4:251–272, 1995.
P. Blackburn and J. Seligman. What are hybrid languages? In Kracht et al. [281],
pages 41–62.
P. Blackburn and E. Spaan. A modal perspective on the computational complexity of
attribute value grammar. Journal of Logic, Language and Information, 2:129–169,
1993.
P. Blackburn and M. Tzakova. Hybridizing concept languages. Annals of Mathe-
matics and Artiﬁcial Intelligence, 24:23–49, 1998.
P. Blackburn and M. Tzakova. Hybrid languages and temporal logic. Logic Journal
of the IGPL, 7(1):27–54, 1999.
W.J. Blok. An axiomatization of the modal theory of the veiled recession frame.Bibliography
[65]
[66]
[67]
[68]
[69]
[70]
[71]
[72]
[73]
[74]
[75]
[76]
[77]
[78]
[79]
[80]
[81]
[82]
[83]
[84]
[85]
[86]
[87]
[88]
[89]
527
Technical report, Department of Mathematics, University of Amsterdam, 1977.
W.J. Blok. On the degree of incompleteness in modal logic and the covering rela-
tions in the lattice of modal logics. Technical Report 78–07, Department of Mathe-
matics, University of Amsterdam, 1978.
W.J. Blok. The lattice of modal algebras: An algebraic investigation. Journal of
Symbolic Logic, 45:221–236, 1980.
W.J. Blok and D. Pigozzi. Algebraizable logics. Memoirs of the American Mathe-
matical Society, 77, 396, 1989.
G. Boolos. The Unprovability of Consistency. Cambridge University Press, 1979.
G. Boolos. The Logic of Provability. Cambridge University Press, 1993.
G. Boolos and R. Jeffrey. Computability and Logic. Cambridge University Press,
1989.
E. Börger, E. Grädel, and Y. Gurevich. The Classical Decision Problem. Springer,
1997.
J.R. Büchi. On a decision method in restricted second order arithmetic. In Pro-
ceedings International Congress on Logic, Methodology and Philosophy of Science
1960. Stanford University Press, 1962.
R. Bull. An approach to tense logic. Theoria, 36:282–300, 1970.
R.A. Bull. That all normal extensions of S4.3 have the ﬁnite model property.
Zeitschrift für mathemathische Logik und Grundlagen der Mathematik, 12:314–344,
1966.
R.A. Bull and K. Segerberg. Basic modal logic. In Gabbay and Guenthner [154],
pages 1–88.
P. Buneman, S. Davidson, M. Fernandez, and D. Suciu. Adding structure to un-
structered data. In Proceedings ICDT’97, 1997.
J. Burgess. Decidability for branching time. Studia logica, 39:203–218, 1980.
J. Burgess. Axioms for tense logic I: ‘since’ and ‘until’. Notre Dame Journal of
Formal Logic, 23:375–383, 1982.
J.P. Burgess. Basic tense logic. In Gabbay and Guenthner [154], pages 89–133.
J.P. Burgess and Y. Gurevich. The decision problem for linear temporal logic. Notre
Dame Journal of Formal Logic, 26:115–128, 1985.
S. Burris and H.P. Sankappanavar. A Course in Universal Algebra. Graduate Texts
in Mathematics. Springer, 1981.
R. Burstall. Program proving as hand simulation with a little induction. In Informa-
tion Processing ’74, pages 308–312. North-Holland Publishing Company, 1974.
S.R. Buss, editor. Handbook of Proof Theory. Elsevier Science, 1998.
D. Calvanese, G. De Giacomo, and M. Lenzerini. Modeling and querying semi-
structured data. Networking and Information Systems, pages 253–273, 1999.
R. Carnap. Modalities and quantiﬁcation. Journal of Symbolic Logic, 11:33–64,
1946.
R. Carnap. Meaning and Necessity. University of Chicago Press, 1947.
A. Chagrov, F. Wolter, and M. Zakharyaschev. Advanced modal logic. In Handbook
of Philosophical Logic, volume 3, pages 83–266. Kluwer Academic Publishers, sec-
ond edition, 2001.
A. Chagrov and M. Zakharyaschev. Modal Logic, volume 35 of Oxford Logic
Guides. Oxford University Press, 1997.
L.A. Chagrova. An undecidable problem in correspondence theory. Journal of528
Bibliography
Symbolic Logic, 56:1261–1272, 1991.
D. Chalmers. The Conscious Mind. Oxford University Press, 1996.
C.C. Chang and H.J. Keisler. Model Theory. North-Holland Publishing Company,
Amsterdam, 1973.
[92] B.F. Chellas. Modal Logic, an Introduction. Cambridge University Press, 1980.
[93] B. Chlebus. Domino-tiling games. Journal of Computer and System Sciences,
32:374–392, 1986.
[94] E.M. Clarke and E.A. Emerson. Design and synthesis of synchronisation skeletons
using branching time temporal logic. In D. Kozen, editor, Logics of Programs, pages
52–71. Springer, 1981.
[95] E.M. Clarke, O. Grumberg, and D.A. Peled. Model Checking. The MIT Press, 1999.
[96] E.M. Clarke and B.-H. Schlingloff. Model checking. In Robinson and Voronkov
[388].
[97] B.J. Copeland, editor. Logic and Reality. Essays on the Legacy of Arthur Prior.
Clarendon Press, 1996.
[98] W. Craig. On axiomatizability within a system. Journal of Symbolic Logic, 18:30–
32, 1953.
[99] M.J. Cresswell. A Henkin completeness theorem for T. Notre Dame Journal of
Formal Logic, 8:186–90, 1967.
[100] M.J. Cresswell. An incomplete decidable modal logic. Journal of Symbolic Logic,
49:520–527, 1984.
[101] G. Crocco. Fondements Logiques du Raisonnement Contextuel. Une Etude sur les
Logiques des Conditionnels. Padova Unipress, 1996.
[102] L. Csirmaz, D.M. Gabbay, and M. de Rijke, editors. Logic Colloquium ’92, num-
ber 1 in Studies in Logic, Language and Information. CSLI Publications, 1995.
[103] N. Cutland. Computability. An Introduction to Recursive Function Theory. Cam-
bridge University Press, 1980.
[104] M. D’Agostino, D.M. Gabbay, R. Hähnle, and J. Posegga, editors. Handbook of
Tableau Methods. Kluwer Academic Publishers, 1999.
[105] B.A. Davey and H.A. Priestly. Introduction to Lattices and Order. Cambridge
University Press, 1990.
[106] G. De Giacomo. Decidability of Class-Based Knowledge Representation For-
malisms. PhD thesis, Università di Roma “La Sapienza”, 1995.
[107] S. Demri. Sequent calculi for nominal tense logics: a step towards mechanization?
In Murray [339], pages 140–154.
[108] S. Demri and R. Goré. Cut-free display calculi for nominal tense logics. In Murray
[339], pages 155–170.
[109] H. van Ditmarsch. Knowledge Games. PhD thesis, Department of Mathematics and
Computer Science, Rijksuniversiteit Groningen, 2000.
[110] H.C. Doets. Completeness and Deﬁnability: Applications of the Ehrenfeucht Game
in Intensional and Second-Order Logic. PhD thesis, Department of Mathematics
and Computer Science, University of Amsterdam, 1987.
[111] K. Doets. Basic Model Theory. Studies in Logic, Language and Information. CSLI
Publications, 1996.
[112] K. Doets and J. van Benthem. Higher-order logic. In Gabbay and Guenthner [153],
pages 275–329.
[113] J. Doner. Tree acceptors and some of their applications. Journal of Computer and
[90]
[91]Bibliography
529
System Sciences, 4:406–451, 1970.
[114] F.M. Donini, M. Lenzerini, D. Nardi, and W. Nutt. The complexity of concept
languages. Information and Computation, 134:1–58, 1997.
[115] F.M. Donini, M. Lenzerini, D. Nardi, and A. Schaerf. Reasoning in description
logics. In G. Brewka, editor, Principles of Knowledge Representation, Studies in
Logic, Language and Information, pages 191–236. CSLI Publications, 1996.
[116] J. Dugundji. Note on a property of matrices for Lewis and Langford’s calculi of
propositions. Journal of Symbolic Logic, 5:150–151, 1940.
[117] M.A.E. Dummett and E.J. Lemmon. Modal logics between S4 and S5. Zeitschrift
für mathemathische Logik und Grundlagen der Mathematik, 5:250–264, 1959.
[118] H.-D. Ebbinghaus and J. Flum. Finite Model Theory. Perspectives in Mathematical
Logic. Springer, 1995.
[119] A. Ehrenfeucht. An application of games to the completeness problem for formal-
ized theories. Fundamenta Mathematicae, 49:129–141, 1961.
[120] P. van Emde Boas. The convenience of tilings. Technical Report CT-96-01, ILLC,
University of Amsterdam, 1996.
[121] E.A. Emerson. Temporal and modal logics. In van Leeuwen [293], pages 995–1072.
[122] H.B. Enderton. A Mathematical Introduction to Logic. Academic Press, New York,
1972.
[123] L.L. Esakia. Topological Kripke models. Soviet Mathematics Doklady, 15:147–151,
1974.
[124] L.L. Esakia and V.Yu. Meskhi. Five critical systems. Theoria, 40:52–60, 1977.
[125] R. Fagin, J.Y. Halpern, Y. Moses, and M.Y. Vardi. Reasoning About Knowledge.
The MIT Press, 1995.
[126] T. Fernando. A modal logic for non-deterministic discourse processing. Journal of
Logic, Language and Information, 8:455–468, 1999.
[127] K. Fine. Propositional quantiﬁers in modal logic. Theoria, 36:331–346, 1970.
[128] K. Fine. The logics containing S4.3. Zeitschrift f ür mathemathische Logik und
Grundlagen der Mathematik, 17:371–376, 1971.
[129] K. Fine. An incomplete logic containing S4. Theoria, 40:23–29, 1974.
[130] K. Fine. Logics extending K4. Part I. Journal of Symbolic Logic, 39:31–42, 1974.
[131] K. Fine. Normal forms in modal logic. Notre Dame Journal of Formal Logic,
16:229–234, 1975.
[132] K. Fine. Some connections between elementary and modal logic. In Kanger [263].
[133] K. Fine. Modal logics containing K4. Part II. Journal of Symbolic Logic, 50:619–
651, 1985.
[134] M. Finger. Handling database updates in two-dimensional temporal logic. Journal
of Applied Non-Classical Logics, 2:201–224, 1992.
[135] M.J. Fischer and R.E. Ladner. Propositional dynamic logic of regular programs.
Journal of Computer and System Sciences, 18:194–211, 1979.
[136] F. Fitch. A correlation between modal reduction principles and properties of rela-
tions. Journal of Philosophical Logic, 2:97–101, 1973.
[137] M. Fitting. Proof Methods for Modal and Intuitionistic Logic. Reidel, 1983.
[138] M. Fitting. Basic modal logic. In Gabbay et al. [157], pages 368–449.
[139] M. Fitting. Types, Tableaus, and Goedel’s God. Kluwer Academic Publishers, 2002.
[140] M. Fitting and R.L. Mendelsohn. First-Order Modal Logic. Kluwer Academic
Publishers, 1998.530
Bibliography
[141] R. Fraı̈ssé. Sur quelques classiﬁcations des systèmes de relations. Publ. Sci. Univ.
Alger., 1:35–182, 1954.
[142] N. Friedman and J.Y. Halpern. Modeling belief in dynamic systems, part i: Foun-
dations. Artiﬁcial Intelligence, 95:257–316, 1997.
[143] M. Frixione. Logica, Signiﬁcato e Intelligenza Artiﬁciale. FrancoAngeli, Milano,
1994.
[144] A. Fuhrmann. On the modal logic of theory change. In A. Fuhrmann and M. Mor-
reau, editors, LNAI, volume 465, pages 259–281. Springer, 1990.
[145] D.M. Gabbay. Decidability results in non-classical logics. Annals of Mathematical
Logic, 10:237–285, 1971.
[146] D.M. Gabbay. On decidable, ﬁnitely axiomatizable modal and tense logics without
the ﬁnite model property I. Israel Journal of Mathematics, 10:478–495, 1971.
[147] D.M. Gabbay. On decidable, ﬁnitely axiomatizable modal and tense logics without
the ﬁnite model property II. Israel Journal of Mathematics, 10:496–503, 1971.
[148] D.M. Gabbay. The separation property of tense logics. Unpublished manuscript,
September 1979.
[149] D.M. Gabbay. An irreﬂexivity lemma with applications to axiomatizations of con-
ditions on linear frames. In U. Mönnich, editor, Aspects of Philosophical Logic,
pages 67–89. Reidel, 1981.
[150] D.M. Gabbay. The declarative past and imperative future: executable temporal logic
for interactive systems. In Banieqbal et al. [23], pages 431–448.
[151] D.M. Gabbay. Labelled Deductive Systems. Clarendon Press, Oxford, 1996.
[152] D.M. Gabbay and M. de Rijke, editors. Frontiers of Combining Systems 2. Research
Studies Press, 2000.
[153] D.M. Gabbay and F. Guenthner, editors. Handbook of Philosophical Logic, vol-
ume 1. Reidel, 1983.
[154] D.M. Gabbay and F. Guenthner, editors. Handbook of Philosophical Logic, vol-
ume 2. Reidel, 1984.
[155] D.M. Gabbay and I.M. Hodkinson. An axiomatization of the temporal logic with
Since and Until over the real numbers. Journal of Logic and Computation, 1:229–
259, 1991.
[156] D.M. Gabbay, I.M. Hodkinson, and M. Reynolds. Temporal Logic: Mathematical
Foundations and Computational Aspects. Oxford University Press, 1994.
[157] D.M. Gabbay, C.J. Hogger, and J.A. Robinson, editors. Handbook of Logic in Ar-
tiﬁcial Intelligence and Logic Programming, volume 1. Oxford University Press,
1993.
[158] D.M. Gabbay, C.J. Hogger, and J.A. Robinson, editors. Handbook of Logic in Ar-
tiﬁcial Intelligence and Logic Programming, volume 4. Oxford University Press,
1994.
[159] D.M. Gabbay, A. Kurucz, F. Wolter, and M. Zakharyaschev. Many-Dimensional
Modal Logics: Theory and Applications, volume 146 of Studies in Logic and the
Foundations of Mathematics. Elsevier, 2003.
[160] D.M. Gabbay, A. Pnueli, S. Shelah, and J. Stavi. On the temporal analysis of fair-
ness. In Proc. 7th ACM Symposium on Principles of Programming Languages,
pages 163–173, 1980.
[161] J. Gardies. La Logique du Temps. Presses Universitaires de France, Paris, 1975.
[162] J. Gardies. Essai sur les Logiques des Modalit és. Presses Universitaires de France,Bibliography
531
Paris, 1979.
[163] M.R. Garey and D.S. Johnson. Computers and Intractibility. A Guide to the Theory
of NP-Completeness. W.H. Freeman, 1979.
[164] G. Gargov and V. Goranko. Modal logic with names. Journal of Philosophical
Logic, 22:607–636, 1993.
[165] G. Gargov and S. Passy. A note on Boolean modal logic. In P.P. Petkov, editor,
Mathematical Logic. Proceedings of the 1988 Heyting Summerschool, pages 311–
321. Plenum Press, 1990.
[166] G. Gargov, S. Passy, and T. Tinchev. Modal environment for Boolean speculations.
In D. Skordev, editor, Mathematical Logic and its Applications, pages 253–263.
Plenum Press, 1987.
[167] F. Gecseg and M. Steinby. Tree languages. In Rozenberg and Salomaa [395], pages
1–68.
[168] M. Gehrke and J. Harding. Bounded lattice expansions. Journal of Algebra,
238:345–371, 2001.
[169] M. Gehrke and B. Jónsson. Bounded distributive lattices with operators. Mathemat-
ica Japonica, 40:207–215, 1994.
[170] J. Gerbrandy and W. Groeneveld. Reasoning about information change. Journal of
Logic, Language and Information, 6:147–169, 1997.
[171] S. Ghilardi and G. Meloni. Constructive canonicity in non-classical logics. Annals
of Pure and Applied Logic, 86:1–32, 1997.
[172] R. Girle. Modal Logics and Philosophy. Acumen, 2000.
[173] R. van Glabbeek. The linear time-branching time spectrum II; the semantics of
sequential processes with silent moves. In Proceedings CONCUR ’93, volume 715
of LNCS, pages 66–81. Springer, 1993.
[174] P. Gochet, P. Gribomont, and A. Thayse. Logique. Volume 3. M éthodes pour
l’intelligence artiﬁcielle. Hermes, 2000.
[175] K. Gödel. Eine Interpretation des intuitionistischen Aussagenkalkülus. In Ergeb-
nisse eines mathematischen Kolloquiums 4, pages 34–40, 1933.
[176] R. Goldblatt. Semantic analysis of orthologic. Journal of Philosophical Logic,
3:19–35, 1974.
[177] R. Goldblatt. Logics of Time and Computation, volume 7 of Lecture Notes. CSLI
Publications, 1987.
[178] R. Goldblatt. Mathematics of Modality, volume 43 of Lecture Notes. CSLI Publi-
cations, 1993.
[179] R. Goldblatt. Saturation and the Hennessy-Milner property. In Ponse et al. [360].
[180] R. Goldblatt. Elementary generation and canonicity for varieties of boolean algebras
with operators. Algebra Universalis, 34:551–607, 1995.
[181] R. Goldblatt. Algebraic polymodal logic: a survey. Logic Journal of the IGPL,
8:393–450, 2000.
[182] R. Goldblatt. Mathematical modal logic: a view of its evolution, 2000. To appear.
Draft available at http://www.vuw.ac.nz/˜rob.
[183] R.I. Goldblatt. First-order deﬁnability in modal logic. Journal of Symbolic Logic,
40:35–40, 1975.
[184] R.I. Goldblatt. Metamathematics of modal logic I. Reports on Mathematical Logic,
6:41–78, 1976.
[185] R.I. Goldblatt. Metamathematics of modal logic II. Reports on Mathematical Logic,532
Bibliography
7:21–52, 1976.
[186] R.I. Goldblatt. Varieties of complex algebras. Annals of Pure and Applied Logic,
38:173–241, 1989.
[187] R.I. Goldblatt. The McKinsey axiom is not canonical. Journal of Symbolic Logic,
56:554–562, 1991.
[188] R.I. Goldblatt and S.K. Thomason. Axiomatic classes in propositional modal logic.
In J. Crossley, editor, Algebra and Logic, pages 163–173. Springer, 1974.
[189] V. Goranko. Modal deﬁnability in enriched languages. Notre Dame Journal of
Formal Logic, 31:81–105, 1990.
[190] V. Goranko. Hierarchies of modal and temporal logics with reference pointers.
Journal of Logic, Language and Information, 5:1–24, 1996.
[191] V. Goranko and B. Kapron. The modal logic of the countable random frame. Archive
for Mathematical Logic, 42:221–243, 2003.
[192] V. Goranko and S. Passy. Using the universal modality: Gains and questions. Jour-
nal of Logic and Computation, 2:5–30, 1992.
[193] R. Goré. Tableau methods for modal and temporal logics. In D’Agostino et al.
[104].
[194] E. Grädel. On the restraining power of guards. Journal of Symbolic Logic, 64:1719–
1742, 1999.
[195] E. Grädel, P. Kolaitis, and M.Y. Vardi. On the decision problem for two-variable
ﬁrst-order logic. Bulletin of Symbolic Logic, 3:53–69, 1997.
[196] E. Grädel, M. Otto, and E. Rosen. Two-variable logic with counting is decidable. In
Proceedings 12th IEEE Symposium on Logic in Computer Science LICS’97, 1997.
[197] E. Grädel and I. Walukiewicz. Guarded ﬁxed point logic. In Proceedings 14th IEEE
Symposium on Logic in Computer Science LICS’99, 1999.
[198] G. Grätzer. Universal Algebra. Springer, 1979.
[199] A.J. Grove, J.Y. Halpern, and D. Koller. Asymptotic conditional probabilities: the
non-unary case. Journal of Symbolic Logic, 61:250–275, 1996.
[200] A.J. Grove, J.Y. Halpern, and D. Koller. Asymptotic conditional probabilities: the
unary case. SIAM Journal on Computing, 25:1–51, 1996.
[201] Y. Gurevich and S. Shelah. The decision problem for branching time logic. Journal
of Symbolic Logic, 50:669–681, 1985.
[202] P. R. Halmos. Algebraic Logic. Chelsea Publishing Company, 1962.
[203] J.Y. Halpern. The effect of bounding the number of primitive propositions and the
depth of nesting on the complexity of modal logic. Artiﬁcial Intelligence, 75:361–
372, 1995.
[204] J.Y. Halpern and B.M. Kapron. Zero-one laws for modal logic. Annals of Pure and
Applied Logic, 69:157–193, 1994.
[205] J.Y. Halpern and Y.O. Moses. A guide to the completeness and complexity for
modal logics of knowledge and belief. Artiﬁcial Intelligence, 54:319–379, 1992.
[206] J.Y. Halpern and M.Y. Vardi. The complexity of reasoning about knowledge and
time, I: Lower bounds. Journal of Computer and System Sciences, 38:195–237,
1989.
[207] J.Y. Halpern and M.Y. Vardi. Model checking vs. theorem proving: a manifesto.
In J.A. Allen, R. Fikes, and E. Sandewall, editors, Principles of Knowledge Rep-
resentation and Reasoning: Proc. Second International Conference (KR’91), pages
325–334. Morgan Kaufmann, 1991.Bibliography
533
[208] D. Harel. Recurring dominoes: making the highly undecidable highly understand-
able. In Proc. of the Conference on Foundations of Computing Theory, volume 158
of LNCS, pages 177–194. Springer, 1983.
[209] D. Harel. Dynamic logic. In Gabbay and Guenthner [154], pages 497–604.
[210] D. Harel. Recurring dominoes: making the highly undecidable highly understand-
able. Annals of Discrete Mathematics, 24:51–72, 1985.
[211] D. Harel. Effective transformations on inﬁnite trees, with applications to high un-
decidability. Journal of the ACM, 33:224–248, 1986.
[212] D. Harel, D. Kozen, and J. Tiuryn. Dynamic Logic. The MIT Press, 2000.
[213] R. Harrop. On the existence of ﬁnite models and decision procedures for proposi-
tional calculi. Proceedings of the Cambridge Philosophical Society, 54:1–13, 1958.
[214] T. Hayashi. Finite automata on inﬁnite objects. Math. Res. Kyushu University,
15:13–66, 1985.
[215] E. Hemaspaandra. The price of universality. Notre Dame Journal of Formal Logic,
37:174–203, 1996.
[216] L. Henkin. Logical systems containing only a ﬁnite number of symbols. Séminiare
de Mathématique Supérieures 21, Les Presses de l’Université de Montréal,
Montréal, 1967.
[217] L. Henkin. Completeness in the theory of types. Journal of Symbolic Logic, 15:81–
91, 1950.
[218] L. Henkin, J.D. Monk, and A. Tarski. Cylindric Algebras. Part 1. Part 2. North-
Holland Publishing Company, Amsterdam, 1971, 1985.
[219] M. Hennessy and R. Milner. Algebraic laws for indeterminism and concurrency.
Journal of the ACM, 32:137–162, 1985.
[220] J.G. Henriksen, J. Jensen, M. Jørgensen, N. Klarlund, R. Paige, T. Rauhe, and
A. Sandhol. MONA: Monadic second-order logic in practice. In Proceedings
TACAS’95, LNCS, pages 479–506. Springer, 1995.
[221] M. Henzinger, T. Henzinger, and P. Kopke. Computing simulations on ﬁnite and in-
ﬁnite graphs. In Proceedings 20th Symposium on Foundations of Computer Science,
pages 453–462, 1995.
[222] B. Herwig. Extending partial isomorphisms on ﬁnite structures. Combinatorica,
15:365–371, 1995.
[223] J. Hindley and J. Seldin. Introduction to Combinators and the Lambda Calculus.
London Mathematical Society Student Texts vol. 1. Cambridge University Press,
1986.
[224] J. Hintikka. Knowledge and Belief. Cornell University Press, 1962.
[225] R. Hirsch and I.M. Hodkinson. Step by step — building representations in algebraic
logic. Journal of Symbolic Logic, 62:225–279, 1997.
[226] R. Hirsch and I.M. Hodkinson. Relation Algebras by Games. Number 147 in Studies
in Logic. Elsevier, Amsterdam, 2002.
[227] R. Hirsch, I.M. Hodkinson, M. Marx, Sz. Mikulás, and M. Reynolds. Mosaics and
step-by-step. Remarks on ‘A modal logic of relations’. In Orłowska [349], pages
158–167.
[228] W. Hodges. Elementary predicate logic. In Gabbay and Guenthner [153], pages
1–131.
[229] W. Hodges. Model Theory. Cambridge University Press, 1993.
[230] I.M. Hodkinson. Atom structures of cylindric algebras and relation algebras. Annals534
Bibliography
of Pure and Applied Logic, 89:117–148, 1997.
[231] I.M. Hodkinson. Loosely guarded fragment has ﬁnite model property. Studia Log-
ica, 70:205–240, 2002.
[232] M. Hollenberg. Safety for bisimulation in general modal logic. In Proceedings 10th
Amsterdam Colloquium, 1996.
[233] M.J. Hollenberg. Hennessy-Milner classes and process algebra. In Ponse et al.
[360].
[234] G. Hughes and M.J. Cresswell. A Companion to Modal Logic. Methuen, 1984.
[235] G. Hughes and M.J. Cresswell. A New Introduction to Modal Logic. Routledge,
1996.
[236] I. Humberstone. Inaccessible worlds. Notre Dame Journal of Formal Logic, 24:346–
352, 1983.
[237] U. Hustadt. Resolution-Based Decision Procedures for Subclasses of First-Order
Logic. PhD thesis, Universität des Saarlandes, Saarbrücken, Germany, 1999.
[238] U. Hustadt and R. A. Schmidt. Issues of decidability for description logics in the
framework of resolution. In R. Caferra and G. Salzer, editors, First-order Theorem
Proving—FTP’98, pages 152–161. Technical Report E1852-GS-981, Technische
Universität Wien, 1998.
[239] M.R.A. Huth and M.D. Ryan. Logic in Computer Science. Cambridge University
Press, 2000.
[240] N. Immerman and D. Kozen. Deﬁnability with bounded number of bound variables.
In Proceedings 4th IEEE Symposium on Logic in Computer Science LICS’87. Com-
puter Society Press, 1987.
[241] B. Jacobs. The temporal logic of coalgebras via Galois algebras. Mathematical
Structure in Computer Science, 12:875–903, 2002.
[242] B. Jacobs and J. Rutten. A tutorial on (co)algebras and (co)induction. Bulletin of
the European Association for Theoretical Computer Science, 62:222–259, 1997.
[243] D. Janin and I. Walukiewicz. On the expressive completeness of the propositional
μ-calculus w.r.t. monadic second-order logic. In Proceedings CONCUR ’96, 1996.
[244] R. Jansana. Una Introducci ón a la Lógica Modal. Editorial Tecnos, Madrid, 1990.
[245] G. Japaridze and D. de Jongh. The logic of provability. In Buss [83], pages 475–546.
[246] He Jifeng. Process simulation and reﬁnement. Formal Aspects of Computing,
1:229–241, 1989.
[247] P. Jipsen. Discriminator varieties of boolean algebras with residuated operators. In
C. Rauszer, editor, Algebraic Methods in Logic and Computer Science, volume 28
of Banach Center Publications, pages 239–252. Polish Academy of Sciences, 1993.
[248] P.J. Johnstone. Stone Spaces, volume 3 of Cambridge Studies in Advanced Mathe-
matics. Cambridge University Press, Cambridge, 1982.
[249] D. de Jongh and A. Troelstra. On the connection between partially ordered sets and
some pseudo-boolean algebras. Indigationes Mathematicae, 28:317–329, 1966.
[250] D. de Jongh and F. Veltman. Intensional logic, 1986. Course notes.
[251] B. Jónsson. Varieties of relation algebras. Algebra Universalis, 15:273–298, 1982.
[252] B. Jónsson. The theory of binary relations. In Andréka et al. [8], pages 241–292.
[253] B. Jónsson. A survey of boolean algebras with operators. In Algebras and Orders,
pages 239–286. Kluwer Academic Publishers, 1993.
[254] B. Jónsson. On the canonicity of Sahlqvist identities. Studia Logica, 4:473–491,
1994.Bibliography
535
[255] B. Jónsson and A. Tarski. Boolean algebras with operators, Part I. American Journal
of Mathematics, 73:891–939, 1952.
[256] B. Jónsson and A. Tarski. Boolean algebras with operators, Part II. American
Journal of Mathematics, 74:127–162, 1952.
[257] G. Kalinowski. La Logique D éductive. Presses Universitaires de France, 1996.
[258] H. Kamp. Tense Logic and the Theory of Linear Order. PhD thesis, University of
California, Los Angeles, 1968.
[259] H. Kamp. Formal properties of ‘Now’. Theoria, 37:227–273, 1971.
[260] M. Kaneko and T. Nagashima. Game logic and its applications. Studia Logica,
57:325–354, 1998.
[261] S. Kanger. The morning star paradox. Theoria, pages 1–11, 1957.
[262] S. Kanger. Provability in Logic. Almqvist & Wiksell, 1957.
[263] S. Kanger, editor. Proceedings of the Third Scandinavian Logic Symposium. Upp-
sala 1973. North-Holland Publishing Company, 1975.
[264] D. Kaplan. Dthat. In P. Cole, editor, Syntax and Semantics Volume 9, pages 221–
253. Academic Press, 1978.
[265] D. Kaplan. On the logic of demonstratives. Journal of Philosophical Logic, 8:81–
98, 1978.
[266] R. Kasper and W. Rounds. The logic of uniﬁcation in grammar. Linguistics and
Philosophy, 13:33–58, 1990.
[267] H.J. Keisler. Model Theory for Inﬁnitary Logic. North-Holland Publishing Com-
pany, 1971.
[268] H. Kirchner and C. Ringeissen, editors. Frontiers of Combining Systems 3. Springer,
2000.
[269] B. Konikowska. A formal language for reasoning about indiscernibility. Bulletin of
the Polish Academy of Sciences, 35:239–249, 1987.
[270] B. Konikowska. A logic for reasoning about relative similarity. Studia Logica,
58:185–226, 1997.
[271] R. Koymans. Specifying Message Passing and Time-Critical Systems with Temporal
Logic, volume 651 of LNCS. Springer, 1992.
[272] D. Kozen. A completeness theorem for Kleene algebras and the algebra of reg-
ular events. In Proceedings 6th IEEE Symposium on Logic in Computer Science
LICS’91, pages 214–225, 1991.
[273] D. Kozen and R. Parikh. An elementary proof of the completeness of PDL. Theo-
retical Computer Science, 14:113–118, 1981.
[274] D. Kozen and J. Tiuryn. Logics of programs. In van Leeuwen [293], pages 789–840.
[275] M. Kracht. Even more about the lattice of tense logics. Archive of Mathematical
Logic, 31:243–357, 1992.
[276] M. Kracht. How completeness and correspondence theory got married. In de Rijke
[379], pages 175–214.
[277] M. Kracht. Splittings and the ﬁnite model property. Journal of Symbolic Logic,
58:139–157, 1993.
[278] M. Kracht. Lattices of modal logics and their groups of automorphisms. Journal of
Pure and Applied Logic, 100:99–139, 1999.
[279] M. Kracht. Tools and Techniques in Modal Logic. Number 142 in Studies in Logic.
Elsevier, Amsterdam, 1999.
[280] M. Kracht. Logic and syntax — a personal perspective. In Zakharyaschev et al.536
Bibliography
[469], pages 355–384.
[281] M. Kracht, M. de Rijke, H. Wansing, and M. Zakharyaschev, editors. Advances in
Modal Logic, Volume 1, volume 87 of Lecture Notes. CSLI Publications, 1998.
[282] M. Kracht and F. Wolter. Simulation and transfer results in modal logic: A survey.
Studia Logica, 59:149–177, 1997.
[283] S. Kripke. A completeness theorem in modal logic. Journal of Symbolic Logic,
24:1–14, 1959.
[284] S. Kripke. Semantic analysis of modal logic I, normal propositional calculi.
Zeitschrift für mathemathische Logik und Grundlagen der Mathematik, 9:67–96,
1963.
[285] S. Kripke. Semantical considerations on modal logic. Acta Philosophica Fennica,
16:83–94, 1963.
[286] S. Kuhn. Quantiﬁers as diamonds. Studia Logica, 39:173–195, 1980.
[287] N. Kurtonina. Frames and Labels. PhD thesis, OTS, Utrecht University, 1996.
[288] N. Kurtonina and M. de Rijke. Bisimulations for temporal logic. Journal of Logic,
Language and Information, 6:403–425, 1997.
[289] N. Kurtonina and M. de Rijke. Expressiveness of concept expressions in ﬁrst-order
description logics. Artiﬁcial Intelligence, 107:303–333, 1999.
[290] A. Kurz. A co-variety-theorem for modal logic. In Zakharyaschev et al. [469].
[291] A.H. Lachlan. A note on Thomason’s reﬁned structures for tense logics. Theoria,
40:117–120, 1970.
[292] R. Ladner. The computational complexity of provability in systems of modal logic.
SIAM Journal on Computing, 6:467–480, 1977.
[293] J. van Leeuwen, editor. Handbook of Theoretical Computer Science, volume B:
Formal Models and Semantics. Elsevier, 1990.
[294] A. Leitsch, C. Fermüller, and T. Tammet. Resolution decision procedures. In Robin-
son and Voronkov [388].
[295] E.J. Lemmon. Algebraic semantics for modal logics, Parts I & II. Journal of Sym-
bolic Logic, pages 46–65 & 191–218, 1966.
[296] E.J. Lemmon and D.S. Scott. The ‘Lemmon Notes’: An Introduction to Modal Logic.
Blackwell, 1977.
[297] O. Lemon and I. Pratt. On the incompleteness of modal logics of space: advancing
complete modal logics of space. In Kracht et al. [281].
[298] W. Lenzen. Glauben, Wissen und Wahrscheinlichkeit. Systeme der Epistemischen
Logik. Springer, 1980.
[299] C.I. Lewis. A Survey of Symbolic Logic. University of California Press, 1918.
[300] C.I. Lewis and C.H. Langford. Symbolic Logic. Dover, 1932.
[301] H.R. Lewis and C.H. Papadimitriou. Elements of the Theory of Computation.
Prentice-Hall, 1981.
[302] P. Lindström. On extensions of elementary logic. Theoria, 35:1–11, 1969.
[303] C. Lutz and U. Sattler. The complexity of reasoning with boolean modal logics. In
Workshop Proceedings AiML-2000, pages 175–184. Institut für Informatik, Univer-
sität Leipzig, 2000.
[304] R.C. Lyndon. The representation of relation algebras. Annals of Mathematics,
51:707–729, 1950.
[305] H. MacColl. Symbolic Logic and its Applications. Longmans, Green, and Co.,
London, 1906.Bibliography
537
[306] R. Maddux. Introductory course on relation algebras, ﬁnite-dimensional cylindric
algebras, and their interconnections. In Andréka et al. [8], pages 361–392.
[307] D.C. Makinson. On some completeness theorems in modal logic. Zeitschrift f ür
mathemathische Logik und Grundlagen der Mathematik, 12:379–84, 1966.
[308] D.C. Makinson. A generalization of the concept of relational model. Theoria, pages
331–335, 1970.
[309] D.C. Makinson. Some embedding theorems for modal logic. Notre Dame Journal
of Formal Logic, pages 252–254, 1971.
[310] L. Maksimova. Interpolation theorems in modal logic and amalgable varieties of
topological boolean algebras. Algebra and Logic, 18:348–370, 1979.
[311] L.L. Maksimova. Pretabular extensions of Lewis S4. Algebra and Logic, 14:16–33,
1975.
[312] Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems.
Vol. 1 Speciﬁcation. Springer, 1992.
[313] Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems: Safety.
Springer, 1995.
[314] M. Manzano. Extensions of First Order Logic, volume 19 of Tracts in Theoretical
Computer Science. Cambridge University Press, 1996.
[315] R. Martin. Pour une Logique du Sens. Presses Universitaires de France Paris, 1983.
[316] M. Marx. Complexity of modal logics of relations. Technical Report ML–97–02,
Institute for Language, Logic and Computation, May 1997.
[317] M. Marx. Tolerance logic. Journal of Logic, Language and Information, 10:353–
373, 2001.
[318] M. Marx, L. Pólos, and M. Masuch, editors. Arrow Logic and Multi-Modal Logic.
Studies in Logic, Language and Information. CSLI Publications, 1996.
[319] M. Marx, S. Schlobach, and Sz. Mikulás. Labelled deduction for the guarded frag-
ment. In D. Basin et al., editor, Labelled Deduction, Applied Logic Series, pages
193–214. Kluwer Academic Publishers, 2000.
[320] M. Marx and Y. Venema. Multidimensional Modal Logic, volume 4 of Applied
Logic Series. Kluwer Academic Publishers, 1997.
[321] R. McKenzie, G. McNulty, and W. Taylor. Algebras, Lattices, Varieties, volume I.
Wadsworth & Brooks/Cole, 1987.
[322] J.C.C. McKinsey. A solution to the decision problems for the Lewis systems S2 and
S4 with an application to topology. Journal of Symbolic Logic, 6:117–134, 1941.
[323] J.C.C. McKinsey. On the syntactical construction of systems of modal logic. Jour-
nal of Symbolic Logic, 10:83–96, 1945.
[324] J.C.C. McKinsey and A. Tarski. The algebra of topology. Annals of Mathematics,
pages 141–191, 1944.
[325] J.C.C. McKinsey and A. Tarski. Some theorems about the sentential calculi of Lewis
and Heyting. Journal of Symbolic Logic, 13:1–15, 1948.
[326] K. McMillan. Symbolic Model Checking. Kluwer Academic Publishers, 1993.
[327] C. Meredith and A. Prior. Interpretations of different modal logics in the ‘property
calculus’, 1956. Mimeographed manuscript. Philosophy Department, Canterbury
University College.
[328] J.J.-Ch. Meyer and W. van der Hoek. Epistemic Logic for AI and Computer Science.
Cambridge University Press, 1995.
[329] Sz. Mikulás. Taming Logics. PhD thesis, Institute for Language, Logic and Com-538
Bibliography
putation, University of Amsterdam, 1995. ILLC Dissertation Series 95-12.
[330] G. Mints. A Short Introduction to Modal Logic, volume 30 of Lecture Notes. CSLI
Publications, 1992.
[331] J.L. Moens. Forcing et S émantique de Kripke-Joyal. Cabay, 1982.
[332] G. Moisil. Essais sur les Logiques non Chrysipiennes. Editions de l’Académie de
la République Socialiste de Roumanie, 1972.
[333] F. Moller and A. Rabinovich. On the expressive power of CTL ∗ . In Proceedings
14th IEEE Symposium on Logic in Computer Science LICS’99, 1999.
[334] J.D. Monk. On representable relation algebras. Michigan Mathematical Journal,
11:207–210, 1964.
[335] R. Montague. Logical necessity, physical necessity, ethics, and quantiﬁers. Inquiry,
4:259–269, 1960.
[336] R. Montague. Universal grammar. Theoria, 36:373–398, 1970.
[337] M. Mortimer. On languages with two variables. Zeitschrift f ür mathemathische
Logik und Grundlagen der Mathematik, 21:135–140, 1975.
[338] D.E. Muller, A. Saoudi, and P.E. Schupp. Weak alternating automata give a simple
explanation of why most temporal and dynamic logics are decidable in exponential
time. In Proceedings 3rd IEEE Symposium on Logic in Computer Science LICS’88,
pages 422–427, 1988.
[339] N. Murray, editor. Conference on Tableaux Calculi and Related Methods
(TABLEAUX), Saratoga Springs, USA, volume 1617 of LNAI. Springer, 1999.
[340] I. Németi. Free algebras and decidability in algebraic logic, 1986. Thesis for D.Sc.
(a post-habilitation degree) with Math. Inst. Hungar. Ac. Sci. Budapest. In Hungar-
ian, the English version is [342].
[341] I. Németi. Algebraizations of quantiﬁer logics: an overview. Studia Logica, 50:485–
569, 1991.
[342] I. Németi. Decidability of weakened versions of ﬁrst-order logic. In Csirmaz et al.
[102], pages 177–242.
[343] P. Odifreddi. Classical Recursion Theory. North-Holland Publishing Company,
1989.
[344] H.J. Ohlbach, D.M. Gabbay, and D. Plaisted. Killer transformations. In Wansing
[454].
[345] H.J. Ohlbach, A. Nonnengart, M. de Rijke, and D.M. Gabbay. Encoding non-
classical logics in classical logic. In Robinson and Voronkov [388].
[346] H.J. Ohlbach and R.A. Schmidt. Functional translation and second-order frame
properties of modal logics. Journal of Logic and Computation, 7:581–603, 1997.
[347] P. Øhrstrom and P Hasle. Temporal Logic. Kluwer Academic Publishers, 1995.
[348] H. Ono and A. Nakamura. On the size of refutation Kripke models for some linear
modal and tense logics. Studia Logica, 39:325–333, 1980.
[349] E. Orłowska, editor. Logic at Work: Essays Dedicated to the Memory of Elena
Rasiowa. Studies in Fuzziness and Soft Computing. Springer, 1999.
[350] M.J. Osborne and A. Rubinstein. A Course in Game Theory. The MIT Press, 1994.
[351] M. Otto. Bounded Variable Logics and Counting — A Study in Finite Models, vol-
ume 9 of Lecture Notes in Logic. Springer, 1997.
[352] C.H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.
[353] R. Parikh. The completeness of propositional dynamic logic. In Mathematical Foun-
dations of Computer Science 1978, volume 51 of LNCS, pages 403–415. Springer,Bibliography
539
1978.
[354] D. Park. Concurrency and automata on inﬁnite sequences. In Proceedings 5th GI
Conference, pages 167–183. Springer, 1981.
[355] W.T. Parry. The postulates for strict implication. Mind, 43:78–80, 1934.
[356] S. Passy and T. Tinchev. PDL with data constants. Information Processing Letters,
20:35–41, 1985.
[357] S. Passy and T. Tinchev. Quantiﬁers in combinatory PDL: completeness, deﬁnabil-
ity, incompleteness. In Fundamentals of Computation Theory FCT 85, volume 199
of LNCS, pages 512–519. Springer, 1985.
[358] S. Passy and T. Tinchev. An essay in combinatory dynamic logic. Information and
Computation, 93:263–332, 1991.
[359] A. Pnueli. The temporal logic of programs. In Proc. 18th Symp. Foundations of
Computer Science, pages 46–57, 1977.
[360] A. Ponse, M. de Rijke, and Y. Venema, editors. Modal Logic and Process Algebra:
A Bisimulation Perspective, volume 53 of Lecture Notes. CSLI Publications, 1995.
[361] S. Popkorn. First Steps in Modal Logic. Cambridge University Press, 1992.
[362] V.R. Pratt. Semantical considerations on Floyd-Hoare logic. In Proc. 17th IEEE
Symposium on Computer Science, pages 109–121, 1976.
[363] V.R. Pratt. Models of program logics. In Proc. 20th IEEE Symp. Foundations of
Computer Science, pages 115–222, 1979.
[364] A.N. Prior. Time and Modality. Oxford University Press, 1957.
[365] A.N. Prior. Past, Present and Future. Oxford University Press, 1967.
[366] A.N. Prior. Papers on Time and Tense. Oxford University Press, New edition, 2003.
Edited by Hasle, Øhrstrom, Braüner, and Copeland.
[367] A.N. Prior and K. Fine. Worlds, Times and Selves. University of Massachusetts
Press, 1977.
[368] M.O. Rabin. Decidability of second-order theories and automata on inﬁnite trees.
Transactions of the American Mathematical Society, 141:1–35, 1969.
[369] S. Rahman. Hugh MacColl: Eine bibliographische Erschließung seiner Hauptwerke
und Notizen zu ihrer Rezeptionsgeschichte. History and Philosophy of Logic,
18:165–183, 1997.
[370] H. Rasiowa and R. Sikorski. The Mathematics of Metamathematics. Polish Scien-
tiﬁc Publishers, 1963.
[371] H. Rasiowa and R. Sikorski. An Algebraic Approach to Non-Classical Logics. North
Holland, 1974.
[372] W. Rautenberg. Der Verband der normalen verzweigten Modallogiken. Mathema-
tische Zeitschrift, 156:123–140, 1977.
[373] W. Rautenberg. Klassische und nichtklassische Aussagenlogik. Vieweg & Sohn,
1979.
[374] W. Rautenberg. Splitting lattices of logics. Archiv f ür Mathematische Logik,
20:155–159, 1980.
[375] W. Rautenberg, editor. Non-Classical Logics. Ω-bibliography of Mathematical
Logic, Volume II. Springer, 1987.
[376] M. Reape. A feature value logic. In C. Rupp, M. Rosner, and R. Johnson, editors,
Constraints, Language and Computation, Synthese Language Library, pages 77–
110. Academic Press, 1994.
[377] M. Reynolds. A decidable logic of parallelism. Notre Dame Journal of Formal540
Bibliography
Logic, 38:419–436, 1997.
[378] M. de Rijke. The modal logic of inequality. Journal of Symbolic Logic, 57:566–584,
1992.
[379] M. de Rijke, editor. Diamonds and Defaults. Synthese Library vol. 229. Kluwer
Academic Publishers, 1993.
[380] M de. Rijke. Extending Modal Logic. PhD thesis, ILLC, University of Amsterdam,
1993.
[381] M. de Rijke. A Lindström theorem for modal logic. In Ponse et al. [360], pages
217–230.
[382] M. de Rijke. The logic of Peirce algebras. Journal of Logic, Language and Infor-
mation, 4:227–250, 1995.
[383] M. de Rijke, editor. Advances in Intensional Logic. Number 7 in Applied Logic
Series. Kluwer Academic Publishers, 1997.
[384] M. de Rijke. A system of dynamic modal logic. Journal of Philosophical Logic,
27:109–142, 1998.
[385] M. de Rijke. A modal characterization of Peirce algebras. In Orłowska [349], pages
109–123.
[386] M. de Rijke and H. Sturm. Global deﬁnability in basic modal logic. In H. Wansing,
editor, Essays on Non-Classical Logic. King’s College University Press, 2000.
[387] M. de Rijke and Y. Venema. Sahlqvist’s theorem for Boolean algebras with opera-
tors. Studia Logica, 95:61–78, 1995.
[388] A. Robinson and A. Voronkov, editors. Handbook of Automated Reasoning. Elsevier
Science Publishers, to appear.
[389] R.M. Robinson. Undecidability and nonperiodicity for tilings of the plane. Inven-
tiones Mathematicae, 12:177–209, 1971.
[390] P.H. Rodenburg. Intuitionistic Correspondence Theory. PhD thesis, University of
Amsterdam, 1986.
[391] H. Rogers. Theory of Recursive Functions and Effective Computability. McGraw
Hill, 1967.
[392] E. Rosen. Modal logic over ﬁnite structures. Journal of Logic, Language and
Information, 6:427–439, 1997.
[393] M. Rößiger. Coalgebras and modal logic. Electronic Notes in Computer Science,
33:299–320, 2000.
[394] W.C. Rounds. Feature logics. In van Benthem and ter Meulen [51].
[395] G. Rozenberg and A. Salomaa, editors. Handbook of Formal Languages, volume 3:
Beyond Words. Springer, 1997.
[396] H. Sahlqvist. Completeness and correspondence in the ﬁrst and second order se-
mantics for modal logic. In Kanger [263], pages 110–143.
[397] I. Sain. Is ‘some-other-time’ sometimes better than ‘sometime’ for proving partial
correctness of programs? Studia Logica, 47:279–301, 1988.
[398] G. Sambin and V. Vaccaro. Topology and duality in modal logic. Annals of Pure
and Applied Logic, 37:249–296, 1988.
[399] G. Sambin and V. Vaccaro. A topological proof of Sahlqvist’s theorem. Journal of
Symbolic Logic, 54:992–999, 1989.
[400] K. Schild. A correspondence theory for terminological logics. In Proc. 12th IJCAI,
pages 466–471, 1990.
[401] D. Scott. A decision method for validity of sentences in two variables. Journal ofBibliography
541
Symbolic Logic, 27:377, 1962.
[402] K. Segerberg. Decidability of S4.1. Theoria, 34:7–20, 1968.
[403] K. Segerberg. Modal logics with linear alternative relations. Theoria, 36:301–322,
1970.
[404] K. Segerberg. An Essay in Classical Modal Logic. Filosoﬁska Studier 13. University
of Uppsala, 1971.
[405] K. Segerberg. Two-dimensional modal logics. Journal of Philosophical Logic,
2:77–96, 1973.
[406] K. Segerberg. ‘Somewhere else’ and ‘Some other time’. In Wright and Wrong,
pages 61–64, 1976.
[407] K. Segerberg. A completeness theorem in the modal logic of programs. Notices of
the American Mathematical Society, 24:A–552, 1977.
[408] K. Segerberg. A note on the logic of elsewhere. Theoria, 46:183–187, 1980.
[409] K. Segerberg. A completeness theorem in the modal logic of programs. In
T. Traczyk, editor, Universal Algebra and Applications, volume 9 of Banach Centre
Publications, pages 31–46. PWN–Polish Scientiﬁc Publishers, 1982.
[410] K. Segerberg. Proposal for a theory of belief revision along the lines of Lindström
and Rabinowicz. Fundamenta Informaticae, 32:183–191, 1997.
[411] J. Seligman. A cut-free sequent calculus for elementary situated reasoning. Techni-
cal Report HCRC-RP 22, HCRC, Edinburgh, 1991.
[412] J. Seligman. The logic of correct description. In de Rijke [383], pages 107–135.
[413] V. Shehtman. Two-dimensional modal logics. Mathematical Notices of USSR
Academy of Sciences, 23:417–424, 1978.
[414] H. Simmons. The monotonous elimination of predicate variables. Journal of Logic
and Computation, 4, 1994.
[415] A.P. Sistla and E.M. Clarke. The complexity of linear temporal logic. Journal of
the ACM, 32:733–749, 1985.
[416] C. Smoryński. Self-Reference and Modal Logic. Springer, New York, 1985.
[417] R. Smullyan and M Fitting. Set Theory and the Continuum Problem. Clarendon
Press, 1996.
[418] R.M. Smullyan and M. Fitting. Set Theory and the Continuum Problem. Oxford
University Press, 1997.
[419] E. Spaan. Complexity of Modal Logics. PhD thesis, ILLC, University of Amsterdam,
1993.
[420] E. Spaan. The complexity of propositional tense logics. In de Rijke [379], pages
239–252.
[421] B. Stalnaker. Assertion. In P. Cole, editor, Syntax and Semantics Volume 9, pages
316–322. Academic Press, 1978.
[422] J. Stavi. Functional completeness over the rationals. Unpublished manuscript. Bar-
Ilan University, Ramat-Gan, Israel, 1979.
[423] V. Stebletsova. Algebras, Relations and Geometries. PhD thesis, Zeno (The Leiden-
Utrecht Research Institute of Philosophy), Utrecht, 2000.
[424] C. Stirling. Modal and temporal logics. In Abramsky et al. [1], pages 477–563.
[425] M.H. Stone. The theory of representations for boolean algebras. Transactions of the
American Mathematical Society, 40:37–111, 1936.
[426] H. Sturm. Modale Fragmente von L ωω und Lω1 ω . PhD thesis, CIS, University of
Munich, 1997.542
Bibliography
[427] A. Tarski. On the calculus of relations. Journal of Symbolic Logic, 6:73–89, 1941.
[428] A. Tarski and S. Givant. A Formalization of Set Theory without Variables, vol-
ume 41. AMS Colloquium Publications, Providence, Rhode Island, 1987.
[429] J.W. Thatcher and J.B. Wright. Generalized ﬁnite automata theory with an appli-
cation to a decision problem of second-order logic. Mathematical Systems Theory,
2:57–81, 1968.
[430] A. Thayse, editor. From Modal Logic to Deductive Databases. Wiley, 1989.
[431] W. Thomas. Automata on inﬁnite objects. In van Leeuwen [293], pages 135–191.
[432] W. Thomas. Languages, automata and logic. In Rozenberg and Salomaa [395],
pages 389–456.
[433] S.K. Thomason. Semantic analysis of tense logics. Journal of Symbolic Logic,
37:150–158, 1972.
[434] S.K. Thomason. An incompleteness theorem in modal logic. Theoria, 40:150–158,
1974.
[435] S.K. Thomason. Categories of frames for modal logics. Journal of Symbolic Logic,
40:439–442, 1975.
[436] S.K. Thomason. Reduction of second-order logic to modal logic. Zeitschrift f ür
mathemathische Logik und Grundlagen der Mathematik, 21:107–114, 1975.
[437] S.K. Thomason. Reduction of tense logic to modal logic II. Theoria, 41:154–169,
1975.
[438] D. Toman and D. Niwiński. First-order queries over temporal databases inexpress-
ible in temporal logic. Manuscript, 1997.
[439] M. Tzakova. Tableaux calculi for hybrid logics. In Murray [339], pages 278–292.
[440] A. Urquhart. Decidability and the ﬁnite model property. Journal of Philosophical
Logic, 10:367–370, 1981.
[441] M.Y. Vardi. Why is modal logic so robustly decidable? In DIMACS Series in
Discrete Mathematics and Theoretical Computer Science 31, pages 149–184. AMS,
1997.
[442] M.Y. Vardi and P. Wolper. Automata-theoretic techniques for modal logics of pro-
grams. Journal of Computer and System Sciences, 32:183–221, 1986.
[443] Y. Venema. Completeness via completeness: Since and Until. In de Rijke [379],
pages 279–286.
[444] Y. Venema. Derivation rules as anti-axioms in modal logic. Journal of Symbolic
Logic, 58:1003–1034, 1993.
[445] Y. Venema. Cylindric modal logic. Journal of Symbolic Logic, 60:591–623, 1995.
[446] Y. Venema. Atom structures and Sahlqvist equations. Algebra Universalis, 38:185–
199, 1997.
[447] Y. Venema. Modal deﬁnability, purely modal. In J. Gerbrandy, M. Marx,
M. de Rijke, and Y. Venema, editors, JFAK. Essays Dedicated to Johan van Benthem
on the Occasion of his 50th Birthday. Vossiuspers AUP, Amsterdam, 1999.
[448] Y. Venema. Points, lines and diamonds: a two-sorted modal logic for projective
geometry. Journal of Logic and Computation, 9:601–621, 1999.
[449] Y. Venema. Canonical pseudo-correspondence. In Zakharyaschev et al. [469], pages
439–448.
[450] A. Visser. Modal logic and bisimulation. Tutorial for the workshop ‘Three days of
bisimulation’, Amsterdam, 1994.
[451] A. Visser. An overview of interpretability logic. In Kracht et al. [281], pages 307–Bibliography
543
359.
[452] H. Vlach. ‘Now’ and ‘Then’. PhD thesis, University of California, Los Angeles,
1973.
[453] H. Wang. Proving theorems by pattern recognition II. Bell Systs. Tech. J, 40:1–41,
1961.
[454] H. Wansing, editor. Proof Theory of Modal Logic. Kluwer Academic Publishers,
1996.
[455] H. Wansing. Displaying Modal Logic. Kluwer Academic Publishers, 1998.
[456] P. Wolper. Temporal logic can be more expressive. Information and Control, 56:72–
93, 1983.
[457] F. Wolter. Tense logic without tense operators. Mathematical Logic Quarterly,
42:145–171, 1996.
[458] F. Wolter. Completeness and decidability of tense logics closely related to logics
containing K4. Journal of Symbolic Logic, 62:131–158, 1997.
[459] F. Wolter. The structure of lattices of subframe logics. Annals of Pure and Applied
Logic, 86:47–100, 1997.
[460] F. Wolter. The product of converse PDL and polymodal K. Journal of Logic and
Computation, 10:223–251, 2000.
[461] F. Wolter, H. Wansing, M. de Rijke, and M. Zakharyaschev, editors. Advances in
Modal Logic, Volume 3. World Scientiﬁc, 2002.
[462] F. Wolter and M. Zakharyaschev. Satisﬁability problem in description logics with
modal operators. In Principles of Knowledge Representation and Reasoning: Proc.
Sixth International Conference (KR’98), pages 512–523. Morgan Kaufmann, 1998.
[463] M. Wooldridge and N. Jennings. Intelligent agents: theory and practice. Knowledge
Engineering Review, 10:115–152, 1995.
[464] G.H. von Wright. An Essay in Modal Logic. North-Holland Publishing Company,
1951.
[465] G.H. von Wright. A modal logic of place. In E. Sosa, editor, The Philosophy of
Nicholas Rescher, pages 65–73. Publications of the Group in Logic and Methodol-
ogy of Science of Real Finland, vol. 3, 1979.
[466] M. Xu. On some U,S-tense logics. Journal of Philosophical Logic, 17:181–202,
1988.
[467] M. Zakharyaschev. Canonical formulas for modal and superintuitionistic logics: a
short outline. In de Rijke [383], pages 195–248.
[468] M. Zakharyaschev and A. Alekseev. All ﬁnitely axiomatizable normal extensions
of K4.3 are decidable. Mathematical Logic Quaterly, 41:15–23, 1995.
[469] M. Zakharyaschev, K. Segerberg, M. de Rijke, and H. Wansing, editors. Advances
in Modal Logic, Volume 2. CSLI Publications, 2000.
[470] M.V. Zakharyaschev. On intermediate logics. Soviet Mathematics Doklady, 27:274–
277, 1983.
[471] M.V. Zakharyaschev. Normal modal logics containing S4. Soviet Mathematics
Doklady, 28:252–255, 1984.
[472] M.V. Zakharyaschev. Syntax and semantics of modal logics containing S4. Algebra
and Logic, 27:408–428, 1988.
[473] M.V. Zakharyaschev. Canonical formulas for K4. Part I: basic results. Journal of
Symbolic Logic, 57:1377–1402, 1992.
[474] J. Zeman. Modal Logic: The Lewis Modal Systems. Oxford University Press, 1973.List of Notation
Modalities
3, 2, Deﬁnition 1.9
K, Example 1.10
, Deﬁnition 1.11
3a , a, Deﬁnition 1.11
, Deﬁnition 1.13
2a , [a], Deﬁnition 1.13
F , P , G, H, Example 1.14
π, [π], Example 1.15
◦, ⊗, 1’, Example 1.16
30 , 31 , 32 , . . . , Example 1.22
E, A, Example 2.4, page 415
[∗], page 371
D, D, page 419
[| · |], page 424
S, U , page 427
S  , U  , Deﬁnition 429
@i , page 436
↓, page 444
Id ij , Equation 7.11
σ , page 461
ιδij , Deﬁnition 7.41
ij , En
i , Dn , page 467
Other syntax
p, q, r, . . . , Deﬁnition 1.9
τ , Deﬁnition 1.11
ρ, Deﬁnition 1.11 and B.1
π1 ∪ π2 , π1 ; π2 , π ∗ , π1 ∩ π2 , Example 1.15
φ?, Example 1.15
(∀yx), (∃yx), page 170
∀r , ∃r , page 170
∼φ, Deﬁnition 4.79
Bool , Deﬁnition 5.1
Ter τ (Φ), Deﬁnition 5.18
i, j, k, page 435
Formulas and axioms
K, Dual, Deﬁnition 1.39
4, Example 3.6, page 207
T, 5, Example 3.6
M, Example 3.11
φF,w , page 143
REL, AT, POS, page 157
BOX-AT, page 162
B, D, .3, L, page 192
Ki , Dual , Deﬁnition 4.13
Dr , Dl , den, page 207
.3r , .3l , page 208
.rr , Dr , Ll , page 212
name(φ), page 230
φB (m), Table 6.5
fL (β), Table 6.6
(A1a)–(A7a), (A1b)–(A7b), Deﬁnition 7.13
D, L, W, N, Deﬁnition 7.13
G(x, y), page 446
(CM1 i )–(CM8 i ), Deﬁnition 7.48
Maps and operations on formulas
φσ , Deﬁnition 1.18
deg, Deﬁnition 2.28
ST x , Deﬁnition 2.45
cφ (x), Theorem 3.54
φ≈ , Deﬁnition 5.26
Free(φ), Deﬁnition 7.31
(·)t , Deﬁnition 7.42
(·)• , page 466
Languages
τ , Deﬁnition 1.11
τ→ , Example 1.16
ML(τ, Φ), Deﬁnition 1.12
PDL , Example 1.15
L1τ (Φ), Deﬁnition 2.44
L2τ (Φ), L2τ , page 126
SnS, Deﬁnition 6.17
KR , page 367
KRA , page 368
KRA [∗], page 371
ML(3), page 415
ML(E), ML(3, E), page 415
ML(D), ML(3, D), page 419
MLR n , Deﬁnition 7.41
L1 , page 486
LX , Deﬁnition A.9
Lω1 ω , page 496
Sets of formulas
Form(τ, Φ), Deﬁnition 1.12
544List of Notation
ΛF , Deﬁnition 1.28
FL(Σ), ¬FL(Σ), Deﬁnition 4.79
ClΓ , Cl(φ), Deﬁnition 6.23
Dem(H, 3ψ), Deﬁnition 6.43
PF , GF , PF n , GF n , Deﬁnition 7.31
Ln , rn , Deﬁnition 7.40
CMLn , Deﬁnition 7.41
Logics
ΛF , Deﬁnition 1.28
K, Deﬁnition 1.42
ΛS , ΛS , Example 4.2
PC, page 190
K4, T, B, KD, S4, S5, K4.3, S4.3, KL, Table 4.1
Kτ , Kτ Γ, Deﬁnition 4.14
Kt , Deﬁnition 4.33
Kt Q, Deﬁnition 4.40
ΛFt , Deﬁnition 4.32
KvB, Exercise 4.4.2
Kt Tho, Kt ThoM, page 212
Kt Q+ , Deﬁnition 4.66
PDL, Deﬁnition 4.78
Kn Alt1 , page 341
Kt N, page 360
Kg , page 417
Ktd Σ, page 420
ΛdF , Theorem 7.8
B, BW, BN, page 431
Kh + RULES, page 437 and 441
Kg , Deﬁnition 7.23
Maps
mR , Deﬁnition 1.30, 2.55
lR , Deﬁnition 2.55
d, page 494
Operations on maps
θ̃, Deﬁnition B.12, 5.23
θ + , η+ , Deﬁnition 5.50
Relations
C, R, I, Example 1.8
R1 , page 424
Ra , Rb , . . . Example 1.24(i)
R , Deﬁnition 1.23
Rπ , Deﬁnition 1.26
↔, Deﬁnition 2.16
↔n , Deﬁnition 2.30
RΛ , Deﬁnition 4.18
Λ
RΛ
P , RF , Deﬁnition 4.34
≡C , page 269
≡Λ , Deﬁnition 5.29
Qf , Deﬁnition 5.40
, page 323
∼U , page 492
ker f , Deﬁnition B.3
sub, Deﬁnition 4.92
R−α , page 424
≡i , Equation 7.10
1σ , Equation 7.13
Relations between structures
w  w  , M  M , Deﬁnition 2.1
545
M  M, Deﬁnition 2.5
M∼
= M , Deﬁnition 2.8, A.5
M  M , Deﬁnition 2.10
Z : M, w ↔ M , w  and Z : M ↔ M ,
Deﬁnition 2.16
M, w ↔ M , w  and w ↔ w  , Deﬁnition 2.16
M ↔ M , Deﬁnition 2.16
w Σ w  , Deﬁnition 2.36
F  F, F  F , Deﬁnition 3.13
f : A  B and A  B, Deﬁnition A.8
A ≡ B, page 487
Operations on relations
R+ , R∗ , Example 1.6
Rˇ, Example 1.25
R0 , R1 , R2 , . . . , Example 1.22(iii)
Rf , Deﬁnition 2.36
Rs , Rl , page 79
Rt , Deﬁnition 2.42
Rue , Deﬁnition 2.57
P ?, Example 2.80(ii)
∼R, Example 2.80(iii)
Rβ , R , Convention 3.46
Truth, validity and consequence
M, w  φ, Deﬁnition 1.20
M, w  Σ, Deﬁnition 1.20
w  φ, page 18
M  φ, Deﬁnition 1.21
F, w  φ, Deﬁnition 1.28
F  φ, Deﬁnition 1.28
F  φ, Deﬁnition 1.28
Σ S φ, Deﬁnition 1.35
Σ gS φ, Deﬁnition 1.37
(F, V ), s  ρ, Convention 5.88
tA [g], page 486
tA [a1 , . . . , an ], page 486
A |= α[a1 , . . . , an ], page 486
A |= α[a1 , . . . , an , x → a], page 487
Π |= γ, page 487
A |= s ≈ t, A |= E, Deﬁnition B.17
Structures
(N, <), (Z, <), (Q, <), (R, <), (ω, <),
Example 1.2
SU , Example 1.8
MΛ , FΛ , Deﬁnition 4.18 and 4.34
2, Deﬁnition 5.2
Form(Φ), Deﬁnition 5.3
P(A), Deﬁnition 5.7
LC (Φ), Deﬁnition 5.13
LΛ (Φ), Deﬁnition 5.31
fcΛ , Example 5.61
Nn , Deﬁnition 6.17
Cn (U ), CW
n (U ), Deﬁnition 7.45
AX , Deﬁnition A.9
TerF (X), Deﬁnition B.13
Form(τ, Φ), Deﬁnition 5.28
Operations on structures
i Mi , Deﬁnition 2.2
M k, Deﬁnition 2.32
MfΣ , Mf , Deﬁnition 2.36546
ueM, ueF, Deﬁnition 2.57
i Fi , Deﬁnition 3.13
FX , Fw , Deﬁnition 3.13
 = (W
 , R,
 V
 ), Deﬁnition 4.51
M
F+ , Deﬁnition 5.21
A+ , Deﬁnition 5.40
EmA+ , Deﬁnition 5.40
Uf
 284
 A, page
A , U A, Deﬁnition A.18
U i
J
j∈J Aj , A , Deﬁnition B.6
A/∼, Deﬁnition B.9
Classes of structures
Frφ , FrΓ , Deﬁnition 3.1
Set, Deﬁnition 5.7
BA, Deﬁnition 5.10
Fn
1 , page 341
Cn , Rn , Deﬁnition 7.45
HCFn , page 468
Operations on classes
K, page 107
Cm, Deﬁnition 5.21
V, Deﬁnition 5.55
H, Deﬁnition B.3
I, Deﬁnition B.4
S, Deﬁnition B.5
P, Deﬁnition B.6
V, Deﬁnition B.7
Special sets
Φ, Deﬁnition 1.9
Vm , Example 3.7
At(Σ), Deﬁnition 4.80
W Λ , Deﬁnition 4.18
Tn , Deﬁnition 6.17
Ter F (X), Deﬁnition B.11
Operations on sets
P(W ), Deﬁnition 1.19
W \ X, Deﬁnition 1.32
Uf (W ), Deﬁnition 2.57
P ?, Example 2.80(ii)
 page 242
A,
R[c],
Proposition 5.83

A , page 492
 i∈I i
A
U i,
U A, Deﬁnition A.17
Hin(Σ), Deﬁnition 6.53
Miscellaneous
K φ, Deﬁnition 1.39
|w|Σ , |w|, Deﬁnition 2.36
Λ φ, Deﬁnition 4.1
[φ], Deﬁnition 5.13
f , Deﬁnition 5.19
 Example 5.61
φ,
 α, page 488
Π  γ, page 488
πw , Deﬁnition A.15
fU , Deﬁnition A.17
fa , fw , page 494
[a], Deﬁnition B.9
List of Notation
≈, Deﬁnition B.11
Π10 , Σ11 , page 508
Σ ∗ , Deﬁnition C.4
O, page 515Index
abstract modal logic, 473
additivity, 275
admissible
set, 29
valuation, 29
algebra, 497
as logic, 262
of truth values, 265
algebraic interpretation of modal logic, 278
algebraic perspective, 39, 45
algebraizing
modal axiomatics, 279
modal semantics, 277
propositional axiomatics, 268
propositional semantics, 263
algorithm
witness, 386
antisymmetry, 3, 217
arrow
frame
square, 8
logic, 7, 16, 26, 30, 60
and the three variable fragment, 91
bisimilarity and squares, 72
bounded morphism, 62
ﬁnite model property, 83
frame for, 8
generated submodel, 57
language of, 14
model for, 23
relativized square, 229
square arrow frame, 8
standard translation, 90
ultraﬁlter extension, 99
structure, 7
atom, 241, 358
axiom, 33, 192
induction, 132
Segerberg’s, 132
axiomatic system, see Hilbert system, normal modal
logic
axiomatizable, 342
axiomatization, 195
back condition, 65
basic
hybrid language, 435
modal language, 9
decidability, 340
frame for, 16
model for, 16
temporal language
bisimulation, 70, 72
bounded morphism, 62
completeness-via-canonicity, 204–209
deﬁnability of bidirectionality, 26, 137
deﬁnition of, 11
dense frame, 129
expressiveness, 63
frame for, 21
generated submodel, 57
model for, 21
over (Q, <), 224–237
standard translation, 89
strong completeness of Kt Q+ , 239
transitive temporal ﬁltration, 83
ultraﬁlter extension, 99
undeﬁnability of progressive, 72
basic hybrid language, 435
basic temporal language, 137
bidirectional model and frame, 21
binary tree, 382–384
Birkhoff’s Theorem, 502
bisimilar, 65
bisimilarity-somewhere-else, 98, 102
bisimulation, 64–73
locality and computation, 67
n-, 74
safe for, 112
boolean
algebra, 269
and classical theoremhood, 269
algebra with operators ( BAO ), 275
homomorphism, 296
modal logic, 424–425
bounded
morphic image, 59
morphism
duals of, 313
547Index
548
for frames, 138
for general frames, 309
for models, 57–73
box
2, 9
2a , 11
[a], 11
boxed atom, 161
BR, 425
Bull’s Theorem, 43, 247–252
bulldozing, 220–222
canonical
class of algebras, 292
embedding algebra, 288
equation, 292
formula, 203
logic, 203
model, 42
arbitrary similarity type, 200
basic modal language, 197
basic temporal language, 205
over a ﬁnite set of formulas, 243
relation, 198
valuation, 198
Canonical Model Theorem, 199
canonicity
and d-persistence, 319
and ﬁrst-order deﬁnability, 215
failure of, 211
for a property, 204
Cantor’s Theorem, 225, 229
carrier
of an algebra, 497
Chagrova’s Theorem, 167
characterization
of frame classes, 125
Church’s Thesis, 507
Church-Rosser property, 160
classical era, (1959–1972), 41
closed
formula, 151
subset of general frame, 315
closure
Fischer-Ladner, 241
transitive, 5
under single negations, 241
under subformulas, 77, 241
universal, 445
cluster, 81
and completeness proofs, 220
co-ﬁnite set, 30
coﬁnality, 213
compact
logic, 212
compactness
over models, 86
Compactness Theorem, 488
complete logic, 212
completely additive formula, 113
completeness
strong, 194
of Kt Q, 228
of Kt Q+ , 236
of Kt , 206
of Kt 4.3, 220, 221
of Kt Q, 209
of K4.3, 210
of K4, 202
of KB, 202
of KD, 202
of K, 199, 219
of S4.3, 210
of S4, 203, 219
of S5, 203
of T, 202
via completeness, 432
weak, 194
via Stone’s Theorem, 273
completeness-via-canonicity, 202
complex algebra, 277
composition relation, 7
computable, 505
conﬂuence, see Church-Rosser property
congruence, 499
natural map associated with, 500
connected, 3, 247
coNP, 512
consistency, 191, 194
problem, 334
converse
axioms
canonicity of, 206
of a relation, 22
Cook-Levine Theorem, 512
coPSPACE, 514
correspondence
for models, 85
global, for frames, 126
language, 84
local, for frames, 149
theory, 86
corresponding algebraic similarity type, 275
Craig’s Lemma, 342
cube
over U , 465
relativized, 465
current state, 18
cylindric modal logic, 462
d-persistence, 318
daughter-of, 6
dead-end, 19
decidability, 338, 505
via ﬁnite models, 338–346
via interpretations, 347–356
via quasi-models and mosaics, 356–364
decidable, 338, 505
Dedekind complete, 429
deducibility, 190
deﬁnability
of a property, 125
of frame classes, 125
of model classes, 88
of models, 107–109
deﬁnable variant, 146Index
deﬁnably well-ordered, 431
degree, 74
density, 207
canonicity of, 207
deﬁnability of, 129
descriptive
frames and BAO s, 311
general frame, 306
Detour Lemma, 102
di-persistence, 318
diamond
3, 9
3a , 11
a, 11
saturated, 231
difference operator, 63, 238, 419–424
discriminator variety, 419
disjoint union
of frames, 138
of general frames, 310
of models, 52–55
distinguishing model, 146
distribution axiom, see K axiom
domain, 2
downward monotone, 152
Dual axiom, 33, 191, 195
dual operator, 9
duality theory
applications, 299–303
basic ideas, 294–299
DUWTO -frame, 207
elementarily equivalent, 487
elementary
class of models, 494
extension, 490
submodel, 490
elimination of Hintikka sets, 402–405
embedding, 58
endomorphism, 501
epistemic logic, 10, 19
equation, 500
equational
class, 502
logic, 502
equivalence
elementary, 487
expressive, 90
ﬁrst-order, 487
modal, 52
euclidean, 128
Existence Lemma
basic modal language, 198
for arbitrary programs in PDL, 245
for basic programs in PDL, 243
exponentially deep models, 393–395
expressive
power, 43, 45, 73, 97
expressive completeness, 430
EXPTIME, 514
and modal logic, 393–406
global modality, 422
guarded fragment, 453
hardness via tiling, 395–402
extension
elementary, 490
ultraﬁlter, 138
extensions of S4.3
Bull’s Theorem, 247–252
ﬁnite axiomatizability, 252–255
Hemaspaandra’s Theorem, 380
negative characterization, 255–256
f.f.p., 335
f.m.p., 73, 336
false in a model, 18
falsiﬁable, 18
ﬁlter
of a boolean algebra, 284
over a set, 491
ﬁltration, 77–82
largest, 79
natural map, 78
smallest, 79
transitive, 80
transitive temporal, 83
Filtration Theorem, 79
ﬁnite
character, 335
frame property, 145–148
general case, 335
intersection property, 492
meet property, 285
model property
for normal modal logics, 145
for similarity types, 73
general case, 336
strong, 339
models
via ﬁltrations, 77–82
via selections, 74–77
transitive frame, 143–144
-variable fragment, 87
ﬁnitely
axiomatizable, 252, 342
based, 335
ﬁrst-order logic
assignment, 486
basic properties, 487–489
compactness, 488
completeness, 488
formula, 485
Löwenheim-Skolem Theorem, 488
modal fragment, 100
model, 486
model theory, 489–495
satisfaction deﬁnition, 486
sentence, 486
term, 485
ultraproducts, 492
validity and semantic consequence, 487
Fischer-Ladner closure, 241
ﬂat set of lists, 255
formula
algebra
modal logic, 280
549550
propositional logic, 265
as term, 264
completely additive, 113
ﬁrst-order, 485
Grzegorczyk, 256
Jankov-Fine, 143
Kracht, 170
Löb, 10, 130
McKinsey, 12, 30, 133
modal, 9, 11
monotone, 152
Sahlqvist
general case, 164
very simple, 156
Sahqlvist
simple, 160
uniform, 151
universal second-order, 495
forth condition, 64
fragment
guarded, 446
packed, 446
universal, 458
frame
arbitrary similarity type, 20
arrow logic, 8
basic modal language, 16
basic temporal language, 21
connected, 247
deﬁnability, 125
relative, 125
DUWTO , 207
general, see general frame
incompleteness, see incompleteness
language
ﬁrst-order, 126
second-order, 126
of type τ , 20
propositional dynamic logic, 22
square, 229
underlying a model, 17
general frame, 28–31
algebraic perspective, 303–318
and second-order logic, 136
compact, 306
descriptive, 306
differentiated, 306
discrete, 306
full, 306
general completeness result, 306
reﬁned, 306
tight, 306
topological aspects, 314–317
general ultraﬁlter frame, 310
generalization, 33, 191
generated
point-, 56
subframe, 138
submodel, 55–57
global
modality, 54, 367–371, 415–419
truth, 18
Index
Goldblatt-Thomason Theorem, 142, 178–181
algebraic proof, 300–301
Grzegorczyk formula, 137, 256
guarantee properties, 427
guarded
fragment, 446–458
quantiﬁcation, 448
height, 75
Hemaspaandra’s Theorem, 380
Hennessy-Milner
class, 92
property, 92
Theorem, 69
highly undecidable, 508
Hilbert systems and normal modal logic, 33–37
Hintikka set, 357
homomorphism, 57
modal, 296
of algebras, 498
hybrid logic, 434–444
hypercylindric frame, 468
identity arrow, 7
image-ﬁnite, 69
incompleteness, 44, 212
ﬁrst-order example, 216
of Kt ThoM, 214
of KvB, 216
ramiﬁcations of, 214–216
inconsistent
formula, 191
logic, 190
induction axiom, see Segerberg’s axiom
inﬁnitary logic, 496
instant, 2
internal, 18
interpretation
in SnS, 347–355
invariance, 52
irreﬂexivity, 2, 217, 229
isomorphism
of algebras, 498
of ﬁrst-order models, 489
of modal models, 58
Jónsson-Tarski Theorem, 40
and canonicity, 291–293
statement and proof, 289–291
Jankov-Fine formula, 143
K axiom, 33, 191, 195
Kracht formula, 170
Kracht’s Theorem, 171, 210
Kripke semantics, 42
Kruskal’s Theorem, 253
Löb formula, 10, 130
Löwenheim-Skolem Theorem, 488
for modal models, 86
labeled transition system, 3
lambda notation, 155
languageIndex
basic modal, 9
modal, 11
left-unboundedness, 207
Lindenbaum’s Lemma, 197
Lindenbaum-Tarski algebra
modal logic, 281
propositional logic, 271
Lindström Theorem for modal logic, 470–476
linear order, 2
local, 18
frame correspondence, 149
logic
compact, 212
complete, 212
epistemic, 10, 19
equational, 502
inﬁnitary, 496
modal, 189
normal modal, 191, 195
normal temporal, 205
of a class of frames, 24
provability, 10
second-order, 495
since/until, 426, 434
loose
model, 454–458
loosely guarded fragment, 458
Łoś’s Theorem, 493
m-saturation, 91–93
master modality, 371–373
maximal consistent set, 196
McKinsey formula, 12, 30, 133
MCS , see maximal consistent set
modal
consequence relation, 31–32
constant, see nullary modality
homomorphism, 296
language of relations, 462
logic, 189
boolean, 424–425
multi-dimensional, 458
operator
arity, 11
modal logic
abstract, 473
modality
global, 406
master, 371–373
nullary, 11, 195, 201
substitution, 461
universal, 478
modally equivalent, 52
model
arrow logic, 23
based on a frame, 17
basic modal language, 16
basic temporal language, 21
canonical, 197
ﬁnitely based, 335
ﬁrst-order logic, 486
loose, 454–458
named, 238
551
on a general frame, 29
pointed, 107
propositional dynamic logic, 22
saturated, 100
modern era, (1972–present), 44
modus ponens, 33, 189
monadic
second-order logic, 495
second-order theory of n successor functions, 348
monotone
downward, 152
formula, 152
upward, 152
monotonicity
in boolean algebras, 276
of formulas, 152
morphism, see bounded morphism
mosaics
for packed and guarded fragments, 450–453
for tense logic of naturals, 360–363
multi-dimensional modal logic, 458–470
n-bisimulation, 74
nabla, , 11
named model, 238
natural valuation
on canonical model, 198
necessarily, 10, 19, 127
necessitation, see generalization
negation
single, 241, 356
negative occurrence, 151
network, 224, 232, 454
NEXPTIME, 515
node, 2
nominal, 238, 435
non-branching, 209
to the right, 193
normal modal logic, 33–37
alternative deﬁnition, 191
and ﬁnite frames, 145
arbitrary similarity type, 195
basic modal language, 191
basic temporal language, 205
generated by a set of formulas, 192
incomplete, 212
minimal, 192
propositional dynamic logic, 240
normality
algebraic deﬁnition, 275
NP, 511
and modal logic, 373–381
NPSPACE, 514
nullary modality, 11, 195, 201
operation, 497
operator
algebraic deﬁnition, 275
difference, 238
dual, 9
since, 43
until, 43, 72
oracle, 508552
P, 511
packed
fragment, 446–458
universal, 458
quantiﬁcation, 448
partial order, 3, 217
PDL, see propositional dynamic logic
permissible, 16
persistence, 318
point, 2
point-generated
frame, 139
model, 56
pointed model, 107, 471
polynomial
space, 513
time, 509
reduction, 510
polysize model property, 339
positive
existential formula, 111
occurrence, 151
possible world, 19
possibly, 10, 19, 127
preservation, 51
problem, 505
as strings of symbols, 506
completeness of, 511
consistency, 334
decidable, 505
EXPTIME, 514
hardness of, 511
non-elementary, 373
NP, 511
P, 511
provability, 334
PSPACE, 513
satisﬁability, 333
tiling, 366
undecidable, 507
validity, 333
product
of algebras, 498
progressive operator, 72
proof
in K, 33, 35
propositional dynamic logic, 16, 26
and inﬁnitary logic, 89
as three variable fragment, 89
axiomatization, 240
bisimulation, 71
bounded morphism, 62
compactness failure, 240
decidability of, 343
deﬁnability of regular frames, 132
EXPTIME algorithm for, 403
EXPTIME hardness of, 397
frame for, 22
generated submodel, 57
language, 12
model for, 22
regular, 13
standard translation, 89–90
Index
test, 13
with intersection, 13, 367–373
provability
logic, 10
problem, 334
provable
in K, 33
provable equivalence as a congruence
modal logic, 281
propositional logic, 270
PSPACE, 513
algorithm for K, 384–389
and modal logic, 381–393
hybrid logic, 436
Ladner’s Theorem, 389–392
QBF, 389, 513
truth problem, 513
validity problem, 389
quantiﬁcation
guarded, 448
packed, 448
quantiﬁed boolean formula, 389
quantiﬁers as modalities, 459–460
quotient algebra, 500
r-persistence, 318
Rabin’s Theorem, 350
recursive, 505
recursively
axiomatizable, 342
enumerable, 506
reduction, 508
reﬂexive
and transitive tree, 7
closure, 3, 8
linear order, 3
total order, 3
transitive closure, 5
reﬂexivity, 3, 127
refutable, see falsiﬁable
refuted in a model, see false in a model
regular frames and models, 22
relational
semantics, 41
structure, 2
relativized
cube over U , 465
square, 229
reverse relation, 8
right-unboundedness, 193, 207
root
of tree, 6
rooted, see point-generated
rules
as sequents, 443
for the undeﬁnable
IRR , 229–238
S4.3
decidability of extensions, 345
NP-completeness of extensions, 380
safety, 112Index
Sahlqvist
Completeness Theorem, 210
Correspondence Theorem, 165
formula
general case, 164
simple, 160
very simple, 156
Sahlqvist Completeness Theorem
statement and proof, 322–325
Sahlqvist-van Benthem algorithm, 156–166
satisfaction operator, 238
satisﬁability
problem, 333
satisﬁable, 18
ﬁnitely, 92
satisﬁed in a model
arbitrary similarity type, 20
basic modal language, 17
nullary modality, 20
saturated model, 100, 101
saturation
diamond, 231
m-, 91–93
Savitch’s Theorem, 514
second-order
logic, 495
translation, 135
Segerberg’s axiom, 13, 132
semantic consequence
global, 32
local, 31
set algebra, 267
similarity type
algebraic, 497
modal, 11
simulation, 110
since operator, 43
since/until logic, 426–434
situation, 2
SnS, 348
soundness, 193
square
frame, 229
over U , 8
relativized, 229
standard translation, 83–91
and second-order frame language, 135
until, 429
state, 2
Stavi connectives, 429
step-by-step method, 223–228
Stone Representation Theorem
full statement and proof, 286
short statement, 273
strict
partial order, 2
total order, 220
strong
completeness, 194
of Kt Q, 228
of Kt Q+ , 236
of Kt , 206
of Kt 4.3, 220, 221
553
of Kt Q, 209
of K4.3, 210
of K4, 202
of KB, 202
of KD, 202
of K, 199, 219
of S4.3, 210
of S4, 203, 219
of S5, 203
of T, 202
ﬁnite model property, 339
homomorphism, 58
subalgebra, 498
subformula closed, 77
submodel, 56
elementary, 490
substitution, 15
modality, 461
successor, 18
syntactic era, (1918–1959), 38
syntactically driven, 43
temporal, see basic temporal
tense logic, 40, 205
term, 485, 500
algebra, 501
as formula, 435
theorem, 189
tile, 365
tiling
game, 395
problem
N × N, 366
N × N recurrent, 366
times, 2
total order, 2
tractable, 509
transitive
closure, 5
tree, 7, 9
transitivity, 2
translation
second-order, 135
standard, see standard translation
tree, 6, 347, 348
-like, 6
binary, 382–384
model, 62
model property, 62
reﬂexive and transitive, 7
transitive, 7, 9
triangle, , 11
trichotomy, 2, 207
true in a model, see satisﬁed in a model
truth and validity in algebras, 502
Truth Lemma, 199
Turing machine, 504
exponentially time bounded, 514
non-deterministic, 507
non-deterministic polynomially time bounded, 511
polynomially space bounded, 513
polynomially time bounded, 509
with oracles, 508554
ultraﬁlter
countably incomplete, 106
extension
of a frame, 138
of a model, 93–100
temporal language, 99
frame, 287
general, 310
of a boolean algebra, 284
over a set, 491
principal, 492
Ultraﬁlter Theorem, 285, 492
ultrapower, 493
ultraproduct, 492–493
of modal models, 104–107
unbounded, 207
undecidability
via tiling, 364–373
undecidable, 338, 507
unfolding, see unraveling
uniform
formula, 151–155
substitution, 33, 189
universal
modality, 478
second-order formula, 495
universally true, see global truth
universe, 2
unraveling, 63
in completeness proofs, 218–220
until operator, 43, 72, 427
unwinding, see unraveling
upward monotone, 152
Index
valid, 24
at a state in a frame, 24
in a frame, 24
in a general frame, 29
on a class of frames, 24
validity
deﬁnition of, 24, 124
problem, 333
valuation, 17
van Benthem Characterization Theorem, 100–104
variant
deﬁnable, 146
variety, 499
weak
completeness, 194
of propositional dynamic logic, 239–246
of KL, 212
via Stone’s Theorem, 273
linearity, 207
total order, 207
well-founded, 8
well-order
deﬁnably, 431
well-ordered, 429
window, 424
witness
algorithm, 386
set, 385
world, 2
